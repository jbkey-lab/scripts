{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import os\n",
    "import random\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = \"/home/jacoblamkey/Documents/Data/.kaggle\"\n",
    "BATCH_SIZE=128\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "BATCH_SIZE = BATCH_SIZE*strategy.num_replicas_in_sync\n",
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add infos\n"
     ]
    }
   ],
   "source": [
    "tr = pd.read_csv(f\"{ROOT}/train.csv\")\n",
    "tr.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
    "chunk = pd.read_csv(f\"{ROOT}/test.csv\")\n",
    "\n",
    "print(\"add infos\")\n",
    "sub = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n",
    "sub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\n",
    "sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\n",
    "sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['WHERE'] = 'train'\n",
    "chunk['WHERE'] = 'val'\n",
    "sub['WHERE'] = 'test'\n",
    "data = tr.append([chunk, sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1535, 8) (5, 8) (730, 10) (2270, 10)\n",
      "176 5 5 176\n"
     ]
    }
   ],
   "source": [
    "print(tr.shape, chunk.shape, sub.shape, data.shape)\n",
    "print(tr.Patient.nunique(), chunk.Patient.nunique(), sub.Patient.nunique(), \n",
    "      data.Patient.nunique())\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min_week'] = data['Weeks']\n",
    "data.loc[data.WHERE=='test','min_week'] = np.nan\n",
    "data['min_week'] = data.groupby('Patient')['min_week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = data.loc[data.Weeks == data.min_week]\n",
    "base = base[['Patient','FVC']].copy()\n",
    "base.columns = ['Patient','min_FVC']\n",
    "base['nb'] = 1\n",
    "base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n",
    "base = base[base.nb==1]\n",
    "base.drop('nb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(base, on='Patient', how='left')\n",
    "data['base_week'] = data['Weeks'] - data['min_week']\n",
    "del base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['Sex','SmokingStatus'] #,'Age'\n",
    "FE = []\n",
    "for col in COLS:\n",
    "    for mod in data[col].unique():\n",
    "        FE.append(mod)\n",
    "        data[mod] = (data[col] == mod).astype(int)\n",
    "#================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "data['age'] = (data['Age'] - data['Age'].min() ) / ( data['Age'].max() - data['Age'].min() )\n",
    "data['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) / ( data['min_FVC'].max() - data['min_FVC'].min() )\n",
    "data['week'] = (data['base_week'] - data['base_week'].min() ) / ( data['base_week'].max() - data['base_week'].min() )\n",
    "data['percent'] = (data['Percent'] - data['Percent'].min() ) / ( data['Percent'].max() - data['Percent'].min() )\n",
    "FE += ['age','percent','week','BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = data.loc[data.WHERE=='train']\n",
    "chunk = data.loc[data.WHERE=='val']\n",
    "sub = data.loc[data.WHERE=='test']\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1535, 22), (5, 22), (730, 22))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape, chunk.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                        Patient  Weeks   FVC    Percent  Age   Sex  \\\\\\n0     ID00007637202177411956430     -4  2315  58.253649   79  Male   \\n1     ID00007637202177411956430      5  2214  55.712129   79  Male   \\n2     ID00007637202177411956430      7  2061  51.862104   79  Male   \\n3     ID00007637202177411956430      9  2144  53.950679   79  Male   \\n4     ID00007637202177411956430     11  2069  52.063412   79  Male   \\n...                         ...    ...   ...        ...  ...   ...   \\n1530  ID00426637202313170790466     13  2712  66.594637   73  Male   \\n1531  ID00426637202313170790466     19  2978  73.126412   73  Male   \\n1532  ID00426637202313170790466     31  2908  71.407524   73  Male   \\n1533  ID00426637202313170790466     43  2975  73.052745   73  Male   \\n1534  ID00426637202313170790466     59  2774  68.117081   73  Male   \\n\\n     SmokingStatus  WHERE  Confidence Patient_Week  ...  base_week  Male  \\\\\\n0        Ex-smoker  train         NaN          NaN  ...        0.0     1   \\n1        Ex-smoker  train         NaN          NaN  ...        9.0     1   \\n2        Ex-smoker  train         NaN          NaN  ...       11.0     1   \\n3        Ex-smoker  train         NaN          NaN  ...       13.0     1   \\n4        Ex-smoker  train         NaN          NaN  ...       15.0     1   \\n...            ...    ...         ...          ...  ...        ...   ...   \\n1530  Never smoked  train         NaN          NaN  ...       13.0     1   \\n1531  Never smoked  train         NaN          NaN  ...       19.0     1   \\n1532  Never smoked  train         NaN          NaN  ...       31.0     1   \\n1533  Never smoked  train         NaN          NaN  ...       43.0     1   \\n1534  Never smoked  train         NaN          NaN  ...       59.0     1   \\n\\n      Female  Ex-smoker  Never smoked  Currently smokes       age      BASE  \\\\\\n0          0          1             0                 0  0.769231  0.241456   \\n1          0          1             0                 0  0.769231  0.241456   \\n2          0          1             0                 0  0.769231  0.241456   \\n3          0          1             0                 0  0.769231  0.241456   \\n4          0          1             0                 0  0.769231  0.241456   \\n...      ...        ...           ...               ...       ...       ...   \\n1530       0          0             1                 0  0.615385  0.354755   \\n1531       0          0             1                 0  0.615385  0.354755   \\n1532       0          0             1                 0  0.615385  0.354755   \\n1533       0          0             1                 0  0.615385  0.354755   \\n1534       0          0             1                 0  0.615385  0.354755   \\n\\n          week   percent  \\n0     0.179012  0.236393  \\n1     0.234568  0.215941  \\n2     0.246914  0.184960  \\n3     0.259259  0.201767  \\n4     0.271605  0.186580  \\n...        ...       ...  \\n1530  0.259259  0.303514  \\n1531  0.296296  0.356076  \\n1532  0.370370  0.342244  \\n1533  0.444444  0.355484  \\n1534  0.543210  0.315766  \\n\\n[1535 rows x 22 columns]'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BASELINE NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n",
    "#=============================#\n",
    "def score(y_true, y_pred):\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "    #sigma_clip = sigma + C1\n",
    "    sigma_clip = tf.maximum(sigma, C1)\n",
    "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "    delta = tf.minimum(delta, C2)\n",
    "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "    return K.mean(metric)\n",
    "#=============================#\n",
    "def score_fold(y_true, y_pred):\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "    #sigma_clip = sigma + C1\n",
    "    sigma_clip = tf.maximum(sigma, C1)\n",
    "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "    delta = tf.minimum(delta, C2)\n",
    "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "    return K.mean(metric)\n",
    "#============================#\n",
    "def qloss(y_true, y_pred):\n",
    "    # Pinball loss for multiple quantiles\n",
    "    qs = [0.2, 0.50, 0.8]\n",
    "    q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
    "    e = y_true - y_pred\n",
    "    v = tf.maximum(q*e, (q-1)*e)\n",
    "    return K.mean(v)\n",
    "#============================#\n",
    "def tilted_loss(q,y,f):\n",
    "    e = (y-f)\n",
    "    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)\n",
    "#=============================#\n",
    "def mloss(_lambda):\n",
    "    def loss(y_true, y_pred):\n",
    "        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
    "    return loss\n",
    "#=================\n",
    "def make_model(nh,D,ML):\n",
    "    z = L.Input((nh,), name=\"Patient\")\n",
    "    #x = L.Dense(2112, activation=\"relu\", name=\"d0\")(z)\n",
    "    #x = L.Dense(1056, activation=\"relu\", name=\"d1\")(z)\n",
    "    #x = L.Dropout(.2, name=\"do2\")(z)\n",
    "    x = L.Dense(D, activation=\"relu\", name=\"d2\")(z)\n",
    "    #x = L.Dense(256, activation=\"relu\", name=\"d3\")(z)\n",
    "    x = L.Dense(D, activation=\"relu\", name=\"d4\")(x)\n",
    "    #x = L.Dense(16, activation=\"relu\", name=\"d5\")(x)\n",
    "\n",
    "    p1 = L.Dense(3, activation=\"linear\", name=\"p1\")(x)\n",
    "    p2 = L.Dense(3, activation=\"relu\", name=\"p2\")(x)\n",
    "\n",
    "    preds = L.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "                     name=\"preds\")([p1, p2])\n",
    "\n",
    "    model = M.Model(z, preds, name=\"CNN\")\n",
    "    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n",
    "    model.compile(loss=mloss(ML), optimizer=tf.keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False), metrics=[score])\n",
    "    return model\n",
    "\n",
    "my_callbacks = [\n",
    "   tf.keras.callbacks.EarlyStopping(patience=200, mode='max',monitor=[score]),\n",
    "   tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5',monitor=[score],save_best_only=True, mode = 'max'),\n",
    "   # tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tr['FVC'].values.astype(np.float32)\n",
    "z = tr[FE].values.astype(np.float32)\n",
    "ze = sub[FE].values.astype(np.float32)\n",
    "nh = z.shape[1]\n",
    "pe = np.zeros((ze.shape[0], 3))\n",
    "pred = np.zeros((z.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Patient (InputLayer)            [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "d2 (Dense)                      (None, 100)          1000        Patient[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "d4 (Dense)                      (None, 100)          10100       d2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "p1 (Dense)                      (None, 3)            303         d4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "p2 (Dense)                      (None, 3)            303         d4[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "preds (Lambda)                  (None, 3)            0           p1[0][0]                         \n",
      "                                                                 p2[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 11,706\n",
      "Trainable params: 11,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "11706\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    net = make_model(nh,D=100,ML=.8)\n",
    "\n",
    "print(net.summary())\n",
    "print(net.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLD = 5\n",
    "kf = KFold(n_splits=NFOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs=[100,200]\n",
    "#batches=[64,128]\n",
    "\n",
    "#neural_network = KerasClassifier(build_fn=make_model(nh), verbose=0)\n",
    "#hyperparameters = dict(epochs=epochs, \n",
    "#                       batch_size=batches)\n",
    "\n",
    "#grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters, n_jobs=-1, cv=3)\n",
    "#from numpy import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_result = grid.fit(reshape(tr[FE],tr[FE].shape), reshape(tr['FVC'],tr['FVC'].shape))\n",
    "#grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "train [30.696556091308594, 6.644939422607422]\n",
      "val [30.766624450683594, 6.598270416259766]\n",
      "predict val...\n",
      "predict test...\n",
      "133.05984 274.02014\n",
      "118.39258 274.02014 479.38135 1.0\n",
      "FOLD 2\n",
      "train [31.226743698120117, 6.660839080810547]\n",
      "val [30.695993423461914, 6.715459823608398]\n",
      "predict val...\n",
      "predict test...\n",
      "131.13551 276.17792\n",
      "127.23303 276.17792 471.90723 1.0\n",
      "FOLD 3\n",
      "train [30.088600158691406, 6.610232353210449]\n",
      "val [33.746185302734375, 6.778390884399414]\n",
      "predict val...\n",
      "predict test...\n",
      "146.87589 264.07074\n",
      "100.89966 264.07074 576.7197 1.0\n",
      "FOLD 4\n",
      "train [31.646528244018555, 6.6710004806518555]\n",
      "val [33.12985610961914, 6.641823768615723]\n",
      "predict val...\n",
      "predict test...\n",
      "146.18066 248.59528\n",
      "78.879395 248.59528 420.1709 1.0\n",
      "FOLD 5\n",
      "train [30.22873878479004, 6.608458042144775]\n",
      "val [33.40381622314453, 6.704052448272705]\n",
      "predict val...\n",
      "predict test...\n",
      "144.90843 238.69162\n",
      "85.93762 238.69162 424.7046 1.0\n",
      "FOLD 6\n",
      "train [29.272130966186523, 6.573548316955566]\n",
      "val [32.210453033447266, 6.771172523498535]\n",
      "predict val...\n",
      "predict test...\n",
      "138.99779 249.67061\n",
      "121.37268 249.67061 435.80713 1.0\n",
      "FOLD 7\n",
      "train [29.751096725463867, 6.595190525054932]\n",
      "val [29.26633071899414, 6.588325500488281]\n",
      "predict val...\n",
      "predict test...\n",
      "120.539406 261.41928\n",
      "134.5664 261.41928 443.03174 1.0\n",
      "FOLD 8\n",
      "train [28.754331588745117, 6.542612552642822]\n",
      "val [35.45233154296875, 6.740619659423828]\n",
      "predict val...\n",
      "predict test...\n",
      "153.32903 242.38322\n",
      "110.27942 242.38322 537.92725 1.0\n",
      "FOLD 9\n",
      "train [31.584550857543945, 6.664237976074219]\n",
      "val [32.92384719848633, 6.632456302642822]\n",
      "predict val...\n",
      "predict test...\n",
      "145.38104 242.1035\n",
      "75.52484 242.1035 409.63672 1.0\n",
      "FOLD 10\n",
      "train [29.90040397644043, 6.594752311706543]\n",
      "val [33.04727554321289, 6.6907734870910645]\n",
      "predict val...\n",
      "predict test...\n",
      "143.74182 241.54703\n",
      "89.315674 241.54703 418.79443 1.0\n",
      "FOLD 11\n",
      "train [29.339553833007812, 6.577406406402588]\n",
      "val [31.167179107666016, 6.693414688110352]\n",
      "predict val...\n",
      "predict test...\n",
      "134.62097 251.27332\n",
      "117.89868 251.27332 441.39355 1.0\n",
      "FOLD 12\n",
      "train [30.425189971923828, 6.613206386566162]\n",
      "val [29.678064346313477, 6.628171920776367]\n",
      "predict val...\n",
      "predict test...\n",
      "124.12923 263.0594\n",
      "134.60693 263.0594 442.75684 1.0\n",
      "FOLD 13\n",
      "train [28.461118698120117, 6.527379512786865]\n",
      "val [35.02091598510742, 6.686117172241211]\n",
      "predict val...\n",
      "predict test...\n",
      "151.19452 235.09055\n",
      "108.17932 235.09055 518.08203 1.0\n",
      "FOLD 14\n",
      "train [31.040748596191406, 6.631468296051025]\n",
      "val [28.663223266601562, 6.521177291870117]\n",
      "predict val...\n",
      "predict test...\n",
      "125.38055 228.6389\n",
      "81.48688 228.6389 379.73926 1.0\n",
      "FOLD 15\n",
      "train [29.675277709960938, 6.574978828430176]\n",
      "val [32.60169982910156, 6.6759033203125]\n",
      "predict val...\n",
      "predict test...\n",
      "142.01738 243.38437\n",
      "152.11377 243.38437 359.06006 1.0\n",
      "FOLD 16\n",
      "train [30.15522003173828, 6.605669975280762]\n",
      "val [30.47909164428711, 6.5867462158203125]\n",
      "predict val...\n",
      "predict test...\n",
      "131.04321 253.01962\n",
      "113.9314 253.01962 438.7002 1.0\n",
      "FOLD 17\n",
      "train [29.634632110595703, 6.582052707672119]\n",
      "val [29.45414924621582, 6.5788116455078125]\n",
      "predict val...\n",
      "predict test...\n",
      "121.19969 255.10973\n",
      "134.95886 255.10973 431.72705 1.0\n",
      "FOLD 18\n",
      "train [28.19462776184082, 6.507489204406738]\n",
      "val [36.804691314697266, 6.702834129333496]\n",
      "predict val...\n",
      "predict test...\n",
      "160.45631 228.78583\n",
      "108.55493 228.78583 499.479 1.0\n",
      "FOLD 19\n",
      "train [31.03175926208496, 6.630619049072266]\n",
      "val [28.759138107299805, 6.524199485778809]\n",
      "predict val...\n",
      "predict test...\n",
      "125.898895 227.99619\n",
      "80.12952 227.99619 378.02246 1.0\n",
      "FOLD 20\n",
      "train [29.087181091308594, 6.556445121765137]\n",
      "val [31.547943115234375, 6.62921142578125]\n",
      "predict val...\n",
      "predict test...\n",
      "137.9184 231.83751\n",
      "102.216736 231.83751 406.38232 1.0\n",
      "FOLD 21\n",
      "train [30.059865951538086, 6.597367763519287]\n",
      "val [30.54183578491211, 6.59427547454834]\n",
      "predict val...\n",
      "predict test...\n",
      "130.82507 250.14536\n",
      "117.0332 250.14536 430.76416 1.0\n",
      "FOLD 22\n",
      "train [29.530250549316406, 6.575473785400391]\n",
      "val [29.723852157592773, 6.581804275512695]\n",
      "predict val...\n",
      "predict test...\n",
      "122.52533 253.71246\n",
      "133.02014 253.71246 427.83984 1.0\n",
      "FOLD 23\n",
      "train [27.899385452270508, 6.496710777282715]\n",
      "val [36.03444290161133, 6.66026496887207]\n",
      "predict val...\n",
      "predict test...\n",
      "157.94106 227.95003\n",
      "119.69177 227.95003 449.354 1.0\n",
      "FOLD 24\n",
      "train [30.939258575439453, 6.624955177307129]\n",
      "val [28.062366485595703, 6.510662078857422]\n",
      "predict val...\n",
      "predict test...\n",
      "122.887024 229.30986\n",
      "87.055115 229.30986 374.74072 1.0\n",
      "FOLD 25\n",
      "train [29.116811752319336, 6.555805206298828]\n",
      "val [32.11981964111328, 6.647159099578857]\n",
      "predict val...\n",
      "predict test...\n",
      "140.12271 233.72679\n",
      "105.361084 233.72679 398.77393 1.0\n",
      "FOLD 26\n",
      "train [29.247779846191406, 6.570462226867676]\n",
      "val [30.85875701904297, 6.705559730529785]\n",
      "predict val...\n",
      "predict test...\n",
      "134.1934 249.17984\n",
      "128.00366 249.17984 418.71973 1.0\n",
      "FOLD 27\n",
      "train [29.973146438598633, 6.592890739440918]\n",
      "val [29.676284790039062, 6.603714942932129]\n",
      "predict val...\n",
      "predict test...\n",
      "123.73677 259.7753\n",
      "140.10193 259.7753 428.68848 1.0\n",
      "FOLD 28\n",
      "train [28.000776290893555, 6.499502658843994]\n",
      "val [36.649391174316406, 6.696580410003662]\n",
      "predict val...\n",
      "predict test...\n",
      "159.6309 228.38495\n",
      "118.79822 228.38495 456.98877 1.0\n",
      "FOLD 29\n",
      "train [30.975738525390625, 6.629199028015137]\n",
      "val [28.432016372680664, 6.522113800048828]\n",
      "predict val...\n",
      "predict test...\n",
      "124.39869 230.5372\n",
      "85.60651 230.5372 376.4917 1.0\n",
      "FOLD 30\n",
      "train [28.93612289428711, 6.556540489196777]\n",
      "val [32.641815185546875, 6.654950141906738]\n",
      "predict val...\n",
      "predict test...\n",
      "143.36548 237.7497\n",
      "122.2926 237.7497 371.16113 1.0\n",
      "FOLD 31\n",
      "train [30.064014434814453, 6.6000471115112305]\n",
      "val [30.54340362548828, 6.595364570617676]\n",
      "predict val...\n",
      "predict test...\n",
      "130.50188 254.41635\n",
      "123.8053 254.41635 431.76367 1.0\n",
      "FOLD 32\n",
      "train [29.4221134185791, 6.5770263671875]\n",
      "val [29.577497482299805, 6.577286243438721]\n",
      "predict val...\n",
      "predict test...\n",
      "122.52092 252.5566\n",
      "141.0625 252.5566 414.91357 1.0\n",
      "FOLD 33\n",
      "train [28.018831253051758, 6.501380920410156]\n",
      "val [36.82109451293945, 6.691004753112793]\n",
      "predict val...\n",
      "predict test...\n",
      "159.98602 228.42549\n",
      "108.135376 228.42549 497.9839 1.0\n",
      "FOLD 34\n",
      "train [30.975112915039062, 6.629391670227051]\n",
      "val [28.204191207885742, 6.518709182739258]\n",
      "predict val...\n",
      "predict test...\n",
      "123.369705 231.63208\n",
      "87.17139 231.63208 376.59668 1.0\n",
      "FOLD 35\n",
      "train [29.80422019958496, 6.577494144439697]\n",
      "val [32.45164108276367, 6.663360595703125]\n",
      "predict val...\n",
      "predict test...\n",
      "140.86108 235.25923\n",
      "103.34558 235.25923 386.24658 1.0\n",
      "FOLD 36\n",
      "train [29.201818466186523, 6.570796966552734]\n",
      "val [31.020036697387695, 6.70067024230957]\n",
      "predict val...\n",
      "predict test...\n",
      "134.22366 249.24512\n",
      "126.89502 249.24512 415.00977 1.0\n",
      "FOLD 37\n",
      "train [29.719223022460938, 6.592813014984131]\n",
      "val [29.335079193115234, 6.582606315612793]\n",
      "predict val...\n",
      "predict test...\n",
      "120.81387 262.37073\n",
      "138.59424 262.37073 445.34277 1.0\n",
      "FOLD 38\n",
      "train [29.021299362182617, 6.544127464294434]\n",
      "val [35.99801254272461, 6.709672927856445]\n",
      "predict val...\n",
      "predict test...\n",
      "156.21593 238.38715\n",
      "112.109375 238.38715 504.36572 1.0\n",
      "FOLD 39\n",
      "train [30.486995697021484, 6.615201473236084]\n",
      "val [28.4764347076416, 6.501224517822266]\n",
      "predict val...\n",
      "predict test...\n",
      "124.128426 226.02179\n",
      "82.38782 226.02179 372.6892 1.0\n",
      "FOLD 40\n",
      "train [28.928020477294922, 6.555761814117432]\n",
      "val [32.65467071533203, 6.6546406745910645]\n",
      "predict val...\n",
      "predict test...\n",
      "142.82458 238.43681\n",
      "115.37915 238.43681 380.90283 1.0\n",
      "FOLD 41\n",
      "train [29.197755813598633, 6.572265625]\n",
      "val [30.9179744720459, 6.689262390136719]\n",
      "predict val...\n",
      "predict test...\n",
      "134.01 250.33643\n",
      "126.757324 250.33643 426.81787 1.0\n",
      "FOLD 42\n",
      "train [29.685056686401367, 6.5832414627075195]\n",
      "val [29.365890502929688, 6.572973251342773]\n",
      "predict val...\n",
      "predict test...\n",
      "120.43175 257.1494\n",
      "136.93616 257.1494 433.3452 1.0\n",
      "FOLD 43\n",
      "train [29.017425537109375, 6.54483699798584]\n",
      "val [35.768577575683594, 6.710256099700928]\n",
      "predict val...\n",
      "predict test...\n",
      "155.40108 239.51697\n",
      "114.111206 239.51697 501.1665 1.0\n",
      "FOLD 44\n",
      "train [30.983125686645508, 6.6306915283203125]\n",
      "val [28.358116149902344, 6.522492408752441]\n",
      "predict val...\n",
      "predict test...\n",
      "124.133995 232.01361\n",
      "86.55298 232.01361 379.18652 1.0\n",
      "FOLD 45\n",
      "train [28.915267944335938, 6.549948215484619]\n",
      "val [32.45697784423828, 6.647611141204834]\n",
      "predict val...\n",
      "predict test...\n",
      "142.14825 233.59685\n",
      "127.458374 233.59685 368.20605 1.0\n",
      "FOLD 46\n",
      "train [29.20026206970215, 6.566149711608887]\n",
      "val [30.96123695373535, 6.707320213317871]\n",
      "predict val...\n",
      "predict test...\n",
      "134.63556 247.53484\n",
      "138.2251 247.53484 405.30518 1.0\n",
      "FOLD 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [30.358051300048828, 6.606923580169678]\n",
      "val [29.60151481628418, 6.6154375076293945]\n",
      "predict val...\n",
      "predict test...\n",
      "124.06029 259.23154\n",
      "150.81335 259.23154 417.54053 1.0\n",
      "FOLD 48\n",
      "train [27.897594451904297, 6.499150276184082]\n",
      "val [36.294525146484375, 6.685854911804199]\n",
      "predict val...\n",
      "predict test...\n",
      "158.26205 229.88101\n",
      "112.20398 229.88101 484.55957 1.0\n",
      "FOLD 49\n",
      "train [30.037038803100586, 6.594184875488281]\n",
      "val [29.116844177246094, 6.504361152648926]\n",
      "predict val...\n",
      "predict test...\n",
      "127.11054 228.41893\n",
      "108.76141 228.41893 362.19824 1.0\n",
      "FOLD 50\n",
      "train [29.70334815979004, 6.571998596191406]\n",
      "val [32.550621032714844, 6.665587425231934]\n",
      "predict val...\n",
      "predict test...\n",
      "141.38986 236.205\n",
      "104.38367 236.205 393.04346 1.0\n",
      "FOLD 51\n",
      "train [34.977291107177734, 6.629694938659668]\n",
      "val [34.97207260131836, 6.600438117980957]\n",
      "predict val...\n",
      "predict test...\n",
      "131.2106 271.83685\n",
      "122.72974 271.83685 477.3252 1.0\n",
      "FOLD 52\n",
      "train [34.57533264160156, 6.601718902587891]\n",
      "val [34.680450439453125, 6.628419399261475]\n",
      "predict val...\n",
      "predict test...\n",
      "124.90764 260.7054\n",
      "129.0011 260.7054 447.85205 1.0\n",
      "FOLD 53\n",
      "train [34.504417419433594, 6.601737976074219]\n",
      "val [39.30852508544922, 6.7660675048828125]\n",
      "predict val...\n",
      "predict test...\n",
      "147.26768 262.83282\n",
      "101.88721 262.83282 569.42236 1.0\n",
      "FOLD 54\n",
      "train [36.364505767822266, 6.653077602386475]\n",
      "val [35.59809112548828, 6.577518463134766]\n",
      "predict val...\n",
      "predict test...\n",
      "135.55083 237.17598\n",
      "81.04297 237.17598 398.95166 1.0\n",
      "FOLD 55\n",
      "train [35.239715576171875, 6.635409355163574]\n",
      "val [40.15584182739258, 6.744414806365967]\n",
      "predict val...\n",
      "predict test...\n",
      "151.53072 250.05762\n",
      "82.769226 250.05762 448.3452 1.0\n",
      "FOLD 56\n",
      "train [34.931556701660156, 6.617056369781494]\n",
      "val [35.178855895996094, 6.583843231201172]\n",
      "predict val...\n",
      "predict test...\n",
      "130.81639 263.44235\n",
      "121.48279 263.44235 456.13818 1.0\n",
      "FOLD 57\n",
      "train [35.192726135253906, 6.613931179046631]\n",
      "val [34.267215728759766, 6.632199287414551]\n",
      "predict val...\n",
      "predict test...\n",
      "124.153015 263.71286\n",
      "130.36145 263.71286 447.25488 1.0\n",
      "FOLD 58\n",
      "train [33.458065032958984, 6.544862270355225]\n",
      "val [41.305076599121094, 6.721484184265137]\n",
      "predict val...\n",
      "predict test...\n",
      "153.98624 238.79657\n",
      "101.79077 238.79657 521.2612 1.0\n",
      "FOLD 59\n",
      "train [35.074073791503906, 6.621321201324463]\n",
      "val [33.943145751953125, 6.53441858291626]\n",
      "predict val...\n",
      "predict test...\n",
      "128.93294 230.76537\n",
      "89.50775 230.76537 391.12402 1.0\n",
      "FOLD 60\n",
      "train [34.07334899902344, 6.581797122955322]\n",
      "val [38.149192810058594, 6.687849521636963]\n",
      "predict val...\n",
      "predict test...\n",
      "143.24376 242.93301\n",
      "97.71997 242.93301 429.57764 1.0\n",
      "FOLD 61\n",
      "train [34.94093704223633, 6.610099792480469]\n",
      "val [35.34374237060547, 6.593843936920166]\n",
      "predict val...\n",
      "predict test...\n",
      "130.34271 255.0115\n",
      "114.52075 255.0115 443.45557 1.0\n",
      "FOLD 62\n",
      "train [35.243717193603516, 6.618527412414551]\n",
      "val [34.63606643676758, 6.646730899810791]\n",
      "predict val...\n",
      "predict test...\n",
      "126.11665 264.42987\n",
      "131.67297 264.42987 447.45264 1.0\n",
      "FOLD 63\n",
      "train [32.435691833496094, 6.509690284729004]\n",
      "val [42.49317932128906, 6.711977481842041]\n",
      "predict val...\n",
      "predict test...\n",
      "159.4885 235.09897\n",
      "106.30859 235.09897 524.062 1.0\n",
      "FOLD 64\n",
      "train [35.91094970703125, 6.632258415222168]\n",
      "val [33.130245208740234, 6.523427963256836]\n",
      "predict val...\n",
      "predict test...\n",
      "125.336754 229.19855\n",
      "78.21954 229.19855 382.9265 1.0\n",
      "FOLD 65\n",
      "train [33.37450408935547, 6.554069519042969]\n",
      "val [37.49534225463867, 6.651705265045166]\n",
      "predict val...\n",
      "predict test...\n",
      "141.30534 236.83235\n",
      "100.997986 236.83235 414.1875 1.0\n",
      "FOLD 66\n",
      "train [34.819541931152344, 6.606578826904297]\n",
      "val [35.46376419067383, 6.588089942932129]\n",
      "predict val...\n",
      "predict test...\n",
      "130.89983 254.92442\n",
      "115.63074 254.92442 442.94873 1.0\n",
      "FOLD 67\n",
      "train [34.22406005859375, 6.583754062652588]\n",
      "val [33.906944274902344, 6.57818603515625]\n",
      "predict val...\n",
      "predict test...\n",
      "120.60423 257.30383\n",
      "134.92896 257.30383 437.55127 1.0\n",
      "FOLD 68\n",
      "train [32.427764892578125, 6.506828308105469]\n",
      "val [42.9510612487793, 6.709414958953857]\n",
      "predict val...\n",
      "predict test...\n",
      "161.18173 231.56277\n",
      "107.93945 231.56277 507.83887 1.0\n",
      "FOLD 69\n",
      "train [35.859031677246094, 6.629744529724121]\n",
      "val [32.642051696777344, 6.514472961425781]\n",
      "predict val...\n",
      "predict test...\n",
      "123.62272 227.84831\n",
      "78.51422 227.84831 379.62744 1.0\n",
      "FOLD 70\n",
      "train [33.67108154296875, 6.554407596588135]\n",
      "val [37.068359375, 6.643410682678223]\n",
      "predict val...\n",
      "predict test...\n",
      "139.00172 232.93361\n",
      "107.4834 232.93361 396.563 1.0\n",
      "FOLD 71\n",
      "train [33.845916748046875, 6.576144218444824]\n",
      "val [35.76172637939453, 6.686690330505371]\n",
      "predict val...\n",
      "predict test...\n",
      "133.59402 250.4774\n",
      "120.36609 250.4774 440.87842 1.0\n",
      "FOLD 72\n",
      "train [34.715721130371094, 6.597314357757568]\n",
      "val [35.0181999206543, 6.633742332458496]\n",
      "predict val...\n",
      "predict test...\n",
      "127.903625 260.4918\n",
      "143.05005 260.4918 437.4463 1.0\n",
      "FOLD 73\n",
      "train [32.381099700927734, 6.502612113952637]\n",
      "val [42.968299865722656, 6.700730800628662]\n",
      "predict val...\n",
      "predict test...\n",
      "161.39032 228.84242\n",
      "108.62561 228.84242 492.55713 1.0\n",
      "FOLD 74\n",
      "train [35.902862548828125, 6.629960536956787]\n",
      "val [32.442378997802734, 6.511382102966309]\n",
      "predict val...\n",
      "predict test...\n",
      "123.010254 227.96162\n",
      "80.7652 227.96162 377.96753 1.0\n",
      "FOLD 75\n",
      "train [34.49333572387695, 6.58095645904541]\n",
      "val [37.737483978271484, 6.671745300292969]\n",
      "predict val...\n",
      "predict test...\n",
      "141.09187 236.47618\n",
      "94.86792 236.47618 402.95508 1.0\n",
      "FOLD 76\n",
      "train [33.78368377685547, 6.569499969482422]\n",
      "val [35.88593673706055, 6.7073564529418945]\n",
      "predict val...\n",
      "predict test...\n",
      "134.6742 248.52515\n",
      "134.39294 248.52515 415.2744 1.0\n",
      "FOLD 77\n",
      "train [34.1818962097168, 6.583165168762207]\n",
      "val [34.13041305541992, 6.578926086425781]\n",
      "predict val...\n",
      "predict test...\n",
      "121.51206 257.2734\n",
      "142.57349 257.2734 431.25928 1.0\n",
      "FOLD 78\n",
      "train [32.362396240234375, 6.501926422119141]\n",
      "val [42.60287857055664, 6.7011284828186035]\n",
      "predict val...\n",
      "predict test...\n",
      "159.60606 228.91734\n",
      "110.68628 228.91734 494.67383 1.0\n",
      "FOLD 79\n",
      "train [35.02842712402344, 6.601056098937988]\n",
      "val [33.99381637573242, 6.49797248840332]\n",
      "predict val...\n",
      "predict test...\n",
      "127.55218 224.02469\n",
      "89.20471 224.02469 371.3745 1.0\n",
      "FOLD 80\n",
      "train [33.50306701660156, 6.561265468597412]\n",
      "val [37.86921691894531, 6.655951023101807]\n",
      "predict val...\n",
      "predict test...\n",
      "143.0938 240.13625\n",
      "113.17407 240.13625 401.85303 1.0\n",
      "FOLD 81\n",
      "train [34.786903381347656, 6.6020708084106445]\n",
      "val [35.41685485839844, 6.597172260284424]\n",
      "predict val...\n",
      "predict test...\n",
      "130.70491 255.29723\n",
      "123.05798 255.29723 434.5122 1.0\n",
      "FOLD 82\n",
      "train [34.76237869262695, 6.600537300109863]\n",
      "val [34.754539489746094, 6.624809265136719]\n",
      "predict val...\n",
      "predict test...\n",
      "126.63965 261.35455\n",
      "151.42896 261.35455 434.2666 1.0\n",
      "FOLD 83\n",
      "train [33.52885055541992, 6.544358730316162]\n",
      "val [41.90892791748047, 6.711384296417236]\n",
      "predict val...\n",
      "predict test...\n",
      "156.41783 238.13286\n",
      "110.34985 238.13286 507.04883 1.0\n",
      "FOLD 84\n",
      "train [34.99038314819336, 6.604727268218994]\n",
      "val [32.33125305175781, 6.496314525604248]\n",
      "predict val...\n",
      "predict test...\n",
      "122.34358 228.1138\n",
      "97.245544 228.1138 368.4331 1.0\n",
      "FOLD 85\n",
      "train [34.46330261230469, 6.5797576904296875]\n",
      "val [37.64885711669922, 6.66722297668457]\n",
      "predict val...\n",
      "predict test...\n",
      "140.85872 238.36462\n",
      "101.84155 238.36462 399.79004 1.0\n",
      "FOLD 86\n",
      "train [33.36790466308594, 6.561733245849609]\n",
      "val [36.914310455322266, 6.755511283874512]\n",
      "predict val...\n",
      "predict test...\n",
      "137.10396 252.20984\n",
      "154.55457 252.20984 311.13672 1.0\n",
      "FOLD 87\n",
      "train [34.721675872802734, 6.596141815185547]\n",
      "val [34.56231689453125, 6.617325782775879]\n",
      "predict val...\n",
      "predict test...\n",
      "125.36479 261.13187\n",
      "141.25647 261.13187 436.7505 1.0\n",
      "FOLD 88\n",
      "train [33.522491455078125, 6.544264793395996]\n",
      "val [41.85007095336914, 6.710718154907227]\n",
      "predict val...\n",
      "predict test...\n",
      "156.1752 238.3123\n",
      "111.2124 238.3123 505.2163 1.0\n",
      "FOLD 89\n",
      "train [35.785335540771484, 6.625284671783447]\n",
      "val [32.46818542480469, 6.514326095581055]\n",
      "predict val...\n",
      "predict test...\n",
      "123.04529 234.65656\n",
      "111.05408 234.65656 362.41895 1.0\n",
      "FOLD 90\n",
      "train [34.47023391723633, 6.580477714538574]\n",
      "val [37.729347229003906, 6.671695709228516]\n",
      "predict val...\n",
      "predict test...\n",
      "141.43071 237.86044\n",
      "98.52295 237.86044 400.29883 1.0\n",
      "FOLD 91\n",
      "train [33.646095275878906, 6.564558982849121]\n",
      "val [36.00680160522461, 6.703125953674316]\n",
      "predict val...\n",
      "predict test...\n",
      "136.07143 250.4673\n",
      "144.98694 250.4673 389.8706 1.0\n",
      "FOLD 92\n",
      "train [34.49753952026367, 6.589044094085693]\n",
      "val [34.009403228759766, 6.595036029815674]\n",
      "predict val...\n",
      "predict test...\n",
      "122.2911 260.1312\n",
      "139.85168 260.1312 437.07373 1.0\n",
      "FOLD 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [33.514930725097656, 6.546181678771973]\n",
      "val [41.53068923950195, 6.708395004272461]\n",
      "predict val...\n",
      "predict test...\n",
      "155.21565 240.71677\n",
      "115.68396 240.71677 505.22266 1.0\n",
      "FOLD 94\n",
      "train [34.98744583129883, 6.602511405944824]\n",
      "val [33.42472457885742, 6.493968963623047]\n",
      "predict val...\n",
      "predict test...\n",
      "125.785065 227.02782\n",
      "92.135376 227.02782 373.2788 1.0\n",
      "FOLD 95\n",
      "train [33.357723236083984, 6.552081108093262]\n",
      "val [37.75050735473633, 6.652715682983398]\n",
      "predict val...\n",
      "predict test...\n",
      "143.01688 236.22165\n",
      "120.12805 236.22165 367.354 1.0\n",
      "FOLD 96\n",
      "train [34.243980407714844, 6.578795433044434]\n",
      "val [37.518829345703125, 6.744870185852051]\n",
      "predict val...\n",
      "predict test...\n",
      "138.97577 247.26898\n",
      "125.68347 247.26898 411.45508 1.0\n",
      "FOLD 97\n",
      "train [35.06781005859375, 6.609925746917725]\n",
      "val [34.21543884277344, 6.616328239440918]\n",
      "predict val...\n",
      "predict test...\n",
      "124.05387 261.07162\n",
      "167.36487 261.07162 412.06152 1.0\n",
      "FOLD 98\n",
      "train [33.52341079711914, 6.545344352722168]\n",
      "val [41.51416015625, 6.708529949188232]\n",
      "predict val...\n",
      "predict test...\n",
      "155.03989 239.57141\n",
      "113.796265 239.57141 504.42773 1.0\n",
      "FOLD 99\n",
      "train [35.864845275878906, 6.631343841552734]\n",
      "val [32.81052017211914, 6.525078773498535]\n",
      "predict val...\n",
      "predict test...\n",
      "124.41022 232.61304\n",
      "87.272766 232.61304 379.47144 1.0\n",
      "FOLD 100\n",
      "train [34.463802337646484, 6.58010196685791]\n",
      "val [37.74574661254883, 6.670693397521973]\n",
      "predict val...\n",
      "predict test...\n",
      "141.44496 237.7813\n",
      "100.75116 237.7813 398.80615 1.0\n",
      "FOLD 101\n",
      "train [39.00136184692383, 6.614871025085449]\n",
      "val [41.15757751464844, 6.7198286056518555]\n",
      "predict val...\n",
      "predict test...\n",
      "136.36632 265.20798\n",
      "122.68799 265.20798 470.41895 1.0\n",
      "FOLD 102\n",
      "train [40.8568000793457, 6.655517578125]\n",
      "val [40.25107192993164, 6.711826324462891]\n",
      "predict val...\n",
      "predict test...\n",
      "130.82678 276.93643\n",
      "129.07947 276.93643 472.55713 1.0\n",
      "FOLD 103\n",
      "train [37.36983871459961, 6.5471343994140625]\n",
      "val [46.419551849365234, 6.734508037567139]\n",
      "predict val...\n",
      "predict test...\n",
      "153.62856 250.03468\n",
      "107.78662 250.03468 561.4131 1.0\n",
      "FOLD 104\n",
      "train [41.487369537353516, 6.664936065673828]\n",
      "val [42.8745002746582, 6.625931739807129]\n",
      "predict val...\n",
      "predict test...\n",
      "143.34814 245.4545\n",
      "78.712524 245.4545 414.91113 1.0\n",
      "FOLD 105\n",
      "train [39.82695388793945, 6.627634525299072]\n",
      "val [45.07570266723633, 6.729569911956787]\n",
      "predict val...\n",
      "predict test...\n",
      "148.85893 247.46117\n",
      "82.88043 247.46117 443.66553 1.0\n",
      "FOLD 106\n",
      "train [38.2537727355957, 6.574307441711426]\n",
      "val [42.33881759643555, 6.765329360961914]\n",
      "predict val...\n",
      "predict test...\n",
      "138.75041 252.22469\n",
      "121.07141 252.22469 438.66162 1.0\n",
      "FOLD 107\n",
      "train [39.54204559326172, 6.62970495223999]\n",
      "val [39.27796173095703, 6.639761924743652]\n",
      "predict val...\n",
      "predict test...\n",
      "124.35137 275.80032\n",
      "132.04456 275.80032 479.38184 1.0\n",
      "FOLD 108\n",
      "train [37.412471771240234, 6.536851406097412]\n",
      "val [45.88459396362305, 6.705343246459961]\n",
      "predict val...\n",
      "predict test...\n",
      "149.15717 240.7288\n",
      "109.34851 240.7288 525.6826 1.0\n",
      "FOLD 109\n",
      "train [40.821083068847656, 6.635996341705322]\n",
      "val [38.2322998046875, 6.537955284118652]\n",
      "predict val...\n",
      "predict test...\n",
      "127.68557 230.97786\n",
      "75.883606 230.97786 388.11792 1.0\n",
      "FOLD 110\n",
      "train [38.254756927490234, 6.57834529876709]\n",
      "val [43.661094665527344, 6.675382614135742]\n",
      "predict val...\n",
      "predict test...\n",
      "145.2399 244.91768\n",
      "98.7594 244.91768 436.75488 1.0\n",
      "FOLD 111\n",
      "train [38.29035949707031, 6.572890281677246]\n",
      "val [41.979732513427734, 6.744083404541016]\n",
      "predict val...\n",
      "predict test...\n",
      "137.82005 251.65012\n",
      "119.79541 251.65012 436.93555 1.0\n",
      "FOLD 112\n",
      "train [39.7032470703125, 6.604127407073975]\n",
      "val [39.29541778564453, 6.635140419006348]\n",
      "predict val...\n",
      "predict test...\n",
      "125.47689 261.67548\n",
      "132.61841 261.67548 442.22266 1.0\n",
      "FOLD 113\n",
      "train [37.143226623535156, 6.522427558898926]\n",
      "val [46.467288970947266, 6.675278186798096]\n",
      "predict val...\n",
      "predict test...\n",
      "151.55632 234.61284\n",
      "110.20947 234.61284 511.16602 1.0\n",
      "FOLD 114\n",
      "train [40.66194152832031, 6.627816677093506]\n",
      "val [37.28336715698242, 6.521175384521484]\n",
      "predict val...\n",
      "predict test...\n",
      "124.774506 230.54695\n",
      "83.37103 230.54695 383.12427 1.0\n",
      "FOLD 115\n",
      "train [38.006752014160156, 6.562713623046875]\n",
      "val [42.77534103393555, 6.652068138122559]\n",
      "predict val...\n",
      "predict test...\n",
      "141.88162 240.42015\n",
      "109.68823 240.42015 408.00195 1.0\n",
      "FOLD 116\n",
      "train [39.61595153808594, 6.609335422515869]\n",
      "val [40.12794876098633, 6.589107513427734]\n",
      "predict val...\n",
      "predict test...\n",
      "130.44821 256.08472\n",
      "116.12842 256.08472 443.70703 1.0\n",
      "FOLD 117\n",
      "train [39.82493209838867, 6.604583740234375]\n",
      "val [39.069976806640625, 6.623048782348633]\n",
      "predict val...\n",
      "predict test...\n",
      "125.016136 259.00555\n",
      "137.00757 259.00555 428.26367 1.0\n",
      "FOLD 118\n",
      "train [36.86184310913086, 6.513648986816406]\n",
      "val [48.132568359375, 6.697404861450195]\n",
      "predict val...\n",
      "predict test...\n",
      "158.38025 233.22682\n",
      "109.93054 233.22682 502.21338 1.0\n",
      "FOLD 119\n",
      "train [40.78666687011719, 6.629937648773193]\n",
      "val [36.627803802490234, 6.510656356811523]\n",
      "predict val...\n",
      "predict test...\n",
      "122.58887 229.10144\n",
      "81.981445 229.10144 378.24756 1.0\n",
      "FOLD 120\n",
      "train [38.15505599975586, 6.562647342681885]\n",
      "val [42.437767028808594, 6.648752212524414]\n",
      "predict val...\n",
      "predict test...\n",
      "140.88971 236.57123\n",
      "105.19031 236.57123 403.1548 1.0\n",
      "FOLD 121\n",
      "train [39.60245895385742, 6.605008125305176]\n",
      "val [40.25645446777344, 6.601618766784668]\n",
      "predict val...\n",
      "predict test...\n",
      "130.81998 253.51738\n",
      "121.660645 253.51738 432.66113 1.0\n",
      "FOLD 122\n",
      "train [39.964813232421875, 6.6104607582092285]\n",
      "val [39.21854782104492, 6.630654811859131]\n",
      "predict val...\n",
      "predict test...\n",
      "125.887955 260.07834\n",
      "135.99255 260.07834 435.59082 1.0\n",
      "FOLD 123\n",
      "train [38.072296142578125, 6.545762538909912]\n",
      "val [47.70705032348633, 6.708603382110596]\n",
      "predict val...\n",
      "predict test...\n",
      "155.92339 238.5285\n",
      "107.34668 238.5285 512.8716 1.0\n",
      "FOLD 124\n",
      "train [40.769691467285156, 6.6299848556518555]\n",
      "val [36.85140609741211, 6.513540744781494]\n",
      "predict val...\n",
      "predict test...\n",
      "123.23331 228.77118\n",
      "81.44928 228.77118 377.54883 1.0\n",
      "FOLD 125\n",
      "train [37.88687515258789, 6.5541205406188965]\n",
      "val [42.87518310546875, 6.654219627380371]\n",
      "predict val...\n",
      "predict test...\n",
      "142.36104 236.44646\n",
      "107.38208 236.44646 405.08008 1.0\n",
      "FOLD 126\n",
      "train [39.57876968383789, 6.606077671051025]\n",
      "val [40.125450134277344, 6.5920209884643555]\n",
      "predict val...\n",
      "predict test...\n",
      "130.3517 255.09123\n",
      "120.83325 255.09123 435.87842 1.0\n",
      "FOLD 127\n",
      "train [39.937564849853516, 6.60785436630249]\n",
      "val [38.972286224365234, 6.621002674102783]\n",
      "predict val...\n",
      "predict test...\n",
      "124.44771 258.38538\n",
      "134.1919 258.38538 432.58594 1.0\n",
      "FOLD 128\n",
      "train [38.00301742553711, 6.543976783752441]\n",
      "val [47.45661926269531, 6.7053632736206055]\n",
      "predict val...\n",
      "predict test...\n",
      "155.57362 238.09558\n",
      "115.906006 238.09558 503.813 1.0\n",
      "FOLD 129\n",
      "train [40.721702575683594, 6.630992889404297]\n",
      "val [37.010807037353516, 6.522365570068359]\n",
      "predict val...\n",
      "predict test...\n",
      "123.83983 231.94981\n",
      "83.9704 231.94981 379.97485 1.0\n",
      "FOLD 130\n",
      "train [37.88810729980469, 6.558651924133301]\n",
      "val [43.14767837524414, 6.656561851501465]\n",
      "predict val...\n",
      "predict test...\n",
      "143.19733 240.48651\n",
      "119.42859 240.48651 391.48486 1.0\n",
      "FOLD 131\n",
      "train [39.486263275146484, 6.602972507476807]\n",
      "val [40.18384552001953, 6.596580505371094]\n",
      "predict val...\n",
      "predict test...\n",
      "130.5235 256.19894\n",
      "121.822266 256.19894 438.70654 1.0\n",
      "FOLD 132\n",
      "train [38.948692321777344, 6.592765808105469]\n",
      "val [38.566741943359375, 6.585156440734863]\n",
      "predict val...\n",
      "predict test...\n",
      "121.63701 260.705\n",
      "151.60583 260.705 431.43994 1.0\n",
      "FOLD 133\n",
      "train [38.043392181396484, 6.545001029968262]\n",
      "val [47.737945556640625, 6.711642265319824]\n",
      "predict val...\n",
      "predict test...\n",
      "156.1843 237.86925\n",
      "108.80591 237.86925 508.5669 1.0\n",
      "FOLD 134\n",
      "train [39.9166259765625, 6.614920616149902]\n",
      "val [36.146461486816406, 6.496514797210693]\n",
      "predict val...\n",
      "predict test...\n",
      "120.918045 229.96536\n",
      "96.03363 229.96536 381.51514 1.0\n",
      "FOLD 135\n",
      "train [39.12413024902344, 6.581219673156738]\n",
      "val [42.81463623046875, 6.66890811920166]\n",
      "predict val...\n",
      "predict test...\n",
      "140.97858 238.4691\n",
      "98.12848 238.4691 403.5293 1.0\n",
      "FOLD 136\n",
      "train [37.90913391113281, 6.560947418212891]\n",
      "val [42.4603157043457, 6.788569450378418]\n",
      "predict val...\n",
      "predict test...\n",
      "139.50098 249.67697\n",
      "123.41455 249.67697 432.24463 1.0\n",
      "FOLD 137\n",
      "train [39.90797424316406, 6.611055850982666]\n",
      "val [38.93851089477539, 6.623835563659668]\n",
      "predict val...\n",
      "predict test...\n",
      "124.51486 262.2193\n",
      "140.96619 262.2193 433.03516 1.0\n",
      "FOLD 138\n",
      "train [37.66565704345703, 6.539492607116699]\n",
      "val [47.81700897216797, 6.714344024658203]\n",
      "predict val...\n",
      "predict test...\n",
      "156.30304 242.39078\n",
      "117.649414 242.39078 513.5503 1.0\n",
      "FOLD 139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [40.68708801269531, 6.629997253417969]\n",
      "val [36.66423797607422, 6.5128607749938965]\n",
      "predict val...\n",
      "predict test...\n",
      "122.643555 231.36914\n",
      "89.050415 231.36914 379.20923 1.0\n",
      "FOLD 140\n",
      "train [38.03007888793945, 6.558180332183838]\n",
      "val [42.75737380981445, 6.652887344360352]\n",
      "predict val...\n",
      "predict test...\n",
      "141.78879 237.8609\n",
      "107.055176 237.8609 408.3213 1.0\n",
      "FOLD 141\n",
      "train [39.42227554321289, 6.59928035736084]\n",
      "val [40.084136962890625, 6.595267295837402]\n",
      "predict val...\n",
      "predict test...\n",
      "130.46657 254.13768\n",
      "121.02356 254.13768 434.7295 1.0\n",
      "FOLD 142\n",
      "train [38.621089935302734, 6.5758185386657715]\n",
      "val [38.13352966308594, 6.574634552001953]\n",
      "predict val...\n",
      "predict test...\n",
      "120.29489 255.52187\n",
      "145.49219 255.52187 426.32568 1.0\n",
      "FOLD 143\n",
      "train [38.007293701171875, 6.546316623687744]\n",
      "val [47.276397705078125, 6.706886291503906]\n",
      "predict val...\n",
      "predict test...\n",
      "155.08258 240.83784\n",
      "117.77551 240.83784 503.33203 1.0\n",
      "FOLD 144\n",
      "train [39.7154655456543, 6.597914695739746]\n",
      "val [37.7000617980957, 6.4871931076049805]\n",
      "predict val...\n",
      "predict test...\n",
      "125.11597 226.88731\n",
      "100.83386 226.88731 356.2417 1.0\n",
      "FOLD 145\n",
      "train [37.905418395996094, 6.559216499328613]\n",
      "val [42.94710922241211, 6.65275764465332]\n",
      "predict val...\n",
      "predict test...\n",
      "142.6392 239.6707\n",
      "121.801025 239.6707 376.83496 1.0\n",
      "FOLD 146\n",
      "train [38.8033561706543, 6.573474884033203]\n",
      "val [40.73096466064453, 6.598804473876953]\n",
      "predict val...\n",
      "predict test...\n",
      "132.82855 242.61945\n",
      "138.0415 242.61945 376.32666 1.0\n",
      "FOLD 147\n",
      "train [39.0203742980957, 6.589938163757324]\n",
      "val [38.27588653564453, 6.585320949554443]\n",
      "predict val...\n",
      "predict test...\n",
      "121.50252 259.6205\n",
      "158.26123 259.6205 420.33594 1.0\n",
      "FOLD 148\n",
      "train [36.494747161865234, 6.499264717102051]\n",
      "val [48.512908935546875, 6.695441246032715]\n",
      "predict val...\n",
      "predict test...\n",
      "159.21375 230.92804\n",
      "133.19019 230.92804 369.14453 1.0\n",
      "FOLD 149\n",
      "train [40.737857818603516, 6.631805419921875]\n",
      "val [37.17340087890625, 6.524980545043945]\n",
      "predict val...\n",
      "predict test...\n",
      "124.3132 232.9242\n",
      "86.987305 232.9242 380.6338 1.0\n",
      "FOLD 150\n",
      "train [37.71302032470703, 6.5544753074646]\n",
      "val [43.06550979614258, 6.652599334716797]\n",
      "predict val...\n",
      "predict test...\n",
      "142.68756 240.07716\n",
      "139.94824 240.07716 346.8208 1.0\n",
      "FOLD 151\n",
      "train [44.525794982910156, 6.623409271240234]\n",
      "val [45.187522888183594, 6.594664573669434]\n",
      "predict val...\n",
      "predict test...\n",
      "131.66028 265.57895\n",
      "116.40576 265.57895 465.19092 1.0\n",
      "FOLD 152\n",
      "train [43.96514892578125, 6.611062049865723]\n",
      "val [44.095157623291016, 6.630819320678711]\n",
      "predict val...\n",
      "predict test...\n",
      "125.12199 265.76547\n",
      "131.57263 265.76547 456.12793 1.0\n",
      "FOLD 153\n",
      "train [42.472023010253906, 6.567469596862793]\n",
      "val [50.63372039794922, 6.741828918457031]\n",
      "predict val...\n",
      "predict test...\n",
      "147.24597 256.49173\n",
      "106.51245 256.49173 565.916 1.0\n",
      "FOLD 154\n",
      "train [46.60855484008789, 6.669674873352051]\n",
      "val [48.84508514404297, 6.638546466827393]\n",
      "predict val...\n",
      "predict test...\n",
      "145.58644 247.3521\n",
      "75.99872 247.3521 420.17334 1.0\n",
      "FOLD 155\n",
      "train [44.14649200439453, 6.610456943511963]\n",
      "val [50.128639221191406, 6.708395957946777]\n",
      "predict val...\n",
      "predict test...\n",
      "146.89981 243.45769\n",
      "89.80969 243.45769 430.95264 1.0\n",
      "FOLD 156\n",
      "train [43.06082534790039, 6.582711219787598]\n",
      "val [45.51399230957031, 6.7004899978637695]\n",
      "predict val...\n",
      "predict test...\n",
      "134.37473 254.24828\n",
      "118.68762 254.24828 449.19922 1.0\n",
      "FOLD 157\n",
      "train [44.842132568359375, 6.620355129241943]\n",
      "val [43.5824089050293, 6.638835906982422]\n",
      "predict val...\n",
      "predict test...\n",
      "124.665764 264.8354\n",
      "131.40479 264.8354 449.50293 1.0\n",
      "FOLD 158\n",
      "train [41.115928649902344, 6.512986660003662]\n",
      "val [53.61051559448242, 6.709094047546387]\n",
      "predict val...\n",
      "predict test...\n",
      "157.3661 236.33456\n",
      "104.86072 236.33456 529.13477 1.0\n",
      "FOLD 159\n",
      "train [45.85279083251953, 6.6441650390625]\n",
      "val [44.712921142578125, 6.572731018066406]\n",
      "predict val...\n",
      "predict test...\n",
      "133.21814 237.70572\n",
      "79.64984 237.70572 394.4453 1.0\n",
      "FOLD 160\n",
      "train [42.59286880493164, 6.563545227050781]\n",
      "val [48.24247741699219, 6.663372993469238]\n",
      "predict val...\n",
      "predict test...\n",
      "142.89818 239.1575\n",
      "102.86218 239.1575 419.99023 1.0\n",
      "FOLD 161\n",
      "train [43.009700775146484, 6.585997104644775]\n",
      "val [45.33528518676758, 6.696611404418945]\n",
      "predict val...\n",
      "predict test...\n",
      "133.76007 258.52872\n",
      "123.94751 258.52872 450.25 1.0\n",
      "FOLD 162\n",
      "train [44.551631927490234, 6.612602233886719]\n",
      "val [43.47441482543945, 6.625278472900391]\n",
      "predict val...\n",
      "predict test...\n",
      "123.91251 264.7176\n",
      "136.38586 264.7176 444.90283 1.0\n",
      "FOLD 163\n",
      "train [41.19178771972656, 6.517603874206543]\n",
      "val [53.66323471069336, 6.697419166564941]\n",
      "predict val...\n",
      "predict test...\n",
      "157.39622 236.91132\n",
      "110.55859 236.91132 521.90625 1.0\n",
      "FOLD 164\n",
      "train [45.80817794799805, 6.638880729675293]\n",
      "val [43.063472747802734, 6.544445991516113]\n",
      "predict val...\n",
      "predict test...\n",
      "128.82695 232.60199\n",
      "76.81616 232.60199 390.2578 1.0\n",
      "FOLD 165\n",
      "train [42.067928314208984, 6.5525922775268555]\n",
      "val [49.73039245605469, 6.670197486877441]\n",
      "predict val...\n",
      "predict test...\n",
      "147.82863 235.43678\n",
      "106.03284 235.43678 408.78467 1.0\n",
      "FOLD 166\n",
      "train [44.32010269165039, 6.609302520751953]\n",
      "val [44.92112350463867, 6.589573860168457]\n",
      "predict val...\n",
      "predict test...\n",
      "130.43643 256.67883\n",
      "117.56726 256.67883 442.8628 1.0\n",
      "FOLD 167\n",
      "train [44.728240966796875, 6.6125593185424805]\n",
      "val [43.627628326416016, 6.628532409667969]\n",
      "predict val...\n",
      "predict test...\n",
      "124.55274 261.8273\n",
      "130.229 261.8273 445.4131 1.0\n",
      "FOLD 168\n",
      "train [42.60475158691406, 6.545086860656738]\n",
      "val [53.71371078491211, 6.713141918182373]\n",
      "predict val...\n",
      "predict test...\n",
      "156.35016 236.95477\n",
      "105.38013 236.95477 511.688 1.0\n",
      "FOLD 169\n",
      "train [45.632564544677734, 6.630049228668213]\n",
      "val [41.25486755371094, 6.516135215759277]\n",
      "predict val...\n",
      "predict test...\n",
      "123.64463 230.09177\n",
      "85.150085 230.09177 378.45166 1.0\n",
      "FOLD 170\n",
      "train [44.35043716430664, 6.614800453186035]\n",
      "val [49.98551559448242, 6.712740421295166]\n",
      "predict val...\n",
      "predict test...\n",
      "147.39748 244.17682\n",
      "89.26892 244.17682 429.08496 1.0\n",
      "FOLD 171\n",
      "train [42.85990524291992, 6.5780229568481445]\n",
      "val [45.670257568359375, 6.7017669677734375]\n",
      "predict val...\n",
      "predict test...\n",
      "134.36327 254.10846\n",
      "123.53345 254.10846 440.23584 1.0\n",
      "FOLD 172\n",
      "train [43.65190887451172, 6.595810890197754]\n",
      "val [43.138214111328125, 6.585627555847168]\n",
      "predict val...\n",
      "predict test...\n",
      "121.35902 262.57516\n",
      "144.2229 262.57516 436.46777 1.0\n",
      "FOLD 173\n",
      "train [40.91596603393555, 6.5112409591674805]\n",
      "val [54.44758987426758, 6.695247173309326]\n",
      "predict val...\n",
      "predict test...\n",
      "160.1455 235.05956\n",
      "118.01465 235.05956 499.1548 1.0\n",
      "FOLD 174\n",
      "train [45.64177322387695, 6.630780220031738]\n",
      "val [41.20337677001953, 6.515375137329102]\n",
      "predict val...\n",
      "predict test...\n",
      "123.32816 230.32268\n",
      "84.15796 230.32268 377.88965 1.0\n",
      "FOLD 175\n",
      "train [42.70698165893555, 6.560273170471191]\n",
      "val [47.382869720458984, 6.6489362716674805]\n",
      "predict val...\n",
      "predict test...\n",
      "139.77158 236.01349\n",
      "101.83014 236.01349 406.27246 1.0\n",
      "FOLD 176\n",
      "train [42.65907287597656, 6.571980953216553]\n",
      "val [45.64073181152344, 6.705720901489258]\n",
      "predict val...\n",
      "predict test...\n",
      "134.05714 254.60202\n",
      "143.54407 254.60202 398.59912 1.0\n",
      "FOLD 177\n",
      "train [43.38689422607422, 6.5857038497924805]\n",
      "val [43.259429931640625, 6.5801801681518555]\n",
      "predict val...\n",
      "predict test...\n",
      "121.62172 259.70737\n",
      "139.01355 259.70737 429.87695 1.0\n",
      "FOLD 178\n",
      "train [40.753753662109375, 6.5033860206604]\n",
      "val [54.24595260620117, 6.6904497146606445]\n",
      "predict val...\n",
      "predict test...\n",
      "159.14902 230.39658\n",
      "125.65869 230.39658 471.88623 1.0\n",
      "FOLD 179\n",
      "train [45.607784271240234, 6.631654262542725]\n",
      "val [41.638389587402344, 6.523525714874268]\n",
      "predict val...\n",
      "predict test...\n",
      "124.528625 231.31699\n",
      "83.122925 231.31699 381.6997 1.0\n",
      "FOLD 180\n",
      "train [42.46588897705078, 6.560655117034912]\n",
      "val [48.172935485839844, 6.65547513961792]\n",
      "predict val...\n",
      "predict test...\n",
      "142.51874 240.07854\n",
      "108.41516 240.07854 412.8374 1.0\n",
      "FOLD 181\n",
      "train [42.67112350463867, 6.567688941955566]\n",
      "val [47.33852767944336, 6.758152008056641]\n",
      "predict val...\n",
      "predict test...\n",
      "138.18756 250.27478\n",
      "128.7179 250.27478 423.26025 1.0\n",
      "FOLD 182\n",
      "train [43.4634895324707, 6.587939262390137]\n",
      "val [43.09696960449219, 6.582259178161621]\n",
      "predict val...\n",
      "predict test...\n",
      "120.81386 260.23117\n",
      "135.78015 260.23117 440.41357 1.0\n",
      "FOLD 183\n",
      "train [40.88808822631836, 6.502636909484863]\n",
      "val [55.09559631347656, 6.700316429138184]\n",
      "predict val...\n",
      "predict test...\n",
      "161.37802 231.42122\n",
      "114.7207 231.42122 456.3213 1.0\n",
      "FOLD 184\n",
      "train [45.61174774169922, 6.631178855895996]\n",
      "val [41.74924850463867, 6.523255348205566]\n",
      "predict val...\n",
      "predict test...\n",
      "124.840645 231.13776\n",
      "85.89142 231.13776 380.57593 1.0\n",
      "FOLD 185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [42.448368072509766, 6.558680057525635]\n",
      "val [48.05476760864258, 6.654106140136719]\n",
      "predict val...\n",
      "predict test...\n",
      "142.45071 239.94844\n",
      "121.27252 239.94844 395.94287 1.0\n",
      "FOLD 186\n",
      "train [42.664710998535156, 6.565962314605713]\n",
      "val [47.237850189208984, 6.755136013031006]\n",
      "predict val...\n",
      "predict test...\n",
      "138.14296 248.21445\n",
      "125.50867 248.21445 422.00488 1.0\n",
      "FOLD 187\n",
      "train [44.6812858581543, 6.611593723297119]\n",
      "val [43.606075286865234, 6.6259074211120605]\n",
      "predict val...\n",
      "predict test...\n",
      "124.64731 262.49457\n",
      "138.8241 262.49457 436.25293 1.0\n",
      "FOLD 188\n",
      "train [40.72214889526367, 6.5040106773376465]\n",
      "val [54.157127380371094, 6.691527366638184]\n",
      "predict val...\n",
      "predict test...\n",
      "158.72316 232.39908\n",
      "122.6488 232.39908 474.35645 1.0\n",
      "FOLD 189\n",
      "train [45.619476318359375, 6.632183074951172]\n",
      "val [41.731475830078125, 6.525090217590332]\n",
      "predict val...\n",
      "predict test...\n",
      "124.893936 231.2\n",
      "81.17627 231.2 383.3911 1.0\n",
      "FOLD 190\n",
      "train [43.72996139526367, 6.579514503479004]\n",
      "val [48.02149200439453, 6.671686172485352]\n",
      "predict val...\n",
      "predict test...\n",
      "141.50221 239.17682\n",
      "104.61401 239.17682 395.48535 1.0\n",
      "FOLD 191\n",
      "train [41.584537506103516, 6.528005123138428]\n",
      "val [48.354923248291016, 6.755133628845215]\n",
      "predict val...\n",
      "predict test...\n",
      "143.91151 237.98038\n",
      "128.7135 237.98038 387.48438 1.0\n",
      "FOLD 192\n",
      "train [44.12826919555664, 6.598715782165527]\n",
      "val [43.78287887573242, 6.618656635284424]\n",
      "predict val...\n",
      "predict test...\n",
      "124.84342 263.22803\n",
      "138.14453 263.22803 445.69727 1.0\n",
      "FOLD 193\n",
      "train [40.99104690551758, 6.508051872253418]\n",
      "val [54.30438995361328, 6.7004804611206055]\n",
      "predict val...\n",
      "predict test...\n",
      "159.11401 234.65874\n",
      "114.357666 234.65874 506.10498 1.0\n",
      "FOLD 194\n",
      "train [45.45000457763672, 6.629106044769287]\n",
      "val [41.170902252197266, 6.515018939971924]\n",
      "predict val...\n",
      "predict test...\n",
      "122.95572 229.95656\n",
      "81.315186 229.95656 379.10693 1.0\n",
      "FOLD 195\n",
      "train [43.35614776611328, 6.570487022399902]\n",
      "val [47.67692184448242, 6.670821189880371]\n",
      "predict val...\n",
      "predict test...\n",
      "140.84813 240.32683\n",
      "116.76611 240.32683 391.36182 1.0\n",
      "FOLD 196\n",
      "train [44.290489196777344, 6.607307434082031]\n",
      "val [44.948204040527344, 6.592496395111084]\n",
      "predict val...\n",
      "predict test...\n",
      "130.36572 256.62677\n",
      "121.797 256.62677 438.6626 1.0\n",
      "FOLD 197\n",
      "train [43.397891998291016, 6.586277961730957]\n",
      "val [43.338748931884766, 6.584458351135254]\n",
      "predict val...\n",
      "predict test...\n",
      "121.430244 261.05527\n",
      "138.16968 261.05527 442.54443 1.0\n",
      "FOLD 198\n",
      "train [42.05707931518555, 6.538949489593506]\n",
      "val [53.43296432495117, 6.706577777862549]\n",
      "predict val...\n",
      "predict test...\n",
      "155.28903 242.42413\n",
      "128.78198 242.42413 501.14404 1.0\n",
      "FOLD 199\n",
      "train [45.615028381347656, 6.6319990158081055]\n",
      "val [41.45558166503906, 6.524349689483643]\n",
      "predict val...\n",
      "predict test...\n",
      "124.152435 232.76387\n",
      "85.11499 232.76387 382.48877 1.0\n",
      "FOLD 200\n",
      "train [42.2884407043457, 6.557325839996338]\n",
      "val [48.345924377441406, 6.656352996826172]\n",
      "predict val...\n",
      "predict test...\n",
      "143.26395 240.12321\n",
      "126.316345 240.12321 387.34766 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 201\n",
      "train [29.49599838256836, 6.576401710510254]\n",
      "val [32.43968963623047, 6.7806196212768555]\n",
      "predict val...\n",
      "predict test...\n",
      "139.3568 243.25183\n",
      "111.56677 243.25183 429.16504 1.0\n",
      "FOLD 202\n",
      "train [29.596540451049805, 6.580010890960693]\n",
      "val [30.60071563720703, 6.642650604248047]\n",
      "predict val...\n",
      "predict test...\n",
      "127.861946 254.31981\n",
      "124.98047 254.31981 440.75586 1.0\n",
      "FOLD 203\n",
      "train [28.44521141052246, 6.524138450622559]\n",
      "val [36.36286926269531, 6.699497222900391]\n",
      "predict val...\n",
      "predict test...\n",
      "158.88457 233.61859\n",
      "104.95105 233.61859 512.5405 1.0\n",
      "FOLD 204\n",
      "train [31.47913932800293, 6.646331787109375]\n",
      "val [29.40774917602539, 6.543733596801758]\n",
      "predict val...\n",
      "predict test...\n",
      "129.27896 230.08759\n",
      "77.59369 230.08759 384.8584 1.0\n",
      "FOLD 205\n",
      "train [29.8209171295166, 6.592114448547363]\n",
      "val [32.832427978515625, 6.690398216247559]\n",
      "predict val...\n",
      "predict test...\n",
      "142.78336 238.57587\n",
      "89.4881 238.57587 423.77783 1.0\n",
      "FOLD 206\n",
      "train [30.174474716186523, 6.609716892242432]\n",
      "val [30.495868682861328, 6.588532447814941]\n",
      "predict val...\n",
      "predict test...\n",
      "130.38734 257.605\n",
      "122.911865 257.605 438.7085 1.0\n",
      "FOLD 207\n",
      "train [29.62581443786621, 6.583734035491943]\n",
      "val [29.412132263183594, 6.577557563781738]\n",
      "predict val...\n",
      "predict test...\n",
      "120.96318 256.8296\n",
      "133.85925 256.8296 436.36768 1.0\n",
      "FOLD 208\n",
      "train [28.016948699951172, 6.506707668304443]\n",
      "val [36.03326416015625, 6.6991071701049805]\n",
      "predict val...\n",
      "predict test...\n",
      "157.1353 232.97287\n",
      "106.11426 232.97287 517.19727 1.0\n",
      "FOLD 209\n",
      "train [30.81463050842285, 6.6253790855407715]\n",
      "val [28.67048454284668, 6.5130510330200195]\n",
      "predict val...\n",
      "predict test...\n",
      "124.74547 228.29352\n",
      "83.70447 228.29352 377.6006 1.0\n",
      "FOLD 210\n",
      "train [29.027172088623047, 6.558114051818848]\n",
      "val [32.37367630004883, 6.6538591384887695]\n",
      "predict val...\n",
      "predict test...\n",
      "141.48137 236.37306\n",
      "103.70624 236.37306 414.01514 1.0\n",
      "FOLD 211\n",
      "train [29.116249084472656, 6.566857814788818]\n",
      "val [31.99721336364746, 6.743468284606934]\n",
      "predict val...\n",
      "predict test...\n",
      "138.1066 250.93578\n",
      "123.921875 250.93578 428.2373 1.0\n",
      "FOLD 212\n",
      "train [29.440887451171875, 6.570812225341797]\n",
      "val [30.024620056152344, 6.627939224243164]\n",
      "predict val...\n",
      "predict test...\n",
      "124.889786 250.81966\n",
      "130.83447 250.81966 430.65625 1.0\n",
      "FOLD 213\n",
      "train [27.594568252563477, 6.489346504211426]\n",
      "val [36.28824996948242, 6.674871444702148]\n",
      "predict val...\n",
      "predict test...\n",
      "158.18555 228.8405\n",
      "111.1521 228.8405 495.78955 1.0\n",
      "FOLD 214\n",
      "train [30.289134979248047, 6.602557182312012]\n",
      "val [27.779159545898438, 6.476877212524414]\n",
      "predict val...\n",
      "predict test...\n",
      "120.69824 225.85712\n",
      "87.33917 225.85712 372.73926 1.0\n",
      "FOLD 215\n",
      "train [28.637977600097656, 6.538127899169922]\n",
      "val [32.722293853759766, 6.660123825073242]\n",
      "predict val...\n",
      "predict test...\n",
      "143.2976 232.89824\n",
      "118.27197 232.89824 386.5918 1.0\n",
      "FOLD 216\n",
      "train [29.00896453857422, 6.556681156158447]\n",
      "val [32.39103698730469, 6.792698860168457]\n",
      "predict val...\n",
      "predict test...\n",
      "139.75305 243.91444\n",
      "122.59546 243.91444 412.40137 1.0\n",
      "FOLD 217\n",
      "train [28.864477157592773, 6.545681953430176]\n",
      "val [30.49409294128418, 6.637393951416016]\n",
      "predict val...\n",
      "predict test...\n",
      "127.92075 243.4635\n",
      "128.88745 243.4635 415.10498 1.0\n",
      "FOLD 218\n",
      "train [28.065128326416016, 6.5038347244262695]\n",
      "val [36.18901062011719, 6.680086135864258]\n",
      "predict val...\n",
      "predict test...\n",
      "157.28532 228.36159\n",
      "111.57971 228.36159 485.48145 1.0\n",
      "FOLD 219\n",
      "train [30.078125, 6.590123176574707]\n",
      "val [28.10641098022461, 6.476728439331055]\n",
      "predict val...\n",
      "predict test...\n",
      "122.389305 221.45807\n",
      "93.36151 221.45807 362.66162 1.0\n",
      "FOLD 220\n",
      "train [28.877662658691406, 6.54647159576416]\n",
      "val [31.55705451965332, 6.625984191894531]\n",
      "predict val...\n",
      "predict test...\n",
      "137.4138 232.62581\n",
      "123.86731 232.62581 371.6455 1.0\n",
      "FOLD 221\n",
      "train [28.861095428466797, 6.5568976402282715]\n",
      "val [31.849838256835938, 6.766063690185547]\n",
      "predict val...\n",
      "predict test...\n",
      "138.00458 250.41795\n",
      "152.52246 250.41795 393.66895 1.0\n",
      "FOLD 222\n",
      "train [29.56450653076172, 6.578784942626953]\n",
      "val [29.312042236328125, 6.576186180114746]\n",
      "predict val...\n",
      "predict test...\n",
      "120.516045 255.92905\n",
      "138.2461 255.92905 431.90283 1.0\n",
      "FOLD 223\n",
      "train [27.82400894165039, 6.499018669128418]\n",
      "val [36.6599006652832, 6.687383651733398]\n",
      "predict val...\n",
      "predict test...\n",
      "159.74649 230.76129\n",
      "115.079346 230.76129 489.19678 1.0\n",
      "FOLD 224\n",
      "train [30.23366928100586, 6.605888366699219]\n",
      "val [27.432703018188477, 6.480496406555176]\n",
      "predict val...\n",
      "predict test...\n",
      "119.481094 234.07431\n",
      "112.216064 234.07431 345.61914 1.0\n",
      "FOLD 225\n",
      "train [28.752016067504883, 6.5540618896484375]\n",
      "val [31.846946716308594, 6.639135360717773]\n",
      "predict val...\n",
      "predict test...\n",
      "138.09819 239.2016\n",
      "173.24023 239.2016 332.99634 1.0\n",
      "FOLD 226\n",
      "train [28.75751304626465, 6.54375696182251]\n",
      "val [31.734045028686523, 6.752553939819336]\n",
      "predict val...\n",
      "predict test...\n",
      "137.5118 241.93956\n",
      "123.94043 241.93956 407.75244 1.0\n",
      "FOLD 227\n",
      "train [29.393840789794922, 6.572608947753906]\n",
      "val [29.454381942749023, 6.567102432250977]\n",
      "predict val...\n",
      "predict test...\n",
      "121.67553 250.79657\n",
      "149.448 250.79657 406.63086 1.0\n",
      "FOLD 228\n",
      "train [27.900815963745117, 6.497162818908691]\n",
      "val [36.697383880615234, 6.690706253051758]\n",
      "predict val...\n",
      "predict test...\n",
      "159.83353 227.27866\n",
      "123.09534 227.27866 443.56445 1.0\n",
      "FOLD 229\n",
      "train [30.254302978515625, 6.604071617126465]\n",
      "val [27.958646774291992, 6.494479179382324]\n",
      "predict val...\n",
      "predict test...\n",
      "121.63719 227.86757\n",
      "95.75409 227.86757 371.25635 1.0\n",
      "FOLD 230\n",
      "train [28.652467727661133, 6.544405937194824]\n",
      "val [32.716365814208984, 6.647554397583008]\n",
      "predict val...\n",
      "predict test...\n",
      "143.12253 234.68065\n",
      "116.00073 234.68065 389.7505 1.0\n",
      "FOLD 231\n",
      "train [30.02473258972168, 6.590392112731934]\n",
      "val [30.653406143188477, 6.602731704711914]\n",
      "predict val...\n",
      "predict test...\n",
      "131.33548 246.1933\n",
      "158.96167 246.1933 373.271 1.0\n",
      "FOLD 232\n",
      "train [29.242944717407227, 6.563401699066162]\n",
      "val [29.90914535522461, 6.5996856689453125]\n",
      "predict val...\n",
      "predict test...\n",
      "124.1209 250.55182\n",
      "144.62439 250.55182 415.16113 1.0\n",
      "FOLD 233\n",
      "train [27.954097747802734, 6.497139930725098]\n",
      "val [36.98102569580078, 6.692280292510986]\n",
      "predict val...\n",
      "predict test...\n",
      "161.29543 226.09715\n",
      "123.72717 226.09715 423.43018 1.0\n",
      "FOLD 234\n",
      "train [30.255203247070312, 6.60204553604126]\n",
      "val [27.723119735717773, 6.478056907653809]\n",
      "predict val...\n",
      "predict test...\n",
      "120.73102 229.63411\n",
      "107.81445 229.63411 358.24268 1.0\n",
      "FOLD 235\n",
      "train [28.542924880981445, 6.536234378814697]\n",
      "val [33.32719039916992, 6.675947189331055]\n",
      "predict val...\n",
      "predict test...\n",
      "146.83815 232.19162\n",
      "131.86414 232.19162 374.20557 1.0\n",
      "FOLD 236\n",
      "train [28.859407424926758, 6.552889823913574]\n",
      "val [32.48938751220703, 6.801781177520752]\n",
      "predict val...\n",
      "predict test...\n",
      "140.78964 246.44626\n",
      "135.60718 246.44626 406.1831 1.0\n",
      "FOLD 237\n",
      "train [29.608051300048828, 6.586596488952637]\n",
      "val [29.2503662109375, 6.575865745544434]\n",
      "predict val...\n",
      "predict test...\n",
      "120.655815 257.943\n",
      "158.42627 257.943 425.15137 1.0\n",
      "FOLD 238\n",
      "train [28.119932174682617, 6.516325950622559]\n",
      "val [34.736080169677734, 6.647809028625488]\n",
      "predict val...\n",
      "predict test...\n",
      "150.30716 235.39786\n",
      "127.72998 235.39786 480.3379 1.0\n",
      "FOLD 239\n",
      "train [29.87383270263672, 6.5906081199646]\n",
      "val [28.828968048095703, 6.491769313812256]\n",
      "predict val...\n",
      "predict test...\n",
      "126.45547 228.36269\n",
      "115.045715 228.36269 351.37354 1.0\n",
      "FOLD 240\n",
      "train [28.60498809814453, 6.547112941741943]\n",
      "val [33.341426849365234, 6.683646202087402]\n",
      "predict val...\n",
      "predict test...\n",
      "145.39862 238.81662\n",
      "172.7309 238.81662 337.69214 1.0\n",
      "FOLD 241\n",
      "train [28.88758087158203, 6.554196357727051]\n",
      "val [31.806427001953125, 6.741558074951172]\n",
      "predict val...\n",
      "predict test...\n",
      "137.47864 248.43575\n",
      "149.78113 248.43575 362.07422 1.0\n",
      "FOLD 242\n",
      "train [29.240909576416016, 6.56551456451416]\n",
      "val [29.491315841674805, 6.593899250030518]\n",
      "predict val...\n",
      "predict test...\n",
      "122.46641 253.13692\n",
      "142.599 253.13692 418.71924 1.0\n",
      "FOLD 243\n",
      "train [27.730836868286133, 6.497168064117432]\n",
      "val [36.962623596191406, 6.6748247146606445]\n",
      "predict val...\n",
      "predict test...\n",
      "160.30385 229.43994\n",
      "125.87927 229.43994 428.03027 1.0\n",
      "FOLD 244\n",
      "train [29.95216178894043, 6.595914363861084]\n",
      "val [28.33318328857422, 6.494312286376953]\n",
      "predict val...\n",
      "predict test...\n",
      "124.36139 228.19305\n",
      "104.90503 228.19305 370.68262 1.0\n",
      "FOLD 245\n",
      "train [28.583040237426758, 6.54245138168335]\n",
      "val [32.60182189941406, 6.66355037689209]\n",
      "predict val...\n",
      "predict test...\n",
      "142.85107 237.90804\n",
      "147.81445 237.90804 346.49707 1.0\n",
      "FOLD 246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [30.112085342407227, 6.601592063903809]\n",
      "val [30.56327247619629, 6.593535423278809]\n",
      "predict val...\n",
      "predict test...\n",
      "130.62823 253.15584\n",
      "133.04419 253.15584 420.1538 1.0\n",
      "FOLD 247\n",
      "train [29.452587127685547, 6.581966400146484]\n",
      "val [29.143516540527344, 6.56845760345459]\n",
      "predict val...\n",
      "predict test...\n",
      "122.024864 251.42009\n",
      "181.89612 251.42009 361.25 1.0\n",
      "FOLD 248\n",
      "train [27.74662208557129, 6.493182182312012]\n",
      "val [36.64961624145508, 6.67979097366333]\n",
      "predict val...\n",
      "predict test...\n",
      "159.32465 226.38959\n",
      "127.92883 226.38959 426.70898 1.0\n",
      "FOLD 249\n",
      "train [30.21016502380371, 6.595162391662598]\n",
      "val [28.58660888671875, 6.47869873046875]\n",
      "predict val...\n",
      "predict test...\n",
      "123.818825 225.72455\n",
      "103.47479 225.72455 351.40674 1.0\n",
      "FOLD 250\n",
      "train [28.773517608642578, 6.546777248382568]\n",
      "val [32.619537353515625, 6.6527252197265625]\n",
      "predict val...\n",
      "predict test...\n",
      "143.32016 234.04428\n",
      "152.76367 234.04428 305.2876 1.0\n",
      "FOLD 251\n",
      "train [34.09279251098633, 6.578866004943848]\n",
      "val [37.33380126953125, 6.766837120056152]\n",
      "predict val...\n",
      "predict test...\n",
      "138.71469 245.36676\n",
      "114.52612 245.36676 433.29492 1.0\n",
      "FOLD 252\n",
      "train [34.21845245361328, 6.57565450668335]\n",
      "val [35.52045822143555, 6.642763614654541]\n",
      "predict val...\n",
      "predict test...\n",
      "128.34058 247.02838\n",
      "125.73486 247.02838 427.53418 1.0\n",
      "FOLD 253\n",
      "train [32.789344787597656, 6.530315399169922]\n",
      "val [42.27678680419922, 6.694463729858398]\n",
      "predict val...\n",
      "predict test...\n",
      "159.14519 240.57074\n",
      "106.8999 240.57074 534.76807 1.0\n",
      "FOLD 254\n",
      "train [35.5958251953125, 6.622045993804932]\n",
      "val [33.92877960205078, 6.523687362670898]\n",
      "predict val...\n",
      "predict test...\n",
      "129.25217 225.14497\n",
      "84.5564 225.14497 384.06836 1.0\n",
      "FOLD 255\n",
      "train [34.06059265136719, 6.575273036956787]\n",
      "val [37.87391662597656, 6.679204940795898]\n",
      "predict val...\n",
      "predict test...\n",
      "143.26257 233.4125\n",
      "93.62781 233.4125 417.3999 1.0\n",
      "FOLD 256\n",
      "train [33.728614807128906, 6.565732002258301]\n",
      "val [37.273006439208984, 6.738626480102539]\n",
      "predict val...\n",
      "predict test...\n",
      "138.32831 244.94211\n",
      "114.7843 244.94211 430.90186 1.0\n",
      "FOLD 257\n",
      "train [33.60886764526367, 6.5608978271484375]\n",
      "val [35.27045440673828, 6.627108573913574]\n",
      "predict val...\n",
      "predict test...\n",
      "126.666176 251.04576\n",
      "134.8518 251.04576 424.98584 1.0\n",
      "FOLD 258\n",
      "train [32.2010612487793, 6.502756595611572]\n",
      "val [42.36406326293945, 6.691944122314453]\n",
      "predict val...\n",
      "predict test...\n",
      "158.85187 232.75685\n",
      "109.272095 232.75685 517.1914 1.0\n",
      "FOLD 259\n",
      "train [35.05829620361328, 6.608575344085693]\n",
      "val [33.77469253540039, 6.505788326263428]\n",
      "predict val...\n",
      "predict test...\n",
      "126.60362 228.68959\n",
      "84.23547 228.68959 384.17334 1.0\n",
      "FOLD 260\n",
      "train [33.289451599121094, 6.547641754150391]\n",
      "val [37.715965270996094, 6.656052589416504]\n",
      "predict val...\n",
      "predict test...\n",
      "142.60857 234.40712\n",
      "111.06537 234.40712 402.5542 1.0\n",
      "FOLD 261\n",
      "train [33.455379486083984, 6.563922882080078]\n",
      "val [36.92029571533203, 6.7551727294921875]\n",
      "predict val...\n",
      "predict test...\n",
      "137.71902 251.43929\n",
      "124.69238 251.43929 432.70166 1.0\n",
      "FOLD 262\n",
      "train [34.14168930053711, 6.5843706130981445]\n",
      "val [34.03010559082031, 6.5826568603515625]\n",
      "predict val...\n",
      "predict test...\n",
      "121.121056 260.32782\n",
      "142.61487 260.32782 437.41504 1.0\n",
      "FOLD 263\n",
      "train [31.371156692504883, 6.473111629486084]\n",
      "val [43.08895492553711, 6.705097198486328]\n",
      "predict val...\n",
      "predict test...\n",
      "161.15198 222.70122\n",
      "110.12537 222.70122 470.95947 1.0\n",
      "FOLD 264\n",
      "train [35.88330078125, 6.630456447601318]\n",
      "val [32.61486053466797, 6.516858100891113]\n",
      "predict val...\n",
      "predict test...\n",
      "123.70071 229.71216\n",
      "80.4516 229.71216 382.55078 1.0\n",
      "FOLD 265\n",
      "train [33.336769104003906, 6.5520806312561035]\n",
      "val [36.8037109375, 6.631126403808594]\n",
      "predict val...\n",
      "predict test...\n",
      "139.10367 236.7787\n",
      "122.544556 236.7787 387.2295 1.0\n",
      "FOLD 266\n",
      "train [33.68390655517578, 6.564545631408691]\n",
      "val [37.47309112548828, 6.757796287536621]\n",
      "predict val...\n",
      "predict test...\n",
      "139.06247 247.06912\n",
      "126.92798 247.06912 405.4668 1.0\n",
      "FOLD 267\n",
      "train [33.332305908203125, 6.547585487365723]\n",
      "val [35.02592849731445, 6.626039981842041]\n",
      "predict val...\n",
      "predict test...\n",
      "127.10629 244.48743\n",
      "134.53613 244.48743 413.2832 1.0\n",
      "FOLD 268\n",
      "train [32.60078811645508, 6.51006555557251]\n",
      "val [41.98870849609375, 6.670200347900391]\n",
      "predict val...\n",
      "predict test...\n",
      "156.66577 228.49745\n",
      "111.5636 228.49745 493.50586 1.0\n",
      "FOLD 269\n",
      "train [35.07659912109375, 6.598706245422363]\n",
      "val [32.47777557373047, 6.473430633544922]\n",
      "predict val...\n",
      "predict test...\n",
      "122.22869 220.40625\n",
      "87.06561 220.40625 365.41016 1.0\n",
      "FOLD 270\n",
      "train [33.22814178466797, 6.559129238128662]\n",
      "val [36.668113708496094, 6.6377410888671875]\n",
      "predict val...\n",
      "predict test...\n",
      "137.31055 241.5059\n",
      "177.81409 241.5059 349.04663 1.0\n",
      "FOLD 271\n",
      "train [33.6270751953125, 6.5659918785095215]\n",
      "val [37.04824447631836, 6.749934673309326]\n",
      "predict val...\n",
      "predict test...\n",
      "137.9602 248.36963\n",
      "120.53088 248.36963 430.4419 1.0\n",
      "FOLD 272\n",
      "train [33.93263626098633, 6.5697760581970215]\n",
      "val [33.90220260620117, 6.568953514099121]\n",
      "predict val...\n",
      "predict test...\n",
      "121.63134 249.6715\n",
      "156.47949 249.6715 401.10303 1.0\n",
      "FOLD 273\n",
      "train [32.13251495361328, 6.499861240386963]\n",
      "val [42.718204498291016, 6.685582160949707]\n",
      "predict val...\n",
      "predict test...\n",
      "160.19397 228.70702\n",
      "129.8252 228.70702 435.42627 1.0\n",
      "FOLD 274\n",
      "train [35.891075134277344, 6.6295318603515625]\n",
      "val [32.33625411987305, 6.510593414306641]\n",
      "predict val...\n",
      "predict test...\n",
      "122.65518 228.12488\n",
      "80.09003 228.12488 377.885 1.0\n",
      "FOLD 275\n",
      "train [33.16508865356445, 6.5432329177856445]\n",
      "val [37.65030288696289, 6.657907485961914]\n",
      "predict val...\n",
      "predict test...\n",
      "142.62225 234.17442\n",
      "121.525024 234.17442 390.54492 1.0\n",
      "FOLD 276\n",
      "train [33.700103759765625, 6.5707902908325195]\n",
      "val [35.855491638183594, 6.694104194641113]\n",
      "predict val...\n",
      "predict test...\n",
      "134.05176 250.97522\n",
      "133.00598 250.97522 405.81982 1.0\n",
      "FOLD 277\n",
      "train [33.78815460205078, 6.57257604598999]\n",
      "val [34.195960998535156, 6.577854156494141]\n",
      "predict val...\n",
      "predict test...\n",
      "122.32516 253.12077\n",
      "151.31201 253.12077 412.62305 1.0\n",
      "FOLD 278\n",
      "train [32.102664947509766, 6.495349884033203]\n",
      "val [42.107547760009766, 6.678130626678467]\n",
      "predict val...\n",
      "predict test...\n",
      "157.64494 227.33575\n",
      "118.67053 227.33575 445.4673 1.0\n",
      "FOLD 279\n",
      "train [35.579551696777344, 6.620266914367676]\n",
      "val [33.09148025512695, 6.508031845092773]\n",
      "predict val...\n",
      "predict test...\n",
      "124.45154 226.4684\n",
      "83.84088 226.4684 368.60498 1.0\n",
      "FOLD 280\n",
      "train [33.09843063354492, 6.5459465980529785]\n",
      "val [38.247501373291016, 6.6606316566467285]\n",
      "predict val...\n",
      "predict test...\n",
      "144.40634 237.63185\n",
      "126.10193 237.63185 393.51758 1.0\n",
      "FOLD 281\n",
      "train [33.52871322631836, 6.563230991363525]\n",
      "val [37.0197639465332, 6.7523651123046875]\n",
      "predict val...\n",
      "predict test...\n",
      "137.81384 249.04044\n",
      "130.19812 249.04044 411.36426 1.0\n",
      "FOLD 282\n",
      "train [33.79237365722656, 6.566409111022949]\n",
      "val [34.51202392578125, 6.605572700500488]\n",
      "predict val...\n",
      "predict test...\n",
      "124.027 251.97461\n",
      "145.54321 251.97461 421.85938 1.0\n",
      "FOLD 283\n",
      "train [32.02864074707031, 6.4960432052612305]\n",
      "val [42.90904998779297, 6.6879754066467285]\n",
      "predict val...\n",
      "predict test...\n",
      "160.62451 228.88335\n",
      "120.23279 228.88335 471.78906 1.0\n",
      "FOLD 284\n",
      "train [35.51344680786133, 6.618716239929199]\n",
      "val [32.78706359863281, 6.500047206878662]\n",
      "predict val...\n",
      "predict test...\n",
      "123.365456 225.2532\n",
      "77.77411 225.2532 371.63257 1.0\n",
      "FOLD 285\n",
      "train [34.412845611572266, 6.576401710510254]\n",
      "val [37.65727233886719, 6.668349266052246]\n",
      "predict val...\n",
      "predict test...\n",
      "141.31984 239.0221\n",
      "116.10248 239.0221 390.53613 1.0\n",
      "FOLD 286\n",
      "train [33.323387145996094, 6.553934574127197]\n",
      "val [36.731590270996094, 6.732107639312744]\n",
      "predict val...\n",
      "predict test...\n",
      "137.74913 249.20328\n",
      "139.02527 249.20328 388.79053 1.0\n",
      "FOLD 287\n",
      "train [33.94687271118164, 6.581939697265625]\n",
      "val [34.30003356933594, 6.589035987854004]\n",
      "predict val...\n",
      "predict test...\n",
      "123.66732 256.9266\n",
      "146.50928 256.9266 413.19727 1.0\n",
      "FOLD 288\n",
      "train [31.772493362426758, 6.49111270904541]\n",
      "val [41.125545501708984, 6.641228675842285]\n",
      "predict val...\n",
      "predict test...\n",
      "152.7541 229.00629\n",
      "152.88306 229.00629 354.1582 1.0\n",
      "FOLD 289\n",
      "train [34.619564056396484, 6.598026275634766]\n",
      "val [32.61750411987305, 6.478748321533203]\n",
      "predict val...\n",
      "predict test...\n",
      "122.68396 230.52672\n",
      "113.72693 230.52672 354.7417 1.0\n",
      "FOLD 290\n",
      "train [33.05026626586914, 6.548816680908203]\n",
      "val [37.828468322753906, 6.656787872314453]\n",
      "predict val...\n",
      "predict test...\n",
      "142.15541 239.31311\n",
      "167.96411 239.31311 316.93262 1.0\n",
      "FOLD 291\n",
      "train [33.23227310180664, 6.548159599304199]\n",
      "val [36.546566009521484, 6.749200344085693]\n",
      "predict val...\n",
      "predict test...\n",
      "137.2697 247.68788\n",
      "147.78418 247.68788 369.13574 1.0\n",
      "FOLD 292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [33.91792297363281, 6.573538303375244]\n",
      "val [33.73287582397461, 6.574892044067383]\n",
      "predict val...\n",
      "predict test...\n",
      "120.00185 256.95984\n",
      "141.8219 256.95984 429.7422 1.0\n",
      "FOLD 293\n",
      "train [32.36128616333008, 6.506390571594238]\n",
      "val [42.14463424682617, 6.679712295532227]\n",
      "predict val...\n",
      "predict test...\n",
      "157.30275 231.41643\n",
      "132.66162 231.41643 442.65576 1.0\n",
      "FOLD 294\n",
      "train [35.84281539916992, 6.630570888519287]\n",
      "val [32.448482513427734, 6.519311904907227]\n",
      "predict val...\n",
      "predict test...\n",
      "123.20267 233.56578\n",
      "90.86664 233.56578 378.53467 1.0\n",
      "FOLD 295\n",
      "train [33.02122116088867, 6.548121452331543]\n",
      "val [37.88322448730469, 6.658924102783203]\n",
      "predict val...\n",
      "predict test...\n",
      "142.65858 237.34222\n",
      "169.71948 237.34222 325.89893 1.0\n",
      "FOLD 296\n",
      "train [32.536041259765625, 6.526316165924072]\n",
      "val [35.70590591430664, 6.662169456481934]\n",
      "predict val...\n",
      "predict test...\n",
      "133.13676 238.06212\n",
      "120.65515 238.06212 381.54785 1.0\n",
      "FOLD 297\n",
      "train [33.41565704345703, 6.5587158203125]\n",
      "val [34.798240661621094, 6.626657962799072]\n",
      "predict val...\n",
      "predict test...\n",
      "126.461876 251.30823\n",
      "140.48425 251.30823 421.54004 1.0\n",
      "FOLD 298\n",
      "train [32.105899810791016, 6.500129699707031]\n",
      "val [42.63317108154297, 6.686946868896484]\n",
      "predict val...\n",
      "predict test...\n",
      "159.5286 229.12184\n",
      "125.17468 229.12184 459.78564 1.0\n",
      "FOLD 299\n",
      "train [34.48011779785156, 6.589930057525635]\n",
      "val [32.29706954956055, 6.486910820007324]\n",
      "predict val...\n",
      "predict test...\n",
      "123.0894 235.58667\n",
      "142.91351 235.58667 329.90234 1.0\n",
      "FOLD 300\n",
      "train [33.056156158447266, 6.5492753982543945]\n",
      "val [37.968284606933594, 6.660749435424805]\n",
      "predict val...\n",
      "predict test...\n",
      "142.829 238.60214\n",
      "163.84436 238.60214 330.20923 1.0\n",
      "FOLD 301\n",
      "train [38.33427429199219, 6.57178258895874]\n",
      "val [42.32524108886719, 6.769443035125732]\n",
      "predict val...\n",
      "predict test...\n",
      "138.21454 246.91948\n",
      "115.60791 246.91948 432.98682 1.0\n",
      "FOLD 302\n",
      "train [38.64278793334961, 6.578448295593262]\n",
      "val [40.15366744995117, 6.645674705505371]\n",
      "predict val...\n",
      "predict test...\n",
      "128.10197 255.99644\n",
      "129.89502 255.99644 441.5454 1.0\n",
      "FOLD 303\n",
      "train [37.53694534301758, 6.536208152770996]\n",
      "val [48.54757308959961, 6.720913410186768]\n",
      "predict val...\n",
      "predict test...\n",
      "159.36533 238.22844\n",
      "100.04065 238.22844 529.7715 1.0\n",
      "FOLD 304\n",
      "train [40.65751266479492, 6.622910976409912]\n",
      "val [37.960208892822266, 6.509195804595947]\n",
      "predict val...\n",
      "predict test...\n",
      "127.45554 219.65077\n",
      "76.03412 219.65077 373.23462 1.0\n",
      "FOLD 305\n",
      "train [38.77667999267578, 6.576680660247803]\n",
      "val [42.1359977722168, 6.658876419067383]\n",
      "predict val...\n",
      "predict test...\n",
      "139.99146 231.84111\n",
      "93.99341 231.84111 412.05908 1.0\n",
      "FOLD 306\n",
      "train [38.25862503051758, 6.571321964263916]\n",
      "val [42.33763885498047, 6.759045600891113]\n",
      "predict val...\n",
      "predict test...\n",
      "138.34073 250.94498\n",
      "117.39319 250.94498 442.50244 1.0\n",
      "FOLD 307\n",
      "train [38.91796112060547, 6.5826416015625]\n",
      "val [38.28219223022461, 6.573161602020264]\n",
      "predict val...\n",
      "predict test...\n",
      "120.47068 255.46886\n",
      "135.02332 255.46886 431.14014 1.0\n",
      "FOLD 308\n",
      "train [36.282718658447266, 6.492849826812744]\n",
      "val [47.88414764404297, 6.672613620758057]\n",
      "predict val...\n",
      "predict test...\n",
      "157.90782 226.81194\n",
      "108.85852 226.81194 495.3921 1.0\n",
      "FOLD 309\n",
      "train [39.98618698120117, 6.616036415100098]\n",
      "val [37.9586296081543, 6.5175461769104]\n",
      "predict val...\n",
      "predict test...\n",
      "126.20816 229.54794\n",
      "83.40692 229.54794 388.0254 1.0\n",
      "FOLD 310\n",
      "train [37.96962356567383, 6.556024074554443]\n",
      "val [42.701778411865234, 6.654051780700684]\n",
      "predict val...\n",
      "predict test...\n",
      "141.6023 235.45355\n",
      "105.14099 235.45355 401.07227 1.0\n",
      "FOLD 311\n",
      "train [37.656105041503906, 6.549046993255615]\n",
      "val [42.8576774597168, 6.780937194824219]\n",
      "predict val...\n",
      "predict test...\n",
      "141.04721 245.64241\n",
      "116.918335 245.64241 431.59668 1.0\n",
      "FOLD 312\n",
      "train [38.69344711303711, 6.584822654724121]\n",
      "val [38.45392608642578, 6.58349609375]\n",
      "predict val...\n",
      "predict test...\n",
      "120.408325 262.47943\n",
      "136.76941 262.47943 449.2666 1.0\n",
      "FOLD 313\n",
      "train [36.53414535522461, 6.501587867736816]\n",
      "val [49.03215789794922, 6.695893287658691]\n",
      "predict val...\n",
      "predict test...\n",
      "160.82222 232.27234\n",
      "109.659546 232.27234 497.02393 1.0\n",
      "FOLD 314\n",
      "train [40.64009475708008, 6.628787040710449]\n",
      "val [36.670955657958984, 6.513050079345703]\n",
      "predict val...\n",
      "predict test...\n",
      "122.60528 229.37067\n",
      "78.04004 229.37067 381.5735 1.0\n",
      "FOLD 315\n",
      "train [37.87519836425781, 6.5528564453125]\n",
      "val [41.70999526977539, 6.630453586578369]\n",
      "predict val...\n",
      "predict test...\n",
      "138.09341 236.4289\n",
      "116.255005 236.4289 396.0874 1.0\n",
      "FOLD 316\n",
      "train [38.04766082763672, 6.563647270202637]\n",
      "val [42.15419006347656, 6.761797904968262]\n",
      "predict val...\n",
      "predict test...\n",
      "138.2745 250.23106\n",
      "134.74792 250.23106 391.10254 1.0\n",
      "FOLD 317\n",
      "train [38.889034271240234, 6.584161281585693]\n",
      "val [38.927249908447266, 6.585206031799316]\n",
      "predict val...\n",
      "predict test...\n",
      "122.33113 257.4314\n",
      "137.03174 257.4314 434.78027 1.0\n",
      "FOLD 318\n",
      "train [36.37477111816406, 6.493973731994629]\n",
      "val [49.73255920410156, 6.6849775314331055]\n",
      "predict val...\n",
      "predict test...\n",
      "162.0907 225.70262\n",
      "107.37512 225.70262 462.21436 1.0\n",
      "FOLD 319\n",
      "train [39.75539016723633, 6.603185176849365]\n",
      "val [37.22792434692383, 6.480611324310303]\n",
      "predict val...\n",
      "predict test...\n",
      "123.15956 226.04759\n",
      "88.64093 226.04759 377.9131 1.0\n",
      "FOLD 320\n",
      "train [36.412803649902344, 6.517380714416504]\n",
      "val [42.101173400878906, 6.660096168518066]\n",
      "predict val...\n",
      "predict test...\n",
      "138.35698 226.9234\n",
      "124.84204 226.9234 322.19434 1.0\n",
      "FOLD 321\n",
      "train [38.23217010498047, 6.56276798248291]\n",
      "val [41.52006530761719, 6.725244998931885]\n",
      "predict val...\n",
      "predict test...\n",
      "136.57912 246.75961\n",
      "126.39978 246.75961 416.8921 1.0\n",
      "FOLD 322\n",
      "train [38.5877799987793, 6.582479000091553]\n",
      "val [39.06092071533203, 6.592928886413574]\n",
      "predict val...\n",
      "predict test...\n",
      "123.529236 257.70587\n",
      "139.0376 257.70587 430.02734 1.0\n",
      "FOLD 323\n",
      "train [36.2723274230957, 6.494626522064209]\n",
      "val [49.0248908996582, 6.68411922454834]\n",
      "predict val...\n",
      "predict test...\n",
      "160.07362 229.54436\n",
      "113.58057 229.54436 452.8081 1.0\n",
      "FOLD 324\n",
      "train [39.71391296386719, 6.600768089294434]\n",
      "val [37.04470443725586, 6.475621700286865]\n",
      "predict val...\n",
      "predict test...\n",
      "122.828255 225.4486\n",
      "91.76849 225.4486 368.64746 1.0\n",
      "FOLD 325\n",
      "train [36.97643280029297, 6.52569055557251]\n",
      "val [42.4439697265625, 6.658313751220703]\n",
      "predict val...\n",
      "predict test...\n",
      "141.38939 226.70663\n",
      "132.05566 226.70663 329.8203 1.0\n",
      "FOLD 326\n",
      "train [38.05073165893555, 6.563108921051025]\n",
      "val [41.985450744628906, 6.74589729309082]\n",
      "predict val...\n",
      "predict test...\n",
      "137.68193 248.71303\n",
      "125.41638 248.71303 420.12207 1.0\n",
      "FOLD 327\n",
      "train [39.50294494628906, 6.598304748535156]\n",
      "val [39.40571212768555, 6.623137950897217]\n",
      "predict val...\n",
      "predict test...\n",
      "126.111465 259.38315\n",
      "137.0664 259.38315 434.66553 1.0\n",
      "FOLD 328\n",
      "train [38.016700744628906, 6.5433502197265625]\n",
      "val [47.368690490722656, 6.707741737365723]\n",
      "predict val...\n",
      "predict test...\n",
      "155.08076 237.65987\n",
      "110.770386 237.65987 503.2544 1.0\n",
      "FOLD 329\n",
      "train [40.37169647216797, 6.618838310241699]\n",
      "val [37.620601654052734, 6.510137557983398]\n",
      "predict val...\n",
      "predict test...\n",
      "124.472694 225.74706\n",
      "78.384766 225.74706 371.11084 1.0\n",
      "FOLD 330\n",
      "train [37.66754913330078, 6.549577236175537]\n",
      "val [43.307220458984375, 6.66119909286499]\n",
      "predict val...\n",
      "predict test...\n",
      "143.77257 238.92259\n",
      "127.55121 238.92259 383.94824 1.0\n",
      "FOLD 331\n",
      "train [37.54293441772461, 6.539822578430176]\n",
      "val [43.0238151550293, 6.799291610717773]\n",
      "predict val...\n",
      "predict test...\n",
      "141.60413 240.67712\n",
      "135.65918 240.67712 389.5381 1.0\n",
      "FOLD 332\n",
      "train [37.93889617919922, 6.558160305023193]\n",
      "val [39.75018310546875, 6.628909111022949]\n",
      "predict val...\n",
      "predict test...\n",
      "126.50229 252.57843\n",
      "133.34302 252.57843 428.20703 1.0\n",
      "FOLD 333\n",
      "train [36.23826217651367, 6.492722511291504]\n",
      "val [47.24461364746094, 6.66093635559082]\n",
      "predict val...\n",
      "predict test...\n",
      "155.76674 227.3867\n",
      "118.14368 227.3867 463.50488 1.0\n",
      "FOLD 334\n",
      "train [39.68489456176758, 6.609744071960449]\n",
      "val [35.910255432128906, 6.486072063446045]\n",
      "predict val...\n",
      "predict test...\n",
      "119.54973 236.82991\n",
      "111.62561 236.82991 357.57764 1.0\n",
      "FOLD 335\n",
      "train [37.5072135925293, 6.547590732574463]\n",
      "val [43.46172332763672, 6.660200595855713]\n",
      "predict val...\n",
      "predict test...\n",
      "144.72047 237.69081\n",
      "147.83533 237.69081 366.26807 1.0\n",
      "FOLD 336\n",
      "train [38.815128326416016, 6.584790229797363]\n",
      "val [41.38115310668945, 6.713141441345215]\n",
      "predict val...\n",
      "predict test...\n",
      "138.00887 254.89508\n",
      "150.41858 254.89508 410.19922 1.0\n",
      "FOLD 337\n",
      "train [38.42229461669922, 6.582804203033447]\n",
      "val [39.53876876831055, 6.643220901489258]\n",
      "predict val...\n",
      "predict test...\n",
      "127.840775 258.32935\n",
      "144.38684 258.32935 424.36963 1.0\n",
      "FOLD 338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.62803268432617, 6.505090236663818]\n",
      "val [48.520965576171875, 6.700624465942383]\n",
      "predict val...\n",
      "predict test...\n",
      "159.68707 233.12404\n",
      "108.17139 233.12404 511.25928 1.0\n",
      "FOLD 339\n",
      "train [39.71244812011719, 6.606321811676025]\n",
      "val [36.27988815307617, 6.487943172454834]\n",
      "predict val...\n",
      "predict test...\n",
      "121.19297 233.7132\n",
      "112.23407 233.7132 360.7588 1.0\n",
      "FOLD 340\n",
      "train [37.479679107666016, 6.547454833984375]\n",
      "val [42.937313079833984, 6.6496124267578125]\n",
      "predict val...\n",
      "predict test...\n",
      "143.05775 238.40271\n",
      "157.3233 238.40271 307.1931 1.0\n",
      "FOLD 341\n",
      "train [39.53273391723633, 6.607241153717041]\n",
      "val [40.161102294921875, 6.595480918884277]\n",
      "predict val...\n",
      "predict test...\n",
      "130.48444 258.60403\n",
      "130.73438 258.60403 431.91943 1.0\n",
      "FOLD 342\n",
      "train [38.57987976074219, 6.5740966796875]\n",
      "val [39.55557632446289, 6.628781318664551]\n",
      "predict val...\n",
      "predict test...\n",
      "125.082985 253.18933\n",
      "141.81665 253.18933 418.38477 1.0\n",
      "FOLD 343\n",
      "train [36.37604522705078, 6.5037970542907715]\n",
      "val [47.74418640136719, 6.67191743850708]\n",
      "predict val...\n",
      "predict test...\n",
      "156.82216 232.12206\n",
      "132.00305 232.12206 436.58203 1.0\n",
      "FOLD 344\n",
      "train [38.70741653442383, 6.579930305480957]\n",
      "val [35.7449836730957, 6.465149402618408]\n",
      "predict val...\n",
      "predict test...\n",
      "119.84834 232.53186\n",
      "142.58423 232.53186 293.2495 1.0\n",
      "FOLD 345\n",
      "train [37.44001770019531, 6.547701835632324]\n",
      "val [42.37648010253906, 6.646950721740723]\n",
      "predict val...\n",
      "predict test...\n",
      "138.8646 237.90872\n",
      "153.66345 237.90872 329.32617 1.0\n",
      "FOLD 346\n",
      "train [37.94340896606445, 6.5580644607543945]\n",
      "val [42.408409118652344, 6.760112762451172]\n",
      "predict val...\n",
      "predict test...\n",
      "138.3952 249.092\n",
      "178.04688 249.092 324.16357 1.0\n",
      "FOLD 347\n",
      "train [38.517662048339844, 6.575401306152344]\n",
      "val [38.52685546875, 6.567218780517578]\n",
      "predict val...\n",
      "predict test...\n",
      "121.32586 254.11548\n",
      "153.22168 254.11548 409.5835 1.0\n",
      "FOLD 348\n",
      "train [36.431610107421875, 6.4986772537231445]\n",
      "val [48.16202163696289, 6.679218769073486]\n",
      "predict val...\n",
      "predict test...\n",
      "158.33337 227.96634\n",
      "119.26489 227.96634 445.10498 1.0\n",
      "FOLD 349\n",
      "train [40.322296142578125, 6.616389274597168]\n",
      "val [37.110591888427734, 6.499831199645996]\n",
      "predict val...\n",
      "predict test...\n",
      "123.28862 227.82718\n",
      "95.17688 227.82718 360.8003 1.0\n",
      "FOLD 350\n",
      "train [37.26353454589844, 6.544354438781738]\n",
      "val [43.80449676513672, 6.680562973022461]\n",
      "predict val...\n",
      "predict test...\n",
      "144.43224 234.16612\n",
      "128.18689 234.16612 381.01025 1.0\n",
      "FOLD 351\n",
      "train [43.10730743408203, 6.575386047363281]\n",
      "val [48.20386505126953, 6.796518325805664]\n",
      "predict val...\n",
      "predict test...\n",
      "140.73582 247.71017\n",
      "118.03906 247.71017 435.51855 1.0\n",
      "FOLD 352\n",
      "train [44.97794723510742, 6.6247878074646]\n",
      "val [44.3398551940918, 6.667056083679199]\n",
      "predict val...\n",
      "predict test...\n",
      "128.1859 264.44095\n",
      "128.40662 264.44095 452.79736 1.0\n",
      "FOLD 353\n",
      "train [41.54423522949219, 6.5391998291015625]\n",
      "val [53.03571319580078, 6.716343879699707]\n",
      "predict val...\n",
      "predict test...\n",
      "157.13423 246.25557\n",
      "105.128296 246.25557 552.5991 1.0\n",
      "FOLD 354\n",
      "train [46.38540267944336, 6.653564453125]\n",
      "val [43.869720458984375, 6.562814712524414]\n",
      "predict val...\n",
      "predict test...\n",
      "131.66078 235.11009\n",
      "74.801636 235.11009 395.25146 1.0\n",
      "FOLD 355\n",
      "train [43.5894775390625, 6.581067085266113]\n",
      "val [48.38109588623047, 6.68179988861084]\n",
      "predict val...\n",
      "predict test...\n",
      "142.51608 233.16837\n",
      "87.27307 233.16837 409.81836 1.0\n",
      "FOLD 356\n",
      "train [42.731407165527344, 6.56805419921875]\n",
      "val [47.354713439941406, 6.758176803588867]\n",
      "predict val...\n",
      "predict test...\n",
      "137.88786 248.41455\n",
      "118.94849 248.41455 435.4956 1.0\n",
      "FOLD 357\n",
      "train [43.51948165893555, 6.588263034820557]\n",
      "val [43.217445373535156, 6.589689254760742]\n",
      "predict val...\n",
      "predict test...\n",
      "121.35085 261.70703\n",
      "133.60608 261.70703 448.19678 1.0\n",
      "FOLD 358\n",
      "train [40.96498489379883, 6.512165069580078]\n",
      "val [53.711769104003906, 6.7054595947265625]\n",
      "predict val...\n",
      "predict test...\n",
      "157.63261 238.00636\n",
      "108.5271 238.00636 530.9082 1.0\n",
      "FOLD 359\n",
      "train [44.79924392700195, 6.621119499206543]\n",
      "val [42.3597297668457, 6.522293567657471]\n",
      "predict val...\n",
      "predict test...\n",
      "125.96061 234.05853\n",
      "90.43573 234.05853 390.2627 1.0\n",
      "FOLD 360\n",
      "train [42.25163650512695, 6.552386283874512]\n",
      "val [47.39584732055664, 6.649652481079102]\n",
      "predict val...\n",
      "predict test...\n",
      "140.7175 238.14093\n",
      "101.32831 238.14093 416.55762 1.0\n",
      "FOLD 361\n",
      "train [42.49861145019531, 6.566300868988037]\n",
      "val [47.82712173461914, 6.7762651443481445]\n",
      "predict val...\n",
      "predict test...\n",
      "139.66992 252.60359\n",
      "129.90503 252.60359 423.36328 1.0\n",
      "FOLD 362\n",
      "train [43.17145538330078, 6.584855556488037]\n",
      "val [43.190364837646484, 6.588727951049805]\n",
      "predict val...\n",
      "predict test...\n",
      "122.002495 259.8173\n",
      "142.11841 259.8173 436.63965 1.0\n",
      "FOLD 363\n",
      "train [41.268699645996094, 6.519903659820557]\n",
      "val [52.38768768310547, 6.6790266036987305]\n",
      "predict val...\n",
      "predict test...\n",
      "152.53406 234.72244\n",
      "110.151855 234.72244 517.7627 1.0\n",
      "FOLD 364\n",
      "train [44.58451843261719, 6.605448246002197]\n",
      "val [41.99863052368164, 6.495257377624512]\n",
      "predict val...\n",
      "predict test...\n",
      "124.96384 225.52336\n",
      "87.29852 225.52336 377.13525 1.0\n",
      "FOLD 365\n",
      "train [42.254852294921875, 6.552831172943115]\n",
      "val [47.1627311706543, 6.639425754547119]\n",
      "predict val...\n",
      "predict test...\n",
      "140.13437 237.39447\n",
      "105.58533 237.39447 414.90625 1.0\n",
      "FOLD 366\n",
      "train [42.324867248535156, 6.5563836097717285]\n",
      "val [47.540069580078125, 6.785670280456543]\n",
      "predict val...\n",
      "predict test...\n",
      "139.36491 249.90666\n",
      "126.49292 249.90666 424.5293 1.0\n",
      "FOLD 367\n",
      "train [42.99541473388672, 6.569587707519531]\n",
      "val [44.08158493041992, 6.613275527954102]\n",
      "predict val...\n",
      "predict test...\n",
      "124.62888 255.40437\n",
      "132.8595 255.40437 437.49316 1.0\n",
      "FOLD 368\n",
      "train [40.99037170410156, 6.507279872894287]\n",
      "val [54.77150344848633, 6.691608428955078]\n",
      "predict val...\n",
      "predict test...\n",
      "161.0428 230.8398\n",
      "109.43164 230.8398 503.2417 1.0\n",
      "FOLD 369\n",
      "train [44.5701904296875, 6.59973669052124]\n",
      "val [40.83600616455078, 6.471789360046387]\n",
      "predict val...\n",
      "predict test...\n",
      "121.56553 221.13776\n",
      "87.0495 221.13776 365.6875 1.0\n",
      "FOLD 370\n",
      "train [42.251224517822266, 6.551491737365723]\n",
      "val [47.82109069824219, 6.652475357055664]\n",
      "predict val...\n",
      "predict test...\n",
      "141.68617 236.71228\n",
      "132.05957 236.71228 378.48828 1.0\n",
      "FOLD 371\n",
      "train [42.469757080078125, 6.562655448913574]\n",
      "val [47.01948547363281, 6.7428131103515625]\n",
      "predict val...\n",
      "predict test...\n",
      "137.85332 250.1248\n",
      "141.55078 250.1248 400.20068 1.0\n",
      "FOLD 372\n",
      "train [42.86591720581055, 6.57126522064209]\n",
      "val [44.06398391723633, 6.597929954528809]\n",
      "predict val...\n",
      "predict test...\n",
      "124.28798 253.93251\n",
      "136.99011 253.93251 429.30615 1.0\n",
      "FOLD 373\n",
      "train [40.82966613769531, 6.501981258392334]\n",
      "val [54.710784912109375, 6.692262649536133]\n",
      "predict val...\n",
      "predict test...\n",
      "160.56924 230.54504\n",
      "119.30249 230.54504 461.29688 1.0\n",
      "FOLD 374\n",
      "train [44.09471130371094, 6.595865726470947]\n",
      "val [41.777156829833984, 6.491301536560059]\n",
      "predict val...\n",
      "predict test...\n",
      "123.86258 227.44612\n",
      "93.74036 227.44612 379.8047 1.0\n",
      "FOLD 375\n",
      "train [41.86610412597656, 6.540156364440918]\n",
      "val [48.6777229309082, 6.662219047546387]\n",
      "predict val...\n",
      "predict test...\n",
      "144.4566 235.18536\n",
      "123.56787 235.18536 397.45312 1.0\n",
      "FOLD 376\n",
      "train [43.60957717895508, 6.583451271057129]\n",
      "val [45.09241485595703, 6.598533630371094]\n",
      "predict val...\n",
      "predict test...\n",
      "131.25906 249.54364\n",
      "158.93994 249.54364 359.9458 1.0\n",
      "FOLD 377\n",
      "train [42.44340515136719, 6.5583953857421875]\n",
      "val [43.82173538208008, 6.6115312576293945]\n",
      "predict val...\n",
      "predict test...\n",
      "125.16405 249.1676\n",
      "143.1278 249.1676 409.79004 1.0\n",
      "FOLD 378\n",
      "train [40.58680725097656, 6.501097202301025]\n",
      "val [54.78600311279297, 6.693061828613281]\n",
      "predict val...\n",
      "predict test...\n",
      "160.51564 232.05016\n",
      "118.059326 232.05016 498.5454 1.0\n",
      "FOLD 379\n",
      "train [44.503108978271484, 6.598989963531494]\n",
      "val [41.9220085144043, 6.484748840332031]\n",
      "predict val...\n",
      "predict test...\n",
      "124.03555 224.28761\n",
      "92.995605 224.28761 364.55518 1.0\n",
      "FOLD 380\n",
      "train [40.93295669555664, 6.528362274169922]\n",
      "val [51.48775100708008, 6.719000816345215]\n",
      "predict val...\n",
      "predict test...\n",
      "151.71368 234.82736\n",
      "139.70728 234.82736 335.08105 1.0\n",
      "FOLD 381\n",
      "train [43.6271858215332, 6.585951328277588]\n",
      "val [45.46003341674805, 6.673055648803711]\n",
      "predict val...\n",
      "predict test...\n",
      "134.25388 252.04272\n",
      "126.45764 252.04272 427.51025 1.0\n",
      "FOLD 382\n",
      "train [43.37091064453125, 6.5832672119140625]\n",
      "val [43.12710952758789, 6.578335762023926]\n",
      "predict val...\n",
      "predict test...\n",
      "121.38219 257.31693\n",
      "148.2627 257.31693 423.5923 1.0\n",
      "FOLD 383\n",
      "train [40.79349899291992, 6.503836631774902]\n",
      "val [53.850563049316406, 6.683091163635254]\n",
      "predict val...\n",
      "predict test...\n",
      "158.07686 232.20316\n",
      "119.62622 232.20316 483.8999 1.0\n",
      "FOLD 384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [44.429473876953125, 6.599175453186035]\n",
      "val [41.68201446533203, 6.479660987854004]\n",
      "predict val...\n",
      "predict test...\n",
      "123.673195 225.2702\n",
      "90.808044 225.2702 367.27417 1.0\n",
      "FOLD 385\n",
      "train [41.75309371948242, 6.542014122009277]\n",
      "val [48.90201187133789, 6.666016578674316]\n",
      "predict val...\n",
      "predict test...\n",
      "145.5608 238.09566\n",
      "146.45044 238.09566 352.30713 1.0\n",
      "FOLD 386\n",
      "train [42.228919982910156, 6.550879001617432]\n",
      "val [47.26223373413086, 6.767679214477539]\n",
      "predict val...\n",
      "predict test...\n",
      "137.77081 244.5482\n",
      "167.41455 244.5482 330.4336 1.0\n",
      "FOLD 387\n",
      "train [42.93791961669922, 6.569808006286621]\n",
      "val [43.107147216796875, 6.579161167144775]\n",
      "predict val...\n",
      "predict test...\n",
      "121.73192 255.54507\n",
      "146.34924 255.54507 416.6831 1.0\n",
      "FOLD 388\n",
      "train [40.65068817138672, 6.50728702545166]\n",
      "val [53.850093841552734, 6.685758590698242]\n",
      "predict val...\n",
      "predict test...\n",
      "157.69336 234.97679\n",
      "137.44043 234.97679 436.70557 1.0\n",
      "FOLD 389\n",
      "train [45.48049545288086, 6.627776145935059]\n",
      "val [40.91827392578125, 6.509529113769531]\n",
      "predict val...\n",
      "predict test...\n",
      "122.45284 229.00056\n",
      "86.60663 229.00056 373.97388 1.0\n",
      "FOLD 390\n",
      "train [42.001773834228516, 6.55136251449585]\n",
      "val [48.409423828125, 6.657942771911621]\n",
      "predict val...\n",
      "predict test...\n",
      "142.60623 240.50702\n",
      "139.85614 240.50702 366.98242 1.0\n",
      "FOLD 391\n",
      "train [42.231143951416016, 6.55169677734375]\n",
      "val [46.24627685546875, 6.712245941162109]\n",
      "predict val...\n",
      "predict test...\n",
      "136.63998 247.9997\n",
      "137.94055 247.9997 395.2256 1.0\n",
      "FOLD 392\n",
      "train [42.61357498168945, 6.563809871673584]\n",
      "val [43.4420280456543, 6.582178115844727]\n",
      "predict val...\n",
      "predict test...\n",
      "123.398094 253.6366\n",
      "156.27759 253.6366 401.1416 1.0\n",
      "FOLD 393\n",
      "train [40.62142562866211, 6.5047478675842285]\n",
      "val [54.09577178955078, 6.682796001434326]\n",
      "predict val...\n",
      "predict test...\n",
      "158.64928 233.5273\n",
      "134.42859 233.5273 431.31396 1.0\n",
      "FOLD 394\n",
      "train [42.933048248291016, 6.572168827056885]\n",
      "val [42.32612991333008, 6.476335525512695]\n",
      "predict val...\n",
      "predict test...\n",
      "126.442726 226.87207\n",
      "113.971924 226.87207 335.61035 1.0\n",
      "FOLD 395\n",
      "train [43.111263275146484, 6.5638885498046875]\n",
      "val [47.562156677246094, 6.649277687072754]\n",
      "predict val...\n",
      "predict test...\n",
      "139.55751 236.63983\n",
      "111.45764 236.63983 389.58398 1.0\n",
      "FOLD 396\n",
      "train [42.353057861328125, 6.55727481842041]\n",
      "val [46.89503479003906, 6.748785018920898]\n",
      "predict val...\n",
      "predict test...\n",
      "137.48286 248.82866\n",
      "145.84143 248.82866 365.41064 1.0\n",
      "FOLD 397\n",
      "train [42.8779182434082, 6.574704647064209]\n",
      "val [43.68784713745117, 6.5920891761779785]\n",
      "predict val...\n",
      "predict test...\n",
      "123.67106 255.27332\n",
      "146.47363 255.27332 413.37256 1.0\n",
      "FOLD 398\n",
      "train [40.48080062866211, 6.500230312347412]\n",
      "val [54.099246978759766, 6.672851085662842]\n",
      "predict val...\n",
      "predict test...\n",
      "157.60985 228.66948\n",
      "162.46143 228.66948 305.01758 1.0\n",
      "FOLD 399\n",
      "train [45.55004119873047, 6.628785610198975]\n",
      "val [41.146759033203125, 6.516396522521973]\n",
      "predict val...\n",
      "predict test...\n",
      "122.93047 233.88936\n",
      "98.75891 233.88936 373.07715 1.0\n",
      "FOLD 400\n",
      "train [41.82301330566406, 6.5461745262146]\n",
      "val [48.21370315551758, 6.65739107131958]\n",
      "predict val...\n",
      "predict test...\n",
      "143.95885 238.23491\n",
      "137.94568 238.23491 368.0835 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 401\n",
      "train [29.35194969177246, 6.573301792144775]\n",
      "val [32.50211715698242, 6.7865142822265625]\n",
      "predict val...\n",
      "predict test...\n",
      "139.97504 246.27448\n",
      "115.0459 246.27448 437.93408 1.0\n",
      "FOLD 402\n",
      "train [29.491905212402344, 6.572484016418457]\n",
      "val [30.300113677978516, 6.622528076171875]\n",
      "predict val...\n",
      "predict test...\n",
      "125.89467 252.42023\n",
      "125.835815 252.42023 438.69434 1.0\n",
      "FOLD 403\n",
      "train [28.533235549926758, 6.527412414550781]\n",
      "val [37.714881896972656, 6.711165428161621]\n",
      "predict val...\n",
      "predict test...\n",
      "165.25975 233.22926\n",
      "106.937744 233.22926 527.49316 1.0\n",
      "FOLD 404\n",
      "train [31.402597427368164, 6.638070106506348]\n",
      "val [28.838937759399414, 6.520493507385254]\n",
      "predict val...\n",
      "predict test...\n",
      "126.37065 221.06606\n",
      "72.81128 221.06606 372.76416 1.0\n",
      "FOLD 405\n",
      "train [29.281160354614258, 6.560061454772949]\n",
      "val [32.31719970703125, 6.664579391479492]\n",
      "predict val...\n",
      "predict test...\n",
      "141.32184 228.33871\n",
      "93.361084 228.33871 404.2461 1.0\n",
      "FOLD 406\n",
      "train [28.8945255279541, 6.548619747161865]\n",
      "val [32.5056037902832, 6.766463279724121]\n",
      "predict val...\n",
      "predict test...\n",
      "140.8958 242.6788\n",
      "115.033936 242.6788 423.89697 1.0\n",
      "FOLD 407\n",
      "train [29.240966796875, 6.5667314529418945]\n",
      "val [29.656007766723633, 6.575890064239502]\n",
      "predict val...\n",
      "predict test...\n",
      "122.529396 249.57314\n",
      "138.85779 249.57314 416.13672 1.0\n",
      "FOLD 408\n",
      "train [27.912179946899414, 6.496793270111084]\n",
      "val [37.09988784790039, 6.678140640258789]\n",
      "predict val...\n",
      "predict test...\n",
      "161.61444 224.7388\n",
      "116.855225 224.7388 452.40332 1.0\n",
      "FOLD 409\n",
      "train [30.047870635986328, 6.593076229095459]\n",
      "val [28.673599243164062, 6.485138416290283]\n",
      "predict val...\n",
      "predict test...\n",
      "124.15014 224.16821\n",
      "90.564026 224.16821 368.33252 1.0\n",
      "FOLD 410\n",
      "train [28.84225082397461, 6.546608924865723]\n",
      "val [32.43259048461914, 6.6560139656066895]\n",
      "predict val...\n",
      "predict test...\n",
      "141.46063 235.26689\n",
      "109.20538 235.26689 402.44287 1.0\n",
      "FOLD 411\n",
      "train [28.703624725341797, 6.547021389007568]\n",
      "val [31.958606719970703, 6.749916076660156]\n",
      "predict val...\n",
      "predict test...\n",
      "138.47429 246.0535\n",
      "122.40869 246.0535 421.39453 1.0\n",
      "FOLD 412\n",
      "train [29.22117042541504, 6.570148468017578]\n",
      "val [29.531208038330078, 6.58720588684082]\n",
      "predict val...\n",
      "predict test...\n",
      "122.07707 255.83408\n",
      "134.98193 255.83408 435.91943 1.0\n",
      "FOLD 413\n",
      "train [27.6323299407959, 6.493448734283447]\n",
      "val [36.278751373291016, 6.672656536102295]\n",
      "predict val...\n",
      "predict test...\n",
      "158.0231 230.74509\n",
      "123.17627 230.74509 459.42236 1.0\n",
      "FOLD 414\n",
      "train [30.30382537841797, 6.602991580963135]\n",
      "val [28.201751708984375, 6.479192733764648]\n",
      "predict val...\n",
      "predict test...\n",
      "122.01144 226.14093\n",
      "85.872925 226.14093 376.85645 1.0\n",
      "FOLD 415\n",
      "train [28.757383346557617, 6.547616481781006]\n",
      "val [33.005714416503906, 6.67567777633667]\n",
      "predict val...\n",
      "predict test...\n",
      "143.98456 236.15315\n",
      "134.01514 236.15315 373.33252 1.0\n",
      "FOLD 416\n",
      "train [28.903167724609375, 6.550599098205566]\n",
      "val [31.622303009033203, 6.737116813659668]\n",
      "predict val...\n",
      "predict test...\n",
      "137.2323 243.87149\n",
      "129.17725 243.87149 402.95312 1.0\n",
      "FOLD 417\n",
      "train [28.951295852661133, 6.558097839355469]\n",
      "val [30.193912506103516, 6.6412353515625]\n",
      "predict val...\n",
      "predict test...\n",
      "127.29489 248.87675\n",
      "150.18604 248.87675 411.05273 1.0\n",
      "FOLD 418\n",
      "train [27.862895965576172, 6.496310234069824]\n",
      "val [36.49307632446289, 6.68549919128418]\n",
      "predict val...\n",
      "predict test...\n",
      "159.14229 227.61848\n",
      "115.543945 227.61848 460.64844 1.0\n",
      "FOLD 419\n",
      "train [30.29285430908203, 6.598514556884766]\n",
      "val [28.179445266723633, 6.473905563354492]\n",
      "predict val...\n",
      "predict test...\n",
      "122.228676 223.66212\n",
      "90.01257 223.66212 363.90283 1.0\n",
      "FOLD 420\n",
      "train [28.48863983154297, 6.5321149826049805]\n",
      "val [32.831886291503906, 6.658990859985352]\n",
      "predict val...\n",
      "predict test...\n",
      "144.19383 229.33392\n",
      "132.03296 229.33392 366.74365 1.0\n",
      "FOLD 421\n",
      "train [28.64575958251953, 6.54428243637085]\n",
      "val [32.069175720214844, 6.772813320159912]\n",
      "predict val...\n",
      "predict test...\n",
      "139.18474 248.34409\n",
      "148.61243 248.34409 372.8203 1.0\n",
      "FOLD 422\n",
      "train [29.332103729248047, 6.569652557373047]\n",
      "val [29.64495086669922, 6.585229873657227]\n",
      "predict val...\n",
      "predict test...\n",
      "122.8951 251.49622\n",
      "131.04126 251.49622 429.53613 1.0\n",
      "FOLD 423\n",
      "train [27.720849990844727, 6.505911350250244]\n",
      "val [36.1838493347168, 6.683631896972656]\n",
      "predict val...\n",
      "predict test...\n",
      "156.47546 236.19508\n",
      "154.80896 236.19508 287.16357 1.0\n",
      "FOLD 424\n",
      "train [29.985013961791992, 6.5961713790893555]\n",
      "val [28.2695255279541, 6.477352142333984]\n",
      "predict val...\n",
      "predict test...\n",
      "122.31759 225.89592\n",
      "91.388306 225.89592 371.75 1.0\n",
      "FOLD 425\n",
      "train [28.626482009887695, 6.544291019439697]\n",
      "val [33.62431335449219, 6.678369998931885]\n",
      "predict val...\n",
      "predict test...\n",
      "147.40436 236.71005\n",
      "161.72485 236.71005 323.9048 1.0\n",
      "FOLD 426\n",
      "train [28.80452537536621, 6.545584678649902]\n",
      "val [31.43370246887207, 6.718795299530029]\n",
      "predict val...\n",
      "predict test...\n",
      "136.80841 245.02179\n",
      "139.84668 245.02179 358.07324 1.0\n",
      "FOLD 427\n",
      "train [29.042678833007812, 6.561393737792969]\n",
      "val [29.682374954223633, 6.596972465515137]\n",
      "predict val...\n",
      "predict test...\n",
      "124.24286 248.60031\n",
      "154.32947 248.60031 402.07422 1.0\n",
      "FOLD 428\n",
      "train [27.927324295043945, 6.502179145812988]\n",
      "val [36.003265380859375, 6.674647331237793]\n",
      "predict val...\n",
      "predict test...\n",
      "156.94995 229.76978\n",
      "115.22925 229.76978 476.70264 1.0\n",
      "FOLD 429\n",
      "train [30.055335998535156, 6.595020294189453]\n",
      "val [28.494831085205078, 6.4899983406066895]\n",
      "predict val...\n",
      "predict test...\n",
      "123.56166 225.96437\n",
      "96.8374 225.96437 372.34473 1.0\n",
      "FOLD 430\n",
      "train [28.74765968322754, 6.5538530349731445]\n",
      "val [32.708866119384766, 6.654230117797852]\n",
      "predict val...\n",
      "predict test...\n",
      "142.01672 239.20976\n",
      "156.63342 239.20976 327.9956 1.0\n",
      "FOLD 431\n",
      "train [28.75404930114746, 6.551989555358887]\n",
      "val [32.15292739868164, 6.789078712463379]\n",
      "predict val...\n",
      "predict test...\n",
      "139.53003 248.19882\n",
      "142.00195 248.19882 394.91797 1.0\n",
      "FOLD 432\n",
      "train [29.128938674926758, 6.561922550201416]\n",
      "val [29.85103988647461, 6.590634346008301]\n",
      "predict val...\n",
      "predict test...\n",
      "124.51373 249.04524\n",
      "157.66125 249.04524 397.79443 1.0\n",
      "FOLD 433\n",
      "train [27.564462661743164, 6.488692283630371]\n",
      "val [36.013153076171875, 6.66808557510376]\n",
      "predict val...\n",
      "predict test...\n",
      "156.4601 224.22646\n",
      "145.37634 224.22646 391.49365 1.0\n",
      "FOLD 434\n",
      "train [29.98197364807129, 6.589195251464844]\n",
      "val [27.85378646850586, 6.466098785400391]\n",
      "predict val...\n",
      "predict test...\n",
      "120.98112 228.6052\n",
      "107.9469 228.6052 335.21436 1.0\n",
      "FOLD 435\n",
      "train [28.426149368286133, 6.543750762939453]\n",
      "val [32.76520919799805, 6.665691375732422]\n",
      "predict val...\n",
      "predict test...\n",
      "143.81169 240.67477\n",
      "154.35864 240.67477 331.78467 1.0\n",
      "FOLD 436\n",
      "train [28.446638107299805, 6.526827335357666]\n",
      "val [32.05851364135742, 6.733835697174072]\n",
      "predict val...\n",
      "predict test...\n",
      "139.59995 239.74242\n",
      "148.1925 239.74242 341.83887 1.0\n",
      "FOLD 437\n",
      "train [29.17693519592285, 6.565863609313965]\n",
      "val [29.255443572998047, 6.58242130279541]\n",
      "predict val...\n",
      "predict test...\n",
      "120.904625 254.66121\n",
      "151.578 254.66121 416.56348 1.0\n",
      "FOLD 438\n",
      "train [27.082412719726562, 6.4844489097595215]\n",
      "val [36.67766571044922, 6.718393325805664]\n",
      "predict val...\n",
      "predict test...\n",
      "159.46173 229.20033\n",
      "126.521484 229.20033 326.20215 1.0\n",
      "FOLD 439\n",
      "train [29.788108825683594, 6.587751865386963]\n",
      "val [28.8021240234375, 6.491273880004883]\n",
      "predict val...\n",
      "predict test...\n",
      "126.83764 232.009\n",
      "133.77692 232.009 335.3501 1.0\n",
      "FOLD 440\n",
      "train [28.709293365478516, 6.554676055908203]\n",
      "val [33.14927291870117, 6.674986839294434]\n",
      "predict val...\n",
      "predict test...\n",
      "144.70369 240.17896\n",
      "160.98792 240.17896 338.5503 1.0\n",
      "FOLD 441\n",
      "train [28.314332962036133, 6.524832248687744]\n",
      "val [32.516273498535156, 6.770512580871582]\n",
      "predict val...\n",
      "predict test...\n",
      "141.72447 242.92004\n",
      "155.33765 242.92004 321.46484 1.0\n",
      "FOLD 442\n",
      "train [29.16338539123535, 6.5631256103515625]\n",
      "val [29.759260177612305, 6.589015960693359]\n",
      "predict val...\n",
      "predict test...\n",
      "123.87414 251.42313\n",
      "152.76367 251.42313 408.98486 1.0\n",
      "FOLD 443\n",
      "train [27.78697967529297, 6.499591827392578]\n",
      "val [36.48253631591797, 6.674787521362305]\n",
      "predict val...\n",
      "predict test...\n",
      "158.942 228.28365\n",
      "143.76343 228.28365 395.12207 1.0\n",
      "FOLD 444\n",
      "train [30.22513198852539, 6.5972442626953125]\n",
      "val [28.46746253967285, 6.476723670959473]\n",
      "predict val...\n",
      "predict test...\n",
      "123.26614 224.68616\n",
      "93.65668 224.68616 364.74707 1.0\n",
      "FOLD 445\n",
      "train [28.656574249267578, 6.546801567077637]\n",
      "val [32.08211135864258, 6.641793251037598]\n",
      "predict val...\n",
      "predict test...\n",
      "139.92888 234.59909\n",
      "157.8695 234.59909 314.60864 1.0\n",
      "FOLD 446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [28.767629623413086, 6.543499946594238]\n",
      "val [32.5684814453125, 6.795211315155029]\n",
      "predict val...\n",
      "predict test...\n",
      "141.25146 243.33578\n",
      "143.24536 243.33578 355.1206 1.0\n",
      "FOLD 447\n",
      "train [28.881235122680664, 6.552000999450684]\n",
      "val [30.52457046508789, 6.634159088134766]\n",
      "predict val...\n",
      "predict test...\n",
      "129.01418 247.23601\n",
      "142.2207 247.23601 400.94434 1.0\n",
      "FOLD 448\n",
      "train [27.5093936920166, 6.486579895019531]\n",
      "val [36.53401565551758, 6.668519496917725]\n",
      "predict val...\n",
      "predict test...\n",
      "159.03021 224.25264\n",
      "153.58643 224.25264 350.22998 1.0\n",
      "FOLD 449\n",
      "train [30.20107078552246, 6.592765808105469]\n",
      "val [28.479053497314453, 6.473496437072754]\n",
      "predict val...\n",
      "predict test...\n",
      "123.72908 224.3777\n",
      "109.32971 224.3777 345.0459 1.0\n",
      "FOLD 450\n",
      "train [28.561519622802734, 6.548841953277588]\n",
      "val [32.99557113647461, 6.669678688049316]\n",
      "predict val...\n",
      "predict test...\n",
      "144.17061 239.70412\n",
      "167.82947 239.70412 339.58496 1.0\n",
      "FOLD 451\n",
      "train [33.91462707519531, 6.5649309158325195]\n",
      "val [37.913177490234375, 6.7969465255737305]\n",
      "predict val...\n",
      "predict test...\n",
      "139.79851 244.67905\n",
      "121.34131 244.67905 412.91602 1.0\n",
      "FOLD 452\n",
      "train [34.175838470458984, 6.580599784851074]\n",
      "val [34.54124450683594, 6.611832618713379]\n",
      "predict val...\n",
      "predict test...\n",
      "124.13724 255.89081\n",
      "128.18103 255.89081 440.62256 1.0\n",
      "FOLD 453\n",
      "train [32.34939193725586, 6.506957054138184]\n",
      "val [42.74614334106445, 6.68459415435791]\n",
      "predict val...\n",
      "predict test...\n",
      "159.75403 231.3308\n",
      "106.14172 231.3308 503.04932 1.0\n",
      "FOLD 454\n",
      "train [35.2978515625, 6.61373233795166]\n",
      "val [33.170955657958984, 6.498927593231201]\n",
      "predict val...\n",
      "predict test...\n",
      "125.95835 223.19864\n",
      "83.50336 223.19864 375.5044 1.0\n",
      "FOLD 455\n",
      "train [33.68408203125, 6.560031890869141]\n",
      "val [37.9823112487793, 6.671819686889648]\n",
      "predict val...\n",
      "predict test...\n",
      "143.11307 230.80336\n",
      "94.38245 230.80336 412.01562 1.0\n",
      "FOLD 456\n",
      "train [33.46883010864258, 6.557223320007324]\n",
      "val [37.429508209228516, 6.77548885345459]\n",
      "predict val...\n",
      "predict test...\n",
      "139.31877 247.5053\n",
      "125.829956 247.5053 423.23096 1.0\n",
      "FOLD 457\n",
      "train [33.9112434387207, 6.571179389953613]\n",
      "val [34.77772903442383, 6.632277965545654]\n",
      "predict val...\n",
      "predict test...\n",
      "125.51549 254.29507\n",
      "131.42322 254.29507 435.7959 1.0\n",
      "FOLD 458\n",
      "train [32.31240463256836, 6.502577304840088]\n",
      "val [42.53929138183594, 6.6771016120910645]\n",
      "predict val...\n",
      "predict test...\n",
      "159.68716 226.36935\n",
      "110.02588 226.36935 490.96338 1.0\n",
      "FOLD 459\n",
      "train [34.65184783935547, 6.597171783447266]\n",
      "val [33.22081756591797, 6.491089820861816]\n",
      "predict val...\n",
      "predict test...\n",
      "124.85806 227.17554\n",
      "90.72888 227.17554 380.99463 1.0\n",
      "FOLD 460\n",
      "train [33.45161056518555, 6.558226108551025]\n",
      "val [37.778411865234375, 6.6613078117370605]\n",
      "predict val...\n",
      "predict test...\n",
      "142.65762 239.07481\n",
      "106.611694 239.07481 410.8379 1.0\n",
      "FOLD 461\n",
      "train [33.18208694458008, 6.5537567138671875]\n",
      "val [37.39216613769531, 6.777118682861328]\n",
      "predict val...\n",
      "predict test...\n",
      "139.92073 251.45683\n",
      "128.69043 251.45683 425.28516 1.0\n",
      "FOLD 462\n",
      "train [33.798301696777344, 6.568352699279785]\n",
      "val [34.4421501159668, 6.6104512214660645]\n",
      "predict val...\n",
      "predict test...\n",
      "123.73122 255.91737\n",
      "140.26685 255.91737 434.05322 1.0\n",
      "FOLD 463\n",
      "train [31.2866153717041, 6.483399868011475]\n",
      "val [42.684024810791016, 6.708926677703857]\n",
      "predict val...\n",
      "predict test...\n",
      "159.90927 228.37021\n",
      "139.60303 228.37021 416.13623 1.0\n",
      "FOLD 464\n",
      "train [35.121604919433594, 6.608136177062988]\n",
      "val [32.64130783081055, 6.482170104980469]\n",
      "predict val...\n",
      "predict test...\n",
      "122.30074 228.75122\n",
      "87.22705 228.75122 382.01758 1.0\n",
      "FOLD 465\n",
      "train [32.792110443115234, 6.5290985107421875]\n",
      "val [37.49447250366211, 6.6548004150390625]\n",
      "predict val...\n",
      "predict test...\n",
      "141.46985 229.07594\n",
      "109.61609 229.07594 392.41943 1.0\n",
      "FOLD 466\n",
      "train [33.321346282958984, 6.5490875244140625]\n",
      "val [36.913543701171875, 6.734539985656738]\n",
      "predict val...\n",
      "predict test...\n",
      "138.18379 243.0937\n",
      "123.68213 243.0937 410.8003 1.0\n",
      "FOLD 467\n",
      "train [33.28336715698242, 6.551518440246582]\n",
      "val [34.937320709228516, 6.616402626037598]\n",
      "predict val...\n",
      "predict test...\n",
      "126.0738 246.7069\n",
      "136.74463 246.7069 414.54883 1.0\n",
      "FOLD 468\n",
      "train [32.0211296081543, 6.499500274658203]\n",
      "val [42.48481750488281, 6.683361530303955]\n",
      "predict val...\n",
      "predict test...\n",
      "159.20232 230.98015\n",
      "133.38342 230.98015 403.0254 1.0\n",
      "FOLD 469\n",
      "train [33.2822151184082, 6.564223289489746]\n",
      "val [32.34999465942383, 6.470908164978027]\n",
      "predict val...\n",
      "predict test...\n",
      "122.51336 220.00127\n",
      "90.81384 220.00127 359.06348 1.0\n",
      "FOLD 470\n",
      "train [32.595245361328125, 6.5276947021484375]\n",
      "val [37.73798370361328, 6.661792755126953]\n",
      "predict val...\n",
      "predict test...\n",
      "141.93582 227.95584\n",
      "111.789795 227.95584 366.48682 1.0\n",
      "FOLD 471\n",
      "train [33.123905181884766, 6.55157995223999]\n",
      "val [37.73242950439453, 6.802704811096191]\n",
      "predict val...\n",
      "predict test...\n",
      "141.25441 250.42683\n",
      "142.01721 250.42683 406.0835 1.0\n",
      "FOLD 472\n",
      "train [33.79004669189453, 6.569441795349121]\n",
      "val [33.91871643066406, 6.578392505645752]\n",
      "predict val...\n",
      "predict test...\n",
      "122.208084 251.19333\n",
      "145.55505 251.19333 415.70166 1.0\n",
      "FOLD 473\n",
      "train [31.597440719604492, 6.487898826599121]\n",
      "val [42.12422561645508, 6.667909622192383]\n",
      "predict val...\n",
      "predict test...\n",
      "156.72374 230.2913\n",
      "126.38208 230.2913 410.43262 1.0\n",
      "FOLD 474\n",
      "train [35.40260314941406, 6.612892150878906]\n",
      "val [32.79694747924805, 6.501185417175293]\n",
      "predict val...\n",
      "predict test...\n",
      "123.569496 225.95216\n",
      "87.03235 225.95216 364.92188 1.0\n",
      "FOLD 475\n",
      "train [32.95085525512695, 6.543051719665527]\n",
      "val [37.99501037597656, 6.655244827270508]\n",
      "predict val...\n",
      "predict test...\n",
      "143.02815 236.8109\n",
      "145.1471 236.8109 338.0835 1.0\n",
      "FOLD 476\n",
      "train [33.02448272705078, 6.5389862060546875]\n",
      "val [37.65812301635742, 6.767665863037109]\n",
      "predict val...\n",
      "predict test...\n",
      "141.40869 240.66037\n",
      "126.86865 240.66037 397.4131 1.0\n",
      "FOLD 477\n",
      "train [33.756629943847656, 6.567073822021484]\n",
      "val [34.09635925292969, 6.595992088317871]\n",
      "predict val...\n",
      "predict test...\n",
      "122.53529 253.11559\n",
      "154.37988 253.11559 417.01758 1.0\n",
      "FOLD 478\n",
      "train [32.190765380859375, 6.5034074783325195]\n",
      "val [41.82500076293945, 6.680487155914307]\n",
      "predict val...\n",
      "predict test...\n",
      "156.49358 230.33183\n",
      "122.63428 230.33183 475.29346 1.0\n",
      "FOLD 479\n",
      "train [34.90880584716797, 6.602142333984375]\n",
      "val [32.11572265625, 6.484465599060059]\n",
      "predict val...\n",
      "predict test...\n",
      "121.08136 234.97636\n",
      "116.54883 234.97636 335.0962 1.0\n",
      "FOLD 480\n",
      "train [33.133544921875, 6.5588507652282715]\n",
      "val [38.020599365234375, 6.66285514831543]\n",
      "predict val...\n",
      "predict test...\n",
      "141.9034 245.15572\n",
      "171.26758 245.15572 334.34595 1.0\n",
      "FOLD 481\n",
      "train [33.081581115722656, 6.546533107757568]\n",
      "val [36.94507598876953, 6.763891696929932]\n",
      "predict val...\n",
      "predict test...\n",
      "137.2896 245.112\n",
      "154.34204 245.112 350.30127 1.0\n",
      "FOLD 482\n",
      "train [32.631507873535156, 6.530582427978516]\n",
      "val [35.28443908691406, 6.581738471984863]\n",
      "predict val...\n",
      "predict test...\n",
      "127.32787 238.48575\n",
      "141.35132 238.48575 383.69824 1.0\n",
      "FOLD 483\n",
      "train [31.993806838989258, 6.5012526512146]\n",
      "val [42.63546371459961, 6.682430267333984]\n",
      "predict val...\n",
      "predict test...\n",
      "159.14745 229.32263\n",
      "145.41882 229.32263 374.09326 1.0\n",
      "FOLD 484\n",
      "train [34.63685607910156, 6.590756416320801]\n",
      "val [32.620113372802734, 6.486123085021973]\n",
      "predict val...\n",
      "predict test...\n",
      "123.9899 230.70297\n",
      "123.71924 230.70297 341.28613 1.0\n",
      "FOLD 485\n",
      "train [33.220149993896484, 6.552406311035156]\n",
      "val [38.02334976196289, 6.658782958984375]\n",
      "predict val...\n",
      "predict test...\n",
      "143.5514 237.6748\n",
      "154.68457 237.6748 322.17383 1.0\n",
      "FOLD 486\n",
      "train [33.313819885253906, 6.554145812988281]\n",
      "val [37.498111724853516, 6.792276382446289]\n",
      "predict val...\n",
      "predict test...\n",
      "139.25668 248.12375\n",
      "145.5498 248.12375 360.1621 1.0\n",
      "FOLD 487\n",
      "train [33.602569580078125, 6.572621822357178]\n",
      "val [34.17890548706055, 6.598060607910156]\n",
      "predict val...\n",
      "predict test...\n",
      "122.962364 258.96463\n",
      "151.69604 258.96463 415.3623 1.0\n",
      "FOLD 488\n",
      "train [30.816158294677734, 6.464936256408691]\n",
      "val [42.652008056640625, 6.688417911529541]\n",
      "predict val...\n",
      "predict test...\n",
      "158.85635 226.45125\n",
      "145.35669 226.45125 341.98926 1.0\n",
      "FOLD 489\n",
      "train [33.616607666015625, 6.565138816833496]\n",
      "val [32.283546447753906, 6.474041938781738]\n",
      "predict val...\n",
      "predict test...\n",
      "122.02809 221.69075\n",
      "96.25342 221.69075 341.66113 1.0\n",
      "FOLD 490\n",
      "train [32.965396881103516, 6.547172546386719]\n",
      "val [38.613433837890625, 6.6673126220703125]\n",
      "predict val...\n",
      "predict test...\n",
      "145.2053 238.38788\n",
      "156.95581 238.38788 325.8037 1.0\n",
      "FOLD 491\n",
      "train [32.738155364990234, 6.531919956207275]\n",
      "val [38.2436408996582, 6.822120666503906]\n",
      "predict val...\n",
      "predict test...\n",
      "142.8878 244.6864\n",
      "154.35535 244.6864 350.92432 1.0\n",
      "FOLD 492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [33.7202262878418, 6.567330360412598]\n",
      "val [34.148529052734375, 6.5937652587890625]\n",
      "predict val...\n",
      "predict test...\n",
      "122.787895 252.72455\n",
      "155.06335 252.72455 405.28223 1.0\n",
      "FOLD 493\n",
      "train [31.940563201904297, 6.502850532531738]\n",
      "val [42.49043655395508, 6.680015563964844]\n",
      "predict val...\n",
      "predict test...\n",
      "158.50601 232.09406\n",
      "169.3175 232.09406 289.9375 1.0\n",
      "FOLD 494\n",
      "train [33.7178955078125, 6.573736667633057]\n",
      "val [32.00065612792969, 6.505863666534424]\n",
      "predict val...\n",
      "predict test...\n",
      "123.15795 232.69344\n",
      "132.44116 232.69344 296.69873 1.0\n",
      "FOLD 495\n",
      "train [33.00218963623047, 6.542784214019775]\n",
      "val [37.75812530517578, 6.661246299743652]\n",
      "predict val...\n",
      "predict test...\n",
      "143.21803 237.1859\n",
      "139.57336 237.1859 371.73828 1.0\n",
      "FOLD 496\n",
      "train [32.826045989990234, 6.5301408767700195]\n",
      "val [36.70778274536133, 6.73881196975708]\n",
      "predict val...\n",
      "predict test...\n",
      "136.15292 238.43289\n",
      "162.37146 238.43289 291.93213 1.0\n",
      "FOLD 497\n",
      "train [33.259525299072266, 6.549699306488037]\n",
      "val [35.66950607299805, 6.6567277908325195]\n",
      "predict val...\n",
      "predict test...\n",
      "130.83784 243.75723\n",
      "164.50537 243.75723 372.45068 1.0\n",
      "FOLD 498\n",
      "train [31.574785232543945, 6.483271598815918]\n",
      "val [43.09172439575195, 6.681922912597656]\n",
      "predict val...\n",
      "predict test...\n",
      "161.12195 226.31052\n",
      "137.64453 226.31052 363.6211 1.0\n",
      "FOLD 499\n",
      "train [33.07786178588867, 6.5423078536987305]\n",
      "val [31.96767234802246, 6.429060935974121]\n",
      "predict val...\n",
      "predict test...\n",
      "119.910934 226.7143\n",
      "140.59583 226.7143 292.61304 1.0\n",
      "FOLD 500\n",
      "train [33.233097076416016, 6.550317287445068]\n",
      "val [37.39299011230469, 6.638706207275391]\n",
      "predict val...\n",
      "predict test...\n",
      "141.3989 235.79196\n",
      "140.94421 235.79196 312.16016 1.0\n",
      "FOLD 501\n",
      "train [38.13169860839844, 6.565202236175537]\n",
      "val [42.0924186706543, 6.766904830932617]\n",
      "predict val...\n",
      "predict test...\n",
      "137.85138 249.36836\n",
      "122.58301 249.36836 435.51514 1.0\n",
      "FOLD 502\n",
      "train [38.743553161621094, 6.573758602142334]\n",
      "val [39.26844787597656, 6.589282512664795]\n",
      "predict val...\n",
      "predict test...\n",
      "123.50831 250.95929\n",
      "134.44385 250.95929 428.85986 1.0\n",
      "FOLD 503\n",
      "train [37.350791931152344, 6.530377388000488]\n",
      "val [49.122955322265625, 6.71190071105957]\n",
      "predict val...\n",
      "predict test...\n",
      "161.82605 236.99414\n",
      "104.53662 236.99414 530.042 1.0\n",
      "FOLD 504\n",
      "train [40.02375411987305, 6.610240936279297]\n",
      "val [37.398075103759766, 6.494821548461914]\n",
      "predict val...\n",
      "predict test...\n",
      "125.19491 223.07709\n",
      "86.53833 223.07709 376.03662 1.0\n",
      "FOLD 505\n",
      "train [38.24424743652344, 6.566954135894775]\n",
      "val [42.466670989990234, 6.667332649230957]\n",
      "predict val...\n",
      "predict test...\n",
      "141.4583 238.05013\n",
      "111.318726 238.05013 412.09326 1.0\n",
      "FOLD 506\n",
      "train [38.055641174316406, 6.561089992523193]\n",
      "val [42.800819396972656, 6.777320384979248]\n",
      "predict val...\n",
      "predict test...\n",
      "140.06541 248.20633\n",
      "116.28882 248.20633 433.23828 1.0\n",
      "FOLD 507\n",
      "train [38.39822006225586, 6.566075325012207]\n",
      "val [39.409610748291016, 6.6002068519592285]\n",
      "predict val...\n",
      "predict test...\n",
      "124.332146 250.23952\n",
      "129.3153 250.23952 431.05176 1.0\n",
      "FOLD 508\n",
      "train [36.58584213256836, 6.496432304382324]\n",
      "val [49.32426452636719, 6.685580253601074]\n",
      "predict val...\n",
      "predict test...\n",
      "161.85416 222.20496\n",
      "105.43689 222.20496 476.49365 1.0\n",
      "FOLD 509\n",
      "train [39.824302673339844, 6.613226413726807]\n",
      "val [36.4967041015625, 6.49259090423584]\n",
      "predict val...\n",
      "predict test...\n",
      "121.57891 232.02202\n",
      "96.20117 232.02202 376.68555 1.0\n",
      "FOLD 510\n",
      "train [37.53495788574219, 6.545129299163818]\n",
      "val [42.694480895996094, 6.649067401885986]\n",
      "predict val...\n",
      "predict test...\n",
      "141.75261 236.86555\n",
      "134.86285 236.86555 377.89307 1.0\n",
      "FOLD 511\n",
      "train [37.94194030761719, 6.559553623199463]\n",
      "val [42.5828742980957, 6.771596908569336]\n",
      "predict val...\n",
      "predict test...\n",
      "140.26357 249.64287\n",
      "124.10901 249.64287 429.19824 1.0\n",
      "FOLD 512\n",
      "train [38.47237777709961, 6.5735297203063965]\n",
      "val [38.615421295166016, 6.583632469177246]\n",
      "predict val...\n",
      "predict test...\n",
      "121.29849 257.64178\n",
      "135.8247 257.64178 437.71924 1.0\n",
      "FOLD 513\n",
      "train [36.21585464477539, 6.49770975112915]\n",
      "val [48.17634201049805, 6.687832832336426]\n",
      "predict val...\n",
      "predict test...\n",
      "158.83673 231.47942\n",
      "120.93396 231.47942 457.88135 1.0\n",
      "FOLD 514\n",
      "train [40.48326873779297, 6.623281002044678]\n",
      "val [37.05667495727539, 6.506821632385254]\n",
      "predict val...\n",
      "predict test...\n",
      "123.58618 227.51573\n",
      "78.476746 227.51573 378.17236 1.0\n",
      "FOLD 515\n",
      "train [37.064598083496094, 6.528401851654053]\n",
      "val [44.70309829711914, 6.673593044281006]\n",
      "predict val...\n",
      "predict test...\n",
      "147.83311 229.82283\n",
      "128.32104 229.82283 342.20166 1.0\n",
      "FOLD 516\n",
      "train [37.76344299316406, 6.555311679840088]\n",
      "val [41.827728271484375, 6.746622085571289]\n",
      "predict val...\n",
      "predict test...\n",
      "137.78076 248.83456\n",
      "126.988525 248.83456 420.55322 1.0\n",
      "FOLD 517\n",
      "train [38.23915481567383, 6.564084053039551]\n",
      "val [39.3242073059082, 6.602306365966797]\n",
      "predict val...\n",
      "predict test...\n",
      "124.792816 253.22313\n",
      "145.38501 253.22313 420.06543 1.0\n",
      "FOLD 518\n",
      "train [36.59638595581055, 6.504307746887207]\n",
      "val [48.81275177001953, 6.693883895874023]\n",
      "predict val...\n",
      "predict test...\n",
      "161.12436 231.02493\n",
      "110.765015 231.02493 488.56885 1.0\n",
      "FOLD 519\n",
      "train [39.208717346191406, 6.597962856292725]\n",
      "val [37.91231155395508, 6.508391380310059]\n",
      "predict val...\n",
      "predict test...\n",
      "126.35856 229.75012\n",
      "98.97827 229.75012 378.40088 1.0\n",
      "FOLD 520\n",
      "train [37.75929641723633, 6.54580020904541]\n",
      "val [42.036373138427734, 6.62718391418457]\n",
      "predict val...\n",
      "predict test...\n",
      "139.70868 233.05522\n",
      "110.87463 233.05522 399.93848 1.0\n",
      "FOLD 521\n",
      "train [37.3066520690918, 6.546353816986084]\n",
      "val [42.09723663330078, 6.759298324584961]\n",
      "predict val...\n",
      "predict test...\n",
      "138.79408 250.73117\n",
      "159.47693 250.73117 367.1416 1.0\n",
      "FOLD 522\n",
      "train [38.159061431884766, 6.566699028015137]\n",
      "val [38.72220230102539, 6.58612060546875]\n",
      "predict val...\n",
      "predict test...\n",
      "122.76869 253.50229\n",
      "144.88135 253.50229 412.52344 1.0\n",
      "FOLD 523\n",
      "train [36.426910400390625, 6.502839088439941]\n",
      "val [48.36030578613281, 6.692501068115234]\n",
      "predict val...\n",
      "predict test...\n",
      "159.11874 232.66501\n",
      "116.65674 232.66501 479.042 1.0\n",
      "FOLD 524\n",
      "train [39.31194305419922, 6.594254493713379]\n",
      "val [37.236690521240234, 6.481678009033203]\n",
      "predict val...\n",
      "predict test...\n",
      "123.40177 226.80273\n",
      "95.70172 226.80273 370.9668 1.0\n",
      "FOLD 525\n",
      "train [37.35528564453125, 6.547077178955078]\n",
      "val [44.17854690551758, 6.685667991638184]\n",
      "predict val...\n",
      "predict test...\n",
      "146.63145 241.86478\n",
      "169.75354 241.86478 330.13037 1.0\n",
      "FOLD 526\n",
      "train [38.0265007019043, 6.561912536621094]\n",
      "val [41.97849655151367, 6.7456865310668945]\n",
      "predict val...\n",
      "predict test...\n",
      "137.82156 248.5136\n",
      "127.46423 248.5136 415.28955 1.0\n",
      "FOLD 527\n",
      "train [38.124210357666016, 6.5600996017456055]\n",
      "val [39.4828987121582, 6.616239070892334]\n",
      "predict val...\n",
      "predict test...\n",
      "125.183174 248.68735\n",
      "139.70325 248.68735 416.76025 1.0\n",
      "FOLD 528\n",
      "train [34.725791931152344, 6.464454650878906]\n",
      "val [50.77790069580078, 6.781352996826172]\n",
      "predict val...\n",
      "predict test...\n",
      "164.10083 224.14908\n",
      "64.56616 224.14908 270.0415 1.0\n",
      "FOLD 529\n",
      "train [39.1256217956543, 6.594341278076172]\n",
      "val [37.90901565551758, 6.505337238311768]\n",
      "predict val...\n",
      "predict test...\n",
      "126.92824 232.84782\n",
      "111.00604 232.84782 362.39844 1.0\n",
      "FOLD 530\n",
      "train [37.66119384765625, 6.555081844329834]\n",
      "val [43.17258071899414, 6.658284664154053]\n",
      "predict val...\n",
      "predict test...\n",
      "142.72336 241.8667\n",
      "138.51813 241.8667 355.10645 1.0\n",
      "FOLD 531\n",
      "train [37.18257522583008, 6.538527011871338]\n",
      "val [42.19918441772461, 6.768503189086914]\n",
      "predict val...\n",
      "predict test...\n",
      "139.27388 250.97408\n",
      "159.70215 250.97408 349.92578 1.0\n",
      "FOLD 532\n",
      "train [38.09219741821289, 6.559652805328369]\n",
      "val [39.46672439575195, 6.606980323791504]\n",
      "predict val...\n",
      "predict test...\n",
      "125.794395 247.72699\n",
      "154.6731 247.72699 392.7539 1.0\n",
      "FOLD 533\n",
      "train [34.035301208496094, 6.430142402648926]\n",
      "val [48.01567840576172, 6.658642768859863]\n",
      "predict val...\n",
      "predict test...\n",
      "156.00362 214.43126\n",
      "122.9812 214.43126 356.6172 1.0\n",
      "FOLD 534\n",
      "train [39.70750427246094, 6.599058628082275]\n",
      "val [37.108036041259766, 6.480506896972656]\n",
      "predict val...\n",
      "predict test...\n",
      "123.032455 225.87933\n",
      "95.572266 225.87933 366.19385 1.0\n",
      "FOLD 535\n",
      "train [36.95130920410156, 6.531976222991943]\n",
      "val [45.067623138427734, 6.678930282592773]\n",
      "predict val...\n",
      "predict test...\n",
      "149.55519 233.73285\n",
      "141.71967 233.73285 313.56396 1.0\n",
      "FOLD 536\n",
      "train [37.346649169921875, 6.546222686767578]\n",
      "val [41.88311004638672, 6.75984001159668]\n",
      "predict val...\n",
      "predict test...\n",
      "137.66011 248.6761\n",
      "164.7832 248.6761 313.93164 1.0\n",
      "FOLD 537\n",
      "train [38.281517028808594, 6.5693511962890625]\n",
      "val [38.808589935302734, 6.599079608917236]\n",
      "predict val...\n",
      "predict test...\n",
      "122.853294 256.25888\n",
      "153.86182 256.25888 419.95996 1.0\n",
      "FOLD 538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.31795120239258, 6.511135101318359]\n",
      "val [47.901893615722656, 6.681687355041504]\n",
      "predict val...\n",
      "predict test...\n",
      "157.32495 236.77713\n",
      "163.28247 236.77713 348.97998 1.0\n",
      "FOLD 539\n",
      "train [39.19404220581055, 6.591526031494141]\n",
      "val [37.732662200927734, 6.491692066192627]\n",
      "predict val...\n",
      "predict test...\n",
      "125.75219 231.49048\n",
      "114.533936 231.49048 349.55225 1.0\n",
      "FOLD 540\n",
      "train [37.48112869262695, 6.5475568771362305]\n",
      "val [42.70868682861328, 6.653207302093506]\n",
      "predict val...\n",
      "predict test...\n",
      "141.53697 238.27661\n",
      "158.40808 238.27661 315.54932 1.0\n",
      "FOLD 541\n",
      "train [37.47997283935547, 6.544554233551025]\n",
      "val [42.34761047363281, 6.781294822692871]\n",
      "predict val...\n",
      "predict test...\n",
      "139.32434 249.08704\n",
      "173.11304 249.08704 320.54346 1.0\n",
      "FOLD 542\n",
      "train [38.25630187988281, 6.569862365722656]\n",
      "val [38.5364875793457, 6.576104164123535]\n",
      "predict val...\n",
      "predict test...\n",
      "121.48746 255.59619\n",
      "162.0188 255.59619 409.8369 1.0\n",
      "FOLD 543\n",
      "train [36.04108428955078, 6.494297981262207]\n",
      "val [49.08309555053711, 6.666608810424805]\n",
      "predict val...\n",
      "predict test...\n",
      "160.89098 228.43933\n",
      "140.68054 228.43933 417.39844 1.0\n",
      "FOLD 544\n",
      "train [40.575252532958984, 6.623641014099121]\n",
      "val [36.148582458496094, 6.501008987426758]\n",
      "predict val...\n",
      "predict test...\n",
      "120.69955 229.17767\n",
      "92.310425 229.17767 365.56494 1.0\n",
      "FOLD 545\n",
      "train [37.24515151977539, 6.542250156402588]\n",
      "val [42.75537109375, 6.654752731323242]\n",
      "predict val...\n",
      "predict test...\n",
      "141.1733 237.9514\n",
      "158.85376 237.9514 320.00342 1.0\n",
      "FOLD 546\n",
      "train [37.61027526855469, 6.5493316650390625]\n",
      "val [42.57486343383789, 6.803457260131836]\n",
      "predict val...\n",
      "predict test...\n",
      "140.67111 248.24376\n",
      "141.32983 248.24376 397.07568 1.0\n",
      "FOLD 547\n",
      "train [37.045066833496094, 6.5301032066345215]\n",
      "val [40.98982238769531, 6.635835647583008]\n",
      "predict val...\n",
      "predict test...\n",
      "132.25839 239.48532\n",
      "143.02539 239.48532 384.1084 1.0\n",
      "FOLD 548\n",
      "train [35.9086799621582, 6.489463806152344]\n",
      "val [48.086769104003906, 6.666626930236816]\n",
      "predict val...\n",
      "predict test...\n",
      "158.05984 228.6835\n",
      "147.58533 228.6835 351.57617 1.0\n",
      "FOLD 549\n",
      "train [39.61199188232422, 6.60584020614624]\n",
      "val [35.736717224121094, 6.492816925048828]\n",
      "predict val...\n",
      "predict test...\n",
      "120.62172 233.24033\n",
      "120.69812 233.24033 358.30176 1.0\n",
      "FOLD 550\n",
      "train [37.218143463134766, 6.545127868652344]\n",
      "val [43.43051528930664, 6.663516044616699]\n",
      "predict val...\n",
      "predict test...\n",
      "143.55357 238.72607\n",
      "157.31079 238.72607 321.3203 1.0\n",
      "FOLD 551\n",
      "train [43.17694091796875, 6.5748395919799805]\n",
      "val [48.41353988647461, 6.803776741027832]\n",
      "predict val...\n",
      "predict test...\n",
      "140.66629 245.68738\n",
      "112.543945 245.68738 439.1167 1.0\n",
      "FOLD 552\n",
      "train [43.65089797973633, 6.591894626617432]\n",
      "val [44.16812515258789, 6.609824180603027]\n",
      "predict val...\n",
      "predict test...\n",
      "124.09613 259.7281\n",
      "128.82214 259.7281 449.67627 1.0\n",
      "FOLD 553\n",
      "train [41.553009033203125, 6.531363010406494]\n",
      "val [54.49553298950195, 6.709939002990723]\n",
      "predict val...\n",
      "predict test...\n",
      "160.94316 241.01051\n",
      "106.02197 241.01051 545.0054 1.0\n",
      "FOLD 554\n",
      "train [45.00572204589844, 6.615736961364746]\n",
      "val [41.8570671081543, 6.499058723449707]\n",
      "predict val...\n",
      "predict test...\n",
      "125.439064 222.09439\n",
      "79.53125 222.09439 373.562 1.0\n",
      "FOLD 555\n",
      "train [42.898895263671875, 6.5686211585998535]\n",
      "val [48.03243637084961, 6.67408561706543]\n",
      "predict val...\n",
      "predict test...\n",
      "142.15176 234.08922\n",
      "95.56799 234.08922 414.49316 1.0\n",
      "FOLD 556\n",
      "train [42.532188415527344, 6.5592041015625]\n",
      "val [46.84420394897461, 6.758577346801758]\n",
      "predict val...\n",
      "predict test...\n",
      "137.51038 245.83789\n",
      "119.987305 245.83789 426.76025 1.0\n",
      "FOLD 557\n",
      "train [43.01188659667969, 6.566916465759277]\n",
      "val [44.06207275390625, 6.613800048828125]\n",
      "predict val...\n",
      "predict test...\n",
      "124.87515 250.71707\n",
      "129.55664 250.71707 431.49854 1.0\n",
      "FOLD 558\n",
      "train [41.15592575073242, 6.506883144378662]\n",
      "val [54.927982330322266, 6.681367874145508]\n",
      "predict val...\n",
      "predict test...\n",
      "160.48724 228.0346\n",
      "109.22742 228.0346 498.8452 1.0\n",
      "FOLD 559\n",
      "train [45.59901809692383, 6.63387393951416]\n",
      "val [41.877681732177734, 6.527279376983643]\n",
      "predict val...\n",
      "predict test...\n",
      "125.193146 233.10785\n",
      "85.56732 233.10785 385.92114 1.0\n",
      "FOLD 560\n",
      "train [42.344703674316406, 6.552372932434082]\n",
      "val [48.09132385253906, 6.66358757019043]\n",
      "predict val...\n",
      "predict test...\n",
      "142.27888 237.42584\n",
      "104.1001 237.42584 413.77148 1.0\n",
      "FOLD 561\n",
      "train [42.69379425048828, 6.566854953765869]\n",
      "val [46.77469253540039, 6.733976364135742]\n",
      "predict val...\n",
      "predict test...\n",
      "137.24329 250.98479\n",
      "121.011475 250.98479 435.14648 1.0\n",
      "FOLD 562\n",
      "train [42.72164535522461, 6.570345878601074]\n",
      "val [43.562347412109375, 6.592216968536377]\n",
      "predict val...\n",
      "predict test...\n",
      "123.00863 256.44586\n",
      "147.0686 256.44586 428.01172 1.0\n",
      "FOLD 563\n",
      "train [40.901893615722656, 6.506519317626953]\n",
      "val [54.56517028808594, 6.698977470397949]\n",
      "predict val...\n",
      "predict test...\n",
      "160.11118 235.01384\n",
      "108.690186 235.01384 518.6719 1.0\n",
      "FOLD 564\n",
      "train [45.23563766479492, 6.617528438568115]\n",
      "val [41.34235382080078, 6.500015735626221]\n",
      "predict val...\n",
      "predict test...\n",
      "123.584045 224.49875\n",
      "84.89673 224.49875 367.57422 1.0\n",
      "FOLD 565\n",
      "train [42.062904357910156, 6.548691749572754]\n",
      "val [48.7900505065918, 6.659564971923828]\n",
      "predict val...\n",
      "predict test...\n",
      "143.90085 237.45885\n",
      "118.45764 237.45885 403.55908 1.0\n",
      "FOLD 566\n",
      "train [42.08183670043945, 6.552115440368652]\n",
      "val [47.2590446472168, 6.75968074798584]\n",
      "predict val...\n",
      "predict test...\n",
      "139.00336 247.70982\n",
      "123.76367 247.70982 427.72607 1.0\n",
      "FOLD 567\n",
      "train [42.54528045654297, 6.560730934143066]\n",
      "val [44.51485824584961, 6.627269744873047]\n",
      "predict val...\n",
      "predict test...\n",
      "126.440475 248.70998\n",
      "133.90674 248.70998 419.70215 1.0\n",
      "FOLD 568\n",
      "train [40.82283020019531, 6.5046234130859375]\n",
      "val [54.77690505981445, 6.692422866821289]\n",
      "predict val...\n",
      "predict test...\n",
      "160.6973 231.06845\n",
      "120.36401 231.06845 472.29785 1.0\n",
      "FOLD 569\n",
      "train [44.331634521484375, 6.604574680328369]\n",
      "val [40.49805450439453, 6.49252986907959]\n",
      "predict val...\n",
      "predict test...\n",
      "121.15421 236.51886\n",
      "114.69568 236.51886 354.44678 1.0\n",
      "FOLD 570\n",
      "train [41.85552215576172, 6.5449934005737305]\n",
      "val [47.8338623046875, 6.646170616149902]\n",
      "predict val...\n",
      "predict test...\n",
      "142.1244 236.57939\n",
      "150.08972 236.57939 343.62598 1.0\n",
      "FOLD 571\n",
      "train [41.91855239868164, 6.547774314880371]\n",
      "val [46.7386360168457, 6.752809524536133]\n",
      "predict val...\n",
      "predict test...\n",
      "138.0104 249.78925\n",
      "159.87805 249.78925 373.2788 1.0\n",
      "FOLD 572\n",
      "train [42.388736724853516, 6.559750556945801]\n",
      "val [43.767234802246094, 6.598211765289307]\n",
      "predict val...\n",
      "predict test...\n",
      "124.63668 252.01791\n",
      "137.7522 252.01791 425.79492 1.0\n",
      "FOLD 573\n",
      "train [40.24635314941406, 6.494694709777832]\n",
      "val [54.86082077026367, 6.688917636871338]\n",
      "predict val...\n",
      "predict test...\n",
      "159.56514 231.03654\n",
      "125.01648 231.03654 443.2837 1.0\n",
      "FOLD 574\n",
      "train [44.46563720703125, 6.6094160079956055]\n",
      "val [40.42182922363281, 6.487786293029785]\n",
      "predict val...\n",
      "predict test...\n",
      "120.444145 231.66791\n",
      "99.18469 231.66791 374.35547 1.0\n",
      "FOLD 575\n",
      "train [42.04556655883789, 6.548182487487793]\n",
      "val [47.52033233642578, 6.645347595214844]\n",
      "predict val...\n",
      "predict test...\n",
      "140.30594 238.1761\n",
      "138.70752 238.1761 358.04248 1.0\n",
      "FOLD 576\n",
      "train [41.204647064208984, 6.518437385559082]\n",
      "val [46.08798599243164, 6.686593055725098]\n",
      "predict val...\n",
      "predict test...\n",
      "136.22778 232.46567\n",
      "135.72473 232.46567 342.6128 1.0\n",
      "FOLD 577\n",
      "train [42.8717155456543, 6.5674920082092285]\n",
      "val [43.3139762878418, 6.599612236022949]\n",
      "predict val...\n",
      "predict test...\n",
      "122.562004 254.8575\n",
      "137.71582 254.8575 429.68457 1.0\n",
      "FOLD 578\n",
      "train [40.30609130859375, 6.488430023193359]\n",
      "val [53.565330505371094, 6.671019554138184]\n",
      "predict val...\n",
      "predict test...\n",
      "157.01672 226.13861\n",
      "126.812744 226.13861 427.48926 1.0\n",
      "FOLD 579\n",
      "train [43.253570556640625, 6.578935146331787]\n",
      "val [43.258018493652344, 6.485119342803955]\n",
      "predict val...\n",
      "predict test...\n",
      "128.20302 229.34833\n",
      "115.57251 229.34833 332.55664 1.0\n",
      "FOLD 580\n",
      "train [42.051361083984375, 6.553753852844238]\n",
      "val [48.221378326416016, 6.657024383544922]\n",
      "predict val...\n",
      "predict test...\n",
      "141.96323 242.91658\n",
      "155.97192 242.91658 341.89844 1.0\n",
      "FOLD 581\n",
      "train [41.23590850830078, 6.527218818664551]\n",
      "val [49.68531036376953, 6.843038082122803]\n",
      "predict val...\n",
      "predict test...\n",
      "147.07765 242.37871\n",
      "139.29004 242.37871 378.01758 1.0\n",
      "FOLD 582\n",
      "train [41.595298767089844, 6.546658992767334]\n",
      "val [43.01483917236328, 6.56927490234375]\n",
      "predict val...\n",
      "predict test...\n",
      "123.21427 248.35591\n",
      "145.75171 248.35591 400.14307 1.0\n",
      "FOLD 583\n",
      "train [39.78401565551758, 6.49166202545166]\n",
      "val [54.96649169921875, 6.6748247146606445]\n",
      "predict val...\n",
      "predict test...\n",
      "160.36055 232.50832\n",
      "144.31714 232.50832 350.11377 1.0\n",
      "FOLD 584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [42.88821029663086, 6.573902130126953]\n",
      "val [40.82304763793945, 6.482100963592529]\n",
      "predict val...\n",
      "predict test...\n",
      "121.30755 220.26425\n",
      "86.33765 220.26425 361.73193 1.0\n",
      "FOLD 585\n",
      "train [41.70512390136719, 6.546543121337891]\n",
      "val [49.1169319152832, 6.671772480010986]\n",
      "predict val...\n",
      "predict test...\n",
      "145.57333 241.6932\n",
      "163.95361 241.6932 331.1084 1.0\n",
      "FOLD 586\n",
      "train [41.88959503173828, 6.546082973480225]\n",
      "val [46.325767517089844, 6.741593837738037]\n",
      "predict val...\n",
      "predict test...\n",
      "136.328 251.36426\n",
      "158.54614 251.36426 371.86182 1.0\n",
      "FOLD 587\n",
      "train [42.71223449707031, 6.569211483001709]\n",
      "val [43.59117126464844, 6.586752891540527]\n",
      "predict val...\n",
      "predict test...\n",
      "122.83748 255.84726\n",
      "138.65222 255.84726 428.23535 1.0\n",
      "FOLD 588\n",
      "train [40.1826171875, 6.501651763916016]\n",
      "val [53.94792175292969, 6.678881645202637]\n",
      "predict val...\n",
      "predict test...\n",
      "157.40111 238.37321\n",
      "161.28772 238.37321 330.71338 1.0\n",
      "FOLD 589\n",
      "train [42.77432632446289, 6.570295810699463]\n",
      "val [41.35067367553711, 6.489129543304443]\n",
      "predict val...\n",
      "predict test...\n",
      "123.50944 223.22618\n",
      "102.42334 223.22618 331.688 1.0\n",
      "FOLD 590\n",
      "train [41.717716217041016, 6.549984931945801]\n",
      "val [49.063201904296875, 6.663776397705078]\n",
      "predict val...\n",
      "predict test...\n",
      "144.76117 240.43011\n",
      "165.8316 240.43011 318.49707 1.0\n",
      "FOLD 591\n",
      "train [41.774169921875, 6.543445587158203]\n",
      "val [48.17912292480469, 6.781398773193359]\n",
      "predict val...\n",
      "predict test...\n",
      "141.28358 247.92928\n",
      "152.45435 247.92928 375.33984 1.0\n",
      "FOLD 592\n",
      "train [42.538055419921875, 6.570925712585449]\n",
      "val [43.132686614990234, 6.589802265167236]\n",
      "predict val...\n",
      "predict test...\n",
      "122.986336 255.15941\n",
      "166.7605 255.15941 385.75244 1.0\n",
      "FOLD 593\n",
      "train [40.541866302490234, 6.502586364746094]\n",
      "val [54.5225715637207, 6.680262565612793]\n",
      "predict val...\n",
      "predict test...\n",
      "159.48239 231.48354\n",
      "140.3706 231.48354 413.02783 1.0\n",
      "FOLD 594\n",
      "train [43.720829010009766, 6.5887298583984375]\n",
      "val [41.22479248046875, 6.4822587966918945]\n",
      "predict val...\n",
      "predict test...\n",
      "123.56227 228.44463\n",
      "111.97565 228.44463 359.98193 1.0\n",
      "FOLD 595\n",
      "train [41.57080078125, 6.540163516998291]\n",
      "val [47.76742172241211, 6.659946441650391]\n",
      "predict val...\n",
      "predict test...\n",
      "141.80537 241.13644\n",
      "161.7583 241.13644 331.48682 1.0\n",
      "FOLD 596\n",
      "train [41.88758850097656, 6.5406951904296875]\n",
      "val [46.827693939208984, 6.754692077636719]\n",
      "predict val...\n",
      "predict test...\n",
      "138.09601 250.06517\n",
      "163.00366 250.06517 332.68115 1.0\n",
      "FOLD 597\n",
      "train [42.519386291503906, 6.559980869293213]\n",
      "val [44.299922943115234, 6.615724086761475]\n",
      "predict val...\n",
      "predict test...\n",
      "126.49495 250.2925\n",
      "152.24219 250.2925 403.4502 1.0\n",
      "FOLD 598\n",
      "train [40.12522506713867, 6.488305568695068]\n",
      "val [54.23303985595703, 6.665835380554199]\n",
      "predict val...\n",
      "predict test...\n",
      "158.84227 227.15935\n",
      "148.98401 227.15935 346.04102 1.0\n",
      "FOLD 599\n",
      "train [41.480438232421875, 6.5394697189331055]\n",
      "val [42.9716796875, 6.471374034881592]\n",
      "predict val...\n",
      "predict test...\n",
      "126.69392 222.70761\n",
      "115.01056 222.70761 318.6128 1.0\n",
      "FOLD 600\n",
      "train [42.06624221801758, 6.5555524826049805]\n",
      "val [48.35023880004883, 6.663142204284668]\n",
      "predict val...\n",
      "predict test...\n",
      "143.54372 242.75183\n",
      "150.94421 242.75183 348.3462 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 601\n",
      "train [28.815853118896484, 6.556406497955322]\n",
      "val [31.946016311645508, 6.743188381195068]\n",
      "predict val...\n",
      "predict test...\n",
      "138.69496 249.77257\n",
      "117.56702 249.77257 442.0 1.0\n",
      "FOLD 602\n",
      "train [29.370508193969727, 6.563832759857178]\n",
      "val [29.413890838623047, 6.574739933013916]\n",
      "predict val...\n",
      "predict test...\n",
      "121.47218 245.57394\n",
      "138.30798 245.57394 416.03516 1.0\n",
      "FOLD 603\n",
      "train [28.253374099731445, 6.51645040512085]\n",
      "val [36.12369155883789, 6.681860446929932]\n",
      "predict val...\n",
      "predict test...\n",
      "157.42513 233.96921\n",
      "107.690796 233.96921 513.7466 1.0\n",
      "FOLD 604\n",
      "train [30.00688934326172, 6.591239929199219]\n",
      "val [29.53043556213379, 6.496801376342773]\n",
      "predict val...\n",
      "predict test...\n",
      "128.35106 216.9165\n",
      "84.16113 216.9165 364.90625 1.0\n",
      "FOLD 605\n",
      "train [29.566997528076172, 6.566636085510254]\n",
      "val [32.18305969238281, 6.662532806396484]\n",
      "predict val...\n",
      "predict test...\n",
      "140.52097 223.54268\n",
      "97.211365 223.54268 394.35352 1.0\n",
      "FOLD 606\n",
      "train [29.216176986694336, 6.563333034515381]\n",
      "val [32.092926025390625, 6.756410121917725]\n",
      "predict val...\n",
      "predict test...\n",
      "137.76184 244.36798\n",
      "125.977295 244.36798 408.7173 1.0\n",
      "FOLD 607\n",
      "train [29.27633285522461, 6.561093330383301]\n",
      "val [30.706741333007812, 6.64307975769043]\n",
      "predict val...\n",
      "predict test...\n",
      "128.80035 247.45888\n",
      "146.48706 247.45888 418.41602 1.0\n",
      "FOLD 608\n",
      "train [27.5461368560791, 6.486451148986816]\n",
      "val [37.74290466308594, 6.7031450271606445]\n",
      "predict val...\n",
      "predict test...\n",
      "163.98315 218.72078\n",
      "104.3396 218.72078 480.85547 1.0\n",
      "FOLD 609\n",
      "train [30.108989715576172, 6.602696895599365]\n",
      "val [28.652629852294922, 6.4931254386901855]\n",
      "predict val...\n",
      "predict test...\n",
      "124.45151 230.08583\n",
      "91.523926 230.08583 384.27002 1.0\n",
      "FOLD 610\n",
      "train [28.761022567749023, 6.543249607086182]\n",
      "val [31.99286460876465, 6.643152713775635]\n",
      "predict val...\n",
      "predict test...\n",
      "139.29488 233.03871\n",
      "110.41174 233.03871 394.00684 1.0\n",
      "FOLD 611\n",
      "train [28.79574966430664, 6.549399375915527]\n",
      "val [31.993484497070312, 6.740900993347168]\n",
      "predict val...\n",
      "predict test...\n",
      "139.29646 248.15727\n",
      "131.94531 248.15727 402.99316 1.0\n",
      "FOLD 612\n",
      "train [28.652681350708008, 6.546904563903809]\n",
      "val [30.43892478942871, 6.6280012130737305]\n",
      "predict val...\n",
      "predict test...\n",
      "127.42233 246.8918\n",
      "155.08777 246.8918 388.8452 1.0\n",
      "FOLD 613\n",
      "train [26.839824676513672, 6.464453220367432]\n",
      "val [36.62062454223633, 6.668539047241211]\n",
      "predict val...\n",
      "predict test...\n",
      "159.34337 223.90004\n",
      "113.480225 223.90004 455.4702 1.0\n",
      "FOLD 614\n",
      "train [29.536666870117188, 6.568909645080566]\n",
      "val [29.59266471862793, 6.473215579986572]\n",
      "predict val...\n",
      "predict test...\n",
      "128.12949 223.95201\n",
      "106.43506 223.95201 323.48193 1.0\n",
      "FOLD 615\n",
      "train [28.60386848449707, 6.5403313636779785]\n",
      "val [33.759822845458984, 6.66884708404541]\n",
      "predict val...\n",
      "predict test...\n",
      "147.59233 234.5345\n",
      "125.98016 234.5345 355.2876 1.0\n",
      "FOLD 616\n",
      "train [28.692750930786133, 6.544236183166504]\n",
      "val [32.49015426635742, 6.773481369018555]\n",
      "predict val...\n",
      "predict test...\n",
      "141.37332 244.15263\n",
      "124.42761 244.15263 416.82422 1.0\n",
      "FOLD 617\n",
      "train [29.084531784057617, 6.562175750732422]\n",
      "val [29.84931755065918, 6.60617208480835]\n",
      "predict val...\n",
      "predict test...\n",
      "124.23234 250.23407\n",
      "154.7279 250.23407 406.14697 1.0\n",
      "FOLD 618\n",
      "train [27.58376121520996, 6.489259243011475]\n",
      "val [36.18739318847656, 6.663725852966309]\n",
      "predict val...\n",
      "predict test...\n",
      "157.77316 225.18571\n",
      "145.3667 225.18571 376.91406 1.0\n",
      "FOLD 619\n",
      "train [29.918954849243164, 6.59850549697876]\n",
      "val [29.294292449951172, 6.505764961242676]\n",
      "predict val...\n",
      "predict test...\n",
      "127.546036 232.50552\n",
      "104.06329 232.50552 371.45215 1.0\n",
      "FOLD 620\n",
      "train [28.53302574157715, 6.543950080871582]\n",
      "val [32.83343505859375, 6.665099143981934]\n",
      "predict val...\n",
      "predict test...\n",
      "142.36493 237.60304\n",
      "156.80432 237.60304 322.54028 1.0\n",
      "FOLD 621\n",
      "train [28.627973556518555, 6.543931484222412]\n",
      "val [32.27781677246094, 6.774141311645508]\n",
      "predict val...\n",
      "predict test...\n",
      "140.70895 248.48636\n",
      "147.25757 248.48636 373.19775 1.0\n",
      "FOLD 622\n",
      "train [29.114547729492188, 6.561199188232422]\n",
      "val [29.813648223876953, 6.605656623840332]\n",
      "predict val...\n",
      "predict test...\n",
      "124.1164 250.61293\n",
      "141.46313 250.61293 416.1831 1.0\n",
      "FOLD 623\n",
      "train [27.32006072998047, 6.488614082336426]\n",
      "val [36.373146057128906, 6.684980869293213]\n",
      "predict val...\n",
      "predict test...\n",
      "157.50343 227.75525\n",
      "149.54395 227.75525 362.94922 1.0\n",
      "FOLD 624\n",
      "train [29.255474090576172, 6.572958946228027]\n",
      "val [28.85801124572754, 6.49608039855957]\n",
      "predict val...\n",
      "predict test...\n",
      "126.59568 223.63905\n",
      "104.42096 223.63905 331.5703 1.0\n",
      "FOLD 625\n",
      "train [28.515666961669922, 6.542819976806641]\n",
      "val [33.294559478759766, 6.680357933044434]\n",
      "predict val...\n",
      "predict test...\n",
      "145.73701 240.02107\n",
      "158.65381 240.02107 349.26074 1.0\n",
      "FOLD 626\n",
      "train [28.83064079284668, 6.545588493347168]\n",
      "val [31.75944709777832, 6.741421222686768]\n",
      "predict val...\n",
      "predict test...\n",
      "137.82751 243.1021\n",
      "140.68884 243.1021 367.12256 1.0\n",
      "FOLD 627\n",
      "train [28.86438751220703, 6.5514960289001465]\n",
      "val [29.5555362701416, 6.596927165985107]\n",
      "predict val...\n",
      "predict test...\n",
      "123.95968 246.52126\n",
      "155.83716 246.52126 392.16406 1.0\n",
      "FOLD 628\n",
      "train [26.77044677734375, 6.45846700668335]\n",
      "val [36.00438690185547, 6.683976173400879]\n",
      "predict val...\n",
      "predict test...\n",
      "156.09253 220.57869\n",
      "135.44531 220.57869 322.00146 1.0\n",
      "FOLD 629\n",
      "train [29.942882537841797, 6.596125602722168]\n",
      "val [29.18739128112793, 6.502841949462891]\n",
      "predict val...\n",
      "predict test...\n",
      "127.2641 230.68015\n",
      "107.105896 230.68015 363.3003 1.0\n",
      "FOLD 630\n",
      "train [27.9897403717041, 6.529046535491943]\n",
      "val [32.6823616027832, 6.6786394119262695]\n",
      "predict val...\n",
      "predict test...\n",
      "141.93102 232.83179\n",
      "173.80432 232.83179 316.9944 1.0\n",
      "FOLD 631\n",
      "train [28.553592681884766, 6.5437211990356445]\n",
      "val [32.1468620300293, 6.782000541687012]\n",
      "predict val...\n",
      "predict test...\n",
      "138.86977 247.38788\n",
      "138.27136 247.38788 386.1255 1.0\n",
      "FOLD 632\n",
      "train [27.57897186279297, 6.494921684265137]\n",
      "val [30.040321350097656, 6.6434502601623535]\n",
      "predict val...\n",
      "predict test...\n",
      "127.7387 224.6362\n",
      "152.28467 224.6362 316.1167 1.0\n",
      "FOLD 633\n",
      "train [27.291982650756836, 6.4885077476501465]\n",
      "val [37.015953063964844, 6.679108142852783]\n",
      "predict val...\n",
      "predict test...\n",
      "160.36057 229.77504\n",
      "149.7489 229.77504 353.68115 1.0\n",
      "FOLD 634\n",
      "train [29.787214279174805, 6.590214729309082]\n",
      "val [28.523900985717773, 6.492157936096191]\n",
      "predict val...\n",
      "predict test...\n",
      "125.47524 232.09782\n",
      "119.99109 232.09782 342.0298 1.0\n",
      "FOLD 635\n",
      "train [28.3569393157959, 6.541471004486084]\n",
      "val [33.03707504272461, 6.673989295959473]\n",
      "predict val...\n",
      "predict test...\n",
      "144.70078 241.1901\n",
      "172.9248 241.1901 320.59326 1.0\n",
      "FOLD 636\n",
      "train [28.28670883178711, 6.517760276794434]\n",
      "val [32.39548873901367, 6.756439208984375]\n",
      "predict val...\n",
      "predict test...\n",
      "141.74147 236.61772\n",
      "147.42822 236.61772 334.18506 1.0\n",
      "FOLD 637\n",
      "train [29.09610939025879, 6.570326805114746]\n",
      "val [29.36219024658203, 6.583858489990234]\n",
      "predict val...\n",
      "predict test...\n",
      "122.01069 256.2503\n",
      "160.43213 256.2503 404.45996 1.0\n",
      "FOLD 638\n",
      "train [27.568668365478516, 6.493344783782959]\n",
      "val [36.56804275512695, 6.674876689910889]\n",
      "predict val...\n",
      "predict test...\n",
      "156.72093 228.77808\n",
      "150.7649 228.77808 325.54932 1.0\n",
      "FOLD 639\n",
      "train [29.866153717041016, 6.592259407043457]\n",
      "val [28.683998107910156, 6.490540981292725]\n",
      "predict val...\n",
      "predict test...\n",
      "126.23064 234.42473\n",
      "140.91718 234.42473 328.97217 1.0\n",
      "FOLD 640\n",
      "train [27.542936325073242, 6.514121055603027]\n",
      "val [32.491477966308594, 6.691832542419434]\n",
      "predict val...\n",
      "predict test...\n",
      "140.4491 228.3551\n",
      "164.70398 228.3551 329.31152 1.0\n",
      "FOLD 641\n",
      "train [28.294612884521484, 6.52623987197876]\n",
      "val [31.99583625793457, 6.720015525817871]\n",
      "predict val...\n",
      "predict test...\n",
      "140.42451 241.73326\n",
      "133.92798 241.73326 369.81592 1.0\n",
      "FOLD 642\n",
      "train [29.01511001586914, 6.561431884765625]\n",
      "val [29.694969177246094, 6.581573009490967]\n",
      "predict val...\n",
      "predict test...\n",
      "123.5844 250.03822\n",
      "157.08862 250.03822 399.6372 1.0\n",
      "FOLD 643\n",
      "train [27.16556739807129, 6.482090950012207]\n",
      "val [36.67888641357422, 6.6681809425354]\n",
      "predict val...\n",
      "predict test...\n",
      "159.6677 230.49619\n",
      "158.45203 230.49619 273.58496 1.0\n",
      "FOLD 644\n",
      "train [29.655000686645508, 6.579967498779297]\n",
      "val [29.137794494628906, 6.477348327636719]\n",
      "predict val...\n",
      "predict test...\n",
      "126.11351 221.7446\n",
      "99.35889 221.7446 350.99902 1.0\n",
      "FOLD 645\n",
      "train [28.458484649658203, 6.544862270355225]\n",
      "val [33.02321243286133, 6.670774936676025]\n",
      "predict val...\n",
      "predict test...\n",
      "144.22836 239.04199\n",
      "161.51953 239.04199 330.3286 1.0\n",
      "FOLD 646\n",
      "train [28.37176513671875, 6.52187442779541]\n",
      "val [33.43228530883789, 6.817844390869141]\n",
      "predict val...\n",
      "predict test...\n",
      "145.46082 237.09001\n",
      "151.8435 237.09001 314.58984 1.0\n",
      "FOLD 647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [28.91305160522461, 6.554080009460449]\n",
      "val [30.588367462158203, 6.646234512329102]\n",
      "predict val...\n",
      "predict test...\n",
      "129.67192 245.4314\n",
      "165.83533 245.4314 375.18164 1.0\n",
      "FOLD 648\n",
      "train [26.81618309020996, 6.467665195465088]\n",
      "val [36.68803787231445, 6.670292854309082]\n",
      "predict val...\n",
      "predict test...\n",
      "157.62213 227.87335\n",
      "126.00879 227.87335 275.562 1.0\n",
      "FOLD 649\n",
      "train [29.713838577270508, 6.586656093597412]\n",
      "val [28.072046279907227, 6.47582483291626]\n",
      "predict val...\n",
      "predict test...\n",
      "123.443886 233.09721\n",
      "140.73132 233.09721 320.9126 1.0\n",
      "FOLD 650\n",
      "train [27.65777015686035, 6.512940406799316]\n",
      "val [33.23822021484375, 6.70557975769043]\n",
      "predict val...\n",
      "predict test...\n",
      "145.25629 230.19028\n",
      "173.8363 230.19028 302.71875 1.0\n",
      "FOLD 651\n",
      "train [33.61588668823242, 6.562838554382324]\n",
      "val [36.93327713012695, 6.7470550537109375]\n",
      "predict val...\n",
      "predict test...\n",
      "137.15285 247.30423\n",
      "122.57947 247.30423 428.1709 1.0\n",
      "FOLD 652\n",
      "train [33.98136520385742, 6.570466041564941]\n",
      "val [35.950416564941406, 6.673593997955322]\n",
      "predict val...\n",
      "predict test...\n",
      "130.55927 251.89641\n",
      "129.52502 251.89641 431.4209 1.0\n",
      "FOLD 653\n",
      "train [32.29998779296875, 6.506492614746094]\n",
      "val [41.59540939331055, 6.682901859283447]\n",
      "predict val...\n",
      "predict test...\n",
      "156.16283 234.64574\n",
      "106.083496 234.64574 522.02 1.0\n",
      "FOLD 654\n",
      "train [35.13189697265625, 6.604496955871582]\n",
      "val [32.78311538696289, 6.490267276763916]\n",
      "predict val...\n",
      "predict test...\n",
      "124.38803 220.29951\n",
      "85.01282 220.29951 368.72656 1.0\n",
      "FOLD 655\n",
      "train [33.33322525024414, 6.538933753967285]\n",
      "val [39.0289421081543, 6.67514181137085]\n",
      "predict val...\n",
      "predict test...\n",
      "147.95285 222.68623\n",
      "101.68445 222.68623 380.1587 1.0\n",
      "FOLD 656\n",
      "train [33.66868209838867, 6.564294338226318]\n",
      "val [37.30683898925781, 6.756504058837891]\n",
      "predict val...\n",
      "predict test...\n",
      "138.38394 247.26186\n",
      "125.52344 247.26186 422.55273 1.0\n",
      "FOLD 657\n",
      "train [34.00056457519531, 6.568129062652588]\n",
      "val [35.23520278930664, 6.612954139709473]\n",
      "predict val...\n",
      "predict test...\n",
      "126.5222 248.26137\n",
      "131.87695 248.26137 421.9004 1.0\n",
      "FOLD 658\n",
      "train [31.448284149169922, 6.475345611572266]\n",
      "val [42.27554702758789, 6.680494785308838]\n",
      "predict val...\n",
      "predict test...\n",
      "158.43488 219.04988\n",
      "115.22681 219.04988 427.0913 1.0\n",
      "FOLD 659\n",
      "train [33.99757766723633, 6.581841945648193]\n",
      "val [33.05685806274414, 6.47638463973999]\n",
      "predict val...\n",
      "predict test...\n",
      "123.41391 221.40843\n",
      "88.15747 221.40843 369.27734 1.0\n",
      "FOLD 660\n",
      "train [33.24384307861328, 6.550983428955078]\n",
      "val [37.231834411621094, 6.645275115966797]\n",
      "predict val...\n",
      "predict test...\n",
      "140.32222 238.71216\n",
      "130.08984 238.71216 375.85205 1.0\n",
      "FOLD 661\n",
      "train [32.93986511230469, 6.549884796142578]\n",
      "val [37.52268981933594, 6.794809341430664]\n",
      "predict val...\n",
      "predict test...\n",
      "140.23299 254.79794\n",
      "149.48938 254.79794 391.60303 1.0\n",
      "FOLD 662\n",
      "train [33.64148712158203, 6.566476345062256]\n",
      "val [34.532222747802734, 6.608136177062988]\n",
      "predict val...\n",
      "predict test...\n",
      "124.10505 254.01445\n",
      "143.02942 254.01445 424.80664 1.0\n",
      "FOLD 663\n",
      "train [32.00230407714844, 6.498204708099365]\n",
      "val [42.65424728393555, 6.68344783782959]\n",
      "predict val...\n",
      "predict test...\n",
      "159.39223 231.13936\n",
      "130.14087 231.13936 449.98535 1.0\n",
      "FOLD 664\n",
      "train [34.2955436706543, 6.587866306304932]\n",
      "val [32.764854431152344, 6.479145050048828]\n",
      "predict val...\n",
      "predict test...\n",
      "123.805046 222.07191\n",
      "89.61902 222.07191 372.94092 1.0\n",
      "FOLD 665\n",
      "train [32.74801254272461, 6.5309271812438965]\n",
      "val [38.75284957885742, 6.674788475036621]\n",
      "predict val...\n",
      "predict test...\n",
      "145.58176 231.84543\n",
      "129.3966 231.84543 365.52686 1.0\n",
      "FOLD 666\n",
      "train [32.625335693359375, 6.524417877197266]\n",
      "val [36.48756408691406, 6.709596157073975]\n",
      "predict val...\n",
      "predict test...\n",
      "137.50833 239.00687\n",
      "142.74829 239.00687 379.7915 1.0\n",
      "FOLD 667\n",
      "train [33.596336364746094, 6.566728115081787]\n",
      "val [34.21809387207031, 6.59318733215332]\n",
      "predict val...\n",
      "predict test...\n",
      "123.60374 253.22836\n",
      "159.84619 253.22836 394.75195 1.0\n",
      "FOLD 668\n",
      "train [31.77355194091797, 6.487900733947754]\n",
      "val [43.439170837402344, 6.681618690490723]\n",
      "predict val...\n",
      "predict test...\n",
      "161.73878 228.88269\n",
      "131.3523 228.88269 399.18652 1.0\n",
      "FOLD 669\n",
      "train [34.35248947143555, 6.58255672454834]\n",
      "val [33.991729736328125, 6.476295471191406]\n",
      "predict val...\n",
      "predict test...\n",
      "125.9233 223.94336\n",
      "98.98743 223.94336 365.36816 1.0\n",
      "FOLD 670\n",
      "train [32.93634796142578, 6.543316841125488]\n",
      "val [37.3385009765625, 6.649903297424316]\n",
      "predict val...\n",
      "predict test...\n",
      "141.18877 239.32542\n",
      "146.99927 239.32542 367.9419 1.0\n",
      "FOLD 671\n",
      "train [32.983734130859375, 6.539564609527588]\n",
      "val [37.43396759033203, 6.760607719421387]\n",
      "predict val...\n",
      "predict test...\n",
      "140.90825 246.6111\n",
      "136.86511 246.6111 391.27295 1.0\n",
      "FOLD 672\n",
      "train [33.86137771606445, 6.568200588226318]\n",
      "val [33.86991500854492, 6.572283744812012]\n",
      "predict val...\n",
      "predict test...\n",
      "121.1822 251.87144\n",
      "147.45422 251.87144 413.06445 1.0\n",
      "FOLD 673\n",
      "train [31.52511978149414, 6.485252380371094]\n",
      "val [42.03700256347656, 6.668038368225098]\n",
      "predict val...\n",
      "predict test...\n",
      "156.16986 230.69987\n",
      "156.80176 230.69987 302.09766 1.0\n",
      "FOLD 674\n",
      "train [34.44516372680664, 6.592715263366699]\n",
      "val [33.047821044921875, 6.488572597503662]\n",
      "predict val...\n",
      "predict test...\n",
      "125.01635 229.90529\n",
      "112.95386 229.90529 356.8042 1.0\n",
      "FOLD 675\n",
      "train [32.973087310791016, 6.5380859375]\n",
      "val [37.95549774169922, 6.660449981689453]\n",
      "predict val...\n",
      "predict test...\n",
      "143.1066 231.47939\n",
      "145.5653 231.47939 323.76465 1.0\n",
      "FOLD 676\n",
      "train [33.0963249206543, 6.544039726257324]\n",
      "val [36.78510284423828, 6.727601051330566]\n",
      "predict val...\n",
      "predict test...\n",
      "138.15369 246.08\n",
      "147.07532 246.08 367.1089 1.0\n",
      "FOLD 677\n",
      "train [32.460018157958984, 6.522853851318359]\n",
      "val [33.91606903076172, 6.549764633178711]\n",
      "predict val...\n",
      "predict test...\n",
      "124.53718 235.08153\n",
      "161.97144 235.08153 332.31494 1.0\n",
      "FOLD 678\n",
      "train [30.892187118530273, 6.463091850280762]\n",
      "val [42.77629852294922, 6.687009811401367]\n",
      "predict val...\n",
      "predict test...\n",
      "158.91609 222.0447\n",
      "143.03662 222.0447 305.87598 1.0\n",
      "FOLD 679\n",
      "train [34.51359558105469, 6.592273712158203]\n",
      "val [33.007591247558594, 6.489563941955566]\n",
      "predict val...\n",
      "predict test...\n",
      "125.06582 231.65446\n",
      "116.36755 231.65446 359.0122 1.0\n",
      "FOLD 680\n",
      "train [32.91445541381836, 6.5443549156188965]\n",
      "val [38.59476089477539, 6.666525840759277]\n",
      "predict val...\n",
      "predict test...\n",
      "144.74524 237.70004\n",
      "149.59961 237.70004 330.62402 1.0\n",
      "FOLD 681\n",
      "train [32.940975189208984, 6.537530422210693]\n",
      "val [37.643394470214844, 6.775886058807373]\n",
      "predict val...\n",
      "predict test...\n",
      "141.3715 243.71178\n",
      "125.512695 243.71178 408.88574 1.0\n",
      "FOLD 682\n",
      "train [33.448604583740234, 6.562670707702637]\n",
      "val [34.5129280090332, 6.594903945922852]\n",
      "predict val...\n",
      "predict test...\n",
      "125.30459 250.4822\n",
      "162.81482 250.4822 389.9287 1.0\n",
      "FOLD 683\n",
      "train [30.676658630371094, 6.457025051116943]\n",
      "val [40.86628341674805, 6.655567169189453]\n",
      "predict val...\n",
      "predict test...\n",
      "151.59938 215.9723\n",
      "120.829346 215.9723 286.9126 1.0\n",
      "FOLD 684\n",
      "train [34.37953567504883, 6.5936126708984375]\n",
      "val [32.9273567199707, 6.498312473297119]\n",
      "predict val...\n",
      "predict test...\n",
      "126.893524 234.79454\n",
      "135.90802 234.79454 336.4292 1.0\n",
      "FOLD 685\n",
      "train [32.04899597167969, 6.525388240814209]\n",
      "val [37.86139678955078, 6.684680938720703]\n",
      "predict val...\n",
      "predict test...\n",
      "142.92636 231.04375\n",
      "159.57349 231.04375 313.51416 1.0\n",
      "FOLD 686\n",
      "train [33.144351959228516, 6.547421455383301]\n",
      "val [37.25722885131836, 6.776454925537109]\n",
      "predict val...\n",
      "predict test...\n",
      "139.76297 248.67747\n",
      "141.74365 248.67747 386.3252 1.0\n",
      "FOLD 687\n",
      "train [33.20994567871094, 6.552687644958496]\n",
      "val [35.0007209777832, 6.613617420196533]\n",
      "predict val...\n",
      "predict test...\n",
      "127.10736 248.79736\n",
      "149.14441 248.79736 407.90234 1.0\n",
      "FOLD 688\n",
      "train [31.805383682250977, 6.494927883148193]\n",
      "val [41.956092834472656, 6.67121696472168]\n",
      "predict val...\n",
      "predict test...\n",
      "157.02884 231.63503\n",
      "149.32483 231.63503 370.87988 1.0\n",
      "FOLD 689\n",
      "train [33.61945724487305, 6.575875282287598]\n",
      "val [32.96446990966797, 6.504283428192139]\n",
      "predict val...\n",
      "predict test...\n",
      "126.09306 239.21425\n",
      "146.86945 239.21425 285.25098 1.0\n",
      "FOLD 690\n",
      "train [32.75301742553711, 6.540743827819824]\n",
      "val [38.52200698852539, 6.669020175933838]\n",
      "predict val...\n",
      "predict test...\n",
      "144.96147 236.82927\n",
      "166.64624 236.82927 319.85425 1.0\n",
      "FOLD 691\n",
      "train [33.01609802246094, 6.548719882965088]\n",
      "val [36.24986267089844, 6.741994857788086]\n",
      "predict val...\n",
      "predict test...\n",
      "136.65674 251.03957\n",
      "172.5929 251.03957 332.03418 1.0\n",
      "FOLD 692\n",
      "train [32.645442962646484, 6.531521797180176]\n",
      "val [35.696929931640625, 6.62464714050293]\n",
      "predict val...\n",
      "predict test...\n",
      "131.81047 238.63185\n",
      "152.74805 238.63185 375.11182 1.0\n",
      "FOLD 693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [31.947433471679688, 6.507260799407959]\n",
      "val [42.816646575927734, 6.68303108215332]\n",
      "predict val...\n",
      "predict test...\n",
      "160.16182 235.91403\n",
      "165.60156 235.91403 303.49072 1.0\n",
      "FOLD 694\n",
      "train [34.423423767089844, 6.5898308753967285]\n",
      "val [32.42488479614258, 6.482544898986816]\n",
      "predict val...\n",
      "predict test...\n",
      "123.23323 232.06036\n",
      "125.19824 232.06036 341.62305 1.0\n",
      "FOLD 695\n",
      "train [32.84626007080078, 6.543754577636719]\n",
      "val [37.433265686035156, 6.656434059143066]\n",
      "predict val...\n",
      "predict test...\n",
      "142.15965 240.5652\n",
      "159.66553 240.5652 329.01 1.0\n",
      "FOLD 696\n",
      "train [33.38520050048828, 6.553786277770996]\n",
      "val [36.9262809753418, 6.756865501403809]\n",
      "predict val...\n",
      "predict test...\n",
      "137.68478 247.1048\n",
      "166.1908 247.1048 325.8047 1.0\n",
      "FOLD 697\n",
      "train [33.763633728027344, 6.56622314453125]\n",
      "val [34.135536193847656, 6.574466705322266]\n",
      "predict val...\n",
      "predict test...\n",
      "122.37887 250.03137\n",
      "156.95801 250.03137 406.60596 1.0\n",
      "FOLD 698\n",
      "train [30.88408088684082, 6.45987606048584]\n",
      "val [40.86399841308594, 6.630902290344238]\n",
      "predict val...\n",
      "predict test...\n",
      "151.58035 219.65553\n",
      "127.73413 219.65553 281.35645 1.0\n",
      "FOLD 699\n",
      "train [34.18779754638672, 6.578912258148193]\n",
      "val [33.08504867553711, 6.492991924285889]\n",
      "predict val...\n",
      "predict test...\n",
      "126.93614 227.7883\n",
      "118.52557 227.7883 330.42432 1.0\n",
      "FOLD 700\n",
      "train [31.92312240600586, 6.516207695007324]\n",
      "val [39.838775634765625, 6.694007873535156]\n",
      "predict val...\n",
      "predict test...\n",
      "149.68509 235.33075\n",
      "167.65332 235.33075 312.11914 1.0\n",
      "FOLD 701\n",
      "train [37.895816802978516, 6.557961463928223]\n",
      "val [42.40065383911133, 6.772277355194092]\n",
      "predict val...\n",
      "predict test...\n",
      "139.29906 249.29996\n",
      "120.99634 249.29996 428.15527 1.0\n",
      "FOLD 702\n",
      "train [38.456546783447266, 6.570603847503662]\n",
      "val [39.7479362487793, 6.614066123962402]\n",
      "predict val...\n",
      "predict test...\n",
      "125.33314 252.29143\n",
      "130.53369 252.29143 434.56445 1.0\n",
      "FOLD 703\n",
      "train [36.511112213134766, 6.512274742126465]\n",
      "val [48.91930389404297, 6.686820983886719]\n",
      "predict val...\n",
      "predict test...\n",
      "161.82993 234.93315\n",
      "109.63208 234.93315 519.69727 1.0\n",
      "FOLD 704\n",
      "train [40.102508544921875, 6.608141899108887]\n",
      "val [37.29901885986328, 6.494767189025879]\n",
      "predict val...\n",
      "predict test...\n",
      "124.79625 221.26155\n",
      "82.66687 221.26155 372.04834 1.0\n",
      "FOLD 705\n",
      "train [38.308143615722656, 6.557469367980957]\n",
      "val [42.3360710144043, 6.658369541168213]\n",
      "predict val...\n",
      "predict test...\n",
      "140.2273 225.63052\n",
      "97.78125 225.63052 399.67383 1.0\n",
      "FOLD 706\n",
      "train [38.199806213378906, 6.56518030166626]\n",
      "val [42.88957977294922, 6.806241989135742]\n",
      "predict val...\n",
      "predict test...\n",
      "139.90828 248.09218\n",
      "118.91174 248.09218 434.167 1.0\n",
      "FOLD 707\n",
      "train [38.1844482421875, 6.565038204193115]\n",
      "val [40.02618408203125, 6.6278486251831055]\n",
      "predict val...\n",
      "predict test...\n",
      "127.47824 255.11284\n",
      "141.46326 255.11284 432.0581 1.0\n",
      "FOLD 708\n",
      "train [36.660762786865234, 6.504477500915527]\n",
      "val [48.67301940917969, 6.675725936889648]\n",
      "predict val...\n",
      "predict test...\n",
      "159.66852 227.5508\n",
      "115.083374 227.5508 483.62695 1.0\n",
      "FOLD 709\n",
      "train [38.421348571777344, 6.578238010406494]\n",
      "val [35.92380905151367, 6.448956489562988]\n",
      "predict val...\n",
      "predict test...\n",
      "118.321205 222.16777\n",
      "88.55542 222.16777 369.3369 1.0\n",
      "FOLD 710\n",
      "train [37.822608947753906, 6.558844089508057]\n",
      "val [43.24885559082031, 6.672861576080322]\n",
      "predict val...\n",
      "predict test...\n",
      "143.5805 242.72127\n",
      "114.26776 242.72127 410.6997 1.0\n",
      "FOLD 711\n",
      "train [37.62858581542969, 6.554586887359619]\n",
      "val [42.00039291381836, 6.755602836608887]\n",
      "predict val...\n",
      "predict test...\n",
      "138.29132 253.61194\n",
      "142.08545 253.61194 383.56006 1.0\n",
      "FOLD 712\n",
      "train [38.1850471496582, 6.574670314788818]\n",
      "val [38.393009185791016, 6.582418441772461]\n",
      "predict val...\n",
      "predict test...\n",
      "122.07894 256.4034\n",
      "158.65955 256.4034 405.17188 1.0\n",
      "FOLD 713\n",
      "train [35.87498092651367, 6.484318733215332]\n",
      "val [48.510986328125, 6.696657657623291]\n",
      "predict val...\n",
      "predict test...\n",
      "159.2776 224.63788\n",
      "105.97412 224.63788 486.93115 1.0\n",
      "FOLD 714\n",
      "train [38.410186767578125, 6.572487831115723]\n",
      "val [36.96947479248047, 6.478116989135742]\n",
      "predict val...\n",
      "predict test...\n",
      "122.55204 219.8862\n",
      "87.75745 219.8862 360.83643 1.0\n",
      "FOLD 715\n",
      "train [37.06574630737305, 6.5364789962768555]\n",
      "val [45.745948791503906, 6.680207252502441]\n",
      "predict val...\n",
      "predict test...\n",
      "150.1605 235.49417\n",
      "148.4115 235.49417 327.4629 1.0\n",
      "FOLD 716\n",
      "train [37.712738037109375, 6.55535364151001]\n",
      "val [42.43572998046875, 6.790445327758789]\n",
      "predict val...\n",
      "predict test...\n",
      "140.06189 253.75362\n",
      "149.16357 253.75362 382.47168 1.0\n",
      "FOLD 717\n",
      "train [38.10331344604492, 6.567543983459473]\n",
      "val [39.028411865234375, 6.601316452026367]\n",
      "predict val...\n",
      "predict test...\n",
      "123.83319 254.09319\n",
      "154.02307 254.09319 415.88135 1.0\n",
      "FOLD 718\n",
      "train [36.10094451904297, 6.490602016448975]\n",
      "val [48.400760650634766, 6.679396629333496]\n",
      "predict val...\n",
      "predict test...\n",
      "158.19183 226.90034\n",
      "110.58008 226.90034 486.47266 1.0\n",
      "FOLD 719\n",
      "train [38.94578170776367, 6.592919826507568]\n",
      "val [37.21205520629883, 6.485313415527344]\n",
      "predict val...\n",
      "predict test...\n",
      "123.2181 228.30145\n",
      "97.31146 228.30145 363.94287 1.0\n",
      "FOLD 720\n",
      "train [37.69952392578125, 6.556138038635254]\n",
      "val [42.14326095581055, 6.636702537536621]\n",
      "predict val...\n",
      "predict test...\n",
      "139.16066 241.52306\n",
      "154.75342 241.52306 330.46045 1.0\n",
      "FOLD 721\n",
      "train [37.84886932373047, 6.557382106781006]\n",
      "val [42.07111740112305, 6.760467052459717]\n",
      "predict val...\n",
      "predict test...\n",
      "137.85721 248.08266\n",
      "127.19946 248.08266 419.32422 1.0\n",
      "FOLD 722\n",
      "train [37.947200775146484, 6.564100742340088]\n",
      "val [39.021907806396484, 6.603142738342285]\n",
      "predict val...\n",
      "predict test...\n",
      "124.70437 251.7981\n",
      "159.07812 251.7981 399.56787 1.0\n",
      "FOLD 723\n",
      "train [35.0998649597168, 6.472095489501953]\n",
      "val [48.87786865234375, 6.731908798217773]\n",
      "predict val...\n",
      "predict test...\n",
      "159.83102 224.37062\n",
      "86.65527 224.37062 360.08057 1.0\n",
      "FOLD 724\n",
      "train [38.56584167480469, 6.5726823806762695]\n",
      "val [37.347267150878906, 6.468210220336914]\n",
      "predict val...\n",
      "predict test...\n",
      "124.4549 223.94972\n",
      "119.48712 223.94972 338.12012 1.0\n",
      "FOLD 725\n",
      "train [37.679325103759766, 6.549340724945068]\n",
      "val [44.06398391723633, 6.671413898468018]\n",
      "predict val...\n",
      "predict test...\n",
      "146.6069 236.07133\n",
      "111.05847 236.07133 408.30713 1.0\n",
      "FOLD 726\n",
      "train [37.37784194946289, 6.536674499511719]\n",
      "val [42.60582733154297, 6.757452964782715]\n",
      "predict val...\n",
      "predict test...\n",
      "141.40402 245.87184\n",
      "148.86267 245.87184 370.33398 1.0\n",
      "FOLD 727\n",
      "train [38.21806716918945, 6.569749355316162]\n",
      "val [38.38519287109375, 6.58118200302124]\n",
      "predict val...\n",
      "predict test...\n",
      "121.58361 254.44443\n",
      "150.02344 254.44443 418.45557 1.0\n",
      "FOLD 728\n",
      "train [36.319786071777344, 6.501178741455078]\n",
      "val [47.74937057495117, 6.67414665222168]\n",
      "predict val...\n",
      "predict test...\n",
      "156.52998 231.50366\n",
      "136.60596 231.50366 428.40967 1.0\n",
      "FOLD 729\n",
      "train [39.574195861816406, 6.604828834533691]\n",
      "val [37.54656982421875, 6.4942402839660645]\n",
      "predict val...\n",
      "predict test...\n",
      "124.02135 232.9349\n",
      "103.46887 232.9349 371.46387 1.0\n",
      "FOLD 730\n",
      "train [37.35464859008789, 6.544634819030762]\n",
      "val [44.172340393066406, 6.686321258544922]\n",
      "predict val...\n",
      "predict test...\n",
      "146.48393 235.50739\n",
      "157.30139 235.50739 327.66577 1.0\n",
      "FOLD 731\n",
      "train [37.400367736816406, 6.5449371337890625]\n",
      "val [42.13023376464844, 6.7618207931518555]\n",
      "predict val...\n",
      "predict test...\n",
      "139.04584 249.67737\n",
      "149.97583 249.67737 382.5713 1.0\n",
      "FOLD 732\n",
      "train [37.64494323730469, 6.548823356628418]\n",
      "val [38.9372673034668, 6.57659912109375]\n",
      "predict val...\n",
      "predict test...\n",
      "124.006836 247.44135\n",
      "163.80981 247.44135 369.09424 1.0\n",
      "FOLD 733\n",
      "train [34.2139892578125, 6.443856716156006]\n",
      "val [49.04801559448242, 6.661515235900879]\n",
      "predict val...\n",
      "predict test...\n",
      "159.48666 224.12184\n",
      "150.18762 224.12184 331.42236 1.0\n",
      "FOLD 734\n",
      "train [39.40614700317383, 6.598265647888184]\n",
      "val [37.12902069091797, 6.492406368255615]\n",
      "predict val...\n",
      "predict test...\n",
      "123.819115 229.14856\n",
      "101.68091 229.14856 372.34375 1.0\n",
      "FOLD 735\n",
      "train [36.2522087097168, 6.529581546783447]\n",
      "val [43.7481575012207, 6.7015533447265625]\n",
      "predict val...\n",
      "predict test...\n",
      "144.69058 235.31645\n",
      "165.6499 235.31645 326.5813 1.0\n",
      "FOLD 736\n",
      "train [37.0474739074707, 6.529829978942871]\n",
      "val [44.35641098022461, 6.83566951751709]\n",
      "predict val...\n",
      "predict test...\n",
      "146.31174 246.62251\n",
      "149.40784 246.62251 364.18066 1.0\n",
      "FOLD 737\n",
      "train [38.14924621582031, 6.573210716247559]\n",
      "val [38.5174446105957, 6.583176612854004]\n",
      "predict val...\n",
      "predict test...\n",
      "122.437195 256.55426\n",
      "167.07043 256.55426 391.73633 1.0\n",
      "FOLD 738\n",
      "train [36.19099807739258, 6.50885009765625]\n",
      "val [48.06535339355469, 6.680575370788574]\n",
      "predict val...\n",
      "predict test...\n",
      "157.2253 237.17126\n",
      "165.15393 237.17126 322.17676 1.0\n",
      "FOLD 739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [38.33018112182617, 6.576866149902344]\n",
      "val [38.62747573852539, 6.492260456085205]\n",
      "predict val...\n",
      "predict test...\n",
      "128.61975 233.1766\n",
      "149.4856 233.1766 328.84375 1.0\n",
      "FOLD 740\n",
      "train [37.09513473510742, 6.5368242263793945]\n",
      "val [43.88624954223633, 6.684206962585449]\n",
      "predict val...\n",
      "predict test...\n",
      "145.23395 244.26283\n",
      "160.23096 244.26283 331.49023 1.0\n",
      "FOLD 741\n",
      "train [37.41309356689453, 6.5466485023498535]\n",
      "val [42.12834167480469, 6.781020164489746]\n",
      "predict val...\n",
      "predict test...\n",
      "139.37292 251.48221\n",
      "172.0376 251.48221 340.10352 1.0\n",
      "FOLD 742\n",
      "train [37.8488883972168, 6.559833526611328]\n",
      "val [39.34305191040039, 6.614985942840576]\n",
      "predict val...\n",
      "predict test...\n",
      "125.97426 250.41974\n",
      "156.6748 250.41974 403.40723 1.0\n",
      "FOLD 743\n",
      "train [35.15300369262695, 6.467259407043457]\n",
      "val [49.07555389404297, 6.683882713317871]\n",
      "predict val...\n",
      "predict test...\n",
      "159.7261 222.96852\n",
      "156.29626 222.96852 284.99512 1.0\n",
      "FOLD 744\n",
      "train [39.000831604003906, 6.586249351501465]\n",
      "val [37.10003662109375, 6.488456726074219]\n",
      "predict val...\n",
      "predict test...\n",
      "124.432236 227.13316\n",
      "101.8999 227.13316 366.39844 1.0\n",
      "FOLD 745\n",
      "train [36.95368576049805, 6.530256748199463]\n",
      "val [43.724609375, 6.6868896484375]\n",
      "predict val...\n",
      "predict test...\n",
      "145.7923 237.85118\n",
      "174.51392 237.85118 324.1267 1.0\n",
      "FOLD 746\n",
      "train [37.61479949951172, 6.540017604827881]\n",
      "val [42.152889251708984, 6.776484489440918]\n",
      "predict val...\n",
      "predict test...\n",
      "137.97377 242.74054\n",
      "137.78003 242.74054 366.33984 1.0\n",
      "FOLD 747\n",
      "train [35.848899841308594, 6.5072503089904785]\n",
      "val [40.582210540771484, 6.547955513000488]\n",
      "predict val...\n",
      "predict test...\n",
      "131.38278 246.21063\n",
      "136.20288 246.21063 303.9414 1.0\n",
      "FOLD 748\n",
      "train [36.11369323730469, 6.496755123138428]\n",
      "val [48.49348449707031, 6.673342704772949]\n",
      "predict val...\n",
      "predict test...\n",
      "159.0891 229.61531\n",
      "149.48059 229.61531 354.7588 1.0\n",
      "FOLD 749\n",
      "train [38.66281509399414, 6.585492134094238]\n",
      "val [36.52079391479492, 6.4819655418396]\n",
      "predict val...\n",
      "predict test...\n",
      "122.174774 241.01898\n",
      "161.98737 241.01898 321.9917 1.0\n",
      "FOLD 750\n",
      "train [37.323604583740234, 6.550164699554443]\n",
      "val [42.916141510009766, 6.658756256103516]\n",
      "predict val...\n",
      "predict test...\n",
      "141.6749 241.52458\n",
      "163.15698 241.52458 343.54004 1.0\n",
      "FOLD 751\n",
      "train [42.25514602661133, 6.5568742752075195]\n",
      "val [48.17977523803711, 6.7861433029174805]\n",
      "predict val...\n",
      "predict test...\n",
      "141.2197 250.09946\n",
      "116.01306 250.09946 440.9087 1.0\n",
      "FOLD 752\n",
      "train [43.55056381225586, 6.574558258056641]\n",
      "val [44.26325225830078, 6.600274085998535]\n",
      "predict val...\n",
      "predict test...\n",
      "124.27759 248.91516\n",
      "125.35535 248.91516 429.3086 1.0\n",
      "FOLD 753\n",
      "train [40.61784744262695, 6.494239807128906]\n",
      "val [54.72581100463867, 6.711832046508789]\n",
      "predict val...\n",
      "predict test...\n",
      "159.83391 227.37444\n",
      "102.47131 227.37444 504.34766 1.0\n",
      "FOLD 754\n",
      "train [45.353389739990234, 6.622692108154297]\n",
      "val [41.31150817871094, 6.492338180541992]\n",
      "predict val...\n",
      "predict test...\n",
      "123.552155 222.25114\n",
      "76.62604 222.25114 376.79004 1.0\n",
      "FOLD 755\n",
      "train [43.002845764160156, 6.553630828857422]\n",
      "val [47.178955078125, 6.650115966796875]\n",
      "predict val...\n",
      "predict test...\n",
      "139.308 224.55331\n",
      "110.445496 224.55331 382.77344 1.0\n",
      "FOLD 756\n",
      "train [42.20836639404297, 6.547123908996582]\n",
      "val [48.47901153564453, 6.804512977600098]\n",
      "predict val...\n",
      "predict test...\n",
      "142.08281 243.38928\n",
      "121.37793 243.38928 415.32324 1.0\n",
      "FOLD 757\n",
      "train [42.75381088256836, 6.562277793884277]\n",
      "val [45.1650505065918, 6.621235370635986]\n",
      "predict val...\n",
      "predict test...\n",
      "127.981804 248.17032\n",
      "133.45557 248.17032 419.56152 1.0\n",
      "FOLD 758\n",
      "train [40.81734848022461, 6.499937534332275]\n",
      "val [54.82278060913086, 6.681177616119385]\n",
      "predict val...\n",
      "predict test...\n",
      "160.29604 224.56174\n",
      "106.05701 224.56174 493.33887 1.0\n",
      "FOLD 759\n",
      "train [44.45281219482422, 6.607929229736328]\n",
      "val [41.73830795288086, 6.494231224060059]\n",
      "predict val...\n",
      "predict test...\n",
      "123.78336 230.09808\n",
      "83.6532 230.09808 383.99536 1.0\n",
      "FOLD 760\n",
      "train [42.05919647216797, 6.5432538986206055]\n",
      "val [47.5654411315918, 6.64616584777832]\n",
      "predict val...\n",
      "predict test...\n",
      "140.67682 233.78351\n",
      "116.44202 233.78351 393.53418 1.0\n",
      "FOLD 761\n",
      "train [41.65370178222656, 6.543182373046875]\n",
      "val [47.739315032958984, 6.757844924926758]\n",
      "predict val...\n",
      "predict test...\n",
      "140.77664 249.29051\n",
      "126.31677 249.29051 417.52686 1.0\n",
      "FOLD 762\n",
      "train [42.170799255371094, 6.556223392486572]\n",
      "val [44.46622085571289, 6.619117736816406]\n",
      "predict val...\n",
      "predict test...\n",
      "126.35044 254.80428\n",
      "138.37292 254.80428 431.4673 1.0\n",
      "FOLD 763\n",
      "train [40.32442855834961, 6.494574069976807]\n",
      "val [53.455413818359375, 6.673464775085449]\n",
      "predict val...\n",
      "predict test...\n",
      "156.94756 231.16212\n",
      "131.17468 231.16212 446.8423 1.0\n",
      "FOLD 764\n",
      "train [44.278839111328125, 6.604792594909668]\n",
      "val [41.64470672607422, 6.491004943847656]\n",
      "predict val...\n",
      "predict test...\n",
      "123.05635 233.98833\n",
      "101.87689 233.98833 369.57373 1.0\n",
      "FOLD 765\n",
      "train [41.87334442138672, 6.54396915435791]\n",
      "val [47.828067779541016, 6.64324951171875]\n",
      "predict val...\n",
      "predict test...\n",
      "141.54845 237.61823\n",
      "139.4762 237.61823 372.437 1.0\n",
      "FOLD 766\n",
      "train [42.214393615722656, 6.557056427001953]\n",
      "val [47.4372444152832, 6.775996208190918]\n",
      "predict val...\n",
      "predict test...\n",
      "138.95149 251.33978\n",
      "135.58057 251.33978 417.00342 1.0\n",
      "FOLD 767\n",
      "train [42.14104461669922, 6.554422855377197]\n",
      "val [43.733943939208984, 6.607184410095215]\n",
      "predict val...\n",
      "predict test...\n",
      "124.82231 248.70747\n",
      "156.76233 248.70747 385.5298 1.0\n",
      "FOLD 768\n",
      "train [39.84000778198242, 6.482092380523682]\n",
      "val [54.28376388549805, 6.6661787033081055]\n",
      "predict val...\n",
      "predict test...\n",
      "157.38396 227.2019\n",
      "131.16199 227.2019 399.4121 1.0\n",
      "FOLD 769\n",
      "train [44.133079528808594, 6.600218296051025]\n",
      "val [43.38605880737305, 6.511569023132324]\n",
      "predict val...\n",
      "predict test...\n",
      "128.68205 229.79616\n",
      "97.72357 229.79616 375.2378 1.0\n",
      "FOLD 770\n",
      "train [40.38908386230469, 6.5145583152771]\n",
      "val [51.801658630371094, 6.726349830627441]\n",
      "predict val...\n",
      "predict test...\n",
      "150.88832 229.53955\n",
      "150.85681 229.53955 326.1162 1.0\n",
      "FOLD 771\n",
      "train [42.20564270019531, 6.556524753570557]\n",
      "val [47.57381820678711, 6.788018226623535]\n",
      "predict val...\n",
      "predict test...\n",
      "138.88785 250.53845\n",
      "153.6001 250.53845 357.4834 1.0\n",
      "FOLD 772\n",
      "train [42.394378662109375, 6.558658599853516]\n",
      "val [43.53428268432617, 6.5997114181518555]\n",
      "predict val...\n",
      "predict test...\n",
      "123.91144 250.2502\n",
      "150.28992 250.2502 413.2412 1.0\n",
      "FOLD 773\n",
      "train [39.8476448059082, 6.49722146987915]\n",
      "val [55.12736511230469, 6.687451362609863]\n",
      "predict val...\n",
      "predict test...\n",
      "160.48482 235.71208\n",
      "145.6532 235.71208 358.41846 1.0\n",
      "FOLD 774\n",
      "train [43.36890411376953, 6.586078643798828]\n",
      "val [42.413734436035156, 6.4984354972839355]\n",
      "predict val...\n",
      "predict test...\n",
      "127.95375 230.06529\n",
      "119.146545 230.06529 355.3042 1.0\n",
      "FOLD 775\n",
      "train [41.3984489440918, 6.536426544189453]\n",
      "val [50.41851043701172, 6.6892900466918945]\n",
      "predict val...\n",
      "predict test...\n",
      "148.78232 234.26091\n",
      "145.67542 234.26091 321.86377 1.0\n",
      "FOLD 776\n",
      "train [40.99412155151367, 6.539563179016113]\n",
      "val [47.15486145019531, 6.780450820922852]\n",
      "predict val...\n",
      "predict test...\n",
      "139.1952 255.27293\n",
      "170.74011 255.27293 319.85254 1.0\n",
      "FOLD 777\n",
      "train [42.21714401245117, 6.552464962005615]\n",
      "val [44.126075744628906, 6.630023956298828]\n",
      "predict val...\n",
      "predict test...\n",
      "125.71417 249.71075\n",
      "142.5758 249.71075 412.16162 1.0\n",
      "FOLD 778\n",
      "train [40.032981872558594, 6.490541934967041]\n",
      "val [54.64720916748047, 6.673435211181641]\n",
      "predict val...\n",
      "predict test...\n",
      "158.35161 231.76212\n",
      "142.19397 231.76212 352.80713 1.0\n",
      "FOLD 779\n",
      "train [43.430145263671875, 6.582023620605469]\n",
      "val [43.51816177368164, 6.491196155548096]\n",
      "predict val...\n",
      "predict test...\n",
      "128.81734 225.78125\n",
      "104.98297 225.78125 357.0454 1.0\n",
      "FOLD 780\n",
      "train [41.93528747558594, 6.550002098083496]\n",
      "val [48.825069427490234, 6.6669511795043945]\n",
      "predict val...\n",
      "predict test...\n",
      "144.12534 238.0729\n",
      "138.69507 238.0729 352.67578 1.0\n",
      "FOLD 781\n",
      "train [41.910606384277344, 6.5505051612854]\n",
      "val [46.83094787597656, 6.761926174163818]\n",
      "predict val...\n",
      "predict test...\n",
      "138.42638 254.69954\n",
      "163.71936 254.69954 356.1416 1.0\n",
      "FOLD 782\n",
      "train [41.91688537597656, 6.5572333335876465]\n",
      "val [44.245296478271484, 6.606001377105713]\n",
      "predict val...\n",
      "predict test...\n",
      "126.15153 252.30525\n",
      "162.13428 252.30525 386.54053 1.0\n",
      "FOLD 783\n",
      "train [38.832176208496094, 6.471658229827881]\n",
      "val [56.3525505065918, 6.732387542724609]\n",
      "predict val...\n",
      "predict test...\n",
      "163.39812 228.65698\n",
      "119.610596 228.65698 304.37598 1.0\n",
      "FOLD 784\n",
      "train [42.813716888427734, 6.565342903137207]\n",
      "val [42.26200866699219, 6.4720234870910645]\n",
      "predict val...\n",
      "predict test...\n",
      "125.39756 236.44351\n",
      "138.49475 236.44351 296.4624 1.0\n",
      "FOLD 785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [39.813446044921875, 6.5131378173828125]\n",
      "val [47.81896209716797, 6.6896820068359375]\n",
      "predict val...\n",
      "predict test...\n",
      "142.5918 233.21875\n",
      "150.45312 233.21875 353.30176 1.0\n",
      "FOLD 786\n",
      "train [41.981624603271484, 6.549762725830078]\n",
      "val [47.537296295166016, 6.794644355773926]\n",
      "predict val...\n",
      "predict test...\n",
      "140.2431 252.02219\n",
      "169.45703 252.02219 359.13477 1.0\n",
      "FOLD 787\n",
      "train [42.081844329833984, 6.5622053146362305]\n",
      "val [43.3023796081543, 6.61197566986084]\n",
      "predict val...\n",
      "predict test...\n",
      "125.710045 256.0784\n",
      "176.70068 256.0784 364.92773 1.0\n",
      "FOLD 788\n",
      "train [38.84076690673828, 6.460413932800293]\n",
      "val [53.97684860229492, 6.679698944091797]\n",
      "predict val...\n",
      "predict test...\n",
      "157.18755 223.96101\n",
      "162.96753 223.96101 281.70215 1.0\n",
      "FOLD 789\n",
      "train [43.31551742553711, 6.591277122497559]\n",
      "val [41.52067565917969, 6.500764846801758]\n",
      "predict val...\n",
      "predict test...\n",
      "124.59744 237.903\n",
      "129.29596 237.903 338.0039 1.0\n",
      "FOLD 790\n",
      "train [41.74238967895508, 6.547757148742676]\n",
      "val [48.5, 6.662689208984375]\n",
      "predict val...\n",
      "predict test...\n",
      "143.08621 241.65309\n",
      "177.28174 241.65309 347.73853 1.0\n",
      "FOLD 791\n",
      "train [41.284481048583984, 6.528958797454834]\n",
      "val [49.58903121948242, 6.815601825714111]\n",
      "predict val...\n",
      "predict test...\n",
      "146.36865 244.68248\n",
      "138.43396 244.68248 377.24463 1.0\n",
      "FOLD 792\n",
      "train [42.2398567199707, 6.5564374923706055]\n",
      "val [43.937137603759766, 6.609042167663574]\n",
      "predict val...\n",
      "predict test...\n",
      "126.0227 247.0368\n",
      "159.78748 247.0368 384.68994 1.0\n",
      "FOLD 793\n",
      "train [38.86036682128906, 6.461905002593994]\n",
      "val [56.85759353637695, 6.691532135009766]\n",
      "predict val...\n",
      "predict test...\n",
      "163.61156 224.81392\n",
      "149.62512 224.81392 263.64966 1.0\n",
      "FOLD 794\n",
      "train [43.52498245239258, 6.586050510406494]\n",
      "val [41.258880615234375, 6.487432479858398]\n",
      "predict val...\n",
      "predict test...\n",
      "123.53606 233.22585\n",
      "123.96265 233.22585 338.88306 1.0\n",
      "FOLD 795\n",
      "train [40.035560607910156, 6.5154314041137695]\n",
      "val [47.0299186706543, 6.672809600830078]\n",
      "predict val...\n",
      "predict test...\n",
      "139.05147 231.28757\n",
      "151.39136 231.28757 316.2959 1.0\n",
      "FOLD 796\n",
      "train [41.75526809692383, 6.538771629333496]\n",
      "val [47.04500961303711, 6.752463340759277]\n",
      "predict val...\n",
      "predict test...\n",
      "138.6048 243.44536\n",
      "155.03345 243.44536 333.37695 1.0\n",
      "FOLD 797\n",
      "train [42.03330993652344, 6.555473327636719]\n",
      "val [44.98330307006836, 6.642121315002441]\n",
      "predict val...\n",
      "predict test...\n",
      "127.77921 248.50107\n",
      "150.61621 248.50107 408.2671 1.0\n",
      "FOLD 798\n",
      "train [39.804874420166016, 6.496527671813965]\n",
      "val [55.28171920776367, 6.676797389984131]\n",
      "predict val...\n",
      "predict test...\n",
      "160.40654 235.14806\n",
      "159.00964 235.14806 334.4458 1.0\n",
      "FOLD 799\n",
      "train [43.499149322509766, 6.587159633636475]\n",
      "val [40.79811096191406, 6.492585182189941]\n",
      "predict val...\n",
      "predict test...\n",
      "123.45753 237.78387\n",
      "154.56927 237.78387 350.5459 1.0\n",
      "FOLD 800\n",
      "train [41.58771514892578, 6.547168731689453]\n",
      "val [49.02104568481445, 6.6761627197265625]\n",
      "predict val...\n",
      "predict test...\n",
      "144.34332 241.97958\n",
      "171.53491 241.97958 332.63916 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 801\n",
      "train [28.956287384033203, 6.551865577697754]\n",
      "val [31.72244644165039, 6.741887092590332]\n",
      "predict val...\n",
      "predict test...\n",
      "137.5272 242.81474\n",
      "125.70154 242.81474 415.3042 1.0\n",
      "FOLD 802\n",
      "train [29.035207748413086, 6.557295322418213]\n",
      "val [29.99692726135254, 6.595065116882324]\n",
      "predict val...\n",
      "predict test...\n",
      "124.251434 248.84456\n",
      "140.40271 248.84456 421.6919 1.0\n",
      "FOLD 803\n",
      "train [27.892864227294922, 6.503060817718506]\n",
      "val [35.72216033935547, 6.6810808181762695]\n",
      "predict val...\n",
      "predict test...\n",
      "155.15399 233.14482\n",
      "108.59009 233.14482 509.77246 1.0\n",
      "FOLD 804\n",
      "train [29.996164321899414, 6.596031188964844]\n",
      "val [28.73252296447754, 6.492397785186768]\n",
      "predict val...\n",
      "predict test...\n",
      "125.13615 225.98035\n",
      "90.52496 225.98035 380.49902 1.0\n",
      "FOLD 805\n",
      "train [29.429183959960938, 6.555399417877197]\n",
      "val [32.23945617675781, 6.658416748046875]\n",
      "predict val...\n",
      "predict test...\n",
      "140.64526 221.41887\n",
      "113.09857 221.41887 376.65332 1.0\n",
      "FOLD 806\n",
      "train [29.006813049316406, 6.557372093200684]\n",
      "val [32.23204803466797, 6.77451229095459]\n",
      "predict val...\n",
      "predict test...\n",
      "138.81381 247.8608\n",
      "127.65283 247.8608 404.542 1.0\n",
      "FOLD 807\n",
      "train [28.7524356842041, 6.542455196380615]\n",
      "val [31.717130661010742, 6.636887073516846]\n",
      "predict val...\n",
      "predict test...\n",
      "133.41823 239.11024\n",
      "142.81897 239.11024 395.9121 1.0\n",
      "FOLD 808\n",
      "train [27.295074462890625, 6.469460964202881]\n",
      "val [36.22304153442383, 6.662714004516602]\n",
      "predict val...\n",
      "predict test...\n",
      "155.38277 217.96628\n",
      "109.49609 217.96628 427.2539 1.0\n",
      "FOLD 809\n",
      "train [30.164409637451172, 6.6087493896484375]\n",
      "val [28.329164505004883, 6.499081611633301]\n",
      "predict val...\n",
      "predict test...\n",
      "123.67465 232.53008\n",
      "97.61743 232.53008 383.9995 1.0\n",
      "FOLD 810\n",
      "train [28.6220645904541, 6.532794952392578]\n",
      "val [32.40763854980469, 6.660004615783691]\n",
      "predict val...\n",
      "predict test...\n",
      "142.08736 228.75717\n",
      "126.5332 228.75717 358.6162 1.0\n",
      "FOLD 811\n",
      "train [28.579158782958984, 6.545895576477051]\n",
      "val [32.139198303222656, 6.744140625]\n",
      "predict val...\n",
      "predict test...\n",
      "139.96756 249.86978\n",
      "127.85339 249.86978 420.80322 1.0\n",
      "FOLD 812\n",
      "train [28.7343807220459, 6.5564398765563965]\n",
      "val [30.141443252563477, 6.62909460067749]\n",
      "predict val...\n",
      "predict test...\n",
      "127.18522 250.93684\n",
      "143.23828 250.93684 412.58008 1.0\n",
      "FOLD 813\n",
      "train [27.65896987915039, 6.496988773345947]\n",
      "val [36.10289764404297, 6.680019378662109]\n",
      "predict val...\n",
      "predict test...\n",
      "157.45242 231.22324\n",
      "138.1084 231.22324 417.62207 1.0\n",
      "FOLD 814\n",
      "train [29.681913375854492, 6.589880466461182]\n",
      "val [28.47856903076172, 6.481985092163086]\n",
      "predict val...\n",
      "predict test...\n",
      "124.40482 226.25621\n",
      "101.6355 226.25621 356.46436 1.0\n",
      "FOLD 815\n",
      "train [28.430458068847656, 6.539141654968262]\n",
      "val [33.39607238769531, 6.67820405960083]\n",
      "predict val...\n",
      "predict test...\n",
      "145.20091 236.50363\n",
      "152.27051 236.50363 333.09717 1.0\n",
      "FOLD 816\n",
      "train [28.73426628112793, 6.5478410720825195]\n",
      "val [32.059730529785156, 6.771248817443848]\n",
      "predict val...\n",
      "predict test...\n",
      "139.40494 249.12923\n",
      "145.93909 249.12923 372.04785 1.0\n",
      "FOLD 817\n",
      "train [28.59136390686035, 6.539849758148193]\n",
      "val [29.975799560546875, 6.576786041259766]\n",
      "predict val...\n",
      "predict test...\n",
      "124.0485 243.8008\n",
      "142.33716 243.8008 404.917 1.0\n",
      "FOLD 818\n",
      "train [27.42608642578125, 6.487802028656006]\n",
      "val [37.75197219848633, 6.685020446777344]\n",
      "predict val...\n",
      "predict test...\n",
      "164.2325 226.6281\n",
      "130.26257 226.6281 423.09033 1.0\n",
      "FOLD 819\n",
      "train [29.062395095825195, 6.574293613433838]\n",
      "val [28.0512638092041, 6.492584228515625]\n",
      "predict val...\n",
      "predict test...\n",
      "123.439026 244.41342\n",
      "146.21735 244.41342 310.7246 1.0\n",
      "FOLD 820\n",
      "train [28.418020248413086, 6.539958953857422]\n",
      "val [34.24513244628906, 6.701903343200684]\n",
      "predict val...\n",
      "predict test...\n",
      "150.42763 234.67111\n",
      "141.28674 234.67111 336.8413 1.0\n",
      "FOLD 821\n",
      "train [28.763885498046875, 6.553455352783203]\n",
      "val [32.25556564331055, 6.79534912109375]\n",
      "predict val...\n",
      "predict test...\n",
      "140.15115 251.2369\n",
      "157.64368 251.2369 378.6411 1.0\n",
      "FOLD 822\n",
      "train [29.094558715820312, 6.560089111328125]\n",
      "val [29.714200973510742, 6.601308822631836]\n",
      "predict val...\n",
      "predict test...\n",
      "123.975685 248.45541\n",
      "153.60132 248.45541 402.52344 1.0\n",
      "FOLD 823\n",
      "train [27.441387176513672, 6.493646144866943]\n",
      "val [36.60676956176758, 6.669122695922852]\n",
      "predict val...\n",
      "predict test...\n",
      "158.24551 232.47108\n",
      "149.1742 232.47108 352.73486 1.0\n",
      "FOLD 824\n",
      "train [30.015554428100586, 6.595644950866699]\n",
      "val [27.59731674194336, 6.480206489562988]\n",
      "predict val...\n",
      "predict test...\n",
      "120.81922 239.16959\n",
      "143.9751 239.16959 328.6604 1.0\n",
      "FOLD 825\n",
      "train [28.436885833740234, 6.538037300109863]\n",
      "val [33.36812973022461, 6.674778938293457]\n",
      "predict val...\n",
      "predict test...\n",
      "145.849 232.55663\n",
      "149.39539 232.55663 322.2378 1.0\n",
      "FOLD 826\n",
      "train [28.61544418334961, 6.5437445640563965]\n",
      "val [32.19579315185547, 6.779430389404297]\n",
      "predict val...\n",
      "predict test...\n",
      "138.79802 246.24905\n",
      "137.547 246.24905 382.41455 1.0\n",
      "FOLD 827\n",
      "train [27.820693969726562, 6.499736785888672]\n",
      "val [29.885971069335938, 6.570542812347412]\n",
      "predict val...\n",
      "predict test...\n",
      "126.60809 223.23251\n",
      "152.16992 223.23251 317.04248 1.0\n",
      "FOLD 828\n",
      "train [27.25596046447754, 6.477935791015625]\n",
      "val [36.46474075317383, 6.665245056152344]\n",
      "predict val...\n",
      "predict test...\n",
      "158.77252 224.40485\n",
      "149.37036 224.40485 325.61182 1.0\n",
      "FOLD 829\n",
      "train [30.017807006835938, 6.5978899002075195]\n",
      "val [29.037784576416016, 6.492233753204346]\n",
      "predict val...\n",
      "predict test...\n",
      "125.30404 229.44337\n",
      "105.48297 229.44337 362.72217 1.0\n",
      "FOLD 830\n",
      "train [28.27121353149414, 6.530994415283203]\n",
      "val [34.22412109375, 6.699248313903809]\n",
      "predict val...\n",
      "predict test...\n",
      "148.11609 233.30896\n",
      "151.08838 233.30896 338.40845 1.0\n",
      "FOLD 831\n",
      "train [28.574562072753906, 6.541506767272949]\n",
      "val [32.898468017578125, 6.804723739624023]\n",
      "predict val...\n",
      "predict test...\n",
      "142.37021 248.0002\n",
      "145.69153 248.0002 382.8164 1.0\n",
      "FOLD 832\n",
      "train [28.299915313720703, 6.534125328063965]\n",
      "val [29.566625595092773, 6.586537837982178]\n",
      "predict val...\n",
      "predict test...\n",
      "124.768326 248.76021\n",
      "181.2174 248.76021 344.76953 1.0\n",
      "FOLD 833\n",
      "train [26.75463104248047, 6.46484899520874]\n",
      "val [36.97401809692383, 6.698087692260742]\n",
      "predict val...\n",
      "predict test...\n",
      "159.675 223.55606\n",
      "123.397705 223.55606 274.90625 1.0\n",
      "FOLD 834\n",
      "train [29.55448341369629, 6.583587646484375]\n",
      "val [28.436304092407227, 6.5010833740234375]\n",
      "predict val...\n",
      "predict test...\n",
      "125.317894 241.59683\n",
      "138.59485 241.59683 330.65967 1.0\n",
      "FOLD 835\n",
      "train [28.026947021484375, 6.525978088378906]\n",
      "val [33.61964416503906, 6.693941116333008]\n",
      "predict val...\n",
      "predict test...\n",
      "148.06197 235.56476\n",
      "164.18848 235.56476 315.177 1.0\n",
      "FOLD 836\n",
      "train [28.647579193115234, 6.549524784088135]\n",
      "val [32.08268737792969, 6.791665077209473]\n",
      "predict val...\n",
      "predict test...\n",
      "139.35953 251.83118\n",
      "176.27979 251.83118 333.8584 1.0\n",
      "FOLD 837\n",
      "train [29.109323501586914, 6.574463844299316]\n",
      "val [29.281158447265625, 6.58367919921875]\n",
      "predict val...\n",
      "predict test...\n",
      "122.122406 256.35464\n",
      "168.85376 256.35464 396.92676 1.0\n",
      "FOLD 838\n",
      "train [26.106874465942383, 6.442434787750244]\n",
      "val [37.17152404785156, 6.6830596923828125]\n",
      "predict val...\n",
      "predict test...\n",
      "159.39938 222.12877\n",
      "128.7312 222.12877 270.58105 1.0\n",
      "FOLD 839\n",
      "train [29.732192993164062, 6.591931343078613]\n",
      "val [27.817243576049805, 6.485191822052002]\n",
      "predict val...\n",
      "predict test...\n",
      "122.75328 240.01369\n",
      "155.04529 240.01369 318.15723 1.0\n",
      "FOLD 840\n",
      "train [28.507640838623047, 6.544610500335693]\n",
      "val [33.17937088012695, 6.679666519165039]\n",
      "predict val...\n",
      "predict test...\n",
      "145.41177 240.77039\n",
      "173.31714 240.77039 327.6836 1.0\n",
      "FOLD 841\n",
      "train [28.156349182128906, 6.52505350112915]\n",
      "val [32.211204528808594, 6.799144744873047]\n",
      "predict val...\n",
      "predict test...\n",
      "139.80548 245.11668\n",
      "160.81909 245.11668 333.85156 1.0\n",
      "FOLD 842\n",
      "train [28.498491287231445, 6.545645236968994]\n",
      "val [31.229734420776367, 6.622172832489014]\n",
      "predict val...\n",
      "predict test...\n",
      "131.89438 241.11009\n",
      "163.50415 241.11009 351.2456 1.0\n",
      "FOLD 843\n",
      "train [25.5747127532959, 6.402152061462402]\n",
      "val [37.58564758300781, 6.6873884201049805]\n",
      "predict val...\n",
      "predict test...\n",
      "161.77718 211.59235\n",
      "112.384766 211.59235 281.6211 1.0\n",
      "FOLD 844\n",
      "train [29.03045082092285, 6.5574750900268555]\n",
      "val [27.929977416992188, 6.459758758544922]\n",
      "predict val...\n",
      "predict test...\n",
      "122.65202 224.7727\n",
      "135.46326 224.7727 310.0791 1.0\n",
      "FOLD 845\n",
      "train [28.355751037597656, 6.538473606109619]\n",
      "val [32.98460388183594, 6.6756086349487305]\n",
      "predict val...\n",
      "predict test...\n",
      "143.82445 239.51491\n",
      "158.61328 239.51491 341.86108 1.0\n",
      "FOLD 846\n",
      "train [28.923545837402344, 6.549883842468262]\n",
      "val [31.924222946166992, 6.75823450088501]\n",
      "predict val...\n",
      "predict test...\n",
      "137.80956 241.55634\n",
      "151.91943 241.55634 351.35547 1.0\n",
      "FOLD 847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [28.250638961791992, 6.522948265075684]\n",
      "val [31.45453453063965, 6.672764778137207]\n",
      "predict val...\n",
      "predict test...\n",
      "133.22412 240.47241\n",
      "136.53503 240.47241 329.0078 1.0\n",
      "FOLD 848\n",
      "train [27.284542083740234, 6.474159240722656]\n",
      "val [36.34184265136719, 6.658877372741699]\n",
      "predict val...\n",
      "predict test...\n",
      "157.7155 233.68593\n",
      "139.84229 233.68593 368.79565 1.0\n",
      "FOLD 849\n",
      "train [28.846426010131836, 6.550070762634277]\n",
      "val [29.643583297729492, 6.484647274017334]\n",
      "predict val...\n",
      "predict test...\n",
      "130.67496 235.753\n",
      "140.01587 235.753 286.77173 1.0\n",
      "FOLD 850\n",
      "train [27.892026901245117, 6.521609306335449]\n",
      "val [35.15978240966797, 6.741332054138184]\n",
      "predict val...\n",
      "predict test...\n",
      "153.72467 230.40854\n",
      "127.601074 230.40854 323.5227 1.0\n",
      "FOLD 851\n",
      "train [33.601715087890625, 6.558865547180176]\n",
      "val [37.29555892944336, 6.766176223754883]\n",
      "predict val...\n",
      "predict test...\n",
      "139.34973 244.70256\n",
      "118.87195 244.70256 425.1748 1.0\n",
      "FOLD 852\n",
      "train [33.830806732177734, 6.5630927085876465]\n",
      "val [35.0976448059082, 6.6278300285339355]\n",
      "predict val...\n",
      "predict test...\n",
      "127.171165 248.43811\n",
      "129.35767 248.43811 426.88232 1.0\n",
      "FOLD 853\n",
      "train [32.252105712890625, 6.511101722717285]\n",
      "val [41.555564880371094, 6.675446510314941]\n",
      "predict val...\n",
      "predict test...\n",
      "156.14809 238.51909\n",
      "120.75171 238.51909 512.708 1.0\n",
      "FOLD 854\n",
      "train [35.00044250488281, 6.600644111633301]\n",
      "val [33.431312561035156, 6.494733810424805]\n",
      "predict val...\n",
      "predict test...\n",
      "125.722336 223.45679\n",
      "89.23016 223.45679 371.8081 1.0\n",
      "FOLD 855\n",
      "train [34.0183219909668, 6.560856819152832]\n",
      "val [36.830509185791016, 6.647187232971191]\n",
      "predict val...\n",
      "predict test...\n",
      "138.4492 225.24269\n",
      "99.35162 225.24269 384.97803 1.0\n",
      "FOLD 856\n",
      "train [32.39201354980469, 6.522291660308838]\n",
      "val [36.73237991333008, 6.740201950073242]\n",
      "predict val...\n",
      "predict test...\n",
      "137.47844 235.36722\n",
      "121.22925 235.36722 391.68994 1.0\n",
      "FOLD 857\n",
      "train [33.865535736083984, 6.564694404602051]\n",
      "val [35.768272399902344, 6.633135795593262]\n",
      "predict val...\n",
      "predict test...\n",
      "128.33202 248.22797\n",
      "132.25903 248.22797 420.94043 1.0\n",
      "FOLD 858\n",
      "train [31.91228675842285, 6.491395473480225]\n",
      "val [42.71849060058594, 6.681107521057129]\n",
      "predict val...\n",
      "predict test...\n",
      "159.72826 227.67024\n",
      "113.09387 227.67024 460.87354 1.0\n",
      "FOLD 859\n",
      "train [34.59048080444336, 6.607509613037109]\n",
      "val [32.885868072509766, 6.496748924255371]\n",
      "predict val...\n",
      "predict test...\n",
      "123.47104 237.34329\n",
      "95.58649 237.34329 395.9043 1.0\n",
      "FOLD 860\n",
      "train [33.082698822021484, 6.538146018981934]\n",
      "val [37.30769729614258, 6.646732330322266]\n",
      "predict val...\n",
      "predict test...\n",
      "140.7688 231.78827\n",
      "117.73108 231.78827 379.87402 1.0\n",
      "FOLD 861\n",
      "train [33.27909851074219, 6.5518798828125]\n",
      "val [36.156898498535156, 6.704249382019043]\n",
      "predict val...\n",
      "predict test...\n",
      "136.26604 248.77374\n",
      "147.125 248.77374 385.45508 1.0\n",
      "FOLD 862\n",
      "train [32.863685607910156, 6.540215969085693]\n",
      "val [35.66526412963867, 6.619777679443359]\n",
      "predict val...\n",
      "predict test...\n",
      "129.17612 245.92519\n",
      "136.31519 245.92519 411.22852 1.0\n",
      "FOLD 863\n",
      "train [32.212528228759766, 6.5133466720581055]\n",
      "val [41.53764343261719, 6.683193206787109]\n",
      "predict val...\n",
      "predict test...\n",
      "155.55125 238.95267\n",
      "128.19421 238.95267 492.17334 1.0\n",
      "FOLD 864\n",
      "train [33.97454071044922, 6.591104984283447]\n",
      "val [31.97890281677246, 6.470859527587891]\n",
      "predict val...\n",
      "predict test...\n",
      "119.80741 241.66502\n",
      "115.677246 241.66502 353.61328 1.0\n",
      "FOLD 865\n",
      "train [32.941219329833984, 6.541106224060059]\n",
      "val [38.3426628112793, 6.664485931396484]\n",
      "predict val...\n",
      "predict test...\n",
      "145.03955 236.44467\n",
      "136.64258 236.44467 375.57324 1.0\n",
      "FOLD 866\n",
      "train [33.040584564208984, 6.542243957519531]\n",
      "val [36.94200897216797, 6.752994537353516]\n",
      "predict val...\n",
      "predict test...\n",
      "139.26366 246.32553\n",
      "140.1665 246.32553 390.7749 1.0\n",
      "FOLD 867\n",
      "train [33.96600341796875, 6.577907562255859]\n",
      "val [33.80168914794922, 6.568675994873047]\n",
      "predict val...\n",
      "predict test...\n",
      "120.451675 255.75952\n",
      "140.95056 255.75952 417.76904 1.0\n",
      "FOLD 868\n",
      "train [31.723217010498047, 6.4845781326293945]\n",
      "val [42.60097885131836, 6.677350997924805]\n",
      "predict val...\n",
      "predict test...\n",
      "159.89214 226.23087\n",
      "119.89209 226.23087 462.54297 1.0\n",
      "FOLD 869\n",
      "train [34.588409423828125, 6.5953216552734375]\n",
      "val [33.50435256958008, 6.503076553344727]\n",
      "predict val...\n",
      "predict test...\n",
      "127.64672 232.47134\n",
      "116.818726 232.47134 350.96143 1.0\n",
      "FOLD 870\n",
      "train [32.92909622192383, 6.544376373291016]\n",
      "val [38.663475036621094, 6.672084808349609]\n",
      "predict val...\n",
      "predict test...\n",
      "146.12773 237.46695\n",
      "148.46692 237.46695 351.88184 1.0\n",
      "FOLD 871\n",
      "train [32.109596252441406, 6.51807165145874]\n",
      "val [35.21275329589844, 6.623929977416992]\n",
      "predict val...\n",
      "predict test...\n",
      "132.06642 242.22028\n",
      "135.94482 242.22028 338.99414 1.0\n",
      "FOLD 872\n",
      "train [32.72654342651367, 6.538229942321777]\n",
      "val [35.39218521118164, 6.612536430358887]\n",
      "predict val...\n",
      "predict test...\n",
      "130.19638 242.24384\n",
      "156.09583 242.24384 378.7163 1.0\n",
      "FOLD 873\n",
      "train [31.62381935119629, 6.48430871963501]\n",
      "val [41.670387268066406, 6.656959533691406]\n",
      "predict val...\n",
      "predict test...\n",
      "155.45497 226.90092\n",
      "142.34473 226.90092 396.9458 1.0\n",
      "FOLD 874\n",
      "train [34.58163070678711, 6.59351110458374]\n",
      "val [33.00598907470703, 6.491243839263916]\n",
      "predict val...\n",
      "predict test...\n",
      "125.202286 228.39806\n",
      "107.89966 228.39806 355.73633 1.0\n",
      "FOLD 875\n",
      "train [32.547019958496094, 6.533639430999756]\n",
      "val [39.381778717041016, 6.691108703613281]\n",
      "predict val...\n",
      "predict test...\n",
      "147.26033 235.50972\n",
      "175.38562 235.50972 338.23267 1.0\n",
      "FOLD 876\n",
      "train [32.668914794921875, 6.530054569244385]\n",
      "val [36.95182800292969, 6.727556228637695]\n",
      "predict val...\n",
      "predict test...\n",
      "139.73694 245.45168\n",
      "159.13184 245.45168 333.32764 1.0\n",
      "FOLD 877\n",
      "train [33.491058349609375, 6.565691947937012]\n",
      "val [34.167564392089844, 6.598057746887207]\n",
      "predict val...\n",
      "predict test...\n",
      "123.75247 252.5223\n",
      "159.92285 252.5223 403.07227 1.0\n",
      "FOLD 878\n",
      "train [31.406801223754883, 6.479234218597412]\n",
      "val [42.51942825317383, 6.667479515075684]\n",
      "predict val...\n",
      "predict test...\n",
      "160.14485 224.82648\n",
      "143.03809 224.82648 387.2793 1.0\n",
      "FOLD 879\n",
      "train [34.20665740966797, 6.587339878082275]\n",
      "val [33.08015060424805, 6.499781608581543]\n",
      "predict val...\n",
      "predict test...\n",
      "126.78958 235.38899\n",
      "139.20392 235.38899 334.40186 1.0\n",
      "FOLD 880\n",
      "train [32.8331184387207, 6.54965877532959]\n",
      "val [39.13636779785156, 6.700926780700684]\n",
      "predict val...\n",
      "predict test...\n",
      "146.9189 242.8516\n",
      "151.3341 242.8516 348.67725 1.0\n",
      "FOLD 881\n",
      "train [32.16507339477539, 6.5224738121032715]\n",
      "val [38.002803802490234, 6.867144584655762]\n",
      "predict val...\n",
      "predict test...\n",
      "142.31857 244.11215\n",
      "160.77148 244.11215 335.3672 1.0\n",
      "FOLD 882\n",
      "train [33.6440315246582, 6.564627647399902]\n",
      "val [34.27130126953125, 6.582732200622559]\n",
      "predict val...\n",
      "predict test...\n",
      "122.9077 251.00797\n",
      "157.51013 251.00797 403.34473 1.0\n",
      "FOLD 883\n",
      "train [31.5107479095459, 6.4900922775268555]\n",
      "val [43.23743438720703, 6.672919273376465]\n",
      "predict val...\n",
      "predict test...\n",
      "160.43889 235.87332\n",
      "153.0968 235.87332 331.48145 1.0\n",
      "FOLD 884\n",
      "train [35.047508239746094, 6.6001715660095215]\n",
      "val [32.7735595703125, 6.481870174407959]\n",
      "predict val...\n",
      "predict test...\n",
      "123.15775 230.8166\n",
      "115.78516 230.8166 344.16504 1.0\n",
      "FOLD 885\n",
      "train [32.327552795410156, 6.5345778465271]\n",
      "val [38.417484283447266, 6.690579414367676]\n",
      "predict val...\n",
      "predict test...\n",
      "144.42953 235.04117\n",
      "165.41504 235.04117 320.09155 1.0\n",
      "FOLD 886\n",
      "train [32.4542236328125, 6.517974853515625]\n",
      "val [37.46955108642578, 6.757535934448242]\n",
      "predict val...\n",
      "predict test...\n",
      "140.54921 240.05313\n",
      "138.9375 240.05313 354.89355 1.0\n",
      "FOLD 887\n",
      "train [32.28036880493164, 6.523261070251465]\n",
      "val [37.007286071777344, 6.7008056640625]\n",
      "predict val...\n",
      "predict test...\n",
      "136.52301 246.00778\n",
      "152.16724 246.00778 381.7627 1.0\n",
      "FOLD 888\n",
      "train [31.221450805664062, 6.481813907623291]\n",
      "val [42.678565979003906, 6.677567481994629]\n",
      "predict val...\n",
      "predict test...\n",
      "158.53006 230.84608\n",
      "162.15149 230.84608 285.6001 1.0\n",
      "FOLD 889\n",
      "train [34.35246658325195, 6.586092948913574]\n",
      "val [33.21094512939453, 6.499812126159668]\n",
      "predict val...\n",
      "predict test...\n",
      "127.27732 237.19002\n",
      "150.48932 237.19002 315.59277 1.0\n",
      "FOLD 890\n",
      "train [32.61958312988281, 6.538031578063965]\n",
      "val [38.47521209716797, 6.679327011108398]\n",
      "predict val...\n",
      "predict test...\n",
      "145.01099 239.45872\n",
      "161.66333 239.45872 330.41895 1.0\n",
      "FOLD 891\n",
      "train [32.995513916015625, 6.541469573974609]\n",
      "val [37.10198974609375, 6.7765913009643555]\n",
      "predict val...\n",
      "predict test...\n",
      "139.24164 246.82985\n",
      "162.99878 246.82985 343.77393 1.0\n",
      "FOLD 892\n",
      "train [33.02876281738281, 6.547755241394043]\n",
      "val [34.79106521606445, 6.61594295501709]\n",
      "predict val...\n",
      "predict test...\n",
      "128.07787 249.82535\n",
      "171.21875 249.82535 351.09912 1.0\n",
      "FOLD 893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [30.355831146240234, 6.455271244049072]\n",
      "val [45.05994415283203, 6.778236389160156]\n",
      "predict val...\n",
      "predict test...\n",
      "166.1561 225.19153\n",
      "72.428955 225.19153 281.12036 1.0\n",
      "FOLD 894\n",
      "train [34.50934982299805, 6.5980544090271]\n",
      "val [30.985294342041016, 6.482782363891602]\n",
      "predict val...\n",
      "predict test...\n",
      "120.253204 237.29825\n",
      "148.18433 237.29825 333.29395 1.0\n",
      "FOLD 895\n",
      "train [32.75980758666992, 6.540173530578613]\n",
      "val [38.22873306274414, 6.67960262298584]\n",
      "predict val...\n",
      "predict test...\n",
      "143.77983 233.8162\n",
      "164.63611 233.8162 326.41772 1.0\n",
      "FOLD 896\n",
      "train [33.114742279052734, 6.54458475112915]\n",
      "val [37.182525634765625, 6.782846450805664]\n",
      "predict val...\n",
      "predict test...\n",
      "139.18048 245.58247\n",
      "171.9834 245.58247 330.64062 1.0\n",
      "FOLD 897\n",
      "train [33.35725784301758, 6.560196876525879]\n",
      "val [35.17277908325195, 6.620431423187256]\n",
      "predict val...\n",
      "predict test...\n",
      "127.90587 247.66885\n",
      "160.9751 247.66885 381.16943 1.0\n",
      "FOLD 898\n",
      "train [31.422571182250977, 6.479159355163574]\n",
      "val [42.409454345703125, 6.6609015464782715]\n",
      "predict val...\n",
      "predict test...\n",
      "159.42813 223.32832\n",
      "145.40796 223.32832 358.2583 1.0\n",
      "FOLD 899\n",
      "train [34.11747360229492, 6.581843376159668]\n",
      "val [32.28535842895508, 6.475727081298828]\n",
      "predict val...\n",
      "predict test...\n",
      "122.301125 235.90161\n",
      "139.56293 235.90161 329.94922 1.0\n",
      "FOLD 900\n",
      "train [32.79850387573242, 6.543286323547363]\n",
      "val [38.075008392333984, 6.673158645629883]\n",
      "predict val...\n",
      "predict test...\n",
      "142.72354 236.29234\n",
      "169.03516 236.29234 339.74902 1.0\n",
      "FOLD 901\n",
      "train [37.903526306152344, 6.559808254241943]\n",
      "val [42.66062545776367, 6.761178016662598]\n",
      "predict val...\n",
      "predict test...\n",
      "140.36652 249.82393\n",
      "119.21106 249.82393 438.9038 1.0\n",
      "FOLD 902\n",
      "train [37.91512680053711, 6.552611351013184]\n",
      "val [39.80463790893555, 6.615925312042236]\n",
      "predict val...\n",
      "predict test...\n",
      "126.415665 247.01018\n",
      "127.757935 247.01018 425.14307 1.0\n",
      "FOLD 903\n",
      "train [35.76995086669922, 6.484158992767334]\n",
      "val [47.41142272949219, 6.709035396575928]\n",
      "predict val...\n",
      "predict test...\n",
      "156.6047 226.67714\n",
      "105.71936 226.67714 473.9922 1.0\n",
      "FOLD 904\n",
      "train [39.334014892578125, 6.595454216003418]\n",
      "val [37.67649841308594, 6.4969587326049805]\n",
      "predict val...\n",
      "predict test...\n",
      "125.9959 225.8054\n",
      "90.760315 225.8054 373.18457 1.0\n",
      "FOLD 905\n",
      "train [38.12772750854492, 6.547450065612793]\n",
      "val [42.57735061645508, 6.65339994430542]\n",
      "predict val...\n",
      "predict test...\n",
      "141.18806 225.96703\n",
      "105.81189 225.96703 389.3247 1.0\n",
      "FOLD 906\n",
      "train [38.03010177612305, 6.559233665466309]\n",
      "val [42.278812408447266, 6.751556873321533]\n",
      "predict val...\n",
      "predict test...\n",
      "138.54921 247.74298\n",
      "117.891235 247.74298 430.6919 1.0\n",
      "FOLD 907\n",
      "train [38.63532638549805, 6.5689239501953125]\n",
      "val [39.55400848388672, 6.597682476043701]\n",
      "predict val...\n",
      "predict test...\n",
      "125.41083 247.72047\n",
      "138.22437 247.72047 419.042 1.0\n",
      "FOLD 908\n",
      "train [36.178489685058594, 6.499131679534912]\n",
      "val [48.66364669799805, 6.687819480895996]\n",
      "predict val...\n",
      "predict test...\n",
      "160.09253 232.79749\n",
      "118.80005 232.79749 496.99902 1.0\n",
      "FOLD 909\n",
      "train [39.347415924072266, 6.607870578765869]\n",
      "val [37.71617889404297, 6.49797248840332]\n",
      "predict val...\n",
      "predict test...\n",
      "124.7303 236.6872\n",
      "103.13977 236.6872 378.98193 1.0\n",
      "FOLD 910\n",
      "train [37.320343017578125, 6.526615142822266]\n",
      "val [42.5465202331543, 6.664060115814209]\n",
      "predict val...\n",
      "predict test...\n",
      "140.72646 221.8807\n",
      "118.74597 221.8807 352.91504 1.0\n",
      "FOLD 911\n",
      "train [37.89833450317383, 6.566343784332275]\n",
      "val [41.52369689941406, 6.7269206047058105]\n",
      "predict val...\n",
      "predict test...\n",
      "137.76787 258.4875\n",
      "162.7865 258.4875 399.6714 1.0\n",
      "FOLD 912\n",
      "train [38.00809097290039, 6.562246799468994]\n",
      "val [39.019569396972656, 6.619593620300293]\n",
      "predict val...\n",
      "predict test...\n",
      "124.506035 253.2516\n",
      "146.2356 253.2516 427.21436 1.0\n",
      "FOLD 913\n",
      "train [35.91864013671875, 6.496751308441162]\n",
      "val [48.443504333496094, 6.710576057434082]\n",
      "predict val...\n",
      "predict test...\n",
      "158.39108 234.93547\n",
      "129.3866 234.93547 438.31396 1.0\n",
      "FOLD 914\n",
      "train [38.717735290527344, 6.584173679351807]\n",
      "val [37.50861740112305, 6.477869510650635]\n",
      "predict val...\n",
      "predict test...\n",
      "123.51527 227.14832\n",
      "101.948 227.14832 361.22363 1.0\n",
      "FOLD 915\n",
      "train [36.38328552246094, 6.524050235748291]\n",
      "val [43.525733947753906, 6.690421104431152]\n",
      "predict val...\n",
      "predict test...\n",
      "143.86052 232.16734\n",
      "161.2085 232.16734 321.07544 1.0\n",
      "FOLD 916\n",
      "train [37.761573791503906, 6.555508613586426]\n",
      "val [41.67596435546875, 6.738070487976074]\n",
      "predict val...\n",
      "predict test...\n",
      "138.02153 252.78094\n",
      "147.28345 252.78094 382.74707 1.0\n",
      "FOLD 917\n",
      "train [36.96828842163086, 6.525387763977051]\n",
      "val [38.87437057495117, 6.601189613342285]\n",
      "predict val...\n",
      "predict test...\n",
      "124.55179 235.01155\n",
      "143.21716 235.01155 375.56836 1.0\n",
      "FOLD 918\n",
      "train [34.94279479980469, 6.479565620422363]\n",
      "val [50.69277572631836, 6.76266622543335]\n",
      "predict val...\n",
      "predict test...\n",
      "165.52211 230.17314\n",
      "76.99951 230.17314 334.68555 1.0\n",
      "FOLD 919\n",
      "train [39.50283432006836, 6.604418754577637]\n",
      "val [37.94216537475586, 6.502682209014893]\n",
      "predict val...\n",
      "predict test...\n",
      "126.07734 235.9462\n",
      "114.950195 235.9462 354.0796 1.0\n",
      "FOLD 920\n",
      "train [37.50430679321289, 6.554121494293213]\n",
      "val [43.02561569213867, 6.655808925628662]\n",
      "predict val...\n",
      "predict test...\n",
      "141.77702 241.24916\n",
      "157.19751 241.24916 333.78857 1.0\n",
      "FOLD 921\n",
      "train [37.40853500366211, 6.5445709228515625]\n",
      "val [43.29573440551758, 6.812080383300781]\n",
      "predict val...\n",
      "predict test...\n",
      "142.75241 246.99161\n",
      "129.37622 246.99161 418.2119 1.0\n",
      "FOLD 922\n",
      "train [37.720272064208984, 6.555700778961182]\n",
      "val [40.20499038696289, 6.644981384277344]\n",
      "predict val...\n",
      "predict test...\n",
      "128.5852 248.62146\n",
      "150.53906 248.62146 408.5669 1.0\n",
      "FOLD 923\n",
      "train [35.61452102661133, 6.4871087074279785]\n",
      "val [47.93009567260742, 6.663805961608887]\n",
      "predict val...\n",
      "predict test...\n",
      "156.33055 230.70332\n",
      "149.42969 230.70332 375.96875 1.0\n",
      "FOLD 924\n",
      "train [37.68739318847656, 6.558480739593506]\n",
      "val [36.559165954589844, 6.450631141662598]\n",
      "predict val...\n",
      "predict test...\n",
      "121.23131 225.60136\n",
      "107.66345 225.60136 352.26416 1.0\n",
      "FOLD 925\n",
      "train [37.29695129394531, 6.541545867919922]\n",
      "val [43.687171936035156, 6.674788951873779]\n",
      "predict val...\n",
      "predict test...\n",
      "144.56636 235.48204\n",
      "155.9906 235.48204 324.01367 1.0\n",
      "FOLD 926\n",
      "train [36.441688537597656, 6.517298698425293]\n",
      "val [40.02353286743164, 6.6345930099487305]\n",
      "predict val...\n",
      "predict test...\n",
      "132.66231 241.97537\n",
      "142.14319 241.97537 347.47607 1.0\n",
      "FOLD 927\n",
      "train [37.90378952026367, 6.559445381164551]\n",
      "val [39.30233383178711, 6.625382423400879]\n",
      "predict val...\n",
      "predict test...\n",
      "126.01037 249.1692\n",
      "161.34521 249.1692 393.4746 1.0\n",
      "FOLD 928\n",
      "train [35.92802810668945, 6.495368003845215]\n",
      "val [48.89772033691406, 6.684412479400635]\n",
      "predict val...\n",
      "predict test...\n",
      "159.16286 230.94214\n",
      "160.4779 230.94214 303.65967 1.0\n",
      "FOLD 929\n",
      "train [37.31386947631836, 6.5469160079956055]\n",
      "val [37.48828125, 6.470525741577148]\n",
      "predict val...\n",
      "predict test...\n",
      "124.90842 223.62337\n",
      "110.808105 223.62337 342.95264 1.0\n",
      "FOLD 930\n",
      "train [37.26395034790039, 6.544894218444824]\n",
      "val [43.766090393066406, 6.674688339233398]\n",
      "predict val...\n",
      "predict test...\n",
      "144.47606 240.87958\n",
      "156.87524 240.87958 335.1377 1.0\n",
      "FOLD 931\n",
      "train [36.72524642944336, 6.52349853515625]\n",
      "val [44.462528228759766, 6.852148056030273]\n",
      "predict val...\n",
      "predict test...\n",
      "146.0628 246.22447\n",
      "148.49194 246.22447 321.38965 1.0\n",
      "FOLD 932\n",
      "train [36.847496032714844, 6.539662837982178]\n",
      "val [40.66856384277344, 6.631560325622559]\n",
      "predict val...\n",
      "predict test...\n",
      "129.85706 246.90015\n",
      "163.55664 246.90015 371.78906 1.0\n",
      "FOLD 933\n",
      "train [35.73773193359375, 6.491466522216797]\n",
      "val [48.81419372558594, 6.675798416137695]\n",
      "predict val...\n",
      "predict test...\n",
      "160.56056 233.51166\n",
      "160.50696 233.51166 332.73486 1.0\n",
      "FOLD 934\n",
      "train [38.97236633300781, 6.594344139099121]\n",
      "val [36.72040557861328, 6.487077236175537]\n",
      "predict val...\n",
      "predict test...\n",
      "123.03771 244.86322\n",
      "156.11694 244.86322 316.25488 1.0\n",
      "FOLD 935\n",
      "train [36.854705810546875, 6.524361610412598]\n",
      "val [44.246337890625, 6.739343643188477]\n",
      "predict val...\n",
      "predict test...\n",
      "144.4468 241.7109\n",
      "94.416016 241.7109 390.7224 1.0\n",
      "FOLD 936\n",
      "train [37.35234832763672, 6.5426177978515625]\n",
      "val [42.306861877441406, 6.7559428215026855]\n",
      "predict val...\n",
      "predict test...\n",
      "139.60092 252.76682\n",
      "163.8042 252.76682 338.1582 1.0\n",
      "FOLD 937\n",
      "train [37.93446731567383, 6.569982051849365]\n",
      "val [38.15934753417969, 6.578495025634766]\n",
      "predict val...\n",
      "predict test...\n",
      "122.40401 259.84116\n",
      "182.08667 259.84116 379.6294 1.0\n",
      "FOLD 938\n",
      "train [35.15934753417969, 6.471199035644531]\n",
      "val [48.95728302001953, 6.675681114196777]\n",
      "predict val...\n",
      "predict test...\n",
      "158.71967 224.2838\n",
      "144.42175 224.2838 267.08325 1.0\n",
      "FOLD 939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.714813232421875, 6.520773410797119]\n",
      "val [37.689453125, 6.437827110290527]\n",
      "predict val...\n",
      "predict test...\n",
      "123.93924 219.45023\n",
      "127.467285 219.45023 284.44385 1.0\n",
      "FOLD 940\n",
      "train [36.021331787109375, 6.513493537902832]\n",
      "val [49.8554573059082, 6.7682647705078125]\n",
      "predict val...\n",
      "predict test...\n",
      "163.16496 231.22507\n",
      "172.96094 231.22507 291.6333 1.0\n",
      "FOLD 941\n",
      "train [36.2227783203125, 6.5140180587768555]\n",
      "val [40.44072341918945, 6.652132034301758]\n",
      "predict val...\n",
      "predict test...\n",
      "133.27948 243.16719\n",
      "149.96753 243.16719 316.7583 1.0\n",
      "FOLD 942\n",
      "train [38.04483413696289, 6.567831993103027]\n",
      "val [39.2874641418457, 6.617570877075195]\n",
      "predict val...\n",
      "predict test...\n",
      "125.54552 251.9489\n",
      "150.53137 251.9489 397.05566 1.0\n",
      "FOLD 943\n",
      "train [35.31990051269531, 6.47802734375]\n",
      "val [48.61103057861328, 6.669157981872559]\n",
      "predict val...\n",
      "predict test...\n",
      "158.1416 229.25743\n",
      "151.03662 229.25743 316.28564 1.0\n",
      "FOLD 944\n",
      "train [37.8488655090332, 6.562904357910156]\n",
      "val [37.084014892578125, 6.507586479187012]\n",
      "predict val...\n",
      "predict test...\n",
      "124.84752 236.0514\n",
      "171.73694 236.0514 293.0293 1.0\n",
      "FOLD 945\n",
      "train [36.26890563964844, 6.5169267654418945]\n",
      "val [44.20438003540039, 6.6916351318359375]\n",
      "predict val...\n",
      "predict test...\n",
      "144.56575 232.41963\n",
      "136.36768 232.41963 331.72144 1.0\n",
      "FOLD 946\n",
      "train [34.628082275390625, 6.469791412353516]\n",
      "val [39.809349060058594, 6.6978912353515625]\n",
      "predict val...\n",
      "predict test...\n",
      "131.79507 235.00916\n",
      "110.489746 235.00916 292.29443 1.0\n",
      "FOLD 947\n",
      "train [37.496620178222656, 6.546133518218994]\n",
      "val [39.63764572143555, 6.6084089279174805]\n",
      "predict val...\n",
      "predict test...\n",
      "128.25914 246.6035\n",
      "167.41235 246.6035 368.34912 1.0\n",
      "FOLD 948\n",
      "train [35.223506927490234, 6.482118129730225]\n",
      "val [48.850345611572266, 6.682171821594238]\n",
      "predict val...\n",
      "predict test...\n",
      "158.12312 233.42172\n",
      "164.95874 233.42172 281.80347 1.0\n",
      "FOLD 949\n",
      "train [38.41840362548828, 6.565613746643066]\n",
      "val [38.0152702331543, 6.480242729187012]\n",
      "predict val...\n",
      "predict test...\n",
      "127.46071 230.19992\n",
      "128.12622 230.19992 330.05176 1.0\n",
      "FOLD 950\n",
      "train [37.31755065917969, 6.550445556640625]\n",
      "val [43.17129135131836, 6.6580491065979]\n",
      "predict val...\n",
      "predict test...\n",
      "142.86057 240.80945\n",
      "158.09753 240.80945 341.92114 1.0\n",
      "FOLD 951\n",
      "train [42.33774185180664, 6.55672550201416]\n",
      "val [47.658538818359375, 6.760633945465088]\n",
      "predict val...\n",
      "predict test...\n",
      "140.23235 247.27309\n",
      "117.86804 247.27309 432.68848 1.0\n",
      "FOLD 952\n",
      "train [41.81989288330078, 6.5473785400390625]\n",
      "val [45.275779724121094, 6.641116142272949]\n",
      "predict val...\n",
      "predict test...\n",
      "128.58804 246.89093\n",
      "130.92664 246.89093 427.80908 1.0\n",
      "FOLD 953\n",
      "train [41.134098052978516, 6.513741970062256]\n",
      "val [52.84504318237305, 6.687318801879883]\n",
      "predict val...\n",
      "predict test...\n",
      "154.90363 236.58586\n",
      "107.04004 236.58586 520.9341 1.0\n",
      "FOLD 954\n",
      "train [45.265663146972656, 6.619349479675293]\n",
      "val [41.54716491699219, 6.488905906677246]\n",
      "predict val...\n",
      "predict test...\n",
      "124.15372 222.50316\n",
      "79.143555 222.50316 374.7954 1.0\n",
      "FOLD 955\n",
      "train [42.631839752197266, 6.54736328125]\n",
      "val [47.2864875793457, 6.642979145050049]\n",
      "predict val...\n",
      "predict test...\n",
      "140.05403 226.1732\n",
      "99.81671 226.1732 395.04834 1.0\n",
      "FOLD 956\n",
      "train [42.38609313964844, 6.5577073097229]\n",
      "val [47.75165557861328, 6.7923383712768555]\n",
      "predict val...\n",
      "predict test...\n",
      "139.70995 248.818\n",
      "131.59106 248.818 410.27002 1.0\n",
      "FOLD 957\n",
      "train [41.70175552368164, 6.527203559875488]\n",
      "val [46.98336410522461, 6.675201416015625]\n",
      "predict val...\n",
      "predict test...\n",
      "135.1818 233.87556\n",
      "128.93286 233.87556 399.87305 1.0\n",
      "FOLD 958\n",
      "train [40.549171447753906, 6.496949672698975]\n",
      "val [54.015586853027344, 6.663670539855957]\n",
      "predict val...\n",
      "predict test...\n",
      "157.23315 229.24307\n",
      "124.46692 229.24307 424.7749 1.0\n",
      "FOLD 959\n",
      "train [44.1289176940918, 6.608682155609131]\n",
      "val [42.53166198730469, 6.5072526931762695]\n",
      "predict val...\n",
      "predict test...\n",
      "125.86963 238.95807\n",
      "110.41724 238.95807 385.16846 1.0\n",
      "FOLD 960\n",
      "train [41.4355583190918, 6.525563716888428]\n",
      "val [48.67209243774414, 6.6779093742370605]\n",
      "predict val...\n",
      "predict test...\n",
      "143.44041 224.69987\n",
      "139.75586 224.69987 324.72607 1.0\n",
      "FOLD 961\n",
      "train [42.113380432128906, 6.553348541259766]\n",
      "val [46.8973274230957, 6.731905937194824]\n",
      "predict val...\n",
      "predict test...\n",
      "138.66579 251.46635\n",
      "126.12549 251.46635 427.68213 1.0\n",
      "FOLD 962\n",
      "train [42.25205993652344, 6.561635494232178]\n",
      "val [43.52530288696289, 6.607422828674316]\n",
      "predict val...\n",
      "predict test...\n",
      "124.58338 253.1463\n",
      "166.82336 253.1463 388.7339 1.0\n",
      "FOLD 963\n",
      "train [39.547115325927734, 6.483187198638916]\n",
      "val [52.645904541015625, 6.681491851806641]\n",
      "predict val...\n",
      "predict test...\n",
      "153.93347 230.58795\n",
      "139.16724 230.58795 414.52344 1.0\n",
      "FOLD 964\n",
      "train [43.88453674316406, 6.598921775817871]\n",
      "val [42.06418228149414, 6.500531196594238]\n",
      "predict val...\n",
      "predict test...\n",
      "125.35132 232.75096\n",
      "102.89038 232.75096 377.56885 1.0\n",
      "FOLD 965\n",
      "train [41.47945022583008, 6.5359978675842285]\n",
      "val [49.76002502441406, 6.686367034912109]\n",
      "predict val...\n",
      "predict test...\n",
      "147.67645 234.71239\n",
      "139.21606 234.71239 342.5083 1.0\n",
      "FOLD 966\n",
      "train [42.253902435302734, 6.5536041259765625]\n",
      "val [47.05080032348633, 6.756357192993164]\n",
      "predict val...\n",
      "predict test...\n",
      "138.35664 248.36655\n",
      "139.97742 248.36655 391.1211 1.0\n",
      "FOLD 967\n",
      "train [42.49111557006836, 6.564977169036865]\n",
      "val [43.12154006958008, 6.576916694641113]\n",
      "predict val...\n",
      "predict test...\n",
      "122.09309 250.8974\n",
      "155.43237 250.8974 408.58496 1.0\n",
      "FOLD 968\n",
      "train [40.43938446044922, 6.492501258850098]\n",
      "val [54.20127487182617, 6.679234027862549]\n",
      "predict val...\n",
      "predict test...\n",
      "158.18109 227.83765\n",
      "116.087524 227.83765 472.65186 1.0\n",
      "FOLD 969\n",
      "train [43.874412536621094, 6.601010322570801]\n",
      "val [42.55842971801758, 6.507267951965332]\n",
      "predict val...\n",
      "predict test...\n",
      "127.46694 236.62169\n",
      "110.40106 236.62169 359.9795 1.0\n",
      "FOLD 970\n",
      "train [41.723548889160156, 6.549463748931885]\n",
      "val [49.475135803222656, 6.679104804992676]\n",
      "predict val...\n",
      "predict test...\n",
      "145.36581 242.1534\n",
      "157.1831 242.1534 340.17407 1.0\n",
      "FOLD 971\n",
      "train [40.61090850830078, 6.519377708435059]\n",
      "val [45.66621780395508, 6.686246871948242]\n",
      "predict val...\n",
      "predict test...\n",
      "134.5398 243.46944\n",
      "161.90869 243.46944 327.74316 1.0\n",
      "FOLD 972\n",
      "train [38.71698760986328, 6.473701477050781]\n",
      "val [49.480438232421875, 6.915477752685547]\n",
      "predict val...\n",
      "predict test...\n",
      "143.90797 235.6845\n",
      "147.50366 235.6845 292.66406 1.0\n",
      "FOLD 973\n",
      "train [39.30756378173828, 6.476785182952881]\n",
      "val [55.0406608581543, 6.723446369171143]\n",
      "predict val...\n",
      "predict test...\n",
      "160.4641 227.49165\n",
      "117.5686 227.49165 359.07324 1.0\n",
      "FOLD 974\n",
      "train [41.853763580322266, 6.531989097595215]\n",
      "val [42.120548248291016, 6.4414286613464355]\n",
      "predict val...\n",
      "predict test...\n",
      "124.4658 220.08449\n",
      "113.60736 220.08449 303.688 1.0\n",
      "FOLD 975\n",
      "train [41.81380844116211, 6.5489983558654785]\n",
      "val [49.7741584777832, 6.684097766876221]\n",
      "predict val...\n",
      "predict test...\n",
      "146.6926 242.33253\n",
      "144.30469 242.33253 359.375 1.0\n",
      "FOLD 976\n",
      "train [41.782535552978516, 6.541280269622803]\n",
      "val [45.223873138427734, 6.697231292724609]\n",
      "predict val...\n",
      "predict test...\n",
      "133.81746 246.65244\n",
      "150.07434 246.65244 350.89648 1.0\n",
      "FOLD 977\n",
      "train [41.815528869628906, 6.546318054199219]\n",
      "val [44.82510757446289, 6.596645355224609]\n",
      "predict val...\n",
      "predict test...\n",
      "127.744095 247.31184\n",
      "139.01575 247.31184 406.8003 1.0\n",
      "FOLD 978\n",
      "train [38.96738052368164, 6.471478462219238]\n",
      "val [55.16693878173828, 6.690497875213623]\n",
      "predict val...\n",
      "predict test...\n",
      "160.32965 227.30891\n",
      "157.07666 227.30891 279.77295 1.0\n",
      "FOLD 979\n",
      "train [44.19346237182617, 6.602083683013916]\n",
      "val [42.75265121459961, 6.512909889221191]\n",
      "predict val...\n",
      "predict test...\n",
      "126.74169 232.6022\n",
      "102.48602 232.6022 378.10693 1.0\n",
      "FOLD 980\n",
      "train [41.134525299072266, 6.537524223327637]\n",
      "val [50.42168426513672, 6.692163467407227]\n",
      "predict val...\n",
      "predict test...\n",
      "148.58994 240.68536\n",
      "168.59802 240.68536 333.91064 1.0\n",
      "FOLD 981\n",
      "train [41.193321228027344, 6.533524513244629]\n",
      "val [48.111328125, 6.778384685516357]\n",
      "predict val...\n",
      "predict test...\n",
      "141.91655 252.99252\n",
      "158.33228 252.99252 362.42773 1.0\n",
      "FOLD 982\n",
      "train [41.35921859741211, 6.542311191558838]\n",
      "val [44.529518127441406, 6.588665962219238]\n",
      "predict val...\n",
      "predict test...\n",
      "127.986664 245.60643\n",
      "171.09985 245.60643 363.48828 1.0\n",
      "FOLD 983\n",
      "train [39.20663070678711, 6.468621253967285]\n",
      "val [53.626468658447266, 6.6645097732543945]\n",
      "predict val...\n",
      "predict test...\n",
      "155.49207 225.49911\n",
      "146.15833 225.49911 279.35254 1.0\n",
      "FOLD 984\n",
      "train [42.65686798095703, 6.574045658111572]\n",
      "val [41.32917404174805, 6.493146896362305]\n",
      "predict val...\n",
      "predict test...\n",
      "124.76341 227.46346\n",
      "120.88599 227.46346 336.50684 1.0\n",
      "FOLD 985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [41.634620666503906, 6.542043209075928]\n",
      "val [49.69011306762695, 6.684561729431152]\n",
      "predict val...\n",
      "predict test...\n",
      "147.81963 238.67107\n",
      "150.28271 238.67107 343.3794 1.0\n",
      "FOLD 986\n",
      "train [39.943763732910156, 6.508848667144775]\n",
      "val [45.705162048339844, 6.722701072692871]\n",
      "predict val...\n",
      "predict test...\n",
      "133.88246 245.04851\n",
      "101.39331 245.04851 339.19287 1.0\n",
      "FOLD 987\n",
      "train [42.58790969848633, 6.572421073913574]\n",
      "val [43.01298141479492, 6.582217216491699]\n",
      "predict val...\n",
      "predict test...\n",
      "122.31802 256.2565\n",
      "166.70337 256.2565 395.8379 1.0\n",
      "FOLD 988\n",
      "train [39.77832794189453, 6.490384578704834]\n",
      "val [54.3885383605957, 6.674728870391846]\n",
      "predict val...\n",
      "predict test...\n",
      "158.08728 230.51901\n",
      "147.38184 230.51901 377.5952 1.0\n",
      "FOLD 989\n",
      "train [43.23812484741211, 6.580508232116699]\n",
      "val [41.695770263671875, 6.492982387542725]\n",
      "predict val...\n",
      "predict test...\n",
      "124.245674 230.50249\n",
      "123.63971 230.50249 338.354 1.0\n",
      "FOLD 990\n",
      "train [41.798553466796875, 6.5518479347229]\n",
      "val [49.06913375854492, 6.681661605834961]\n",
      "predict val...\n",
      "predict test...\n",
      "144.62749 241.11517\n",
      "165.83887 241.11517 336.52612 1.0\n",
      "FOLD 991\n",
      "train [41.40471649169922, 6.529075622558594]\n",
      "val [48.28170394897461, 6.804538249969482]\n",
      "predict val...\n",
      "predict test...\n",
      "141.30022 242.46361\n",
      "149.17053 242.46361 355.59717 1.0\n",
      "FOLD 992\n",
      "train [40.16429901123047, 6.502955436706543]\n",
      "val [44.13063430786133, 6.596746444702148]\n",
      "predict val...\n",
      "predict test...\n",
      "129.29247 231.74352\n",
      "164.60815 231.74352 281.81592 1.0\n",
      "FOLD 993\n",
      "train [38.95449447631836, 6.469552516937256]\n",
      "val [54.31838607788086, 6.697521209716797]\n",
      "predict val...\n",
      "predict test...\n",
      "157.53781 225.00732\n",
      "114.74634 225.00732 306.79492 1.0\n",
      "FOLD 994\n",
      "train [43.45056915283203, 6.59072732925415]\n",
      "val [39.88362503051758, 6.482851505279541]\n",
      "predict val...\n",
      "predict test...\n",
      "120.26559 242.76466\n",
      "165.92029 242.76466 343.32788 1.0\n",
      "FOLD 995\n",
      "train [41.433631896972656, 6.5430803298950195]\n",
      "val [48.17412567138672, 6.669878005981445]\n",
      "predict val...\n",
      "predict test...\n",
      "142.17363 239.85275\n",
      "174.00317 239.85275 338.71558 1.0\n",
      "FOLD 996\n",
      "train [40.240760803222656, 6.502243995666504]\n",
      "val [45.023319244384766, 6.64605188369751]\n",
      "predict val...\n",
      "predict test...\n",
      "132.78671 232.5513\n",
      "157.96826 232.5513 305.89648 1.0\n",
      "FOLD 997\n",
      "train [40.14366149902344, 6.493687629699707]\n",
      "val [43.93668746948242, 6.600768089294434]\n",
      "predict val...\n",
      "predict test...\n",
      "128.58748 223.95514\n",
      "170.2461 223.95514 279.1704 1.0\n",
      "FOLD 998\n",
      "train [37.97863006591797, 6.430424690246582]\n",
      "val [55.649314880371094, 6.686951637268066]\n",
      "predict val...\n",
      "predict test...\n",
      "160.44263 215.37215\n",
      "113.8468 215.37215 277.71387 1.0\n",
      "FOLD 999\n",
      "train [43.71195602416992, 6.5941267013549805]\n",
      "val [40.79729080200195, 6.480852127075195]\n",
      "predict val...\n",
      "predict test...\n",
      "121.961754 241.44284\n",
      "166.01904 241.44284 317.51294 1.0\n",
      "FOLD 1000\n",
      "train [39.229434967041016, 6.488487243652344]\n",
      "val [48.90689468383789, 6.699350357055664]\n",
      "predict val...\n",
      "predict test...\n",
      "145.06625 223.59142\n",
      "140.90381 223.59142 302.05054 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1001\n",
      "train [29.116840362548828, 6.5682220458984375]\n",
      "val [32.20233154296875, 6.7561492919921875]\n",
      "predict val...\n",
      "predict test...\n",
      "139.83052 252.25221\n",
      "123.06616 252.25221 439.7378 1.0\n",
      "FOLD 1002\n",
      "train [29.179296493530273, 6.560159206390381]\n",
      "val [30.214344024658203, 6.6014556884765625]\n",
      "predict val...\n",
      "predict test...\n",
      "125.26943 247.2832\n",
      "126.46106 247.2832 427.6665 1.0\n",
      "FOLD 1003\n",
      "train [27.753005981445312, 6.499045372009277]\n",
      "val [35.25667190551758, 6.666816711425781]\n",
      "predict val...\n",
      "predict test...\n",
      "153.80943 232.04768\n",
      "106.38013 232.04768 519.1284 1.0\n",
      "FOLD 1004\n",
      "train [30.091888427734375, 6.60198450088501]\n",
      "val [29.265010833740234, 6.5128583908081055]\n",
      "predict val...\n",
      "predict test...\n",
      "127.687614 228.30563\n",
      "91.321655 228.30563 382.3296 1.0\n",
      "FOLD 1005\n",
      "train [27.764949798583984, 6.504611015319824]\n",
      "val [31.89414405822754, 6.669986724853516]\n",
      "predict val...\n",
      "predict test...\n",
      "138.46558 214.5686\n",
      "113.76965 214.5686 360.22363 1.0\n",
      "FOLD 1006\n",
      "train [28.639511108398438, 6.546311855316162]\n",
      "val [31.896604537963867, 6.755032062530518]\n",
      "predict val...\n",
      "predict test...\n",
      "138.4931 249.01044\n",
      "135.15173 249.01044 402.1631 1.0\n",
      "FOLD 1007\n",
      "train [29.008140563964844, 6.554276466369629]\n",
      "val [31.394325256347656, 6.646855354309082]\n",
      "predict val...\n",
      "predict test...\n",
      "132.21707 246.03029\n",
      "148.2179 246.03029 395.4961 1.0\n",
      "FOLD 1008\n",
      "train [27.865068435668945, 6.498129844665527]\n",
      "val [36.302146911621094, 6.663113594055176]\n",
      "predict val...\n",
      "predict test...\n",
      "156.95705 227.83061\n",
      "123.12842 227.83061 446.1089 1.0\n",
      "FOLD 1009\n",
      "train [30.00402069091797, 6.6067214012146]\n",
      "val [29.049177169799805, 6.503244400024414]\n",
      "predict val...\n",
      "predict test...\n",
      "125.53988 235.31444\n",
      "95.895325 235.31444 389.72607 1.0\n",
      "FOLD 1010\n",
      "train [28.1418399810791, 6.5213446617126465]\n",
      "val [33.009315490722656, 6.679800510406494]\n",
      "predict val...\n",
      "predict test...\n",
      "144.1 225.01933\n",
      "144.82886 225.01933 311.4292 1.0\n",
      "FOLD 1011\n",
      "train [28.38686180114746, 6.543632507324219]\n",
      "val [31.415828704833984, 6.687444686889648]\n",
      "predict val...\n",
      "predict test...\n",
      "137.2668 249.12653\n",
      "137.97083 249.12653 392.45605 1.0\n",
      "FOLD 1012\n",
      "train [29.09046745300293, 6.566251277923584]\n",
      "val [29.72933006286621, 6.618683815002441]\n",
      "predict val...\n",
      "predict test...\n",
      "124.59899 253.7724\n",
      "143.95679 253.7724 417.71777 1.0\n",
      "FOLD 1013\n",
      "train [27.621450424194336, 6.502816200256348]\n",
      "val [36.42313766479492, 6.690204620361328]\n",
      "predict val...\n",
      "predict test...\n",
      "157.64038 234.49207\n",
      "137.28418 234.49207 433.4956 1.0\n",
      "FOLD 1014\n",
      "train [29.33257293701172, 6.572120666503906]\n",
      "val [29.16004180908203, 6.46999454498291]\n",
      "predict val...\n",
      "predict test...\n",
      "125.55206 227.40404\n",
      "117.694214 227.40404 334.64697 1.0\n",
      "FOLD 1015\n",
      "train [28.581127166748047, 6.547173976898193]\n",
      "val [33.82646942138672, 6.689279556274414]\n",
      "predict val...\n",
      "predict test...\n",
      "147.15678 232.91608\n",
      "161.52332 232.91608 324.72314 1.0\n",
      "FOLD 1016\n",
      "train [27.492116928100586, 6.5029168128967285]\n",
      "val [31.523775100708008, 6.778013229370117]\n",
      "predict val...\n",
      "predict test...\n",
      "136.25302 240.46117\n",
      "125.5686 240.46117 373.4214 1.0\n",
      "FOLD 1017\n",
      "train [28.83336067199707, 6.558241367340088]\n",
      "val [29.55684471130371, 6.599761009216309]\n",
      "predict val...\n",
      "predict test...\n",
      "124.90681 249.06139\n",
      "173.8241 249.06139 355.60156 1.0\n",
      "FOLD 1018\n",
      "train [27.028654098510742, 6.482940673828125]\n",
      "val [37.00697708129883, 6.697968482971191]\n",
      "predict val...\n",
      "predict test...\n",
      "160.63354 231.57838\n",
      "149.69556 231.57838 332.82227 1.0\n",
      "FOLD 1019\n",
      "train [29.563194274902344, 6.584480285644531]\n",
      "val [28.590824127197266, 6.492795944213867]\n",
      "predict val...\n",
      "predict test...\n",
      "125.566216 232.85724\n",
      "129.25195 232.85724 347.21045 1.0\n",
      "FOLD 1020\n",
      "train [27.322927474975586, 6.501273155212402]\n",
      "val [32.66541290283203, 6.724646091461182]\n",
      "predict val...\n",
      "predict test...\n",
      "140.33754 235.91226\n",
      "2.3308105 235.91226 338.37158 1.0\n",
      "FOLD 1021\n",
      "train [28.082565307617188, 6.522528171539307]\n",
      "val [32.72085189819336, 6.816246032714844]\n",
      "predict val...\n",
      "predict test...\n",
      "141.25092 244.19112\n",
      "143.94592 244.19112 347.26123 1.0\n",
      "FOLD 1022\n",
      "train [27.439058303833008, 6.500512599945068]\n",
      "val [31.07097053527832, 6.652286529541016]\n",
      "predict val...\n",
      "predict test...\n",
      "131.69826 227.4048\n",
      "132.59155 227.4048 318.96338 1.0\n",
      "FOLD 1023\n",
      "train [27.451404571533203, 6.501466274261475]\n",
      "val [37.01275634765625, 6.687135696411133]\n",
      "predict val...\n",
      "predict test...\n",
      "160.85713 235.62016\n",
      "146.97192 235.62016 328.36182 1.0\n",
      "FOLD 1024\n",
      "train [29.50275421142578, 6.582775115966797]\n",
      "val [28.477867126464844, 6.485174655914307]\n",
      "predict val...\n",
      "predict test...\n",
      "124.1807 227.46733\n",
      "105.7337 227.46733 356.5371 1.0\n",
      "FOLD 1025\n",
      "train [28.375782012939453, 6.536680698394775]\n",
      "val [33.354698181152344, 6.671526908874512]\n",
      "predict val...\n",
      "predict test...\n",
      "145.112 235.12688\n",
      "170.55042 235.12688 318.7068 1.0\n",
      "FOLD 1026\n",
      "train [27.459095001220703, 6.505073547363281]\n",
      "val [30.74357032775879, 6.605544567108154]\n",
      "predict val...\n",
      "predict test...\n",
      "132.32074 237.13014\n",
      "154.28394 237.13014 323.32568 1.0\n",
      "FOLD 1027\n",
      "train [28.963823318481445, 6.564395904541016]\n",
      "val [29.55815887451172, 6.585052490234375]\n",
      "predict val...\n",
      "predict test...\n",
      "123.45629 249.93501\n",
      "162.13562 249.93501 385.71973 1.0\n",
      "FOLD 1028\n",
      "train [26.888715744018555, 6.472108364105225]\n",
      "val [37.45350646972656, 6.760422706604004]\n",
      "predict val...\n",
      "predict test...\n",
      "162.12074 224.69386\n",
      "68.18164 224.69386 307.56445 1.0\n",
      "FOLD 1029\n",
      "train [29.116268157958984, 6.554384708404541]\n",
      "val [29.084379196166992, 6.474691867828369]\n",
      "predict val...\n",
      "predict test...\n",
      "125.760994 234.45332\n",
      "115.160645 234.45332 297.9734 1.0\n",
      "FOLD 1030\n",
      "train [27.842058181762695, 6.529347896575928]\n",
      "val [33.95553207397461, 6.716170310974121]\n",
      "predict val...\n",
      "predict test...\n",
      "148.01526 235.95424\n",
      "169.87646 235.95424 327.86426 1.0\n",
      "FOLD 1031\n",
      "train [27.02508544921875, 6.485113620758057]\n",
      "val [30.417306900024414, 6.597474098205566]\n",
      "predict val...\n",
      "predict test...\n",
      "132.12642 232.23042\n",
      "141.24463 232.23042 292.9204 1.0\n",
      "FOLD 1032\n",
      "train [28.56235694885254, 6.544102668762207]\n",
      "val [33.027713775634766, 6.786105155944824]\n",
      "predict val...\n",
      "predict test...\n",
      "138.94641 243.28838\n",
      "153.5509 243.28838 393.46338 1.0\n",
      "FOLD 1033\n",
      "train [26.706844329833984, 6.459348201751709]\n",
      "val [36.62604522705078, 6.697582244873047]\n",
      "predict val...\n",
      "predict test...\n",
      "157.81013 223.59077\n",
      "116.676025 223.59077 277.39233 1.0\n",
      "FOLD 1034\n",
      "train [29.670318603515625, 6.586610317230225]\n",
      "val [28.025981903076172, 6.476475238800049]\n",
      "predict val...\n",
      "predict test...\n",
      "121.75234 236.65984\n",
      "135.36682 236.65984 333.79102 1.0\n",
      "FOLD 1035\n",
      "train [28.151094436645508, 6.5281267166137695]\n",
      "val [34.07331848144531, 6.698586463928223]\n",
      "predict val...\n",
      "predict test...\n",
      "148.68127 231.86635\n",
      "164.90515 231.86635 323.56323 1.0\n",
      "FOLD 1036\n",
      "train [27.836057662963867, 6.515383243560791]\n",
      "val [30.95615577697754, 6.670872688293457]\n",
      "predict val...\n",
      "predict test...\n",
      "134.55342 244.14429\n",
      "139.84167 244.14429 337.8081 1.0\n",
      "FOLD 1037\n",
      "train [27.63228416442871, 6.499942779541016]\n",
      "val [30.211109161376953, 6.610461235046387]\n",
      "predict val...\n",
      "predict test...\n",
      "128.75914 228.58815\n",
      "157.7926 228.58815 306.7578 1.0\n",
      "FOLD 1038\n",
      "train [26.56075668334961, 6.449152946472168]\n",
      "val [36.88176727294922, 6.673053741455078]\n",
      "predict val...\n",
      "predict test...\n",
      "157.89365 222.93053\n",
      "143.42786 222.93053 285.16162 1.0\n",
      "FOLD 1039\n",
      "train [28.851219177246094, 6.548470497131348]\n",
      "val [28.908533096313477, 6.471556663513184]\n",
      "predict val...\n",
      "predict test...\n",
      "125.956665 237.61658\n",
      "132.2561 237.61658 308.93066 1.0\n",
      "FOLD 1040\n",
      "train [27.99810791015625, 6.514459133148193]\n",
      "val [35.099430084228516, 6.725493907928467]\n",
      "predict val...\n",
      "predict test...\n",
      "153.44298 230.04584\n",
      "128.62988 230.04584 306.72925 1.0\n",
      "FOLD 1041\n",
      "train [28.474151611328125, 6.5322771072387695]\n",
      "val [32.12084197998047, 6.776437759399414]\n",
      "predict val...\n",
      "predict test...\n",
      "139.2486 242.5285\n",
      "169.56079 242.5285 319.29248 1.0\n",
      "FOLD 1042\n",
      "train [28.170860290527344, 6.525473594665527]\n",
      "val [31.45985984802246, 6.668832302093506]\n",
      "predict val...\n",
      "predict test...\n",
      "132.57616 243.19887\n",
      "146.63599 243.19887 358.5835 1.0\n",
      "FOLD 1043\n",
      "train [25.698509216308594, 6.4038801193237305]\n",
      "val [37.9180908203125, 6.679065704345703]\n",
      "predict val...\n",
      "predict test...\n",
      "162.78032 210.50618\n",
      "115.033936 210.50618 338.6006 1.0\n",
      "FOLD 1044\n",
      "train [29.338106155395508, 6.5611138343811035]\n",
      "val [28.576086044311523, 6.473820686340332]\n",
      "predict val...\n",
      "predict test...\n",
      "124.29704 234.75804\n",
      "146.80896 234.75804 302.1421 1.0\n",
      "FOLD 1045\n",
      "train [27.940401077270508, 6.524045467376709]\n",
      "val [35.03052520751953, 6.72233772277832]\n",
      "predict val...\n",
      "predict test...\n",
      "153.87958 231.07253\n",
      "162.55798 231.07253 319.59106 1.0\n",
      "FOLD 1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [27.295764923095703, 6.4890456199646]\n",
      "val [33.15509033203125, 6.788025856018066]\n",
      "predict val...\n",
      "predict test...\n",
      "143.24269 237.5574\n",
      "126.46069 237.5574 331.00244 1.0\n",
      "FOLD 1047\n",
      "train [28.757970809936523, 6.5491943359375]\n",
      "val [30.53379249572754, 6.6406049728393555]\n",
      "predict val...\n",
      "predict test...\n",
      "129.45584 243.52846\n",
      "168.36633 243.52846 356.66455 1.0\n",
      "FOLD 1048\n",
      "train [27.3880615234375, 6.499169826507568]\n",
      "val [37.15852737426758, 6.683462142944336]\n",
      "predict val...\n",
      "predict test...\n",
      "160.34172 235.34532\n",
      "157.35461 235.34532 334.9629 1.0\n",
      "FOLD 1049\n",
      "train [28.818883895874023, 6.5542192459106445]\n",
      "val [29.11503028869629, 6.499669551849365]\n",
      "predict val...\n",
      "predict test...\n",
      "127.49514 232.41089\n",
      "161.88354 232.41089 283.6001 1.0\n",
      "FOLD 1050\n",
      "train [27.447265625, 6.491527557373047]\n",
      "val [34.774654388427734, 6.7903642654418945]\n",
      "predict val...\n",
      "predict test...\n",
      "151.5556 226.01277\n",
      "67.83057 226.01277 346.86572 1.0\n",
      "FOLD 1051\n",
      "train [33.40769577026367, 6.556955814361572]\n",
      "val [37.15032196044922, 6.753329277038574]\n",
      "predict val...\n",
      "predict test...\n",
      "139.12595 246.90605\n",
      "119.292114 246.90605 434.61572 1.0\n",
      "FOLD 1052\n",
      "train [33.62080764770508, 6.561872959136963]\n",
      "val [34.88142013549805, 6.616303443908691]\n",
      "predict val...\n",
      "predict test...\n",
      "125.46679 250.64978\n",
      "133.97974 250.64978 426.9043 1.0\n",
      "FOLD 1053\n",
      "train [32.20351791381836, 6.499472618103027]\n",
      "val [41.408424377441406, 6.681591033935547]\n",
      "predict val...\n",
      "predict test...\n",
      "154.60727 229.32135\n",
      "113.72119 229.32135 490.38037 1.0\n",
      "FOLD 1054\n",
      "train [34.95833969116211, 6.60540771484375]\n",
      "val [33.743446350097656, 6.5116400718688965]\n",
      "predict val...\n",
      "predict test...\n",
      "127.46628 226.92421\n",
      "92.5282 226.92421 374.6548 1.0\n",
      "FOLD 1055\n",
      "train [33.358978271484375, 6.536879539489746]\n",
      "val [37.98215866088867, 6.649263858795166]\n",
      "predict val...\n",
      "predict test...\n",
      "143.29254 219.09721\n",
      "100.911865 219.09721 383.042 1.0\n",
      "FOLD 1056\n",
      "train [32.80610275268555, 6.537736415863037]\n",
      "val [38.106781005859375, 6.810476779937744]\n",
      "predict val...\n",
      "predict test...\n",
      "141.90857 243.90175\n",
      "116.385864 243.90175 416.1582 1.0\n",
      "FOLD 1057\n",
      "train [33.208229064941406, 6.544199466705322]\n",
      "val [35.842098236083984, 6.5990190505981445]\n",
      "predict val...\n",
      "predict test...\n",
      "129.36174 241.61041\n",
      "148.90332 241.61041 389.84082 1.0\n",
      "FOLD 1058\n",
      "train [32.29113006591797, 6.502927303314209]\n",
      "val [42.8902702331543, 6.683192729949951]\n",
      "predict val...\n",
      "predict test...\n",
      "161.07799 226.5369\n",
      "112.92151 226.5369 480.38184 1.0\n",
      "FOLD 1059\n",
      "train [34.546180725097656, 6.600027561187744]\n",
      "val [32.357662200927734, 6.484801292419434]\n",
      "predict val...\n",
      "predict test...\n",
      "121.56174 234.78079\n",
      "108.36792 234.78079 364.17578 1.0\n",
      "FOLD 1060\n",
      "train [33.10515213012695, 6.537801265716553]\n",
      "val [37.39656066894531, 6.65682315826416]\n",
      "predict val...\n",
      "predict test...\n",
      "140.78418 230.29276\n",
      "144.52112 230.29276 344.49512 1.0\n",
      "FOLD 1061\n",
      "train [33.332054138183594, 6.557309150695801]\n",
      "val [36.56686019897461, 6.724229335784912]\n",
      "predict val...\n",
      "predict test...\n",
      "137.17691 252.25435\n",
      "124.94556 252.25435 428.91797 1.0\n",
      "FOLD 1062\n",
      "train [32.890933990478516, 6.547018527984619]\n",
      "val [34.75774383544922, 6.6270341873168945]\n",
      "predict val...\n",
      "predict test...\n",
      "126.81959 247.4056\n",
      "151.73462 247.4056 399.15332 1.0\n",
      "FOLD 1063\n",
      "train [31.215938568115234, 6.485434055328369]\n",
      "val [41.989654541015625, 6.694644927978516]\n",
      "predict val...\n",
      "predict test...\n",
      "157.45784 233.95998\n",
      "139.60278 233.95998 403.01855 1.0\n",
      "FOLD 1064\n",
      "train [34.39809799194336, 6.5952253341674805]\n",
      "val [33.12351608276367, 6.493508338928223]\n",
      "predict val...\n",
      "predict test...\n",
      "124.471756 234.42252\n",
      "107.12457 234.42252 368.22168 1.0\n",
      "FOLD 1065\n",
      "train [32.85083770751953, 6.540047645568848]\n",
      "val [39.03376007080078, 6.686680793762207]\n",
      "predict val...\n",
      "predict test...\n",
      "147.10014 236.11899\n",
      "170.06165 236.11899 320.958 1.0\n",
      "FOLD 1066\n",
      "train [32.009765625, 6.509905815124512]\n",
      "val [36.61960983276367, 6.738377571105957]\n",
      "predict val...\n",
      "predict test...\n",
      "137.1462 237.56123\n",
      "165.64734 237.56123 329.3545 1.0\n",
      "FOLD 1067\n",
      "train [33.06967544555664, 6.551458835601807]\n",
      "val [34.768821716308594, 6.638700485229492]\n",
      "predict val...\n",
      "predict test...\n",
      "126.487274 249.73097\n",
      "143.79382 249.73097 420.5786 1.0\n",
      "FOLD 1068\n",
      "train [31.547571182250977, 6.494762420654297]\n",
      "val [42.49052047729492, 6.671072483062744]\n",
      "predict val...\n",
      "predict test...\n",
      "157.92686 238.26842\n",
      "153.2528 238.26842 291.2544 1.0\n",
      "FOLD 1069\n",
      "train [34.226707458496094, 6.586494445800781]\n",
      "val [33.00687789916992, 6.490042209625244]\n",
      "predict val...\n",
      "predict test...\n",
      "125.796265 233.2186\n",
      "120.29675 233.2186 345.77783 1.0\n",
      "FOLD 1070\n",
      "train [32.24869918823242, 6.522891044616699]\n",
      "val [39.04959487915039, 6.69873046875]\n",
      "predict val...\n",
      "predict test...\n",
      "146.73126 230.705\n",
      "143.98767 230.705 320.84863 1.0\n",
      "FOLD 1071\n",
      "train [32.82743835449219, 6.541412353515625]\n",
      "val [37.50375747680664, 6.790818214416504]\n",
      "predict val...\n",
      "predict test...\n",
      "141.13129 252.42009\n",
      "156.50476 252.42009 362.17627 1.0\n",
      "FOLD 1072\n",
      "train [32.221519470214844, 6.516703128814697]\n",
      "val [37.52008819580078, 6.713791847229004]\n",
      "predict val...\n",
      "predict test...\n",
      "137.97534 235.94524\n",
      "134.20569 235.94524 391.31396 1.0\n",
      "FOLD 1073\n",
      "train [30.90599822998047, 6.463365077972412]\n",
      "val [43.01209259033203, 6.733299255371094]\n",
      "predict val...\n",
      "predict test...\n",
      "159.47546 221.11632\n",
      "79.37549 221.11632 310.6377 1.0\n",
      "FOLD 1074\n",
      "train [34.388572692871094, 6.587942600250244]\n",
      "val [32.78045654296875, 6.483676910400391]\n",
      "predict val...\n",
      "predict test...\n",
      "124.19781 230.81311\n",
      "122.66046 230.81311 339.03857 1.0\n",
      "FOLD 1075\n",
      "train [32.71860885620117, 6.5352277755737305]\n",
      "val [38.92555618286133, 6.685890197753906]\n",
      "predict val...\n",
      "predict test...\n",
      "145.95355 234.36745\n",
      "162.16565 234.36745 329.76758 1.0\n",
      "FOLD 1076\n",
      "train [31.874256134033203, 6.5208001136779785]\n",
      "val [36.824764251708984, 6.746795654296875]\n",
      "predict val...\n",
      "predict test...\n",
      "137.54167 251.70811\n",
      "181.66284 251.70811 320.1704 1.0\n",
      "FOLD 1077\n",
      "train [33.32217025756836, 6.551982879638672]\n",
      "val [35.00205612182617, 6.632474899291992]\n",
      "predict val...\n",
      "predict test...\n",
      "127.576675 244.8935\n",
      "168.31348 244.8935 371.59326 1.0\n",
      "FOLD 1078\n",
      "train [29.770740509033203, 6.422769069671631]\n",
      "val [44.74458694458008, 6.692379951477051]\n",
      "predict val...\n",
      "predict test...\n",
      "164.69775 218.96136\n",
      "103.636475 218.96136 280.6045 1.0\n",
      "FOLD 1079\n",
      "train [34.39189147949219, 6.592703819274902]\n",
      "val [32.98268127441406, 6.49757719039917]\n",
      "predict val...\n",
      "predict test...\n",
      "125.730835 240.34894\n",
      "152.22876 240.34894 317.9336 1.0\n",
      "FOLD 1080\n",
      "train [32.361942291259766, 6.5412917137146]\n",
      "val [39.745235443115234, 6.710969924926758]\n",
      "predict val...\n",
      "predict test...\n",
      "150.56743 244.27809\n",
      "167.4209 244.27809 338.19653 1.0\n",
      "FOLD 1081\n",
      "train [32.37214279174805, 6.524233818054199]\n",
      "val [38.93009948730469, 6.830117225646973]\n",
      "predict val...\n",
      "predict test...\n",
      "145.34146 245.8611\n",
      "112.46997 245.8611 359.8589 1.0\n",
      "FOLD 1082\n",
      "train [32.2327766418457, 6.528832912445068]\n",
      "val [33.75755310058594, 6.5611701011657715]\n",
      "predict val...\n",
      "predict test...\n",
      "122.33781 245.12848\n",
      "156.11707 245.12848 370.86426 1.0\n",
      "FOLD 1083\n",
      "train [29.975229263305664, 6.453762054443359]\n",
      "val [45.75621795654297, 6.720666885375977]\n",
      "predict val...\n",
      "predict test...\n",
      "170.47305 226.39912\n",
      "161.74182 226.39912 289.45996 1.0\n",
      "FOLD 1084\n",
      "train [31.865488052368164, 6.515057563781738]\n",
      "val [32.758907318115234, 6.470757484436035]\n",
      "predict val...\n",
      "predict test...\n",
      "123.15775 231.8696\n",
      "135.81372 231.8696 304.93457 1.0\n",
      "FOLD 1085\n",
      "train [32.17069625854492, 6.522627830505371]\n",
      "val [38.51686096191406, 6.692936420440674]\n",
      "predict val...\n",
      "predict test...\n",
      "143.66165 228.8891\n",
      "156.19763 228.8891 321.896 1.0\n",
      "FOLD 1086\n",
      "train [32.34644317626953, 6.52371883392334]\n",
      "val [37.45650863647461, 6.733805179595947]\n",
      "predict val...\n",
      "predict test...\n",
      "140.33461 244.00087\n",
      "143.49023 244.00087 319.75684 1.0\n",
      "FOLD 1087\n",
      "train [32.592262268066406, 6.536221504211426]\n",
      "val [34.669429779052734, 6.564211845397949]\n",
      "predict val...\n",
      "predict test...\n",
      "129.25949 259.7671\n",
      "119.014404 259.7671 426.23462 1.0\n",
      "FOLD 1088\n",
      "train [31.44119644165039, 6.48279333114624]\n",
      "val [43.02864074707031, 6.6700053215026855]\n",
      "predict val...\n",
      "predict test...\n",
      "160.01646 232.32268\n",
      "154.3811 232.32268 281.0083 1.0\n",
      "FOLD 1089\n",
      "train [33.41043472290039, 6.5634765625]\n",
      "val [31.544111251831055, 6.4365034103393555]\n",
      "predict val...\n",
      "predict test...\n",
      "119.9234 232.56772\n",
      "109.870605 232.56772 301.29785 1.0\n",
      "FOLD 1090\n",
      "train [32.399330139160156, 6.530457496643066]\n",
      "val [39.01176834106445, 6.684463977813721]\n",
      "predict val...\n",
      "predict test...\n",
      "146.13383 234.96547\n",
      "177.04407 234.96547 319.4502 1.0\n",
      "FOLD 1091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [32.86677932739258, 6.540387153625488]\n",
      "val [36.84626770019531, 6.765270233154297]\n",
      "predict val...\n",
      "predict test...\n",
      "138.71098 247.26659\n",
      "161.16064 247.26659 338.23535 1.0\n",
      "FOLD 1092\n",
      "train [33.35295486450195, 6.559006690979004]\n",
      "val [34.591251373291016, 6.597104072570801]\n",
      "predict val...\n",
      "predict test...\n",
      "125.652534 250.4219\n",
      "167.28162 250.4219 383.25 1.0\n",
      "FOLD 1093\n",
      "train [29.47467041015625, 6.41070556640625]\n",
      "val [44.667236328125, 6.693788528442383]\n",
      "predict val...\n",
      "predict test...\n",
      "164.69444 216.24231\n",
      "118.15845 216.24231 283.18457 1.0\n",
      "FOLD 1094\n",
      "train [33.97645568847656, 6.581839561462402]\n",
      "val [31.761133193969727, 6.475931167602539]\n",
      "predict val...\n",
      "predict test...\n",
      "120.642586 230.57877\n",
      "134.60516 230.57877 312.43408 1.0\n",
      "FOLD 1095\n",
      "train [32.12986755371094, 6.521146297454834]\n",
      "val [38.26905822753906, 6.712197780609131]\n",
      "predict val...\n",
      "predict test...\n",
      "142.8764 236.21982\n",
      "89.08057 236.21982 327.82593 1.0\n",
      "FOLD 1096\n",
      "train [31.92885971069336, 6.513158321380615]\n",
      "val [35.59054183959961, 6.600554466247559]\n",
      "predict val...\n",
      "predict test...\n",
      "132.31067 238.59879\n",
      "108.31055 238.59879 318.8921 1.0\n",
      "FOLD 1097\n",
      "train [32.386356353759766, 6.5242767333984375]\n",
      "val [36.76962661743164, 6.699808120727539]\n",
      "predict val...\n",
      "predict test...\n",
      "135.76224 244.48473\n",
      "137.42944 244.48473 368.74268 1.0\n",
      "FOLD 1098\n",
      "train [30.349180221557617, 6.441531181335449]\n",
      "val [43.350074768066406, 6.701694488525391]\n",
      "predict val...\n",
      "predict test...\n",
      "160.36642 221.05583\n",
      "138.45044 221.05583 299.36133 1.0\n",
      "FOLD 1099\n",
      "train [33.8762092590332, 6.568758487701416]\n",
      "val [32.68060302734375, 6.481260299682617]\n",
      "predict val...\n",
      "predict test...\n",
      "124.06309 233.28336\n",
      "149.49573 233.28336 312.92114 1.0\n",
      "FOLD 1100\n",
      "train [31.8676700592041, 6.5034990310668945]\n",
      "val [38.73170471191406, 6.728192329406738]\n",
      "predict val...\n",
      "predict test...\n",
      "144.54526 228.36905\n",
      "86.85156 228.36905 306.5337 1.0\n",
      "FOLD 1101\n",
      "train [37.7613525390625, 6.554355621337891]\n",
      "val [42.621612548828125, 6.764830112457275]\n",
      "predict val...\n",
      "predict test...\n",
      "140.56738 249.08556\n",
      "125.89563 249.08556 425.79395 1.0\n",
      "FOLD 1102\n",
      "train [38.33903884887695, 6.5653076171875]\n",
      "val [39.24395751953125, 6.598969459533691]\n",
      "predict val...\n",
      "predict test...\n",
      "123.990776 250.5171\n",
      "130.30957 250.5171 431.97852 1.0\n",
      "FOLD 1103\n",
      "train [36.57079315185547, 6.506401062011719]\n",
      "val [47.54813003540039, 6.690773010253906]\n",
      "predict val...\n",
      "predict test...\n",
      "156.54092 233.43709\n",
      "108.51807 233.43709 511.58545 1.0\n",
      "FOLD 1104\n",
      "train [39.64619827270508, 6.6066155433654785]\n",
      "val [38.108577728271484, 6.510274410247803]\n",
      "predict val...\n",
      "predict test...\n",
      "127.087616 228.84428\n",
      "90.49597 228.84428 383.96387 1.0\n",
      "FOLD 1105\n",
      "train [38.45676803588867, 6.56384801864624]\n",
      "val [42.32635498046875, 6.657420635223389]\n",
      "predict val...\n",
      "predict test...\n",
      "140.26445 231.97522\n",
      "99.09961 231.97522 412.03027 1.0\n",
      "FOLD 1106\n",
      "train [37.52919387817383, 6.535044193267822]\n",
      "val [43.326812744140625, 6.78463888168335]\n",
      "predict val...\n",
      "predict test...\n",
      "142.60692 236.14825\n",
      "118.68799 236.14825 405.3081 1.0\n",
      "FOLD 1107\n",
      "train [38.514427185058594, 6.572003364562988]\n",
      "val [39.76356506347656, 6.602555274963379]\n",
      "predict val...\n",
      "predict test...\n",
      "125.95907 252.18529\n",
      "141.58777 252.18529 420.09912 1.0\n",
      "FOLD 1108\n",
      "train [36.35704040527344, 6.497211456298828]\n",
      "val [49.420135498046875, 6.691039085388184]\n",
      "predict val...\n",
      "predict test...\n",
      "162.94698 226.9406\n",
      "117.63098 226.9406 466.04443 1.0\n",
      "FOLD 1109\n",
      "train [38.54169845581055, 6.583212375640869]\n",
      "val [37.16367721557617, 6.476083755493164]\n",
      "predict val...\n",
      "predict test...\n",
      "123.51307 224.83377\n",
      "92.94678 224.83377 371.20215 1.0\n",
      "FOLD 1110\n",
      "train [37.39387130737305, 6.535744667053223]\n",
      "val [42.28096389770508, 6.649029731750488]\n",
      "predict val...\n",
      "predict test...\n",
      "140.5188 232.84047\n",
      "119.315186 232.84047 385.58594 1.0\n",
      "FOLD 1111\n",
      "train [37.74002456665039, 6.565873146057129]\n",
      "val [42.124122619628906, 6.751558303833008]\n",
      "predict val...\n",
      "predict test...\n",
      "138.98705 261.18683\n",
      "168.10254 261.18683 373.03223 1.0\n",
      "FOLD 1112\n",
      "train [37.76993179321289, 6.556395053863525]\n",
      "val [39.253936767578125, 6.62336540222168]\n",
      "predict val...\n",
      "predict test...\n",
      "125.24711 253.25983\n",
      "152.48279 253.25983 420.7881 1.0\n",
      "FOLD 1113\n",
      "train [36.24324417114258, 6.508903503417969]\n",
      "val [48.212867736816406, 6.6912078857421875]\n",
      "predict val...\n",
      "predict test...\n",
      "157.34134 239.13632\n",
      "147.80591 239.13632 372.12793 1.0\n",
      "FOLD 1114\n",
      "train [38.77055740356445, 6.592710971832275]\n",
      "val [37.471282958984375, 6.499907493591309]\n",
      "predict val...\n",
      "predict test...\n",
      "125.56833 236.62505\n",
      "119.01477 236.62505 353.8247 1.0\n",
      "FOLD 1115\n",
      "train [36.94831085205078, 6.53322696685791]\n",
      "val [46.523094177246094, 6.720653533935547]\n",
      "predict val...\n",
      "predict test...\n",
      "154.39072 234.02934\n",
      "183.54309 234.02934 315.67578 1.0\n",
      "FOLD 1116\n",
      "train [37.20917892456055, 6.5369672775268555]\n",
      "val [41.275726318359375, 6.710298538208008]\n",
      "predict val...\n",
      "predict test...\n",
      "136.29745 245.47984\n",
      "136.01245 245.47984 396.43896 1.0\n",
      "FOLD 1117\n",
      "train [38.069313049316406, 6.5640106201171875]\n",
      "val [38.86113739013672, 6.592868328094482]\n",
      "predict val...\n",
      "predict test...\n",
      "123.05559 253.80415\n",
      "143.84851 253.80415 419.53174 1.0\n",
      "FOLD 1118\n",
      "train [34.11784362792969, 6.445091247558594]\n",
      "val [49.08625030517578, 6.679707050323486]\n",
      "predict val...\n",
      "predict test...\n",
      "160.16809 224.98041\n",
      "143.94897 224.98041 328.93115 1.0\n",
      "FOLD 1119\n",
      "train [39.149871826171875, 6.5966973304748535]\n",
      "val [37.68605422973633, 6.499887466430664]\n",
      "predict val...\n",
      "predict test...\n",
      "125.82535 234.59126\n",
      "111.71564 234.59126 367.95605 1.0\n",
      "FOLD 1120\n",
      "train [36.66933822631836, 6.537086486816406]\n",
      "val [44.008514404296875, 6.691091537475586]\n",
      "predict val...\n",
      "predict test...\n",
      "145.02158 236.97816\n",
      "152.06982 236.97816 330.78467 1.0\n",
      "FOLD 1121\n",
      "train [37.31439971923828, 6.544989585876465]\n",
      "val [41.94949722290039, 6.773055076599121]\n",
      "predict val...\n",
      "predict test...\n",
      "138.52711 253.03418\n",
      "160.34045 253.03418 372.95654 1.0\n",
      "FOLD 1122\n",
      "train [38.00651931762695, 6.564572811126709]\n",
      "val [39.29302215576172, 6.610858917236328]\n",
      "predict val...\n",
      "predict test...\n",
      "125.836395 251.42766\n",
      "158.64233 251.42766 394.75 1.0\n",
      "FOLD 1123\n",
      "train [34.638458251953125, 6.464543342590332]\n",
      "val [49.40447235107422, 6.725346565246582]\n",
      "predict val...\n",
      "predict test...\n",
      "160.02277 230.57866\n",
      "116.29419 230.57866 278.9375 1.0\n",
      "FOLD 1124\n",
      "train [38.68094253540039, 6.585709571838379]\n",
      "val [37.52069091796875, 6.500248908996582]\n",
      "predict val...\n",
      "predict test...\n",
      "126.060234 233.5136\n",
      "121.85535 233.5136 349.167 1.0\n",
      "FOLD 1125\n",
      "train [35.85887145996094, 6.510684013366699]\n",
      "val [44.121788024902344, 6.695257186889648]\n",
      "predict val...\n",
      "predict test...\n",
      "146.6474 227.57954\n",
      "167.33044 227.57954 308.17725 1.0\n",
      "FOLD 1126\n",
      "train [37.447574615478516, 6.545897483825684]\n",
      "val [41.62517166137695, 6.747407913208008]\n",
      "predict val...\n",
      "predict test...\n",
      "137.56497 253.77777\n",
      "152.86597 253.77777 341.9829 1.0\n",
      "FOLD 1127\n",
      "train [37.45802688598633, 6.557342529296875]\n",
      "val [42.785343170166016, 6.767664909362793]\n",
      "predict val...\n",
      "predict test...\n",
      "137.02972 252.16924\n",
      "169.2345 252.16924 380.52295 1.0\n",
      "FOLD 1128\n",
      "train [35.00834274291992, 6.471419334411621]\n",
      "val [48.00263977050781, 6.676568031311035]\n",
      "predict val...\n",
      "predict test...\n",
      "156.37083 223.90244\n",
      "155.31921 223.90244 308.8496 1.0\n",
      "FOLD 1129\n",
      "train [38.10681915283203, 6.574977874755859]\n",
      "val [37.38121795654297, 6.503547668457031]\n",
      "predict val...\n",
      "predict test...\n",
      "126.51051 234.8269\n",
      "145.2489 234.8269 306.6787 1.0\n",
      "FOLD 1130\n",
      "train [35.35111618041992, 6.495831489562988]\n",
      "val [45.92902755737305, 6.725110054016113]\n",
      "predict val...\n",
      "predict test...\n",
      "152.61253 225.9703\n",
      "170.75159 225.9703 302.1836 1.0\n",
      "FOLD 1131\n",
      "train [36.836082458496094, 6.524235725402832]\n",
      "val [42.99367141723633, 6.806936264038086]\n",
      "predict val...\n",
      "predict test...\n",
      "140.3813 246.05573\n",
      "154.46338 246.05573 330.67285 1.0\n",
      "FOLD 1132\n",
      "train [36.76667022705078, 6.532528877258301]\n",
      "val [39.93170166015625, 6.586552143096924]\n",
      "predict val...\n",
      "predict test...\n",
      "128.0205 241.6242\n",
      "162.97803 241.6242 358.3911 1.0\n",
      "FOLD 1133\n",
      "train [35.51276397705078, 6.482820987701416]\n",
      "val [48.13949203491211, 6.669794082641602]\n",
      "predict val...\n",
      "predict test...\n",
      "158.25197 229.84413\n",
      "151.79553 229.84413 366.81494 1.0\n",
      "FOLD 1134\n",
      "train [38.920047760009766, 6.588606834411621]\n",
      "val [37.28079605102539, 6.496855735778809]\n",
      "predict val...\n",
      "predict test...\n",
      "124.93801 235.29082\n",
      "118.84131 235.29082 343.64307 1.0\n",
      "FOLD 1135\n",
      "train [36.28455352783203, 6.527974605560303]\n",
      "val [44.24855041503906, 6.709291458129883]\n",
      "predict val...\n",
      "predict test...\n",
      "147.42842 237.40346\n",
      "158.85059 237.40346 317.54663 1.0\n",
      "FOLD 1136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [37.25074005126953, 6.539231300354004]\n",
      "val [42.31806182861328, 6.783992767333984]\n",
      "predict val...\n",
      "predict test...\n",
      "139.54576 249.72583\n",
      "166.9541 249.72583 350.75488 1.0\n",
      "FOLD 1137\n",
      "train [36.343536376953125, 6.510814666748047]\n",
      "val [39.148406982421875, 6.60097599029541]\n",
      "predict val...\n",
      "predict test...\n",
      "128.4704 231.29222\n",
      "167.42432 231.29222 296.00635 1.0\n",
      "FOLD 1138\n",
      "train [35.64502716064453, 6.484123229980469]\n",
      "val [48.804813385009766, 6.675926685333252]\n",
      "predict val...\n",
      "predict test...\n",
      "159.47984 231.05598\n",
      "163.98328 231.05598 280.49316 1.0\n",
      "FOLD 1139\n",
      "train [37.2049674987793, 6.532063961029053]\n",
      "val [36.993709564208984, 6.481757640838623]\n",
      "predict val...\n",
      "predict test...\n",
      "123.399796 232.56967\n",
      "67.94531 232.56967 328.20557 1.0\n",
      "FOLD 1140\n",
      "train [36.203617095947266, 6.519551753997803]\n",
      "val [45.28647994995117, 6.711282730102539]\n",
      "predict val...\n",
      "predict test...\n",
      "149.51784 229.00618\n",
      "150.25293 229.00618 312.64966 1.0\n",
      "FOLD 1141\n",
      "train [36.41845703125, 6.51868200302124]\n",
      "val [42.48625564575195, 6.7840142250061035]\n",
      "predict val...\n",
      "predict test...\n",
      "139.61974 240.62067\n",
      "128.62598 240.62067 327.9619 1.0\n",
      "FOLD 1142\n",
      "train [35.562252044677734, 6.492516994476318]\n",
      "val [40.585941314697266, 6.636010646820068]\n",
      "predict val...\n",
      "predict test...\n",
      "132.67949 233.78566\n",
      "178.74805 233.78566 289.45312 1.0\n",
      "FOLD 1143\n",
      "train [35.823387145996094, 6.49664831161499]\n",
      "val [49.04708480834961, 6.682817459106445]\n",
      "predict val...\n",
      "predict test...\n",
      "159.44226 239.00533\n",
      "166.11621 239.00533 309.92285 1.0\n",
      "FOLD 1144\n",
      "train [37.31739044189453, 6.541123390197754]\n",
      "val [36.284637451171875, 6.444679260253906]\n",
      "predict val...\n",
      "predict test...\n",
      "122.03897 230.75717\n",
      "150.7514 230.75717 278.70532 1.0\n",
      "FOLD 1145\n",
      "train [36.69491195678711, 6.533234596252441]\n",
      "val [45.29338073730469, 6.712515830993652]\n",
      "predict val...\n",
      "predict test...\n",
      "149.78981 236.66463\n",
      "179.34973 236.66463 315.29907 1.0\n",
      "FOLD 1146\n",
      "train [36.931243896484375, 6.525002479553223]\n",
      "val [42.694637298583984, 6.8162665367126465]\n",
      "predict val...\n",
      "predict test...\n",
      "139.01414 236.44478\n",
      "113.95264 236.44478 329.88525 1.0\n",
      "FOLD 1147\n",
      "train [37.645259857177734, 6.551261901855469]\n",
      "val [39.09360122680664, 6.594260215759277]\n",
      "predict val...\n",
      "predict test...\n",
      "125.969246 246.12816\n",
      "181.10962 246.12816 348.7168 1.0\n",
      "FOLD 1148\n",
      "train [35.859153747558594, 6.4926276206970215]\n",
      "val [49.097930908203125, 6.674272537231445]\n",
      "predict val...\n",
      "predict test...\n",
      "159.80927 232.9545\n",
      "164.953 232.9545 288.39648 1.0\n",
      "FOLD 1149\n",
      "train [37.762916564941406, 6.565428733825684]\n",
      "val [37.785152435302734, 6.5039167404174805]\n",
      "predict val...\n",
      "predict test...\n",
      "127.70721 230.30064\n",
      "145.65546 230.30064 300.3047 1.0\n",
      "FOLD 1150\n",
      "train [36.16425704956055, 6.508223056793213]\n",
      "val [46.17974090576172, 6.752819061279297]\n",
      "predict val...\n",
      "predict test...\n",
      "152.48236 234.51486\n",
      "103.68164 234.51486 340.24487 1.0\n",
      "FOLD 1151\n",
      "train [42.456146240234375, 6.554220676422119]\n",
      "val [47.246334075927734, 6.744263648986816]\n",
      "predict val...\n",
      "predict test...\n",
      "138.97536 240.74348\n",
      "115.333984 240.74348 418.4121 1.0\n",
      "FOLD 1152\n",
      "train [42.569679260253906, 6.559814453125]\n",
      "val [44.31175994873047, 6.624184608459473]\n",
      "predict val...\n",
      "predict test...\n",
      "125.46744 251.22302\n",
      "131.73816 251.22302 433.7246 1.0\n",
      "FOLD 1153\n",
      "train [40.773887634277344, 6.505339622497559]\n",
      "val [53.0692138671875, 6.688467025756836]\n",
      "predict val...\n",
      "predict test...\n",
      "155.83928 234.71007\n",
      "109.55298 234.71007 517.4165 1.0\n",
      "FOLD 1154\n",
      "train [44.1207160949707, 6.596139430999756]\n",
      "val [42.593109130859375, 6.495038986206055]\n",
      "predict val...\n",
      "predict test...\n",
      "126.458275 223.55156\n",
      "86.33765 223.55156 375.72754 1.0\n",
      "FOLD 1155\n",
      "train [42.69122314453125, 6.548516273498535]\n",
      "val [47.44661331176758, 6.647331237792969]\n",
      "predict val...\n",
      "predict test...\n",
      "140.25824 224.76689\n",
      "101.78821 224.76689 391.00732 1.0\n",
      "FOLD 1156\n",
      "train [42.47614288330078, 6.560436248779297]\n",
      "val [47.70988845825195, 6.778594017028809]\n",
      "predict val...\n",
      "predict test...\n",
      "139.16452 247.95297\n",
      "121.14575 247.95297 428.71143 1.0\n",
      "FOLD 1157\n",
      "train [42.561405181884766, 6.5643463134765625]\n",
      "val [45.12419509887695, 6.62894344329834]\n",
      "predict val...\n",
      "predict test...\n",
      "128.54153 251.51506\n",
      "154.21118 251.51506 405.4453 1.0\n",
      "FOLD 1158\n",
      "train [40.769081115722656, 6.504178047180176]\n",
      "val [54.18557357788086, 6.680510520935059]\n",
      "predict val...\n",
      "predict test...\n",
      "159.3771 232.98997\n",
      "124.13257 232.98997 462.25732 1.0\n",
      "FOLD 1159\n",
      "train [43.84239959716797, 6.604400634765625]\n",
      "val [42.34064865112305, 6.503409385681152]\n",
      "predict val...\n",
      "predict test...\n",
      "125.44852 235.06326\n",
      "98.67554 235.06326 389.96094 1.0\n",
      "FOLD 1160\n",
      "train [41.9723014831543, 6.540686130523682]\n",
      "val [47.65947723388672, 6.650605201721191]\n",
      "predict val...\n",
      "predict test...\n",
      "141.49309 232.6876\n",
      "125.214966 232.6876 367.01318 1.0\n",
      "FOLD 1161\n",
      "train [42.09473419189453, 6.560744285583496]\n",
      "val [47.31791305541992, 6.7525177001953125]\n",
      "predict val...\n",
      "predict test...\n",
      "139.53389 259.2579\n",
      "159.31323 259.2579 384.1416 1.0\n",
      "FOLD 1162\n",
      "train [42.27588653564453, 6.555322170257568]\n",
      "val [43.861793518066406, 6.628445148468018]\n",
      "predict val...\n",
      "predict test...\n",
      "125.58581 250.10918\n",
      "144.58398 250.10918 417.18066 1.0\n",
      "FOLD 1163\n",
      "train [39.966060638427734, 6.504798889160156]\n",
      "val [53.13894271850586, 6.681951999664307]\n",
      "predict val...\n",
      "predict test...\n",
      "154.15524 240.06117\n",
      "158.74866 240.06117 360.16992 1.0\n",
      "FOLD 1164\n",
      "train [43.7908935546875, 6.600858211517334]\n",
      "val [42.51035690307617, 6.504461288452148]\n",
      "predict val...\n",
      "predict test...\n",
      "126.26492 232.52754\n",
      "91.12372 232.52754 378.82812 1.0\n",
      "FOLD 1165\n",
      "train [40.389381408691406, 6.525234222412109]\n",
      "val [49.2099494934082, 6.701169013977051]\n",
      "predict val...\n",
      "predict test...\n",
      "144.90004 237.54247\n",
      "173.36267 237.54247 325.54297 1.0\n",
      "FOLD 1166\n",
      "train [41.633480072021484, 6.537564277648926]\n",
      "val [48.295738220214844, 6.816248416900635]\n",
      "predict val...\n",
      "predict test...\n",
      "142.58247 248.96916\n",
      "155.40833 248.96916 371.8369 1.0\n",
      "FOLD 1167\n",
      "train [41.40019226074219, 6.536831855773926]\n",
      "val [45.15034866333008, 6.650529384613037]\n",
      "predict val...\n",
      "predict test...\n",
      "131.11505 243.08551\n",
      "153.44238 243.08551 385.88965 1.0\n",
      "FOLD 1168\n",
      "train [40.108177185058594, 6.497624397277832]\n",
      "val [54.426170349121094, 6.6803083419799805]\n",
      "predict val...\n",
      "predict test...\n",
      "159.956 235.25815\n",
      "121.71924 235.25815 478.25586 1.0\n",
      "FOLD 1169\n",
      "train [42.97623825073242, 6.5865325927734375]\n",
      "val [42.53360366821289, 6.507237911224365]\n",
      "predict val...\n",
      "predict test...\n",
      "127.47778 232.79097\n",
      "115.607666 232.79097 349.9287 1.0\n",
      "FOLD 1170\n",
      "train [41.830223083496094, 6.545655250549316]\n",
      "val [47.59174728393555, 6.637823581695557]\n",
      "predict val...\n",
      "predict test...\n",
      "140.99396 237.37097\n",
      "156.36206 237.37097 323.8684 1.0\n",
      "FOLD 1171\n",
      "train [39.5736198425293, 6.503223419189453]\n",
      "val [47.0046272277832, 6.764144420623779]\n",
      "predict val...\n",
      "predict test...\n",
      "137.65167 247.07861\n",
      "130.4021 247.07861 322.13086 1.0\n",
      "FOLD 1172\n",
      "train [41.91796875, 6.549963474273682]\n",
      "val [44.49138641357422, 6.631606101989746]\n",
      "predict val...\n",
      "predict test...\n",
      "127.80802 245.7497\n",
      "162.71606 245.7497 389.27197 1.0\n",
      "FOLD 1173\n",
      "train [40.13992691040039, 6.495667934417725]\n",
      "val [53.85118103027344, 6.66801643371582]\n",
      "predict val...\n",
      "predict test...\n",
      "157.67796 232.57146\n",
      "156.45972 232.57146 366.4292 1.0\n",
      "FOLD 1174\n",
      "train [43.089012145996094, 6.563950538635254]\n",
      "val [42.489906311035156, 6.485612392425537]\n",
      "predict val...\n",
      "predict test...\n",
      "126.764175 229.46684\n",
      "140.8175 229.46684 288.00195 1.0\n",
      "FOLD 1175\n",
      "train [41.18081283569336, 6.532199859619141]\n",
      "val [49.9857063293457, 6.684344291687012]\n",
      "predict val...\n",
      "predict test...\n",
      "147.62451 232.8011\n",
      "168.2174 232.8011 324.65137 1.0\n",
      "FOLD 1176\n",
      "train [41.35953903198242, 6.539034366607666]\n",
      "val [48.440330505371094, 6.820990562438965]\n",
      "predict val...\n",
      "predict test...\n",
      "142.18355 252.4264\n",
      "170.7992 252.4264 341.27197 1.0\n",
      "FOLD 1177\n",
      "train [42.350711822509766, 6.560894966125488]\n",
      "val [43.84792709350586, 6.5939130783081055]\n",
      "predict val...\n",
      "predict test...\n",
      "124.888664 249.8572\n",
      "159.07324 249.8572 392.9546 1.0\n",
      "FOLD 1178\n",
      "train [39.06705093383789, 6.463630676269531]\n",
      "val [55.11677932739258, 6.749189376831055]\n",
      "predict val...\n",
      "predict test...\n",
      "159.50427 219.82349\n",
      "58.62671 219.82349 304.18604 1.0\n",
      "FOLD 1179\n",
      "train [43.233707427978516, 6.576521396636963]\n",
      "val [41.93522644042969, 6.478813171386719]\n",
      "predict val...\n",
      "predict test...\n",
      "125.35907 227.67905\n",
      "128.8913 227.67905 322.41846 1.0\n",
      "FOLD 1180\n",
      "train [40.6810417175293, 6.522103786468506]\n",
      "val [51.78167724609375, 6.744365692138672]\n",
      "predict val...\n",
      "predict test...\n",
      "152.0577 231.08319\n",
      "123.18701 231.08319 309.63794 1.0\n",
      "FOLD 1181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [41.06950378417969, 6.523568630218506]\n",
      "val [49.231075286865234, 6.802934646606445]\n",
      "predict val...\n",
      "predict test...\n",
      "144.86925 246.4757\n",
      "149.38123 246.4757 332.03027 1.0\n",
      "FOLD 1182\n",
      "train [41.69744873046875, 6.543122291564941]\n",
      "val [44.2255973815918, 6.632079124450684]\n",
      "predict val...\n",
      "predict test...\n",
      "127.1532 247.09866\n",
      "155.15552 247.09866 394.09082 1.0\n",
      "FOLD 1183\n",
      "train [39.20229721069336, 6.468814849853516]\n",
      "val [54.921104431152344, 6.684816360473633]\n",
      "predict val...\n",
      "predict test...\n",
      "158.71404 225.30595\n",
      "130.63916 225.30595 295.19556 1.0\n",
      "FOLD 1184\n",
      "train [42.954132080078125, 6.567112922668457]\n",
      "val [42.21501922607422, 6.490286350250244]\n",
      "predict val...\n",
      "predict test...\n",
      "127.0722 233.8639\n",
      "134.19763 233.8639 307.6455 1.0\n",
      "FOLD 1185\n",
      "train [39.72875213623047, 6.510611534118652]\n",
      "val [47.1380729675293, 6.675144195556641]\n",
      "predict val...\n",
      "predict test...\n",
      "140.03555 231.08957\n",
      "168.0 231.08957 297.71533 1.0\n",
      "FOLD 1186\n",
      "train [41.51883316040039, 6.537154197692871]\n",
      "val [47.42927169799805, 6.77122688293457]\n",
      "predict val...\n",
      "predict test...\n",
      "138.983 242.83392\n",
      "149.4812 242.83392 318.75684 1.0\n",
      "FOLD 1187\n",
      "train [41.91813659667969, 6.557946681976318]\n",
      "val [43.67302322387695, 6.588359355926514]\n",
      "predict val...\n",
      "predict test...\n",
      "124.45339 255.04214\n",
      "170.03955 255.04214 370.03662 1.0\n",
      "FOLD 1188\n",
      "train [39.40207290649414, 6.485250949859619]\n",
      "val [55.11555862426758, 6.681389808654785]\n",
      "predict val...\n",
      "predict test...\n",
      "159.72018 233.89299\n",
      "160.46863 233.89299 284.54468 1.0\n",
      "FOLD 1189\n",
      "train [43.195377349853516, 6.577975273132324]\n",
      "val [40.75859832763672, 6.481965065002441]\n",
      "predict val...\n",
      "predict test...\n",
      "122.58047 238.547\n",
      "162.47705 238.547 295.50684 1.0\n",
      "FOLD 1190\n",
      "train [41.357330322265625, 6.539081573486328]\n",
      "val [48.955814361572266, 6.674853324890137]\n",
      "predict val...\n",
      "predict test...\n",
      "144.79094 240.52538\n",
      "172.95984 240.52538 321.34155 1.0\n",
      "FOLD 1191\n",
      "train [39.69138717651367, 6.497198581695557]\n",
      "val [45.400672912597656, 6.608551979064941]\n",
      "predict val...\n",
      "predict test...\n",
      "133.92001 233.66219\n",
      "165.36072 233.66219 287.10962 1.0\n",
      "FOLD 1192\n",
      "train [38.989803314208984, 6.483501434326172]\n",
      "val [44.93050003051758, 6.589038848876953]\n",
      "predict val...\n",
      "predict test...\n",
      "129.7819 234.90343\n",
      "137.07214 234.90343 316.44092 1.0\n",
      "FOLD 1193\n",
      "train [38.77366638183594, 6.4550628662109375]\n",
      "val [53.9316520690918, 6.678644180297852]\n",
      "predict val...\n",
      "predict test...\n",
      "156.01627 226.73987\n",
      "109.11621 226.73987 310.92822 1.0\n",
      "FOLD 1194\n",
      "train [43.023582458496094, 6.585897922515869]\n",
      "val [40.976871490478516, 6.500289440155029]\n",
      "predict val...\n",
      "predict test...\n",
      "124.66528 242.14314\n",
      "157.2843 242.14314 310.84717 1.0\n",
      "FOLD 1195\n",
      "train [41.28977584838867, 6.530388832092285]\n",
      "val [49.70981216430664, 6.69174337387085]\n",
      "predict val...\n",
      "predict test...\n",
      "147.7999 234.07568\n",
      "181.9331 234.07568 336.45898 1.0\n",
      "FOLD 1196\n",
      "train [39.14139938354492, 6.484609127044678]\n",
      "val [48.152896881103516, 6.793303489685059]\n",
      "predict val...\n",
      "predict test...\n",
      "140.82614 234.11914\n",
      "134.16895 234.11914 331.17725 1.0\n",
      "FOLD 1197\n",
      "train [41.03329086303711, 6.520085334777832]\n",
      "val [54.22953414916992, 7.12187385559082]\n",
      "predict val...\n",
      "predict test...\n",
      "154.5895 236.77359\n",
      "176.81519 236.77359 333.7627 1.0\n",
      "FOLD 1198\n",
      "train [39.514122009277344, 6.479389190673828]\n",
      "val [53.90880584716797, 6.665768623352051]\n",
      "predict val...\n",
      "predict test...\n",
      "156.78552 225.358\n",
      "165.00562 225.358 270.604 1.0\n",
      "FOLD 1199\n",
      "train [42.99696731567383, 6.571150302886963]\n",
      "val [40.71287536621094, 6.490115642547607]\n",
      "predict val...\n",
      "predict test...\n",
      "122.21766 239.54301\n",
      "129.16907 239.54301 326.29028 1.0\n",
      "FOLD 1200\n",
      "train [38.79505920410156, 6.474591255187988]\n",
      "val [47.170684814453125, 6.723520278930664]\n",
      "predict val...\n",
      "predict test...\n",
      "139.47351 232.07166\n",
      "65.881836 232.07166 330.771 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYbElEQVR4nO3da2xk533f8e//nDM33vai5Uqr1cort7Ji1XV9YRPZSRPXshE1Drx+0QAW6mTbql3AKNrYvaRyDMQN+sZ13bQJgjRYWKrUxJXhOmpsBFBiQY2jtlAUU65trSrLusXSaqVdrvbOy1zO+ffFOcMh55Aidzhc6uH+PgDBmWfOzDzPcPib/zznZu6OiIiEJ9rqDoiIyGAU4CIigVKAi4gESgEuIhIoBbiISKCSK/lke/bs8YMHD17JpxQRCd4TTzxx2t0n+9uvaIAfPHiQ6enpK/mUIiLBM7MfrdSuKRQRkUApwEVEAqUAFxEJlAJcRCRQCnARkUApwEVEAqUAFxEJVBAB/sjTJ/mdbz231d0QEXlTCSLAv/XMDF/6Xy9udTdERN5UgghwAJ14QkRkuSAC3GyreyAi8uYTRIADqP4WEVkuiABXAS4iUrZmgJvZATP7UzN72syeMrNfLtp3m9nDZvZs8XvXZnZUU+AiIsutpwLvAP/C3d8O3Ab8EzO7FbgbeMTdbwYeKa5vCtMkuIhIyZoB7u6vuvt3issXgaeB/cAh4P5isfuBj21SH0VEZAWXNQduZgeBdwOPA9e6+6uQhzywd5X7HDGzaTObnpmZGbij2oxQRGS5dQe4mY0BfwB8yt0vrPd+7n7U3afcfWpysnRGIBERGdC6AtzMKuTh/WV3f7BoPmlm+4rb9wGnNqeLOdXfIiLLrWcrFAPuAZ52999YctM3gMPF5cPA14ffvW4fNuuRRUTCtZ6TGv8k8IvAk2b23aLtV4HPA181s7uAl4Bf2JQedqkEFxFZZs0Ad/f/zer70tw+3O6szLQrj4hISRB7YoIKcBGRfkEEuObARUTKgghw0HbgIiL9gghwFeAiImVBBDhoDlxEpF8QAa45cBGRsiACXEREyoIJcK3DFBFZLogA1/HARUTKgghwANdqTBGRZYIIcNXfIiJlQQQ4aA5cRKRfGAGuElxEpCSMAEc78oiI9AsiwHU4WRGRsiACHFAJLiLSJ4gA12bgIiJlQQQ4aDtwEZF+QQS4CnARkbL1nJX+XjM7ZWbHlrS9y8z+3My+a2bTZvbjm9tNbQcuItJvPRX4fcAdfW1fAH7d3d8F/FpxfdNoDlxEpGzNAHf3R4Ez/c3ARHF5B3BiyP0SEZE1JAPe71PAn5jZF8k/BN6/2oJmdgQ4AnDjjTcO+HTailBEpN+gKzE/CXza3Q8AnwbuWW1Bdz/q7lPuPjU5OTnQk2lHHhGRskED/DDwYHH5vwNXYCWmanARkaUGDfATwM8Ulz8IPDuc7qxMKzFFRMrWnAM3sweADwB7zOw48DngHwO/aWYJsEAxx72ZVH+LiCy3ZoC7+52r3PTeIfdlVSrARUTKgtgTE7Qjj4hIvzACXJPgIiIlYQS4iIiUBBHgqr9FRMqCCPAubQsuItITRIBrClxEpCyIABcRkbKgAlwzKCIiPUEEuA5mJSJSFkSAd6kAFxHpCSLAtRJTRKQsiADv0maEIiI9QQS4CnARkbIgArxL9beISE8QAa45cBGRsiACvEtT4CIiPUEEuKkEFxEpCSLAu1yz4CIii4IKcBER6VkzwM3sXjM7ZWbH+tr/qZk9Y2ZPmdkXNq+LPZoDFxHpWU8Ffh9wx9IGM/vbwCHgne7+14AvDr9rIiLyRtYMcHd/FDjT1/xJ4PPu3iyWObUJfVukdZgiImWDzoG/DfhbZva4mf2Zmf3N1RY0syNmNm1m0zMzMwM+nYiI9Bs0wBNgF3Ab8K+Ar9oq2/q5+1F3n3L3qcnJyYGeTIeTFREpGzTAjwMPeu4vgAzYM7xurUwrMUVEegYN8D8EPghgZm8DqsDpIfWpRHPgIiJlyVoLmNkDwAeAPWZ2HPgccC9wb7FpYQs47FfgWK/akUdEpGfNAHf3O1e56RND7suqVICLiJQFtSem5sBFRHqCCHDNgYuIlAUR4F0qwEVEeoIIcG0HLiJSFkSAd+mkxiIiPUEEuObARUTKgghwEREpCyrANYEiItITVICLiEhPUAGudZgiIj1BBLjOSi8iUhZEgC9SBS4isiiIAFf9LSJSFkSAd+lwsiIiPUEEuKbARUTKggjwLm2FIiLSE0SAqwAXESkLIsC7VICLiPQEEeDaDlxEpGzNADeze83sVHEC4/7b/qWZuZnt2ZzuiYjIatZTgd8H3NHfaGYHgA8DLw25T6vS8cBFRHrWDHB3fxQ4s8JN/xH4Fa7A1LRmUEREygaaAzezjwKvuPv31rHsETObNrPpmZmZQZ5ukepvEZGeyw5wMxsBPgv82nqWd/ej7j7l7lOTk5OX+3T5cw50LxGR7W2QCvyvADcB3zOzvwRuAL5jZtcNs2Mr0RS4iEhPcrl3cPcngb3d60WIT7n76SH2azlNgouIlKxnM8IHgMeAW8zsuJndtfndWpkOZiUi0rNmBe7ud65x+8Gh9WYVqr9FRMqC2BNzkQpwEZFFQQS4psBFRMqCCPAuFeAiIj1BBLhpFlxEpCSIAO/SduAiIj1BBLjmwEVEyoIIcBERKQsqwLUjj4hITxABrhkUEZGyIAK8SysxRUR6gghwrcQUESkLIsC7VICLiPQEEeDakUdEpCyIAO/SSY1FRHrCCHAV4CIiJWEEeEEFuIhITxABrgJcRKQsiAAXEZGyIALctCG4iEjJek5qfK+ZnTKzY0va/r2Z/cDMvm9m/8PMdm5qL0VEpGQ9Ffh9wB19bQ8D73D3dwI/BD4z5H6tSCsxRUR61gxwd38UONPX9k137xRX/xy4YRP6tkgTKCIiZcOYA/+HwEOr3WhmR8xs2symZ2ZmNvREOpysiEjPhgLczD4LdIAvr7aMux919yl3n5qcnBzweQbsoIjINpYMekczOwz8PHC7X6F93DUHLiLSM1CAm9kdwL8Gfsbd54bbpZWeb7OfQUQkPOvZjPAB4DHgFjM7bmZ3Ab8NjAMPm9l3zex3N7mfgA4nKyKy1JoVuLvfuULzPZvQl1XpcLIiImVB7InZpcPJioj0BBHgmgMXESkLIsC7VH+LiPQEFeAiItITVIBrClxEpCeoABcRkZ4gAlzHAxcRKQsiwHs0hyIi0hVEgKv+FhEpCyLAu7QSU0SkJ4gA1xS4iEhZEAHepQJcRKQniADXwaxERMqCCPAuzYGLiPQEEeCaAxcRKQsiwLt0UmMRkZ4gAlwFuIhIWRAB3qU5cBGRniACXHPgIiJl6zmp8b1mdsrMji1p221mD5vZs8XvXZvbTRER6beeCvw+4I6+truBR9z9ZuCR4vqm0xSKiEjPmgHu7o8CZ/qaDwH3F5fvBz423G710xyKiEi/QefAr3X3VwGK33tXW9DMjpjZtJlNz8zMDPh0OW1GKCLSs+krMd39qLtPufvU5OTkQI+hlZgiImWDBvhJM9sHUPw+NbwurU5z4CIiPYMG+DeAw8Xlw8DXh9OdlakAFxEpW89mhA8AjwG3mNlxM7sL+DzwYTN7FvhwcV1ERK6gZK0F3P3OVW66fch9WZVOaiwiUhbEnphdmgMXEekJIsBVf4uIlAUR4F3aDlxEpCeIANcUuIhIWRAB3qU5cBGRnqACXEREeoIIcE2hiIiUBRHgXZpBERHpCSLATRsSioiUBBHgXa61mCIii8IIcBXgIiIlYQR4QfW3iEhPEAGuAlxEpCyIAI+K7QjTTDW4iEhXEAF+7UQdgNfOL2xxT0RE3jyCCPADuxsAvHRmbot7IiLy5hFEgI9UE/aM1XhZAS4isiiIAAc4fanJV779Mufn2lvdFRGRN4VgAvyv7h0D4OWzqsJFRGCDAW5mnzazp8zsmJk9YGb1YXWs37899A4ALsyrAhcRgQ0EuJntB/4ZMOXu7wBi4OPD6li/HY0KAOcU4CIiwManUBKgYWYJMAKc2HiXVrZzJA/w8wpwERFgAwHu7q8AXwReAl4Fzrv7N/uXM7MjZjZtZtMzMzMDd7RbgSvARURyG5lC2QUcAm4CrgdGzewT/cu5+1F3n3L3qcnJyYE7OlKNSSLjnLZCEREBNjaF8iHgRXefcfc28CDw/uF0q8zM2DlSUQUuIlLYSIC/BNxmZiNmZsDtwNPD6dbKJhoVbYUiIlLYyBz448DXgO8ATxaPdXRI/VrRzkaFM7OtzXwKEZFgJBu5s7t/DvjckPqypgO7R3j0h4OvCBUR2U6C2RMT4Jbrxjk71+Z3/+z5re6KiMiWCyrAf+l9B3nrnlH++NhrW90VEZEtF1SAj9USfvptkzx78qJOcCwiV72gAhxg/84Gs62UCwudre6KiMiWCi7Ar9uRHy/r5AWdnUdErm7BBvirOr2aiFzlwgvw4vyYJxXgInKVCy7A907UAHhNUygicpULLsBrSczkeI0fva4z84jI1S24AAe4dd8E3zt+TpsSishVLcgA/9Ct1/LcqUs89sLrW90VEZEtE2SA/8J7b+C6iTqff+gHzLfSre6OiMiWCDLA65WYX/3I2/n+8fP89X/zJ9z+H77FJ3//CU6cm9/qromIXDEbOhrhVvro37ie3SNVvvLtl3js+dd56NhrPHTsNWpJRLOTAfCRd+7j1n0TvDAzy/U76+zf2aBeielkvnho2ve8ZRe1JCKOjN/51nO0Ohl/7yfewvU7G1TjiLl2h0d/OMPUwd1U44gDu0fW3cdLzQ71JCKJ88/JVifDcZqdjNfOL7B7tMqesdqy+7g7+eHV8+WrSZCfseu2dLwicnnsSq4InJqa8unp6U157MdfeJ3/89xpTpxf4JWz8zz+4uskcUSrCPNhGq8n1CsxrU7GXKvDSDWhXomoxBFnZ1tUk4hqEnHyQhOARiVmtBZz+lL5WOb7dzaYHK8x1+pwaaHDufk2Y7UEMzh5ocl1E3WqScRoLWGu1cGA0VpCJ3Uyd46fnWdHo8JILWa8lrDQzqhXItrF7fVKzHg94VKzw2yzw+lLLa7fWWeumXJ+vs2N14xQiSLG6gknLyyw0E6pJvnp68ZqCZUkYrbZoVGJmW+n1JKIiXqFM3MtdjYqnJtrM99Oi8du8mP7JoiM/LWYazFSSagmEefmW+waqRJHhgHz7ZRzc22ePXWJt+8bZ7SaL1dLYiqxkcQRBpyda9FJnYVOykg1ZmejykI75cxci3qSj22iUeH0pSbn59s0KvlWSmmWf1A+P3OJPWM1do9UqVUi2mnGjkaVZicfy2wz5VKzwzWjVdppRiWOOHF+nkYlZvdoFcOYb6eM1ZPF/lwzWqPVybjU7HDtRJ35dkqaZVxc6LB3vIaZsXeiRpY5ncxJM8cdGtWYZjullTpJZIzXEzKH+VaHiUaFShxx6uICo7WEJLLF99ilZodXzs4zOV5j73iN1KESG2mWP04ljvDifRZHxvniPVSvxGTuzLVSqklEJTKqRUFRiY3IjFYno5ZEpFn+QRoZRFH+G4y5Vv63b1TjxfdUNY5opRmd1JkcrxGbMdfuUIkjxmoJkRmdLL+9Wxw54A5mEFn+HjCDzKGdZtSTGIA4NprtlNdnWzSK/leTaNljp5nTyTIiy8eeRPnfqJpEdFKnnWV58dVKiSOjXokwjCQyOpnn/SkKh8zz17Dbt24x0c3FNyou3PO/axRtfgFiZk+4+1SpfbsE+Eq8ePNm7sy3U5rtjBPn5nn57DzzrQ7XjNU4M9uiGkfMtjrcuHuE/bsaPPzUSczyTRZbacbBa0Z56sR5Xjk3z4FdI7w+mwdzNY6Yb+dz8JEZC8XlahJx+lKLM7Mt9u9qsHukysWFNknxZts9WiVz6KQZT75yPg/oasJYPQ+xV87Oc81YlbFawpnZFnFkiyeyqMYR5+fb7Cj+4R3HMJqdlIsLHRrV/J++UY05falJEuX/nDtHKtSS/B/xtfPztFNnolGh2U5ZaKd0MqcSR5jl/2hJZDQ7GVHxOnSybPH1ODfXolGNuTDfYd+OOqO1BHfn1MUmjeIbjgOzzQ5JZCSxUU9i2mmGA5k7I5WERjXm4kKbduo0KjGzrc7i65JmeVg0qgnNTgrdt6lBPYkZqca0M+f8XIuFdsae8SppBhfm2ySx0Unz4NzRyE/DV69EnJ1rM1qNudjsMFGv0Erz8Y1WEy4s5H291Oywo1Gh2clodfIPs7FazMzFJpEZFAFUr+R/s5fOzFFLItqZUylesyQ2Ftq9wqG4G1kxhkqcB8nl/OslRQimmba8GobIen+POMqD3D1vT6KIzPMP39FqvPh3N2ChkxGbLf495tspe8drzLXSxQ+FqHiPVIpcqSX5h8nRX5zip27eM1B/VwvwYKdQ1sPMGK3lQxyv52e1P7B7hJ9Y434/dt1Eqe0j79w37O5JYFaa7ml1MiqxLavc3FkM8tiMqKj4mkW121327GyLWiWinsRcXOjQTFN2NCpFhek02xleBMm+HXVaaT711qjEYBAX1eiFhTajtYT5VsrpSy32jtcWK2/I1xlBXunOtVJanYx2mpFEeb87RcWauoPnwZa5L36LaVRj5lsplTivdDOH8aK4SN0xKCr0/PGzIhlrSUwzzcgyp1ukdivxZYEZR4vFT+ZOVPzf5q9j/nyRsRiS7nmR1E4z3KGTefHtJv9AbqUZcWSLr+Vss/fYC52UepJX9q1ORr0S598wi6BOM18c01wrzcO7eO0cZ6xWIc0y0ix/vFolYuZic/HbgbuTef6+yNwXC42RSsx1O5ZPlw7Dtg5wkWFa6et0/zoKM8MsD7T+9m6Qdu0arS5e3jFSASrLH7y+/GotiXnLNaOlPuyd6C341sk3GoFsN9t7DZmIyDa2oQA3s51m9jUz+4GZPW1m7xtWx0RE5I1tdArlN4E/dve/a2ZVYP3b2ImIyIYMHOBmNgH8NPD3Ady9BZS3kxMRkU2xkSmUtwIzwH8xs/9rZl8ys9IaFjM7YmbTZjY9MzOzgacTEZGlNhLgCfAe4D+7+7uBWeDu/oXc/ai7T7n71OSkVpGLiAzLRgL8OHDc3R8vrn+NPNBFROQKGDjA3f014GUzu6Vouh34f0PplYiIrGlDu9Kb2buALwFV4AXgH7j72TdYfgb40YBPtwc4PeB9Q6UxXx005qvDRsb8FncvzUFf0WOhbISZTa90LIDtTGO+OmjMV4fNGLP2xBQRCZQCXEQkUCEF+NGt7sAW0JivDhrz1WHoYw5mDlxERJYLqQIXEZElFOAiIoEKIsDN7A4ze8bMnjOz0u76ITKzA2b2p8VheJ8ys18u2neb2cNm9mzxe9eS+3ymeA2eMbOf3breb4yZxcXxc/6ouL6tx7zSYZevgjF/unhfHzOzB8ysvt3GbGb3mtkpMzu2pO2yx2hm7zWzJ4vbfssu5yzf+SmK3rw/QAw8T37wrCrwPeDWre7XEMa1D3hPcXkc+CFwK/AF4O6i/W7g3xWXby3GXgNuKl6TeKvHMeDY/znw34A/Kq5v6zED9wP/qLhcBXZu5zED+4EXgUZx/avkRy3dVmMmPxrre4BjS9oue4zAXwDvIz/t5kPA31lvH0KowH8ceM7dX/D8kLVfAQ5tcZ82zN1fdffvFJcvAk+Tv/EPkf/DU/z+WHH5EPAVd2+6+4vAc+SvTVDM7AbgI+R78HZt2zEvOezyPZAfdtndz7GNx1xIgIaZJeTnCTjBNhuzuz8KnOlrvqwxmtk+YMLdH/M8zf/rkvusKYQA3w+8vOT68aJt2zCzg8C7gceBa939VchDHthbLLZdXof/BPwKkC1p285jXu2wy9t2zO7+CvBF4CXgVeC8u3+TbTzmJS53jPuLy/3t6xJCgK80H7Rttn00szHgD4BPufuFN1p0hbagXgcz+3nglLs/sd67rNAW1JhZ52GXlwh+zMW87yHyqYLrgVEz+8Qb3WWFtqDGvA6rjXFDYw8hwI8DB5Zcv4H861jwzKxCHt5fdvcHi+aTxdcqit+nivbt8Dr8JPBRM/tL8qmwD5rZ77O9x7zaYZe385g/BLzo7jPu3gYeBN7P9h5z1+WO8Xhxub99XUII8G8DN5vZTcV5Nz8OfGOL+7RhxZrme4Cn3f03ltz0DeBwcfkw8PUl7R83s5qZ3QTcTL7yIxju/hl3v8HdD5L/Hf+nu3+C7T3m1Q67vG3HTD51cpuZjRTv89vJ1/Fs5zF3XdYYi2mWi2Z2W/Fa/dKS+6xtq9fkrnNt78+Rb6XxPPDZre7PkMb0U+Rflb4PfLf4+TngGuAR4Nni9+4l9/ls8Ro8w2WsqX4z/gAfoLcVyrYeM/AuYLr4W/8hsOsqGPOvAz8AjgG/R771xbYaM/AA+Rx/m7ySvmuQMQJTxev0PPDbFHvIr+dHu9KLiAQqhCkUERFZgQJcRCRQCnARkUApwEVEAqUAFxEJlAJcRCRQCnARkUD9fyFII2troa+LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1201\n",
      "train [28.9132137298584, 6.552004337310791]\n",
      "val [31.775854110717773, 6.74070930480957]\n",
      "predict val...\n",
      "predict test...\n",
      "137.85408 242.69482\n",
      "120.52161 242.69482 417.66992 1.0\n",
      "FOLD 1202\n",
      "train [29.301063537597656, 6.565041542053223]\n",
      "val [29.791200637817383, 6.588005542755127]\n",
      "predict val...\n",
      "predict test...\n",
      "122.88811 250.3636\n",
      "126.82898 250.3636 434.91504 1.0\n",
      "FOLD 1203\n",
      "train [27.783504486083984, 6.494719505310059]\n",
      "val [35.86634826660156, 6.675253868103027]\n",
      "predict val...\n",
      "predict test...\n",
      "155.72781 225.41547\n",
      "121.45227 225.41547 447.94238 1.0\n",
      "FOLD 1204\n",
      "train [29.986255645751953, 6.602447509765625]\n",
      "val [29.020732879638672, 6.5101399421691895]\n",
      "predict val...\n",
      "predict test...\n",
      "127.2322 234.02005\n",
      "94.431885 234.02005 386.16504 1.0\n",
      "FOLD 1205\n",
      "train [28.930126190185547, 6.5433759689331055]\n",
      "val [31.779891967773438, 6.6358842849731445]\n",
      "predict val...\n",
      "predict test...\n",
      "139.01277 225.9027\n",
      "108.98132 225.9027 375.5005 1.0\n",
      "FOLD 1206\n",
      "train [28.49199676513672, 6.545261383056641]\n",
      "val [33.09014129638672, 6.842685699462891]\n",
      "predict val...\n",
      "predict test...\n",
      "144.37126 251.42834\n",
      "137.74695 251.42834 391.90967 1.0\n",
      "FOLD 1207\n",
      "train [29.00545883178711, 6.561051368713379]\n",
      "val [30.595537185668945, 6.615257263183594]\n",
      "predict val...\n",
      "predict test...\n",
      "128.13457 250.18185\n",
      "153.02344 250.18185 408.24902 1.0\n",
      "FOLD 1208\n",
      "train [27.93769645690918, 6.506341457366943]\n",
      "val [37.3202018737793, 6.679058074951172]\n",
      "predict val...\n",
      "predict test...\n",
      "163.11491 231.02344\n",
      "134.45215 231.02344 419.34033 1.0\n",
      "FOLD 1209\n",
      "train [29.927658081054688, 6.606194496154785]\n",
      "val [28.7725887298584, 6.509066581726074]\n",
      "predict val...\n",
      "predict test...\n",
      "125.88752 241.23979\n",
      "116.34143 241.23979 365.49902 1.0\n",
      "FOLD 1210\n",
      "train [27.93263053894043, 6.51113224029541]\n",
      "val [32.22425842285156, 6.685593128204346]\n",
      "predict val...\n",
      "predict test...\n",
      "142.0067 219.65736\n",
      "138.68481 219.65736 306.9375 1.0\n",
      "FOLD 1211\n",
      "train [28.42485809326172, 6.552254676818848]\n",
      "val [31.383325576782227, 6.704102993011475]\n",
      "predict val...\n",
      "predict test...\n",
      "137.52695 253.32426\n",
      "145.56152 253.32426 390.85352 1.0\n",
      "FOLD 1212\n",
      "train [28.957021713256836, 6.559868812561035]\n",
      "val [29.601572036743164, 6.601596832275391]\n",
      "predict val...\n",
      "predict test...\n",
      "123.85078 249.51921\n",
      "151.96509 249.51921 409.80176 1.0\n",
      "FOLD 1213\n",
      "train [27.579700469970703, 6.502925872802734]\n",
      "val [36.75624465942383, 6.694073677062988]\n",
      "predict val...\n",
      "predict test...\n",
      "158.84645 235.87546\n",
      "133.40613 235.87546 437.3994 1.0\n",
      "FOLD 1214\n",
      "train [29.88408851623535, 6.602769374847412]\n",
      "val [29.371036529541016, 6.50996208190918]\n",
      "predict val...\n",
      "predict test...\n",
      "129.37308 235.19333\n",
      "118.97052 235.19333 358.62598 1.0\n",
      "FOLD 1215\n",
      "train [28.29775047302246, 6.537668704986572]\n",
      "val [34.51413345336914, 6.698605060577393]\n",
      "predict val...\n",
      "predict test...\n",
      "150.3521 235.97855\n",
      "157.39429 235.97855 329.95215 1.0\n",
      "FOLD 1216\n",
      "train [27.799943923950195, 6.518505096435547]\n",
      "val [31.544227600097656, 6.73325252532959]\n",
      "predict val...\n",
      "predict test...\n",
      "136.68475 241.85689\n",
      "162.54529 241.85689 303.29297 1.0\n",
      "FOLD 1217\n",
      "train [29.10564422607422, 6.563779354095459]\n",
      "val [29.564077377319336, 6.583287239074707]\n",
      "predict val...\n",
      "predict test...\n",
      "122.46519 251.5577\n",
      "142.43921 251.5577 419.84766 1.0\n",
      "FOLD 1218\n",
      "train [27.236648559570312, 6.489282131195068]\n",
      "val [37.14204025268555, 6.670639991760254]\n",
      "predict val...\n",
      "predict test...\n",
      "161.15865 231.34355\n",
      "156.05872 231.34355 326.08008 1.0\n",
      "FOLD 1219\n",
      "train [29.74337387084961, 6.588129997253418]\n",
      "val [28.469226837158203, 6.487175941467285]\n",
      "predict val...\n",
      "predict test...\n",
      "125.263794 229.40826\n",
      "127.270996 229.40826 344.93945 1.0\n",
      "FOLD 1220\n",
      "train [27.60896873474121, 6.5081682205200195]\n",
      "val [32.55867004394531, 6.684226036071777]\n",
      "predict val...\n",
      "predict test...\n",
      "140.72781 223.74501\n",
      "142.55103 223.74501 304.88184 1.0\n",
      "FOLD 1221\n",
      "train [27.340097427368164, 6.4910783767700195]\n",
      "val [31.01274299621582, 6.6350321769714355]\n",
      "predict val...\n",
      "predict test...\n",
      "134.45235 232.39017\n",
      "137.55566 232.39017 292.9624 1.0\n",
      "FOLD 1222\n",
      "train [28.669578552246094, 6.5518646240234375]\n",
      "val [30.05870246887207, 6.609453201293945]\n",
      "predict val...\n",
      "predict test...\n",
      "126.533516 244.8563\n",
      "165.39941 244.8563 372.646 1.0\n",
      "FOLD 1223\n",
      "train [26.6165714263916, 6.4698286056518555]\n",
      "val [37.81999969482422, 6.708467960357666]\n",
      "predict val...\n",
      "predict test...\n",
      "163.75264 231.41022\n",
      "161.72925 231.41022 281.71484 1.0\n",
      "FOLD 1224\n",
      "train [29.65286636352539, 6.581986427307129]\n",
      "val [28.07586669921875, 6.481930732727051]\n",
      "predict val...\n",
      "predict test...\n",
      "123.93882 233.43585\n",
      "143.96777 233.43585 330.93457 1.0\n",
      "FOLD 1225\n",
      "train [27.426610946655273, 6.501627445220947]\n",
      "val [31.966659545898438, 6.689947128295898]\n",
      "predict val...\n",
      "predict test...\n",
      "139.55243 228.61833\n",
      "49.64917 228.61833 309.64575 1.0\n",
      "FOLD 1226\n",
      "train [27.865976333618164, 6.518496036529541]\n",
      "val [32.788291931152344, 6.885777950286865]\n",
      "predict val...\n",
      "predict test...\n",
      "140.9353 238.69427\n",
      "118.38379 238.69427 306.6455 1.0\n",
      "FOLD 1227\n",
      "train [27.432544708251953, 6.489206790924072]\n",
      "val [30.607511520385742, 6.612454414367676]\n",
      "predict val...\n",
      "predict test...\n",
      "131.33824 221.96916\n",
      "155.76343 221.96916 281.8501 1.0\n",
      "FOLD 1228\n",
      "train [25.85139274597168, 6.41607666015625]\n",
      "val [35.91612243652344, 6.6554646492004395]\n",
      "predict val...\n",
      "predict test...\n",
      "155.34134 216.5761\n",
      "106.161255 216.5761 303.63135 1.0\n",
      "FOLD 1229\n",
      "train [29.35478401184082, 6.570394992828369]\n",
      "val [28.15595054626465, 6.499162673950195]\n",
      "predict val...\n",
      "predict test...\n",
      "124.48346 239.27333\n",
      "163.1001 239.27333 313.20508 1.0\n",
      "FOLD 1230\n",
      "train [28.27605628967285, 6.534918308258057]\n",
      "val [33.54454040527344, 6.68149471282959]\n",
      "predict val...\n",
      "predict test...\n",
      "146.30473 235.99245\n",
      "161.63293 235.99245 325.04053 1.0\n",
      "FOLD 1231\n",
      "train [26.89670753479004, 6.49383544921875]\n",
      "val [32.616031646728516, 6.7595062255859375]\n",
      "predict val...\n",
      "predict test...\n",
      "140.3349 242.48856\n",
      "151.31299 242.48856 317.11572 1.0\n",
      "FOLD 1232\n",
      "train [28.685279846191406, 6.543392181396484]\n",
      "val [30.126976013183594, 6.5939621925354]\n",
      "predict val...\n",
      "predict test...\n",
      "126.25488 244.49329\n",
      "142.06421 244.49329 401.167 1.0\n",
      "FOLD 1233\n",
      "train [25.247549057006836, 6.389354228973389]\n",
      "val [38.17552947998047, 6.688782691955566]\n",
      "predict val...\n",
      "predict test...\n",
      "164.55229 216.31627\n",
      "72.14014 216.31627 312.52588 1.0\n",
      "FOLD 1234\n",
      "train [29.859846115112305, 6.592103481292725]\n",
      "val [28.170726776123047, 6.473600387573242]\n",
      "predict val...\n",
      "predict test...\n",
      "121.74537 231.99074\n",
      "119.30939 231.99074 333.41016 1.0\n",
      "FOLD 1235\n",
      "train [27.546384811401367, 6.513144493103027]\n",
      "val [33.54471969604492, 6.72627592086792]\n",
      "predict val...\n",
      "predict test...\n",
      "146.56738 229.22162\n",
      "153.33643 229.22162 300.29175 1.0\n",
      "FOLD 1236\n",
      "train [27.27971649169922, 6.500847816467285]\n",
      "val [30.26096534729004, 6.532935619354248]\n",
      "predict val...\n",
      "predict test...\n",
      "130.84854 239.24326\n",
      "53.11792 239.24326 389.71045 1.0\n",
      "FOLD 1237\n",
      "train [28.871627807617188, 6.560610771179199]\n",
      "val [30.043258666992188, 6.63197135925293]\n",
      "predict val...\n",
      "predict test...\n",
      "126.85734 251.58841\n",
      "156.92236 251.58841 399.58398 1.0\n",
      "FOLD 1238\n",
      "train [26.973722457885742, 6.475041389465332]\n",
      "val [36.96462631225586, 6.6792144775390625]\n",
      "predict val...\n",
      "predict test...\n",
      "161.1749 231.9409\n",
      "143.47485 231.9409 290.20288 1.0\n",
      "FOLD 1239\n",
      "train [28.42685890197754, 6.537182807922363]\n",
      "val [27.8049259185791, 6.444123268127441]\n",
      "predict val...\n",
      "predict test...\n",
      "120.40271 233.62733\n",
      "90.29028 233.62733 310.48462 1.0\n",
      "FOLD 1240\n",
      "train [28.04949951171875, 6.526528835296631]\n",
      "val [33.9875373840332, 6.7027974128723145]\n",
      "predict val...\n",
      "predict test...\n",
      "149.35384 231.46841\n",
      "161.8617 231.46841 318.5979 1.0\n",
      "FOLD 1241\n",
      "train [28.108016967773438, 6.512648105621338]\n",
      "val [31.970470428466797, 6.741950035095215]\n",
      "predict val...\n",
      "predict test...\n",
      "137.95456 234.47298\n",
      "127.8324 234.47298 346.41357 1.0\n",
      "FOLD 1242\n",
      "train [28.117969512939453, 6.527159214019775]\n",
      "val [30.24497413635254, 6.577261924743652]\n",
      "predict val...\n",
      "predict test...\n",
      "127.58436 239.24722\n",
      "158.45288 239.24722 358.56738 1.0\n",
      "FOLD 1243\n",
      "train [26.87370491027832, 6.4642744064331055]\n",
      "val [37.58390808105469, 6.690121650695801]\n",
      "predict val...\n",
      "predict test...\n",
      "163.42497 228.94656\n",
      "94.16455 228.94656 340.66235 1.0\n",
      "FOLD 1244\n",
      "train [28.46442413330078, 6.540607452392578]\n",
      "val [28.505863189697266, 6.480306625366211]\n",
      "predict val...\n",
      "predict test...\n",
      "125.03802 231.73605\n",
      "91.75244 231.73605 309.90845 1.0\n",
      "FOLD 1245\n",
      "train [28.150928497314453, 6.525116920471191]\n",
      "val [32.52840042114258, 6.6685991287231445]\n",
      "predict val...\n",
      "predict test...\n",
      "142.82709 240.83\n",
      "181.93262 240.83 315.40576 1.0\n",
      "FOLD 1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [27.710803985595703, 6.5083417892456055]\n",
      "val [30.21788787841797, 6.619007110595703]\n",
      "predict val...\n",
      "predict test...\n",
      "130.41753 239.56981\n",
      "163.71387 239.56981 309.292 1.0\n",
      "FOLD 1247\n",
      "train [27.81486701965332, 6.51708459854126]\n",
      "val [30.250957489013672, 6.606531143188477]\n",
      "predict val...\n",
      "predict test...\n",
      "127.83599 236.22557\n",
      "124.34839 236.22557 328.51025 1.0\n",
      "FOLD 1248\n",
      "train [26.640666961669922, 6.452287197113037]\n",
      "val [36.844791412353516, 6.694671154022217]\n",
      "predict val...\n",
      "predict test...\n",
      "158.96532 222.52203\n",
      "100.20154 222.52203 315.15063 1.0\n",
      "FOLD 1249\n",
      "train [28.87469482421875, 6.565410614013672]\n",
      "val [28.87143325805664, 6.519400596618652]\n",
      "predict val...\n",
      "predict test...\n",
      "127.2826 239.0362\n",
      "167.10431 239.0362 287.51807 1.0\n",
      "FOLD 1250\n",
      "train [27.25035285949707, 6.478281497955322]\n",
      "val [33.55289077758789, 6.7860307693481445]\n",
      "predict val...\n",
      "predict test...\n",
      "146.48393 228.53151\n",
      "64.77344 228.53151 368.0835 1.0\n",
      "FOLD 1251\n",
      "train [33.41282272338867, 6.5526556968688965]\n",
      "val [36.833839416503906, 6.744132995605469]\n",
      "predict val...\n",
      "predict test...\n",
      "137.7309 243.63548\n",
      "122.20862 243.63548 421.81592 1.0\n",
      "FOLD 1252\n",
      "train [33.78550338745117, 6.564436435699463]\n",
      "val [34.54948425292969, 6.595273494720459]\n",
      "predict val...\n",
      "predict test...\n",
      "123.28457 248.95392\n",
      "131.67456 248.95392 424.94336 1.0\n",
      "FOLD 1253\n",
      "train [32.06631851196289, 6.499580383300781]\n",
      "val [41.558135986328125, 6.677152156829834]\n",
      "predict val...\n",
      "predict test...\n",
      "155.87144 232.34793\n",
      "118.045654 232.34793 465.34912 1.0\n",
      "FOLD 1254\n",
      "train [34.7469482421875, 6.59487247467041]\n",
      "val [33.263587951660156, 6.492390155792236]\n",
      "predict val...\n",
      "predict test...\n",
      "125.53537 222.84578\n",
      "90.40253 222.84578 368.70557 1.0\n",
      "FOLD 1255\n",
      "train [33.36709976196289, 6.544867515563965]\n",
      "val [37.24265670776367, 6.639810562133789]\n",
      "predict val...\n",
      "predict test...\n",
      "140.60352 228.59756\n",
      "111.66168 228.59756 377.1294 1.0\n",
      "FOLD 1256\n",
      "train [33.09678649902344, 6.553544044494629]\n",
      "val [37.35921096801758, 6.7711687088012695]\n",
      "predict val...\n",
      "predict test...\n",
      "139.88449 255.33948\n",
      "135.21716 255.33948 420.29834 1.0\n",
      "FOLD 1257\n",
      "train [33.53553009033203, 6.55838680267334]\n",
      "val [35.77469253540039, 6.640746593475342]\n",
      "predict val...\n",
      "predict test...\n",
      "129.40182 247.41379\n",
      "142.96765 247.41379 408.11865 1.0\n",
      "FOLD 1258\n",
      "train [32.15550231933594, 6.500546455383301]\n",
      "val [42.47214889526367, 6.685877799987793]\n",
      "predict val...\n",
      "predict test...\n",
      "159.17139 229.61238\n",
      "110.29443 229.61238 500.45508 1.0\n",
      "FOLD 1259\n",
      "train [34.08124923706055, 6.591253757476807]\n",
      "val [32.821922302246094, 6.498528480529785]\n",
      "predict val...\n",
      "predict test...\n",
      "123.89874 227.37988\n",
      "84.98193 227.37988 379.81396 1.0\n",
      "FOLD 1260\n",
      "train [33.06829071044922, 6.537806034088135]\n",
      "val [37.75846481323242, 6.660122871398926]\n",
      "predict val...\n",
      "predict test...\n",
      "142.10864 228.12164\n",
      "161.38171 228.12164 334.07227 1.0\n",
      "FOLD 1261\n",
      "train [32.02886962890625, 6.538548469543457]\n",
      "val [37.44022750854492, 6.753622531890869]\n",
      "predict val...\n",
      "predict test...\n",
      "140.58765 259.3607\n",
      "162.65991 259.3607 326.46875 1.0\n",
      "FOLD 1262\n",
      "train [33.21238327026367, 6.5537896156311035]\n",
      "val [34.29491424560547, 6.617184638977051]\n",
      "predict val...\n",
      "predict test...\n",
      "124.802574 251.7587\n",
      "149.2373 251.7587 415.54248 1.0\n",
      "FOLD 1263\n",
      "train [30.908266067504883, 6.472230434417725]\n",
      "val [42.2464485168457, 6.692508697509766]\n",
      "predict val...\n",
      "predict test...\n",
      "157.57066 228.03229\n",
      "133.81128 228.03229 415.56006 1.0\n",
      "FOLD 1264\n",
      "train [33.842655181884766, 6.578609466552734]\n",
      "val [33.118019104003906, 6.49361515045166]\n",
      "predict val...\n",
      "predict test...\n",
      "124.75491 225.33034\n",
      "93.40314 225.33034 365.729 1.0\n",
      "FOLD 1265\n",
      "train [31.539342880249023, 6.5170440673828125]\n",
      "val [37.969303131103516, 6.696046352386475]\n",
      "predict val...\n",
      "predict test...\n",
      "144.29509 235.10138\n",
      "167.28406 235.10138 303.9851 1.0\n",
      "FOLD 1266\n",
      "train [32.1544189453125, 6.534449577331543]\n",
      "val [35.59303283691406, 6.75225830078125]\n",
      "predict val...\n",
      "predict test...\n",
      "132.69872 258.50153\n",
      "140.48389 258.50153 347.22314 1.0\n",
      "FOLD 1267\n",
      "train [33.64682388305664, 6.569732666015625]\n",
      "val [34.040069580078125, 6.592342853546143]\n",
      "predict val...\n",
      "predict test...\n",
      "122.26944 255.75992\n",
      "155.70886 255.75992 418.1167 1.0\n",
      "FOLD 1268\n",
      "train [31.80473518371582, 6.510339260101318]\n",
      "val [43.6398811340332, 6.6941609382629395]\n",
      "predict val...\n",
      "predict test...\n",
      "163.71265 241.03873\n",
      "152.67236 241.03873 370.3955 1.0\n",
      "FOLD 1269\n",
      "train [34.421119689941406, 6.5897698402404785]\n",
      "val [32.75862121582031, 6.486575126647949]\n",
      "predict val...\n",
      "predict test...\n",
      "123.72463 232.1072\n",
      "112.2879 232.1072 350.36572 1.0\n",
      "FOLD 1270\n",
      "train [31.613510131835938, 6.504091739654541]\n",
      "val [39.67738342285156, 6.724769592285156]\n",
      "predict val...\n",
      "predict test...\n",
      "150.09158 227.95348\n",
      "147.43542 227.95348 290.33618 1.0\n",
      "FOLD 1271\n",
      "train [32.786319732666016, 6.534911155700684]\n",
      "val [37.08998489379883, 6.785358428955078]\n",
      "predict val...\n",
      "predict test...\n",
      "138.62547 243.51868\n",
      "158.17676 243.51868 324.3711 1.0\n",
      "FOLD 1272\n",
      "train [32.75058364868164, 6.53701114654541]\n",
      "val [35.43377685546875, 6.640436172485352]\n",
      "predict val...\n",
      "predict test...\n",
      "129.96979 243.15222\n",
      "153.25989 243.15222 385.312 1.0\n",
      "FOLD 1273\n",
      "train [30.769906997680664, 6.462243556976318]\n",
      "val [42.32136917114258, 6.667318344116211]\n",
      "predict val...\n",
      "predict test...\n",
      "156.64217 226.50449\n",
      "146.11133 226.50449 292.2876 1.0\n",
      "FOLD 1274\n",
      "train [33.71356201171875, 6.566168308258057]\n",
      "val [32.68471908569336, 6.476258277893066]\n",
      "predict val...\n",
      "predict test...\n",
      "124.1689 229.12825\n",
      "131.88641 229.12825 312.05713 1.0\n",
      "FOLD 1275\n",
      "train [31.267457962036133, 6.491900444030762]\n",
      "val [39.846683502197266, 6.735357284545898]\n",
      "predict val...\n",
      "predict test...\n",
      "148.12325 224.86693\n",
      "120.04834 224.86693 306.74487 1.0\n",
      "FOLD 1276\n",
      "train [31.522537231445312, 6.491063594818115]\n",
      "val [35.78153991699219, 6.673426628112793]\n",
      "predict val...\n",
      "predict test...\n",
      "132.58734 237.01567\n",
      "120.43384 237.01567 309.9463 1.0\n",
      "FOLD 1277\n",
      "train [33.42110061645508, 6.568961143493652]\n",
      "val [34.14606475830078, 6.606766223907471]\n",
      "predict val...\n",
      "predict test...\n",
      "124.39406 255.16772\n",
      "168.71582 255.16772 378.13135 1.0\n",
      "FOLD 1278\n",
      "train [30.056875228881836, 6.436779022216797]\n",
      "val [44.58505630493164, 6.6866068840026855]\n",
      "predict val...\n",
      "predict test...\n",
      "165.51222 221.65752\n",
      "98.791504 221.65752 290.81567 1.0\n",
      "FOLD 1279\n",
      "train [33.22111511230469, 6.558228492736816]\n",
      "val [33.08935546875, 6.5038228034973145]\n",
      "predict val...\n",
      "predict test...\n",
      "127.48847 235.82817\n",
      "159.23456 235.82817 284.35205 1.0\n",
      "FOLD 1280\n",
      "train [31.83808135986328, 6.494348049163818]\n",
      "val [36.94432830810547, 6.651432514190674]\n",
      "predict val...\n",
      "predict test...\n",
      "136.87029 221.84352\n",
      "42.674316 221.84352 315.45605 1.0\n",
      "FOLD 1281\n",
      "train [32.97573471069336, 6.546862602233887]\n",
      "val [37.10373306274414, 6.760882377624512]\n",
      "predict val...\n",
      "predict test...\n",
      "139.19742 251.46188\n",
      "167.21814 251.46188 326.8208 1.0\n",
      "FOLD 1282\n",
      "train [32.144081115722656, 6.519474029541016]\n",
      "val [37.23401641845703, 6.719367980957031]\n",
      "predict val...\n",
      "predict test...\n",
      "136.18718 240.63518\n",
      "149.3274 240.63518 364.76514 1.0\n",
      "FOLD 1283\n",
      "train [30.869712829589844, 6.464870452880859]\n",
      "val [43.00178146362305, 6.669764518737793]\n",
      "predict val...\n",
      "predict test...\n",
      "160.60153 232.82207\n",
      "126.00122 232.82207 318.40137 1.0\n",
      "FOLD 1284\n",
      "train [32.228729248046875, 6.526824951171875]\n",
      "val [32.79307174682617, 6.481148719787598]\n",
      "predict val...\n",
      "predict test...\n",
      "125.583725 230.52\n",
      "90.93408 230.52 292.14453 1.0\n",
      "FOLD 1285\n",
      "train [31.37234115600586, 6.49315881729126]\n",
      "val [38.39455032348633, 6.737796306610107]\n",
      "predict val...\n",
      "predict test...\n",
      "144.38734 229.94635\n",
      "79.33765 229.94635 321.58447 1.0\n",
      "FOLD 1286\n",
      "train [32.668094635009766, 6.532124996185303]\n",
      "val [37.03145980834961, 6.7686991691589355]\n",
      "predict val...\n",
      "predict test...\n",
      "138.21419 241.3375\n",
      "160.28613 241.3375 322.48926 1.0\n",
      "FOLD 1287\n",
      "train [32.86513137817383, 6.546131134033203]\n",
      "val [34.76167297363281, 6.625638008117676]\n",
      "predict val...\n",
      "predict test...\n",
      "128.33894 255.41139\n",
      "145.62842 255.41139 366.95972 1.0\n",
      "FOLD 1288\n",
      "train [30.08518409729004, 6.420113563537598]\n",
      "val [41.81269073486328, 6.687346935272217]\n",
      "predict val...\n",
      "predict test...\n",
      "155.31529 214.0005\n",
      "105.08154 214.0005 308.52808 1.0\n",
      "FOLD 1289\n",
      "train [32.84612274169922, 6.542242527008057]\n",
      "val [31.56415367126465, 6.457449436187744]\n",
      "predict val...\n",
      "predict test...\n",
      "119.8733 229.16159\n",
      "143.81232 229.16159 292.4275 1.0\n",
      "FOLD 1290\n",
      "train [32.430137634277344, 6.521868705749512]\n",
      "val [38.834102630615234, 6.694448471069336]\n",
      "predict val...\n",
      "predict test...\n",
      "146.14214 232.87611\n",
      "176.72559 232.87611 318.7671 1.0\n",
      "FOLD 1291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [32.28079605102539, 6.516172885894775]\n",
      "val [38.647422790527344, 6.817876815795898]\n",
      "predict val...\n",
      "predict test...\n",
      "144.255 240.5825\n",
      "122.949585 240.5825 345.5913 1.0\n",
      "FOLD 1292\n",
      "train [30.95816421508789, 6.484169960021973]\n",
      "val [34.82075119018555, 6.545803070068359]\n",
      "predict val...\n",
      "predict test...\n",
      "127.30665 230.23326\n",
      "162.3772 230.23326 293.73828 1.0\n",
      "FOLD 1293\n",
      "train [31.37706184387207, 6.485204219818115]\n",
      "val [41.80658721923828, 6.662371635437012]\n",
      "predict val...\n",
      "predict test...\n",
      "154.17033 236.85858\n",
      "157.18726 236.85858 308.9944 1.0\n",
      "FOLD 1294\n",
      "train [34.16815185546875, 6.581734657287598]\n",
      "val [31.80622673034668, 6.490123748779297]\n",
      "predict val...\n",
      "predict test...\n",
      "121.04912 242.65584\n",
      "157.9552 242.65584 353.8108 1.0\n",
      "FOLD 1295\n",
      "train [31.44427490234375, 6.497544765472412]\n",
      "val [39.09304428100586, 6.697986602783203]\n",
      "predict val...\n",
      "predict test...\n",
      "146.12566 227.08014\n",
      "142.14941 227.08014 334.34106 1.0\n",
      "FOLD 1296\n",
      "train [32.73246383666992, 6.529661655426025]\n",
      "val [37.277427673339844, 6.790865898132324]\n",
      "predict val...\n",
      "predict test...\n",
      "138.82054 239.03868\n",
      "153.86108 239.03868 313.27734 1.0\n",
      "FOLD 1297\n",
      "train [33.37287521362305, 6.561612129211426]\n",
      "val [34.65266418457031, 6.610110759735107]\n",
      "predict val...\n",
      "predict test...\n",
      "126.35758 250.1513\n",
      "161.45056 250.1513 369.33594 1.0\n",
      "FOLD 1298\n",
      "train [30.629058837890625, 6.450243949890137]\n",
      "val [42.7574577331543, 6.684662818908691]\n",
      "predict val...\n",
      "predict test...\n",
      "157.5268 221.44989\n",
      "119.159424 221.44989 290.79736 1.0\n",
      "FOLD 1299\n",
      "train [34.057918548583984, 6.576446533203125]\n",
      "val [32.5599250793457, 6.485320568084717]\n",
      "predict val...\n",
      "predict test...\n",
      "123.51883 238.10667\n",
      "165.65442 238.10667 311.35742 1.0\n",
      "FOLD 1300\n",
      "train [32.49089431762695, 6.532092094421387]\n",
      "val [39.60138702392578, 6.702755928039551]\n",
      "predict val...\n",
      "predict test...\n",
      "148.4558 232.0992\n",
      "157.87769 232.0992 326.3672 1.0\n",
      "FOLD 1301\n",
      "train [38.07403564453125, 6.561953544616699]\n",
      "val [42.04714584350586, 6.744856357574463]\n",
      "predict val...\n",
      "predict test...\n",
      "138.60518 247.12006\n",
      "120.19763 247.12006 427.15918 1.0\n",
      "FOLD 1302\n",
      "train [38.574745178222656, 6.5750250816345215]\n",
      "val [38.847129821777344, 6.585490703582764]\n",
      "predict val...\n",
      "predict test...\n",
      "122.33451 255.367\n",
      "134.49866 255.367 436.75 1.0\n",
      "FOLD 1303\n",
      "train [36.18607711791992, 6.496298313140869]\n",
      "val [46.89653015136719, 6.679453372955322]\n",
      "predict val...\n",
      "predict test...\n",
      "154.00314 231.31026\n",
      "114.09119 231.31026 475.0537 1.0\n",
      "FOLD 1304\n",
      "train [39.47537612915039, 6.605668067932129]\n",
      "val [38.26518249511719, 6.5156145095825195]\n",
      "predict val...\n",
      "predict test...\n",
      "127.05698 231.31676\n",
      "89.06262 231.31676 386.86426 1.0\n",
      "FOLD 1305\n",
      "train [37.70792770385742, 6.544093132019043]\n",
      "val [43.2011833190918, 6.659706115722656]\n",
      "predict val...\n",
      "predict test...\n",
      "143.61278 230.35777\n",
      "106.32703 230.35777 391.8623 1.0\n",
      "FOLD 1306\n",
      "train [37.798805236816406, 6.558382987976074]\n",
      "val [42.09613800048828, 6.751955032348633]\n",
      "predict val...\n",
      "predict test...\n",
      "138.44284 252.51898\n",
      "126.531494 252.51898 428.3623 1.0\n",
      "FOLD 1307\n",
      "train [37.64724349975586, 6.540269374847412]\n",
      "val [41.505027770996094, 6.6228251457214355]\n",
      "predict val...\n",
      "predict test...\n",
      "131.77138 240.32538\n",
      "128.77502 240.32538 410.11865 1.0\n",
      "FOLD 1308\n",
      "train [36.281734466552734, 6.4913811683654785]\n",
      "val [49.01987075805664, 6.676613807678223]\n",
      "predict val...\n",
      "predict test...\n",
      "160.65031 222.52713\n",
      "120.21448 222.52713 447.87207 1.0\n",
      "FOLD 1309\n",
      "train [38.80724334716797, 6.585894584655762]\n",
      "val [37.86544418334961, 6.478151321411133]\n",
      "predict val...\n",
      "predict test...\n",
      "124.9064 226.23346\n",
      "93.54602 226.23346 375.2666 1.0\n",
      "FOLD 1310\n",
      "train [37.69022750854492, 6.545210361480713]\n",
      "val [42.563804626464844, 6.652054309844971]\n",
      "predict val...\n",
      "predict test...\n",
      "141.6127 234.2521\n",
      "116.42102 234.2521 383.5747 1.0\n",
      "FOLD 1311\n",
      "train [36.63157272338867, 6.544321537017822]\n",
      "val [42.147762298583984, 6.719419479370117]\n",
      "predict val...\n",
      "predict test...\n",
      "139.5638 259.86685\n",
      "177.36584 259.86685 345.02344 1.0\n",
      "FOLD 1312\n",
      "train [38.069271087646484, 6.571228981018066]\n",
      "val [38.599517822265625, 6.603864669799805]\n",
      "predict val...\n",
      "predict test...\n",
      "123.04889 258.50507\n",
      "156.60303 258.50507 424.2578 1.0\n",
      "FOLD 1313\n",
      "train [36.135215759277344, 6.510842800140381]\n",
      "val [48.141136169433594, 6.691681385040283]\n",
      "predict val...\n",
      "predict test...\n",
      "156.92302 238.64546\n",
      "142.94763 238.64546 426.38574 1.0\n",
      "FOLD 1314\n",
      "train [39.047203063964844, 6.602563381195068]\n",
      "val [38.52058029174805, 6.507938385009766]\n",
      "predict val...\n",
      "predict test...\n",
      "128.6757 238.43918\n",
      "118.40405 238.43918 367.7002 1.0\n",
      "FOLD 1315\n",
      "train [37.39202880859375, 6.548852443695068]\n",
      "val [44.82196807861328, 6.684948921203613]\n",
      "predict val...\n",
      "predict test...\n",
      "148.74164 241.14656\n",
      "148.85828 241.14656 351.0835 1.0\n",
      "FOLD 1316\n",
      "train [36.92061996459961, 6.525791168212891]\n",
      "val [41.381404876708984, 6.709585189819336]\n",
      "predict val...\n",
      "predict test...\n",
      "136.33354 243.26662\n",
      "146.68933 243.26662 347.2085 1.0\n",
      "FOLD 1317\n",
      "train [37.193443298339844, 6.538462162017822]\n",
      "val [39.89852523803711, 6.587345600128174]\n",
      "predict val...\n",
      "predict test...\n",
      "127.13279 242.2501\n",
      "144.40222 242.2501 396.96973 1.0\n",
      "FOLD 1318\n",
      "train [36.32975387573242, 6.507596492767334]\n",
      "val [48.69413757324219, 6.682425022125244]\n",
      "predict val...\n",
      "predict test...\n",
      "160.1428 235.14821\n",
      "145.4342 235.14821 389.83447 1.0\n",
      "FOLD 1319\n",
      "train [39.57998275756836, 6.606646537780762]\n",
      "val [37.54324722290039, 6.500626564025879]\n",
      "predict val...\n",
      "predict test...\n",
      "124.82344 233.43918\n",
      "100.89722 233.43918 375.5371 1.0\n",
      "FOLD 1320\n",
      "train [36.142696380615234, 6.5104079246521]\n",
      "val [43.88290023803711, 6.7551422119140625]\n",
      "predict val...\n",
      "predict test...\n",
      "144.03156 234.64378\n",
      "-34.01294 234.64378 435.28955 0.9837133550488599\n",
      "FOLD 1321\n",
      "train [37.174678802490234, 6.543430328369141]\n",
      "val [42.007686614990234, 6.77079439163208]\n",
      "predict val...\n",
      "predict test...\n",
      "138.2801 252.18187\n",
      "174.27734 252.18187 333.9131 1.0\n",
      "FOLD 1322\n",
      "train [35.76388168334961, 6.498610496520996]\n",
      "val [41.82011795043945, 6.669262886047363]\n",
      "predict val...\n",
      "predict test...\n",
      "134.35867 227.45004\n",
      "155.18762 227.45004 311.55273 1.0\n",
      "FOLD 1323\n",
      "train [34.82181930541992, 6.4733991622924805]\n",
      "val [50.22285079956055, 6.7375006675720215]\n",
      "predict val...\n",
      "predict test...\n",
      "164.27437 228.44211\n",
      "110.32129 228.44211 339.15088 1.0\n",
      "FOLD 1324\n",
      "train [38.74620056152344, 6.58847713470459]\n",
      "val [36.7923698425293, 6.493083477020264]\n",
      "predict val...\n",
      "predict test...\n",
      "123.87206 241.9432\n",
      "146.24872 241.9432 359.00537 1.0\n",
      "FOLD 1325\n",
      "train [35.71044921875, 6.50832462310791]\n",
      "val [45.19273376464844, 6.71617317199707]\n",
      "predict val...\n",
      "predict test...\n",
      "149.27539 229.33183\n",
      "161.67993 229.33183 311.54663 1.0\n",
      "FOLD 1326\n",
      "train [35.97167205810547, 6.516139030456543]\n",
      "val [40.74677276611328, 6.888128757476807]\n",
      "predict val...\n",
      "predict test...\n",
      "132.86186 246.88182\n",
      "53.27002 246.88182 328.01343 1.0\n",
      "FOLD 1327\n",
      "train [36.185672760009766, 6.50277853012085]\n",
      "val [42.20062255859375, 6.644984245300293]\n",
      "predict val...\n",
      "predict test...\n",
      "135.8398 236.05164\n",
      "168.656 236.05164 338.41455 1.0\n",
      "FOLD 1328\n",
      "train [34.31489944458008, 6.448763847351074]\n",
      "val [49.03712844848633, 6.732174396514893]\n",
      "predict val...\n",
      "predict test...\n",
      "159.53827 219.65254\n",
      "102.06372 219.65254 303.31348 1.0\n",
      "FOLD 1329\n",
      "train [38.134666442871094, 6.562413692474365]\n",
      "val [36.48357391357422, 6.502854347229004]\n",
      "predict val...\n",
      "predict test...\n",
      "123.38378 245.13148\n",
      "129.18677 245.13148 337.79272 1.0\n",
      "FOLD 1330\n",
      "train [37.17857360839844, 6.542798042297363]\n",
      "val [43.8575553894043, 6.6752777099609375]\n",
      "predict val...\n",
      "predict test...\n",
      "144.7537 240.33667\n",
      "153.20752 240.33667 330.78467 1.0\n",
      "FOLD 1331\n",
      "train [35.39186096191406, 6.488762855529785]\n",
      "val [42.85758972167969, 6.771114826202393]\n",
      "predict val...\n",
      "predict test...\n",
      "140.21512 235.14703\n",
      "168.94348 235.14703 283.49658 1.0\n",
      "FOLD 1332\n",
      "train [35.55715560913086, 6.490046501159668]\n",
      "val [41.90982437133789, 6.7903828620910645]\n",
      "predict val...\n",
      "predict test...\n",
      "134.91379 226.63019\n",
      "142.6626 226.63019 303.53174 1.0\n",
      "FOLD 1333\n",
      "train [35.42488098144531, 6.483730316162109]\n",
      "val [49.08933639526367, 6.674689292907715]\n",
      "predict val...\n",
      "predict test...\n",
      "159.99608 235.04329\n",
      "144.60913 235.04329 306.1848 1.0\n",
      "FOLD 1334\n",
      "train [38.266265869140625, 6.580132961273193]\n",
      "val [37.8126220703125, 6.510320663452148]\n",
      "predict val...\n",
      "predict test...\n",
      "128.17825 240.37335\n",
      "152.40778 240.37335 289.86426 1.0\n",
      "FOLD 1335\n",
      "train [36.24018859863281, 6.514721870422363]\n",
      "val [48.33640670776367, 6.738320350646973]\n",
      "predict val...\n",
      "predict test...\n",
      "158.10092 232.46536\n",
      "187.4292 232.46536 330.36768 1.0\n",
      "FOLD 1336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.8911018371582, 6.5301947593688965]\n",
      "val [42.661376953125, 6.7906036376953125]\n",
      "predict val...\n",
      "predict test...\n",
      "140.2938 246.5514\n",
      "130.38354 246.5514 397.1289 1.0\n",
      "FOLD 1337\n",
      "train [37.64990234375, 6.556615352630615]\n",
      "val [39.248748779296875, 6.611466407775879]\n",
      "predict val...\n",
      "predict test...\n",
      "127.02437 253.50987\n",
      "172.24646 253.50987 356.49512 1.0\n",
      "FOLD 1338\n",
      "train [34.030799865722656, 6.439947605133057]\n",
      "val [50.286537170410156, 6.71138334274292]\n",
      "predict val...\n",
      "predict test...\n",
      "163.51291 220.13564\n",
      "129.30151 220.13564 306.489 1.0\n",
      "FOLD 1339\n",
      "train [36.00171661376953, 6.512310981750488]\n",
      "val [34.8880500793457, 6.407036781311035]\n",
      "predict val...\n",
      "predict test...\n",
      "116.26932 226.68175\n",
      "120.29883 226.68175 321.50208 1.0\n",
      "FOLD 1340\n",
      "train [35.24428176879883, 6.488802909851074]\n",
      "val [44.05624771118164, 6.77531623840332]\n",
      "predict val...\n",
      "predict test...\n",
      "144.72847 229.4373\n",
      "43.856445 229.4373 322.80127 1.0\n",
      "FOLD 1341\n",
      "train [36.96245193481445, 6.534539699554443]\n",
      "val [41.85039138793945, 6.734494686126709]\n",
      "predict val...\n",
      "predict test...\n",
      "137.67514 245.9066\n",
      "167.75708 245.9066 320.0708 1.0\n",
      "FOLD 1342\n",
      "train [36.92090606689453, 6.532007694244385]\n",
      "val [39.91448974609375, 6.576248645782471]\n",
      "predict val...\n",
      "predict test...\n",
      "128.61041 236.91692\n",
      "156.63647 236.91692 350.2705 1.0\n",
      "FOLD 1343\n",
      "train [35.34025955200195, 6.481163024902344]\n",
      "val [48.54734802246094, 6.667814254760742]\n",
      "predict val...\n",
      "predict test...\n",
      "158.70392 230.44534\n",
      "137.33301 230.44534 284.16162 1.0\n",
      "FOLD 1344\n",
      "train [37.75211715698242, 6.551840305328369]\n",
      "val [35.062171936035156, 6.451375961303711]\n",
      "predict val...\n",
      "predict test...\n",
      "117.5966 233.25412\n",
      "150.86566 233.25412 301.35742 1.0\n",
      "FOLD 1345\n",
      "train [35.42311096191406, 6.499356269836426]\n",
      "val [43.56907272338867, 6.729034423828125]\n",
      "predict val...\n",
      "predict test...\n",
      "143.44681 235.88393\n",
      "82.6145 235.88393 308.0608 1.0\n",
      "FOLD 1346\n",
      "train [37.377689361572266, 6.544352054595947]\n",
      "val [42.107398986816406, 6.781172752380371]\n",
      "predict val...\n",
      "predict test...\n",
      "138.782 249.12062\n",
      "162.02844 249.12062 334.38965 1.0\n",
      "FOLD 1347\n",
      "train [37.688446044921875, 6.5463995933532715]\n",
      "val [39.45342254638672, 6.608121871948242]\n",
      "predict val...\n",
      "predict test...\n",
      "126.91944 242.31805\n",
      "167.89954 242.31805 356.18896 1.0\n",
      "FOLD 1348\n",
      "train [35.53095245361328, 6.479679107666016]\n",
      "val [48.59318542480469, 6.662387847900391]\n",
      "predict val...\n",
      "predict test...\n",
      "158.19894 232.39012\n",
      "139.07751 232.39012 317.2378 1.0\n",
      "FOLD 1349\n",
      "train [37.52703857421875, 6.555105686187744]\n",
      "val [36.876991271972656, 6.481088638305664]\n",
      "predict val...\n",
      "predict test...\n",
      "123.455215 232.53963\n",
      "155.43964 232.53963 295.99023 1.0\n",
      "FOLD 1350\n",
      "train [36.308109283447266, 6.511031150817871]\n",
      "val [44.11147689819336, 6.695163726806641]\n",
      "predict val...\n",
      "predict test...\n",
      "145.17017 231.24698\n",
      "140.71387 231.24698 329.27588 1.0\n",
      "FOLD 1351\n",
      "train [42.48955154418945, 6.561862945556641]\n",
      "val [46.536678314208984, 6.7191267013549805]\n",
      "predict val...\n",
      "predict test...\n",
      "137.38438 248.69722\n",
      "121.163086 248.69722 428.6631 1.0\n",
      "FOLD 1352\n",
      "train [42.644065856933594, 6.560038089752197]\n",
      "val [44.449153900146484, 6.6233015060424805]\n",
      "predict val...\n",
      "predict test...\n",
      "125.67243 248.90945\n",
      "132.62769 248.90945 424.03906 1.0\n",
      "FOLD 1353\n",
      "train [40.5734748840332, 6.493680000305176]\n",
      "val [53.37820053100586, 6.697036266326904]\n",
      "predict val...\n",
      "predict test...\n",
      "156.12985 224.35674\n",
      "107.56311 224.35674 485.54395 1.0\n",
      "FOLD 1354\n",
      "train [44.08766174316406, 6.606443881988525]\n",
      "val [43.68614196777344, 6.530465126037598]\n",
      "predict val...\n",
      "predict test...\n",
      "130.36615 234.97984\n",
      "95.164185 234.97984 392.28516 1.0\n",
      "FOLD 1355\n",
      "train [42.26191711425781, 6.5432915687561035]\n",
      "val [47.42105484008789, 6.640389919281006]\n",
      "predict val...\n",
      "predict test...\n",
      "140.30664 227.92503\n",
      "102.507324 227.92503 393.81006 1.0\n",
      "FOLD 1356\n",
      "train [42.55027770996094, 6.5641889572143555]\n",
      "val [47.82554244995117, 6.789427280426025]\n",
      "predict val...\n",
      "predict test...\n",
      "139.65695 252.12756\n",
      "124.3291 252.12756 429.71826 1.0\n",
      "FOLD 1357\n",
      "train [42.881317138671875, 6.567744255065918]\n",
      "val [44.24946594238281, 6.609226226806641]\n",
      "predict val...\n",
      "predict test...\n",
      "125.26595 252.15492\n",
      "140.04688 252.15492 427.1831 1.0\n",
      "FOLD 1358\n",
      "train [39.534915924072266, 6.477877140045166]\n",
      "val [56.11173629760742, 6.709980487823486]\n",
      "predict val...\n",
      "predict test...\n",
      "163.10129 223.81223\n",
      "124.97925 223.81223 374.875 1.0\n",
      "FOLD 1359\n",
      "train [43.992950439453125, 6.607578277587891]\n",
      "val [42.44294738769531, 6.516811370849609]\n",
      "predict val...\n",
      "predict test...\n",
      "126.38436 238.60374\n",
      "100.77899 238.60374 392.8335 1.0\n",
      "FOLD 1360\n",
      "train [41.244972229003906, 6.519551753997803]\n",
      "val [46.797664642333984, 6.660342216491699]\n",
      "predict val...\n",
      "predict test...\n",
      "137.89032 218.51514\n",
      "135.64624 218.51514 314.62207 1.0\n",
      "FOLD 1361\n",
      "train [42.03480911254883, 6.556321620941162]\n",
      "val [47.13407897949219, 6.746315956115723]\n",
      "predict val...\n",
      "predict test...\n",
      "138.82027 255.37721\n",
      "135.2821 255.37721 418.83496 1.0\n",
      "FOLD 1362\n",
      "train [41.682430267333984, 6.54735803604126]\n",
      "val [44.785179138183594, 6.602130889892578]\n",
      "predict val...\n",
      "predict test...\n",
      "127.48428 248.76517\n",
      "149.9668 248.76517 404.00488 1.0\n",
      "FOLD 1363\n",
      "train [38.423492431640625, 6.454463958740234]\n",
      "val [54.977333068847656, 6.682665824890137]\n",
      "predict val...\n",
      "predict test...\n",
      "160.4814 224.98552\n",
      "129.4137 224.98552 423.68848 1.0\n",
      "FOLD 1364\n",
      "train [43.829627990722656, 6.603567600250244]\n",
      "val [41.70165252685547, 6.503520965576172]\n",
      "predict val...\n",
      "predict test...\n",
      "124.61225 240.84291\n",
      "115.84296 240.84291 369.88818 1.0\n",
      "FOLD 1365\n",
      "train [41.817481994628906, 6.552520751953125]\n",
      "val [49.5085563659668, 6.671638488769531]\n",
      "predict val...\n",
      "predict test...\n",
      "145.79443 241.74016\n",
      "154.3164 241.74016 333.7351 1.0\n",
      "FOLD 1366\n",
      "train [40.837947845458984, 6.5164947509765625]\n",
      "val [46.00957489013672, 6.699368000030518]\n",
      "predict val...\n",
      "predict test...\n",
      "136.03728 237.06464\n",
      "128.93713 237.06464 363.11377 1.0\n",
      "FOLD 1367\n",
      "train [42.46875, 6.5628228187561035]\n",
      "val [43.654964447021484, 6.599373817443848]\n",
      "predict val...\n",
      "predict test...\n",
      "123.89279 252.61018\n",
      "157.1731 252.61018 413.33496 1.0\n",
      "FOLD 1368\n",
      "train [40.046932220458984, 6.4852399826049805]\n",
      "val [55.17881774902344, 6.682684898376465]\n",
      "predict val...\n",
      "predict test...\n",
      "161.38568 226.12546\n",
      "117.28784 226.12546 468.7378 1.0\n",
      "FOLD 1369\n",
      "train [43.5908317565918, 6.594143867492676]\n",
      "val [41.46512985229492, 6.494924545288086]\n",
      "predict val...\n",
      "predict test...\n",
      "124.148705 239.80855\n",
      "128.5658 239.80855 337.16992 1.0\n",
      "FOLD 1370\n",
      "train [41.462379455566406, 6.542897701263428]\n",
      "val [48.48682403564453, 6.664402484893799]\n",
      "predict val...\n",
      "predict test...\n",
      "143.97 239.56738\n",
      "164.5503 239.56738 328.8247 1.0\n",
      "FOLD 1371\n",
      "train [41.64670944213867, 6.546555995941162]\n",
      "val [47.297515869140625, 6.770183563232422]\n",
      "predict val...\n",
      "predict test...\n",
      "139.01353 252.72168\n",
      "158.86707 252.72168 360.04688 1.0\n",
      "FOLD 1372\n",
      "train [42.36603927612305, 6.560937404632568]\n",
      "val [44.3697624206543, 6.611881256103516]\n",
      "predict val...\n",
      "predict test...\n",
      "126.78294 248.5936\n",
      "164.62463 248.5936 369.26758 1.0\n",
      "FOLD 1373\n",
      "train [38.73762130737305, 6.4682416915893555]\n",
      "val [55.060707092285156, 6.723842144012451]\n",
      "predict val...\n",
      "predict test...\n",
      "159.68654 228.92546\n",
      "87.42627 228.92546 319.15967 1.0\n",
      "FOLD 1374\n",
      "train [41.398372650146484, 6.544541358947754]\n",
      "val [40.17245101928711, 6.463183403015137]\n",
      "predict val...\n",
      "predict test...\n",
      "120.6605 234.71422\n",
      "146.646 234.71422 293.74658 1.0\n",
      "FOLD 1375\n",
      "train [41.543548583984375, 6.540196418762207]\n",
      "val [49.1666145324707, 6.681901931762695]\n",
      "predict val...\n",
      "predict test...\n",
      "146.21094 239.65195\n",
      "160.7898 239.65195 332.9651 1.0\n",
      "FOLD 1376\n",
      "train [41.11184310913086, 6.526541233062744]\n",
      "val [47.26768493652344, 6.765812397003174]\n",
      "predict val...\n",
      "predict test...\n",
      "139.08621 243.72687\n",
      "132.38403 243.72687 382.37744 1.0\n",
      "FOLD 1377\n",
      "train [42.111717224121094, 6.562821865081787]\n",
      "val [43.565975189208984, 6.605945110321045]\n",
      "predict val...\n",
      "predict test...\n",
      "125.93005 254.10347\n",
      "175.28845 254.10347 372.17676 1.0\n",
      "FOLD 1378\n",
      "train [39.40390396118164, 6.478170871734619]\n",
      "val [54.497188568115234, 6.68531608581543]\n",
      "predict val...\n",
      "predict test...\n",
      "157.96452 228.27359\n",
      "156.00195 228.27359 291.98975 1.0\n",
      "FOLD 1379\n",
      "train [42.92031478881836, 6.580262660980225]\n",
      "val [42.34486389160156, 6.504111289978027]\n",
      "predict val...\n",
      "predict test...\n",
      "128.32066 235.37367\n",
      "147.81415 235.37367 320.312 1.0\n",
      "FOLD 1380\n",
      "train [41.346500396728516, 6.536498069763184]\n",
      "val [49.661190032958984, 6.689737796783447]\n",
      "predict val...\n",
      "predict test...\n",
      "145.99214 235.40315\n",
      "149.65906 235.40315 329.01074 1.0\n",
      "FOLD 1381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [39.80879211425781, 6.498028755187988]\n",
      "val [48.679325103759766, 6.808487892150879]\n",
      "predict val...\n",
      "predict test...\n",
      "142.96631 241.76628\n",
      "146.50732 241.76628 322.1587 1.0\n",
      "FOLD 1382\n",
      "train [41.223751068115234, 6.539096832275391]\n",
      "val [57.99578857421875, 7.113092422485352]\n",
      "predict val...\n",
      "predict test...\n",
      "161.59085 244.66124\n",
      "156.745 244.66124 393.19922 1.0\n",
      "FOLD 1383\n",
      "train [38.21390151977539, 6.459805965423584]\n",
      "val [56.939064025878906, 6.752270221710205]\n",
      "predict val...\n",
      "predict test...\n",
      "165.35666 228.528\n",
      "89.85425 228.528 300.8335 1.0\n",
      "FOLD 1384\n",
      "train [42.177955627441406, 6.5514817237854]\n",
      "val [42.338748931884766, 6.457853317260742]\n",
      "predict val...\n",
      "predict test...\n",
      "125.29032 229.62938\n",
      "116.270325 229.62938 313.07007 1.0\n",
      "FOLD 1385\n",
      "train [40.5580940246582, 6.511103630065918]\n",
      "val [48.3012580871582, 6.698324203491211]\n",
      "predict val...\n",
      "predict test...\n",
      "144.11562 242.44136\n",
      "132.30786 242.44136 390.12305 1.0\n",
      "FOLD 1386\n",
      "train [40.31599044799805, 6.510875701904297]\n",
      "val [44.918521881103516, 6.608814239501953]\n",
      "predict val...\n",
      "predict test...\n",
      "132.9404 244.204\n",
      "140.74683 244.204 334.52832 1.0\n",
      "FOLD 1387\n",
      "train [42.5276985168457, 6.574145317077637]\n",
      "val [43.48251724243164, 6.605995178222656]\n",
      "predict val...\n",
      "predict test...\n",
      "124.67391 259.81927\n",
      "176.1106 259.81927 384.66064 1.0\n",
      "FOLD 1388\n",
      "train [37.466800689697266, 6.424612998962402]\n",
      "val [57.14325714111328, 6.679525375366211]\n",
      "predict val...\n",
      "predict test...\n",
      "163.93102 219.26749\n",
      "108.84497 219.26749 290.96948 1.0\n",
      "FOLD 1389\n",
      "train [43.13349151611328, 6.575482368469238]\n",
      "val [41.402198791503906, 6.500755310058594]\n",
      "predict val...\n",
      "predict test...\n",
      "124.55686 240.96672\n",
      "127.82196 240.96672 347.99487 1.0\n",
      "FOLD 1390\n",
      "train [41.16434097290039, 6.528977870941162]\n",
      "val [48.76099395751953, 6.681500434875488]\n",
      "predict val...\n",
      "predict test...\n",
      "144.3292 239.34276\n",
      "175.43945 239.34276 319.97388 1.0\n",
      "FOLD 1391\n",
      "train [40.9013557434082, 6.516265869140625]\n",
      "val [47.7313346862793, 6.755499839782715]\n",
      "predict val...\n",
      "predict test...\n",
      "141.03879 240.99191\n",
      "152.25122 240.99191 325.43018 1.0\n",
      "FOLD 1392\n",
      "train [41.72161102294922, 6.5479302406311035]\n",
      "val [45.419891357421875, 6.601624488830566]\n",
      "predict val...\n",
      "predict test...\n",
      "130.21536 246.59303\n",
      "159.95642 246.59303 375.66943 1.0\n",
      "FOLD 1393\n",
      "train [39.402496337890625, 6.479471683502197]\n",
      "val [53.757965087890625, 6.658837795257568]\n",
      "predict val...\n",
      "predict test...\n",
      "156.49745 232.52016\n",
      "141.91199 232.52016 287.86914 1.0\n",
      "FOLD 1394\n",
      "train [41.71562576293945, 6.550450325012207]\n",
      "val [41.57589340209961, 6.518767356872559]\n",
      "predict val...\n",
      "predict test...\n",
      "126.08718 238.99239\n",
      "161.13464 238.99239 300.3706 1.0\n",
      "FOLD 1395\n",
      "train [40.38246536254883, 6.512640476226807]\n",
      "val [49.688846588134766, 6.696345329284668]\n",
      "predict val...\n",
      "predict test...\n",
      "145.9351 234.55838\n",
      "144.77612 234.55838 304.73975 1.0\n",
      "FOLD 1396\n",
      "train [40.15609359741211, 6.5011701583862305]\n",
      "val [45.42292785644531, 6.570686340332031]\n",
      "predict val...\n",
      "predict test...\n",
      "132.34492 228.68411\n",
      "16.019043 228.68411 341.437 1.0\n",
      "FOLD 1397\n",
      "train [41.32090377807617, 6.531196594238281]\n",
      "val [44.79609680175781, 6.569203853607178]\n",
      "predict val...\n",
      "predict test...\n",
      "130.5015 243.06775\n",
      "139.2528 243.06775 343.54688 1.0\n",
      "FOLD 1398\n",
      "train [37.038978576660156, 6.4062676429748535]\n",
      "val [54.01532745361328, 6.646106243133545]\n",
      "predict val...\n",
      "predict test...\n",
      "157.72351 220.65263\n",
      "76.061646 220.65263 334.92236 1.0\n",
      "FOLD 1399\n",
      "train [42.295799255371094, 6.555323600769043]\n",
      "val [41.19988250732422, 6.456254005432129]\n",
      "predict val...\n",
      "predict test...\n",
      "123.25065 231.97926\n",
      "138.7124 231.97926 306.97485 1.0\n",
      "FOLD 1400\n",
      "train [40.57156753540039, 6.5196852684021]\n",
      "val [51.04539108276367, 6.751828193664551]\n",
      "predict val...\n",
      "predict test...\n",
      "150.66556 235.53888\n",
      "133.45264 235.53888 314.83032 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1401\n",
      "train [28.877696990966797, 6.5546464920043945]\n",
      "val [31.788314819335938, 6.724989414215088]\n",
      "predict val...\n",
      "predict test...\n",
      "138.02422 245.56468\n",
      "119.92297 245.56468 425.208 1.0\n",
      "FOLD 1402\n",
      "train [29.222427368164062, 6.559187412261963]\n",
      "val [30.183292388916016, 6.602057456970215]\n",
      "predict val...\n",
      "predict test...\n",
      "125.025604 245.3383\n",
      "129.07178 245.3383 420.12842 1.0\n",
      "FOLD 1403\n",
      "train [27.64826202392578, 6.487248420715332]\n",
      "val [36.13697814941406, 6.6899237632751465]\n",
      "predict val...\n",
      "predict test...\n",
      "156.24965 223.66173\n",
      "111.05969 223.66173 466.22314 1.0\n",
      "FOLD 1404\n",
      "train [30.116329193115234, 6.607896327972412]\n",
      "val [28.51020050048828, 6.5041961669921875]\n",
      "predict val...\n",
      "predict test...\n",
      "124.371284 233.93338\n",
      "97.83118 233.93338 381.50684 1.0\n",
      "FOLD 1405\n",
      "train [28.70399284362793, 6.5319976806640625]\n",
      "val [32.6281623840332, 6.648982048034668]\n",
      "predict val...\n",
      "predict test...\n",
      "142.54466 224.05031\n",
      "118.35242 224.05031 355.32275 1.0\n",
      "FOLD 1406\n",
      "train [28.545717239379883, 6.545891761779785]\n",
      "val [32.61197280883789, 6.7817063331604]\n",
      "predict val...\n",
      "predict test...\n",
      "142.0838 254.79408\n",
      "143.90784 254.79408 383.7339 1.0\n",
      "FOLD 1407\n",
      "train [29.007251739501953, 6.552837371826172]\n",
      "val [30.90152359008789, 6.648001670837402]\n",
      "predict val...\n",
      "predict test...\n",
      "131.54459 245.58575\n",
      "147.88843 245.58575 410.0205 1.0\n",
      "FOLD 1408\n",
      "train [27.719945907592773, 6.490914821624756]\n",
      "val [36.334510803222656, 6.666312217712402]\n",
      "predict val...\n",
      "predict test...\n",
      "157.62062 224.8572\n",
      "136.03137 224.8572 382.3286 1.0\n",
      "FOLD 1409\n",
      "train [30.11406707763672, 6.614638328552246]\n",
      "val [28.392454147338867, 6.50858211517334]\n",
      "predict val...\n",
      "predict test...\n",
      "123.52138 239.5654\n",
      "96.64807 239.5654 395.15576 1.0\n",
      "FOLD 1410\n",
      "train [28.834823608398438, 6.540518283843994]\n",
      "val [32.7540397644043, 6.654296875]\n",
      "predict val...\n",
      "predict test...\n",
      "142.78479 226.54048\n",
      "127.03784 226.54048 335.38574 1.0\n",
      "FOLD 1411\n",
      "train [28.52883529663086, 6.550747871398926]\n",
      "val [31.984813690185547, 6.74594259262085]\n",
      "predict val...\n",
      "predict test...\n",
      "139.04132 257.3913\n",
      "155.94177 257.3913 345.40967 1.0\n",
      "FOLD 1412\n",
      "train [28.312284469604492, 6.547316074371338]\n",
      "val [29.831327438354492, 6.605199813842773]\n",
      "predict val...\n",
      "predict test...\n",
      "126.215416 251.7117\n",
      "163.75293 251.7117 368.95557 1.0\n",
      "FOLD 1413\n",
      "train [26.296764373779297, 6.451428413391113]\n",
      "val [36.8287467956543, 6.6797685623168945]\n",
      "predict val...\n",
      "predict test...\n",
      "159.0599 223.92188\n",
      "135.28687 223.92188 385.8462 1.0\n",
      "FOLD 1414\n",
      "train [29.881826400756836, 6.603524208068848]\n",
      "val [28.664928436279297, 6.497042655944824]\n",
      "predict val...\n",
      "predict test...\n",
      "124.33474 239.02754\n",
      "123.728516 239.02754 353.91455 1.0\n",
      "FOLD 1415\n",
      "train [28.484756469726562, 6.542503356933594]\n",
      "val [34.61394119262695, 6.709233283996582]\n",
      "predict val...\n",
      "predict test...\n",
      "152.31544 236.18022\n",
      "156.62744 236.18022 329.70386 1.0\n",
      "FOLD 1416\n",
      "train [28.359609603881836, 6.531802177429199]\n",
      "val [31.917268753051758, 6.767757415771484]\n",
      "predict val...\n",
      "predict test...\n",
      "137.94098 239.62694\n",
      "143.5415 239.62694 312.87598 1.0\n",
      "FOLD 1417\n",
      "train [27.747770309448242, 6.5052313804626465]\n",
      "val [31.524961471557617, 6.666784286499023]\n",
      "predict val...\n",
      "predict test...\n",
      "134.79005 228.32782\n",
      "149.35608 228.32782 371.9536 1.0\n",
      "FOLD 1418\n",
      "train [26.628143310546875, 6.470883369445801]\n",
      "val [37.42942810058594, 6.730345726013184]\n",
      "predict val...\n",
      "predict test...\n",
      "161.32274 232.07701\n",
      "97.8125 232.07701 309.3999 1.0\n",
      "FOLD 1419\n",
      "train [28.548675537109375, 6.556715488433838]\n",
      "val [28.023155212402344, 6.455865383148193]\n",
      "predict val...\n",
      "predict test...\n",
      "122.258156 237.66612\n",
      "134.4909 237.66612 336.78076 1.0\n",
      "FOLD 1420\n",
      "train [28.016305923461914, 6.523678779602051]\n",
      "val [34.09943771362305, 6.696710586547852]\n",
      "predict val...\n",
      "predict test...\n",
      "149.48709 233.29082\n",
      "161.43274 233.29082 325.66968 1.0\n",
      "FOLD 1421\n",
      "train [28.21273422241211, 6.526236534118652]\n",
      "val [32.7357063293457, 6.804409027099609]\n",
      "predict val...\n",
      "predict test...\n",
      "142.0412 242.25839\n",
      "148.12769 242.25839 333.23438 1.0\n",
      "FOLD 1422\n",
      "train [27.430816650390625, 6.497808933258057]\n",
      "val [30.399747848510742, 6.62658166885376]\n",
      "predict val...\n",
      "predict test...\n",
      "129.92697 228.81079\n",
      "148.39502 228.81079 344.98828 1.0\n",
      "FOLD 1423\n",
      "train [26.57554054260254, 6.452494144439697]\n",
      "val [36.645729064941406, 6.663358688354492]\n",
      "predict val...\n",
      "predict test...\n",
      "157.4812 225.01746\n",
      "87.282715 225.01746 298.6023 1.0\n",
      "FOLD 1424\n",
      "train [28.169008255004883, 6.532062530517578]\n",
      "val [28.44308853149414, 6.490951061248779]\n",
      "predict val...\n",
      "predict test...\n",
      "125.22687 230.79054\n",
      "111.951416 230.79054 290.57617 1.0\n",
      "FOLD 1425\n",
      "train [27.976585388183594, 6.523846626281738]\n",
      "val [34.00663375854492, 6.701414108276367]\n",
      "predict val...\n",
      "predict test...\n",
      "147.28906 231.72173\n",
      "152.90283 231.72173 317.56836 1.0\n",
      "FOLD 1426\n",
      "train [28.24540901184082, 6.52587890625]\n",
      "val [32.298362731933594, 6.840142250061035]\n",
      "predict val...\n",
      "predict test...\n",
      "138.87325 241.63174\n",
      "130.38745 241.63174 328.7942 1.0\n",
      "FOLD 1427\n",
      "train [28.691587448120117, 6.542601585388184]\n",
      "val [30.15252113342285, 6.611085891723633]\n",
      "predict val...\n",
      "predict test...\n",
      "126.86002 240.30281\n",
      "160.53821 240.30281 350.9204 1.0\n",
      "FOLD 1428\n",
      "train [26.09680938720703, 6.422863006591797]\n",
      "val [34.59048080444336, 6.656500816345215]\n",
      "predict val...\n",
      "predict test...\n",
      "148.28168 210.38025\n",
      "93.56323 210.38025 283.81494 1.0\n",
      "FOLD 1429\n",
      "train [28.20035743713379, 6.534621238708496]\n",
      "val [27.34648323059082, 6.475833892822266]\n",
      "predict val...\n",
      "predict test...\n",
      "120.21618 243.54016\n",
      "117.21704 243.54016 356.32593 1.0\n",
      "FOLD 1430\n",
      "train [27.115434646606445, 6.493655204772949]\n",
      "val [32.35115051269531, 6.678652763366699]\n",
      "predict val...\n",
      "predict test...\n",
      "140.7047 218.59676\n",
      "144.78503 218.59676 287.81323 1.0\n",
      "FOLD 1431\n",
      "train [28.338918685913086, 6.535017490386963]\n",
      "val [32.070838928222656, 6.789705753326416]\n",
      "predict val...\n",
      "predict test...\n",
      "138.09174 241.41776\n",
      "129.35522 241.41776 323.24902 1.0\n",
      "FOLD 1432\n",
      "train [28.15154457092285, 6.530536651611328]\n",
      "val [32.26914978027344, 6.749120712280273]\n",
      "predict val...\n",
      "predict test...\n",
      "136.65582 242.79086\n",
      "175.2998 242.79086 343.0498 1.0\n",
      "FOLD 1433\n",
      "train [26.512310028076172, 6.454352378845215]\n",
      "val [38.05740737915039, 6.731944561004639]\n",
      "predict val...\n",
      "predict test...\n",
      "163.4971 222.62665\n",
      "116.4187 222.62665 279.3562 1.0\n",
      "FOLD 1434\n",
      "train [28.23924446105957, 6.51553201675415]\n",
      "val [27.374427795410156, 6.439367294311523]\n",
      "predict val...\n",
      "predict test...\n",
      "118.262276 229.83571\n",
      "51.94336 229.83571 319.59375 1.0\n",
      "FOLD 1435\n",
      "train [27.94292449951172, 6.508196830749512]\n",
      "val [33.591976165771484, 6.712759017944336]\n",
      "predict val...\n",
      "predict test...\n",
      "147.29578 238.27072\n",
      "123.40723 238.27072 336.39404 1.0\n",
      "FOLD 1436\n",
      "train [27.04743194580078, 6.479668617248535]\n",
      "val [32.82390213012695, 6.818027496337891]\n",
      "predict val...\n",
      "predict test...\n",
      "141.12358 225.51955\n",
      "124.78882 225.51955 297.64575 1.0\n",
      "FOLD 1437\n",
      "train [28.603872299194336, 6.553589820861816]\n",
      "val [30.10989761352539, 6.62103796005249]\n",
      "predict val...\n",
      "predict test...\n",
      "126.75387 248.74413\n",
      "170.37341 248.74413 375.65625 1.0\n",
      "FOLD 1438\n",
      "train [26.471437454223633, 6.446542263031006]\n",
      "val [37.87520217895508, 6.707944869995117]\n",
      "predict val...\n",
      "predict test...\n",
      "163.32672 220.70587\n",
      "107.62549 220.70587 287.75293 1.0\n",
      "FOLD 1439\n",
      "train [28.028024673461914, 6.517115116119385]\n",
      "val [27.693891525268555, 6.440619468688965]\n",
      "predict val...\n",
      "predict test...\n",
      "121.10261 228.11589\n",
      "58.56836 228.11589 306.239 1.0\n",
      "FOLD 1440\n",
      "train [27.280487060546875, 6.501961708068848]\n",
      "val [32.707828521728516, 6.706015586853027]\n",
      "predict val...\n",
      "predict test...\n",
      "142.16667 233.11935\n",
      "110.40039 233.11935 282.00586 1.0\n",
      "FOLD 1441\n",
      "train [27.879840850830078, 6.500567436218262]\n",
      "val [31.308313369750977, 6.698240280151367]\n",
      "predict val...\n",
      "predict test...\n",
      "135.66005 237.34738\n",
      "69.84473 237.34738 438.9619 1.0\n",
      "FOLD 1442\n",
      "train [28.03309440612793, 6.534326076507568]\n",
      "val [37.10622787475586, 7.36485481262207]\n",
      "predict val...\n",
      "predict test...\n",
      "154.10901 239.25572\n",
      "134.46606 239.25572 353.7373 1.0\n",
      "FOLD 1443\n",
      "train [26.517276763916016, 6.436514377593994]\n",
      "val [36.55720901489258, 6.670488357543945]\n",
      "predict val...\n",
      "predict test...\n",
      "157.04465 214.64276\n",
      "100.76257 214.64276 327.30737 1.0\n",
      "FOLD 1444\n",
      "train [27.780906677246094, 6.513192176818848]\n",
      "val [26.684598922729492, 6.4186601638793945]\n",
      "predict val...\n",
      "predict test...\n",
      "114.80871 224.32619\n",
      "134.84705 224.32619 309.14087 1.0\n",
      "FOLD 1445\n",
      "train [27.92957878112793, 6.525502681732178]\n",
      "val [33.70014953613281, 6.69954776763916]\n",
      "predict val...\n",
      "predict test...\n",
      "146.51111 234.81479\n",
      "163.76892 234.81479 326.8042 1.0\n",
      "FOLD 1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [27.6417293548584, 6.486181735992432]\n",
      "val [32.64091491699219, 6.879189491271973]\n",
      "predict val...\n",
      "predict test...\n",
      "139.8841 228.57904\n",
      "-0.2109375 228.57904 468.2163 0.996742671009772\n",
      "FOLD 1447\n",
      "train [28.072826385498047, 6.531867980957031]\n",
      "val [30.687185287475586, 6.569732666015625]\n",
      "predict val...\n",
      "predict test...\n",
      "130.07779 239.50275\n",
      "160.01453 239.50275 335.63477 1.0\n",
      "FOLD 1448\n",
      "train [26.133853912353516, 6.420326232910156]\n",
      "val [35.32430648803711, 6.641861915588379]\n",
      "predict val...\n",
      "predict test...\n",
      "151.86078 212.66173\n",
      "112.69092 212.66173 282.71948 1.0\n",
      "FOLD 1449\n",
      "train [28.92881965637207, 6.563051700592041]\n",
      "val [28.78011703491211, 6.510517120361328]\n",
      "predict val...\n",
      "predict test...\n",
      "128.10063 233.44856\n",
      "160.65845 233.44856 298.64014 1.0\n",
      "FOLD 1450\n",
      "train [27.21319007873535, 6.485407829284668]\n",
      "val [33.722686767578125, 6.798831939697266]\n",
      "predict val...\n",
      "predict test...\n",
      "145.40825 231.13583\n",
      "7.659912 231.13583 385.2068 1.0\n",
      "FOLD 1451\n",
      "train [33.46430206298828, 6.561061859130859]\n",
      "val [36.97032165527344, 6.738909721374512]\n",
      "predict val...\n",
      "predict test...\n",
      "138.93138 251.3928\n",
      "134.70251 251.3928 398.54785 1.0\n",
      "FOLD 1452\n",
      "train [32.91993713378906, 6.536022186279297]\n",
      "val [35.388431549072266, 6.636512756347656]\n",
      "predict val...\n",
      "predict test...\n",
      "129.06529 242.58688\n",
      "139.34033 242.58688 406.9419 1.0\n",
      "FOLD 1453\n",
      "train [32.19709777832031, 6.504589080810547]\n",
      "val [41.65287399291992, 6.685323715209961]\n",
      "predict val...\n",
      "predict test...\n",
      "156.85167 233.61739\n",
      "111.03125 233.61739 517.2095 1.0\n",
      "FOLD 1454\n",
      "train [34.763389587402344, 6.601613521575928]\n",
      "val [33.43775177001953, 6.5055036544799805]\n",
      "predict val...\n",
      "predict test...\n",
      "126.84773 231.35866\n",
      "96.16681 231.35866 383.20996 1.0\n",
      "FOLD 1455\n",
      "train [33.200721740722656, 6.542037010192871]\n",
      "val [38.417728424072266, 6.661470890045166]\n",
      "predict val...\n",
      "predict test...\n",
      "145.36247 228.77382\n",
      "113.47797 228.77382 376.28662 1.0\n",
      "FOLD 1456\n",
      "train [33.15009689331055, 6.561551094055176]\n",
      "val [36.9097900390625, 6.7451887130737305]\n",
      "predict val...\n",
      "predict test...\n",
      "138.27519 261.37854\n",
      "159.1593 261.37854 387.76855 1.0\n",
      "FOLD 1457\n",
      "train [32.86348342895508, 6.5379180908203125]\n",
      "val [37.145748138427734, 6.687150955200195]\n",
      "predict val...\n",
      "predict test...\n",
      "137.52449 242.48228\n",
      "146.47192 242.48228 384.29395 1.0\n",
      "FOLD 1458\n",
      "train [32.110130310058594, 6.500903129577637]\n",
      "val [41.09686279296875, 6.651858329772949]\n",
      "predict val...\n",
      "predict test...\n",
      "153.53244 230.21681\n",
      "127.29553 230.21681 469.57373 1.0\n",
      "FOLD 1459\n",
      "train [34.54551315307617, 6.602461338043213]\n",
      "val [33.67708206176758, 6.503498077392578]\n",
      "predict val...\n",
      "predict test...\n",
      "126.36707 233.64546\n",
      "96.28943 233.64546 381.2251 1.0\n",
      "FOLD 1460\n",
      "train [32.17511749267578, 6.508201599121094]\n",
      "val [36.81052017211914, 6.655571937561035]\n",
      "predict val...\n",
      "predict test...\n",
      "137.24054 214.04993\n",
      "149.66248 214.04993 295.61084 1.0\n",
      "FOLD 1461\n",
      "train [32.829952239990234, 6.545494079589844]\n",
      "val [36.543113708496094, 6.720994472503662]\n",
      "predict val...\n",
      "predict test...\n",
      "137.3846 253.8977\n",
      "154.00049 253.8977 371.6089 1.0\n",
      "FOLD 1462\n",
      "train [33.609230041503906, 6.57211446762085]\n",
      "val [34.17129898071289, 6.609285354614258]\n",
      "predict val...\n",
      "predict test...\n",
      "123.196594 259.64435\n",
      "149.1825 259.64435 435.34277 1.0\n",
      "FOLD 1463\n",
      "train [31.83391761779785, 6.507439613342285]\n",
      "val [42.204689025878906, 6.6872453689575195]\n",
      "predict val...\n",
      "predict test...\n",
      "156.78157 240.5256\n",
      "134.68152 240.5256 437.62256 1.0\n",
      "FOLD 1464\n",
      "train [34.47883987426758, 6.603105068206787]\n",
      "val [34.953575134277344, 6.54221248626709]\n",
      "predict val...\n",
      "predict test...\n",
      "133.4295 242.26097\n",
      "119.443726 242.26097 373.41553 1.0\n",
      "FOLD 1465\n",
      "train [32.77734375, 6.536435604095459]\n",
      "val [40.10154342651367, 6.693958759307861]\n",
      "predict val...\n",
      "predict test...\n",
      "151.84612 234.15808\n",
      "140.47607 234.15808 341.25928 1.0\n",
      "FOLD 1466\n",
      "train [32.60933303833008, 6.5301313400268555]\n",
      "val [37.2274284362793, 6.749342918395996]\n",
      "predict val...\n",
      "predict test...\n",
      "138.88313 243.57458\n",
      "161.45068 243.57458 320.52148 1.0\n",
      "FOLD 1467\n",
      "train [31.63188934326172, 6.499057769775391]\n",
      "val [35.20216751098633, 6.592550277709961]\n",
      "predict val...\n",
      "predict test...\n",
      "127.16248 226.65884\n",
      "139.22534 226.65884 311.64893 1.0\n",
      "FOLD 1468\n",
      "train [30.03765296936035, 6.428952693939209]\n",
      "val [43.97337341308594, 6.684361934661865]\n",
      "predict val...\n",
      "predict test...\n",
      "162.98152 218.15121\n",
      "126.22412 218.15121 357.35107 1.0\n",
      "FOLD 1469\n",
      "train [34.18528747558594, 6.580809116363525]\n",
      "val [32.56464385986328, 6.490656852722168]\n",
      "predict val...\n",
      "predict test...\n",
      "124.631 235.5968\n",
      "145.24237 235.5968 333.42798 1.0\n",
      "FOLD 1470\n",
      "train [32.54529571533203, 6.536786079406738]\n",
      "val [39.01067352294922, 6.689727306365967]\n",
      "predict val...\n",
      "predict test...\n",
      "147.3269 240.12321\n",
      "174.93506 240.12321 333.1018 1.0\n",
      "FOLD 1471\n",
      "train [32.95827865600586, 6.5481157302856445]\n",
      "val [36.8639030456543, 6.76572847366333]\n",
      "predict val...\n",
      "predict test...\n",
      "138.5426 254.01025\n",
      "160.14758 254.01025 354.47852 1.0\n",
      "FOLD 1472\n",
      "train [33.357234954833984, 6.564566135406494]\n",
      "val [34.48013687133789, 6.611998558044434]\n",
      "predict val...\n",
      "predict test...\n",
      "125.718445 253.78152\n",
      "162.70007 253.78152 383.58154 1.0\n",
      "FOLD 1473\n",
      "train [31.506393432617188, 6.49447774887085]\n",
      "val [42.66592025756836, 6.677398204803467]\n",
      "predict val...\n",
      "predict test...\n",
      "158.65851 232.75732\n",
      "156.51233 232.75732 353.56494 1.0\n",
      "FOLD 1474\n",
      "train [33.15050506591797, 6.541490077972412]\n",
      "val [31.924890518188477, 6.480982303619385]\n",
      "predict val...\n",
      "predict test...\n",
      "122.6988 229.99501\n",
      "148.93176 229.99501 283.8423 1.0\n",
      "FOLD 1475\n",
      "train [32.672569274902344, 6.531636714935303]\n",
      "val [38.59237289428711, 6.677737712860107]\n",
      "predict val...\n",
      "predict test...\n",
      "145.48898 233.27438\n",
      "153.29688 233.27438 326.10522 1.0\n",
      "FOLD 1476\n",
      "train [31.496707916259766, 6.5080461502075195]\n",
      "val [38.07394790649414, 6.802821159362793]\n",
      "predict val...\n",
      "predict test...\n",
      "142.42383 249.22842\n",
      "161.29785 249.22842 338.22998 1.0\n",
      "FOLD 1477\n",
      "train [31.42888832092285, 6.491703033447266]\n",
      "val [35.301307678222656, 6.7343645095825195]\n",
      "predict val...\n",
      "predict test...\n",
      "130.77815 235.68959\n",
      "135.52563 235.68959 294.18408 1.0\n",
      "FOLD 1478\n",
      "train [29.772323608398438, 6.422804355621338]\n",
      "val [42.25631332397461, 6.655686378479004]\n",
      "predict val...\n",
      "predict test...\n",
      "156.766 217.96555\n",
      "84.111206 217.96555 282.3584 1.0\n",
      "FOLD 1479\n",
      "train [33.601322174072266, 6.572060585021973]\n",
      "val [33.334808349609375, 6.499000549316406]\n",
      "predict val...\n",
      "predict test...\n",
      "128.81154 227.81886\n",
      "123.41742 227.81886 306.7046 1.0\n",
      "FOLD 1480\n",
      "train [31.335247039794922, 6.5019402503967285]\n",
      "val [40.33523941040039, 6.754502773284912]\n",
      "predict val...\n",
      "predict test...\n",
      "152.38606 234.47705\n",
      "150.30225 234.47705 303.98193 1.0\n",
      "FOLD 1481\n",
      "train [32.90385818481445, 6.542730808258057]\n",
      "val [36.84868240356445, 6.77358341217041]\n",
      "predict val...\n",
      "predict test...\n",
      "138.00534 250.26894\n",
      "170.76624 250.26894 335.2754 1.0\n",
      "FOLD 1482\n",
      "train [31.540430068969727, 6.490828514099121]\n",
      "val [34.4566650390625, 6.5730299949646]\n",
      "predict val...\n",
      "predict test...\n",
      "127.39121 227.2825\n",
      "162.41187 227.2825 282.02026 1.0\n",
      "FOLD 1483\n",
      "train [30.833175659179688, 6.449190616607666]\n",
      "val [42.89506912231445, 6.680383205413818]\n",
      "predict val...\n",
      "predict test...\n",
      "158.59839 218.91002\n",
      "107.27185 218.91002 317.73804 1.0\n",
      "FOLD 1484\n",
      "train [32.816551208496094, 6.550370693206787]\n",
      "val [31.068010330200195, 6.475702285766602]\n",
      "predict val...\n",
      "predict test...\n",
      "118.526794 246.21483\n",
      "141.60889 246.21483 340.42798 1.0\n",
      "FOLD 1485\n",
      "train [31.979434967041016, 6.51516580581665]\n",
      "val [38.774696350097656, 6.714574337005615]\n",
      "predict val...\n",
      "predict test...\n",
      "145.43979 234.07805\n",
      "116.177246 234.07805 322.46558 1.0\n",
      "FOLD 1486\n",
      "train [31.29524040222168, 6.493096351623535]\n",
      "val [36.20950698852539, 6.723015785217285]\n",
      "predict val...\n",
      "predict test...\n",
      "132.7979 232.33176\n",
      "77.2063 232.33176 325.90552 1.0\n",
      "FOLD 1487\n",
      "train [32.22380828857422, 6.524556636810303]\n",
      "val [34.36167526245117, 6.598273754119873]\n",
      "predict val...\n",
      "predict test...\n",
      "126.564316 245.69029\n",
      "167.81335 245.69029 342.05957 1.0\n",
      "FOLD 1488\n",
      "train [30.188594818115234, 6.430854797363281]\n",
      "val [42.62770462036133, 6.671292304992676]\n",
      "predict val...\n",
      "predict test...\n",
      "158.84166 214.79173\n",
      "79.137695 214.79173 299.59204 1.0\n",
      "FOLD 1489\n",
      "train [34.03095626831055, 6.571825981140137]\n",
      "val [32.283958435058594, 6.4738545417785645]\n",
      "predict val...\n",
      "predict test...\n",
      "123.72029 227.0567\n",
      "136.1325 227.0567 322.15186 1.0\n",
      "FOLD 1490\n",
      "train [32.0322151184082, 6.516927242279053]\n",
      "val [40.465538024902344, 6.734746932983398]\n",
      "predict val...\n",
      "predict test...\n",
      "153.15704 232.33759\n",
      "142.89258 232.33759 321.69238 1.0\n",
      "FOLD 1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [31.701980590820312, 6.492239952087402]\n",
      "val [37.60081100463867, 6.816336631774902]\n",
      "predict val...\n",
      "predict test...\n",
      "139.64848 231.88335\n",
      "106.07373 231.88335 382.26367 1.0\n",
      "FOLD 1492\n",
      "train [32.1107177734375, 6.51653528213501]\n",
      "val [37.398014068603516, 6.741379737854004]\n",
      "predict val...\n",
      "predict test...\n",
      "139.30533 249.4675\n",
      "150.42908 249.4675 372.76807 1.0\n",
      "FOLD 1493\n",
      "train [31.315502166748047, 6.477182865142822]\n",
      "val [42.649662017822266, 6.674487113952637]\n",
      "predict val...\n",
      "predict test...\n",
      "158.79791 233.84294\n",
      "127.62097 233.84294 307.82373 1.0\n",
      "FOLD 1494\n",
      "train [31.262624740600586, 6.492759704589844]\n",
      "val [33.022621154785156, 6.476849555969238]\n",
      "predict val...\n",
      "predict test...\n",
      "124.3548 227.7245\n",
      "68.71582 227.7245 291.57422 1.0\n",
      "FOLD 1495\n",
      "train [31.624361038208008, 6.491811275482178]\n",
      "val [40.2166862487793, 6.835165023803711]\n",
      "predict val...\n",
      "predict test...\n",
      "150.71608 230.47339\n",
      "13.506348 230.47339 421.12988 1.0\n",
      "FOLD 1496\n",
      "train [31.47368621826172, 6.4853105545043945]\n",
      "val [37.30722427368164, 6.876983165740967]\n",
      "predict val...\n",
      "predict test...\n",
      "138.99315 232.07408\n",
      "79.1521 232.07408 352.1931 1.0\n",
      "FOLD 1497\n",
      "train [32.2294921875, 6.522524833679199]\n",
      "val [34.84547424316406, 6.603262901306152]\n",
      "predict val...\n",
      "predict test...\n",
      "128.00621 245.18478\n",
      "138.88965 245.18478 354.51465 1.0\n",
      "FOLD 1498\n",
      "train [28.48900604248047, 6.377242088317871]\n",
      "val [43.846649169921875, 6.656442642211914]\n",
      "predict val...\n",
      "predict test...\n",
      "162.32759 215.64357\n",
      "64.78418 215.64357 305.4746 1.0\n",
      "FOLD 1499\n",
      "train [34.082313537597656, 6.577581882476807]\n",
      "val [32.07969284057617, 6.501104831695557]\n",
      "predict val...\n",
      "predict test...\n",
      "122.817955 245.3375\n",
      "152.63428 245.3375 333.82983 1.0\n",
      "FOLD 1500\n",
      "train [31.66242027282715, 6.4850945472717285]\n",
      "val [38.58781433105469, 6.760899543762207]\n",
      "predict val...\n",
      "predict test...\n",
      "144.27371 226.14311\n",
      "-0.6069336 226.14311 392.72046 0.996742671009772\n",
      "FOLD 1501\n",
      "train [37.85703659057617, 6.563513278961182]\n",
      "val [42.49187469482422, 6.7479095458984375]\n",
      "predict val...\n",
      "predict test...\n",
      "140.64954 254.89337\n",
      "126.190796 254.89337 437.23682 1.0\n",
      "FOLD 1502\n",
      "train [38.17100524902344, 6.557354927062988]\n",
      "val [39.240875244140625, 6.589043617248535]\n",
      "predict val...\n",
      "predict test...\n",
      "123.77639 244.96771\n",
      "128.6499 244.96771 417.61963 1.0\n",
      "FOLD 1503\n",
      "train [35.9921875, 6.481161594390869]\n",
      "val [48.22694778442383, 6.670331001281738]\n",
      "predict val...\n",
      "predict test...\n",
      "158.25905 221.32309\n",
      "109.84741 221.32309 469.48193 1.0\n",
      "FOLD 1504\n",
      "train [39.50141906738281, 6.610348701477051]\n",
      "val [37.554725646972656, 6.509200096130371]\n",
      "predict val...\n",
      "predict test...\n",
      "124.81555 237.73254\n",
      "95.697815 237.73254 396.4546 1.0\n",
      "FOLD 1505\n",
      "train [37.441280364990234, 6.540711879730225]\n",
      "val [43.390987396240234, 6.66566276550293]\n",
      "predict val...\n",
      "predict test...\n",
      "143.75876 233.72081\n",
      "139.37915 233.72081 359.3838 1.0\n",
      "FOLD 1506\n",
      "train [37.530303955078125, 6.5532684326171875]\n",
      "val [42.01362228393555, 6.760822296142578]\n",
      "predict val...\n",
      "predict test...\n",
      "138.18167 255.18872\n",
      "150.15723 255.18872 366.45898 1.0\n",
      "FOLD 1507\n",
      "train [37.79246139526367, 6.551283359527588]\n",
      "val [40.7800407409668, 6.668307781219482]\n",
      "predict val...\n",
      "predict test...\n",
      "131.39365 247.49336\n",
      "134.91382 247.49336 420.4043 1.0\n",
      "FOLD 1508\n",
      "train [35.130821228027344, 6.466954231262207]\n",
      "val [50.2927360534668, 6.734644889831543]\n",
      "predict val...\n",
      "predict test...\n",
      "163.70792 216.77884\n",
      "90.11279 216.77884 349.1875 1.0\n",
      "FOLD 1509\n",
      "train [38.2043342590332, 6.580042362213135]\n",
      "val [36.33409118652344, 6.4558610916137695]\n",
      "predict val...\n",
      "predict test...\n",
      "120.851585 226.29112\n",
      "104.98523 226.29112 343.96484 1.0\n",
      "FOLD 1510\n",
      "train [37.73410415649414, 6.536768913269043]\n",
      "val [42.32133865356445, 6.653070449829102]\n",
      "predict val...\n",
      "predict test...\n",
      "139.41298 222.74496\n",
      "137.01233 222.74496 323.59277 1.0\n",
      "FOLD 1511\n",
      "train [37.696617126464844, 6.558049201965332]\n",
      "val [40.848628997802734, 6.697016716003418]\n",
      "predict val...\n",
      "predict test...\n",
      "135.61992 255.89394\n",
      "148.09387 255.89394 394.43213 1.0\n",
      "FOLD 1512\n",
      "train [37.99067687988281, 6.567320823669434]\n",
      "val [39.371498107910156, 6.62678337097168]\n",
      "predict val...\n",
      "predict test...\n",
      "125.41616 255.67796\n",
      "160.70227 255.67796 409.28857 1.0\n",
      "FOLD 1513\n",
      "train [36.12736511230469, 6.502790927886963]\n",
      "val [47.907745361328125, 6.682586669921875]\n",
      "predict val...\n",
      "predict test...\n",
      "157.75343 236.11417\n",
      "141.85718 236.11417 420.7788 1.0\n",
      "FOLD 1514\n",
      "train [37.92145538330078, 6.568058013916016]\n",
      "val [38.11022186279297, 6.476195335388184]\n",
      "predict val...\n",
      "predict test...\n",
      "125.90928 226.44081\n",
      "106.6449 226.44081 344.92188 1.0\n",
      "FOLD 1515\n",
      "train [37.347129821777344, 6.543449401855469]\n",
      "val [45.219200134277344, 6.703885078430176]\n",
      "predict val...\n",
      "predict test...\n",
      "149.72328 235.00229\n",
      "146.03467 235.00229 327.57373 1.0\n",
      "FOLD 1516\n",
      "train [35.9815673828125, 6.519862174987793]\n",
      "val [41.79541778564453, 6.768701553344727]\n",
      "predict val...\n",
      "predict test...\n",
      "137.29652 247.33772\n",
      "166.1665 247.33772 313.43457 1.0\n",
      "FOLD 1517\n",
      "train [37.41460037231445, 6.542558193206787]\n",
      "val [39.682395935058594, 6.623120307922363]\n",
      "predict val...\n",
      "predict test...\n",
      "127.89317 246.39687\n",
      "140.1001 246.39687 416.66992 1.0\n",
      "FOLD 1518\n",
      "train [34.29473876953125, 6.446488857269287]\n",
      "val [48.3387336730957, 6.710796356201172]\n",
      "predict val...\n",
      "predict test...\n",
      "156.79768 220.01741\n",
      "102.77173 220.01741 279.3037 1.0\n",
      "FOLD 1519\n",
      "train [38.421714782714844, 6.577784538269043]\n",
      "val [36.926612854003906, 6.492501258850098]\n",
      "predict val...\n",
      "predict test...\n",
      "123.87027 225.26384\n",
      "106.341736 225.26384 343.54102 1.0\n",
      "FOLD 1520\n",
      "train [36.2247314453125, 6.526701927185059]\n",
      "val [44.40774154663086, 6.70784854888916]\n",
      "predict val...\n",
      "predict test...\n",
      "146.43147 238.27759\n",
      "161.56885 238.27759 321.63672 1.0\n",
      "FOLD 1521\n",
      "train [37.46247482299805, 6.554365634918213]\n",
      "val [42.185176849365234, 6.774051189422607]\n",
      "predict val...\n",
      "predict test...\n",
      "139.49448 258.99564\n",
      "175.4054 258.99564 353.93994 1.0\n",
      "FOLD 1522\n",
      "train [36.0996208190918, 6.502311706542969]\n",
      "val [39.819976806640625, 6.593818187713623]\n",
      "predict val...\n",
      "predict test...\n",
      "127.679405 230.48514\n",
      "143.15784 230.48514 351.8916 1.0\n",
      "FOLD 1523\n",
      "train [34.95922088623047, 6.464888572692871]\n",
      "val [49.0135612487793, 6.692055702209473]\n",
      "predict val...\n",
      "predict test...\n",
      "159.85115 225.1545\n",
      "131.36499 225.1545 289.6565 1.0\n",
      "FOLD 1524\n",
      "train [37.7860221862793, 6.552369117736816]\n",
      "val [37.12841033935547, 6.476142883300781]\n",
      "predict val...\n",
      "predict test...\n",
      "124.692566 234.21452\n",
      "128.81787 234.21452 288.76562 1.0\n",
      "FOLD 1525\n",
      "train [36.72766876220703, 6.52362060546875]\n",
      "val [44.95903778076172, 6.67463493347168]\n",
      "predict val...\n",
      "predict test...\n",
      "147.09825 229.07477\n",
      "150.54053 229.07477 329.7849 1.0\n",
      "FOLD 1526\n",
      "train [34.921024322509766, 6.493281364440918]\n",
      "val [41.65544891357422, 6.678832054138184]\n",
      "predict val...\n",
      "predict test...\n",
      "135.77692 245.30199\n",
      "111.089355 245.30199 340.9121 1.0\n",
      "FOLD 1527\n",
      "train [36.57926940917969, 6.528806209564209]\n",
      "val [39.38222122192383, 6.593881607055664]\n",
      "predict val...\n",
      "predict test...\n",
      "127.07527 242.23503\n",
      "173.81714 242.23503 347.30957 1.0\n",
      "FOLD 1528\n",
      "train [35.481266021728516, 6.488722324371338]\n",
      "val [48.26549530029297, 6.667250156402588]\n",
      "predict val...\n",
      "predict test...\n",
      "157.83105 236.41597\n",
      "157.32214 236.41597 288.1577 1.0\n",
      "FOLD 1529\n",
      "train [39.10226821899414, 6.5932512283325195]\n",
      "val [37.25025939941406, 6.498318672180176]\n",
      "predict val...\n",
      "predict test...\n",
      "124.70937 236.65973\n",
      "127.16907 236.65973 339.16504 1.0\n",
      "FOLD 1530\n",
      "train [36.3138542175293, 6.519670009613037]\n",
      "val [47.365455627441406, 6.744818687438965]\n",
      "predict val...\n",
      "predict test...\n",
      "156.37694 234.152\n",
      "184.97656 234.152 315.3103 1.0\n",
      "FOLD 1531\n",
      "train [36.376949310302734, 6.517695426940918]\n",
      "val [41.45405197143555, 6.743824005126953]\n",
      "predict val...\n",
      "predict test...\n",
      "136.10574 246.82614\n",
      "150.31958 246.82614 328.08105 1.0\n",
      "FOLD 1532\n",
      "train [36.90419387817383, 6.5427751541137695]\n",
      "val [40.80723190307617, 6.646271228790283]\n",
      "predict val...\n",
      "predict test...\n",
      "131.70384 252.03543\n",
      "172.18994 252.03543 363.89258 1.0\n",
      "FOLD 1533\n",
      "train [35.380027770996094, 6.474939823150635]\n",
      "val [48.34428024291992, 6.662303924560547]\n",
      "predict val...\n",
      "predict test...\n",
      "156.43678 227.14803\n",
      "150.63672 227.14803 290.87354 1.0\n",
      "FOLD 1534\n",
      "train [37.627784729003906, 6.556527614593506]\n",
      "val [37.334571838378906, 6.526127815246582]\n",
      "predict val...\n",
      "predict test...\n",
      "126.000305 243.61217\n",
      "150.12988 243.61217 324.08447 1.0\n",
      "FOLD 1535\n",
      "train [35.59809875488281, 6.497412204742432]\n",
      "val [46.199493408203125, 6.738588333129883]\n",
      "predict val...\n",
      "predict test...\n",
      "152.71443 232.84808\n",
      "129.15796 232.84808 338.7693 1.0\n",
      "FOLD 1536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.944183349609375, 6.530686855316162]\n",
      "val [42.33378219604492, 6.792154788970947]\n",
      "predict val...\n",
      "predict test...\n",
      "139.42126 241.66878\n",
      "143.78442 241.66878 334.23706 1.0\n",
      "FOLD 1537\n",
      "train [37.18193817138672, 6.550797939300537]\n",
      "val [39.63068771362305, 6.596343040466309]\n",
      "predict val...\n",
      "predict test...\n",
      "126.89169 248.44498\n",
      "174.54285 248.44498 364.71045 1.0\n",
      "FOLD 1538\n",
      "train [35.75901412963867, 6.488163948059082]\n",
      "val [49.92571258544922, 6.6822509765625]\n",
      "predict val...\n",
      "predict test...\n",
      "162.2104 232.78496\n",
      "152.5149 232.78496 296.2661 1.0\n",
      "FOLD 1539\n",
      "train [38.650962829589844, 6.5711350440979]\n",
      "val [36.90438461303711, 6.488641738891602]\n",
      "predict val...\n",
      "predict test...\n",
      "124.2589 231.69661\n",
      "141.97571 231.69661 307.6792 1.0\n",
      "FOLD 1540\n",
      "train [35.3513069152832, 6.487656593322754]\n",
      "val [42.55529022216797, 6.705995559692383]\n",
      "predict val...\n",
      "predict test...\n",
      "140.64671 229.24927\n",
      "84.10889 229.24927 311.74658 1.0\n",
      "FOLD 1541\n",
      "train [34.872379302978516, 6.473488807678223]\n",
      "val [39.816287994384766, 6.557403564453125]\n",
      "predict val...\n",
      "predict test...\n",
      "131.15514 228.16261\n",
      "101.23389 228.16261 284.68848 1.0\n",
      "FOLD 1542\n",
      "train [36.60184097290039, 6.530181884765625]\n",
      "val [38.278892517089844, 6.560649871826172]\n",
      "predict val...\n",
      "predict test...\n",
      "123.932236 246.25682\n",
      "162.01062 246.25682 359.34766 1.0\n",
      "FOLD 1543\n",
      "train [35.591148376464844, 6.493618011474609]\n",
      "val [49.55889129638672, 6.685051918029785]\n",
      "predict val...\n",
      "predict test...\n",
      "161.34862 237.37634\n",
      "158.62122 237.37634 290.42163 1.0\n",
      "FOLD 1544\n",
      "train [37.204627990722656, 6.539532661437988]\n",
      "val [37.31309509277344, 6.491682052612305]\n",
      "predict val...\n",
      "predict test...\n",
      "125.36296 239.02351\n",
      "129.85962 239.02351 324.39673 1.0\n",
      "FOLD 1545\n",
      "train [34.69111251831055, 6.472098350524902]\n",
      "val [44.32413101196289, 6.782930374145508]\n",
      "predict val...\n",
      "predict test...\n",
      "144.93007 222.33046\n",
      "-8.444336 222.33046 300.04102 0.990228013029316\n",
      "FOLD 1546\n",
      "train [36.61811065673828, 6.5044050216674805]\n",
      "val [42.40390396118164, 6.959179878234863]\n",
      "predict val...\n",
      "predict test...\n",
      "138.75203 234.0239\n",
      "23.401611 234.0239 453.38623 1.0\n",
      "FOLD 1547\n",
      "train [36.56379318237305, 6.527144432067871]\n",
      "val [41.788612365722656, 6.672422885894775]\n",
      "predict val...\n",
      "predict test...\n",
      "136.77727 248.77097\n",
      "156.2605 248.77097 330.00977 1.0\n",
      "FOLD 1548\n",
      "train [34.851314544677734, 6.46142578125]\n",
      "val [49.07893371582031, 6.699887275695801]\n",
      "predict val...\n",
      "predict test...\n",
      "160.18369 224.95134\n",
      "128.60791 224.95134 290.73804 1.0\n",
      "FOLD 1549\n",
      "train [35.7272834777832, 6.510439872741699]\n",
      "val [35.54146194458008, 6.451068878173828]\n",
      "predict val...\n",
      "predict test...\n",
      "117.5823 234.72974\n",
      "103.26367 234.72974 349.1493 1.0\n",
      "FOLD 1550\n",
      "train [35.38520050048828, 6.492154121398926]\n",
      "val [43.09969711303711, 6.732614517211914]\n",
      "predict val...\n",
      "predict test...\n",
      "142.01302 228.30576\n",
      "73.80469 228.30576 302.96533 1.0\n",
      "FOLD 1551\n",
      "train [42.3281364440918, 6.563365936279297]\n",
      "val [47.417213439941406, 6.756558418273926]\n",
      "predict val...\n",
      "predict test...\n",
      "139.47592 254.98473\n",
      "129.24023 254.98473 431.38184 1.0\n",
      "FOLD 1552\n",
      "train [42.4473762512207, 6.553893089294434]\n",
      "val [43.87875747680664, 6.579957485198975]\n",
      "predict val...\n",
      "predict test...\n",
      "123.61762 245.88737\n",
      "136.28271 245.88737 411.36328 1.0\n",
      "FOLD 1553\n",
      "train [40.236907958984375, 6.488160610198975]\n",
      "val [53.220767974853516, 6.667049407958984]\n",
      "predict val...\n",
      "predict test...\n",
      "154.57202 225.10123\n",
      "111.6499 225.10123 477.2959 1.0\n",
      "FOLD 1554\n",
      "train [44.071144104003906, 6.616768836975098]\n",
      "val [42.36052703857422, 6.524270057678223]\n",
      "predict val...\n",
      "predict test...\n",
      "125.838356 243.6391\n",
      "95.73682 243.6391 404.2246 1.0\n",
      "FOLD 1555\n",
      "train [42.15253448486328, 6.5453596115112305]\n",
      "val [48.642364501953125, 6.660150051116943]\n",
      "predict val...\n",
      "predict test...\n",
      "144.11456 231.00601\n",
      "103.86755 231.00601 404.83398 1.0\n",
      "FOLD 1556\n",
      "train [41.83039855957031, 6.544960975646973]\n",
      "val [48.604637145996094, 6.8106794357299805]\n",
      "predict val...\n",
      "predict test...\n",
      "142.49478 248.55167\n",
      "124.65869 248.55167 416.15332 1.0\n",
      "FOLD 1557\n",
      "train [42.8255500793457, 6.5622453689575195]\n",
      "val [45.28532028198242, 6.6284027099609375]\n",
      "predict val...\n",
      "predict test...\n",
      "128.2305 247.71582\n",
      "141.3634 247.71582 413.88477 1.0\n",
      "FOLD 1558\n",
      "train [39.99559783935547, 6.484610080718994]\n",
      "val [56.13465118408203, 6.68609619140625]\n",
      "predict val...\n",
      "predict test...\n",
      "164.14357 224.33704\n",
      "125.55298 224.33704 416.12695 1.0\n",
      "FOLD 1559\n",
      "train [43.718482971191406, 6.59890604019165]\n",
      "val [41.295753479003906, 6.491008758544922]\n",
      "predict val...\n",
      "predict test...\n",
      "123.37883 234.0185\n",
      "100.76361 234.0185 383.40967 1.0\n",
      "FOLD 1560\n",
      "train [42.064605712890625, 6.537374973297119]\n",
      "val [48.652931213378906, 6.670927047729492]\n",
      "predict val...\n",
      "predict test...\n",
      "144.40828 227.24107\n",
      "131.8623 227.24107 362.13965 1.0\n",
      "FOLD 1561\n",
      "train [41.84569549560547, 6.5545806884765625]\n",
      "val [47.35029220581055, 6.749948501586914]\n",
      "predict val...\n",
      "predict test...\n",
      "139.39429 254.97142\n",
      "165.37964 254.97142 324.75098 1.0\n",
      "FOLD 1562\n",
      "train [40.45378112792969, 6.524905204772949]\n",
      "val [43.90138626098633, 6.583415508270264]\n",
      "predict val...\n",
      "predict test...\n",
      "125.95537 246.33658\n",
      "162.18494 246.33658 364.00146 1.0\n",
      "FOLD 1563\n",
      "train [38.50020980834961, 6.4618635177612305]\n",
      "val [56.34766387939453, 6.672780990600586]\n",
      "predict val...\n",
      "predict test...\n",
      "162.93106 227.51738\n",
      "123.46216 227.51738 443.6963 1.0\n",
      "FOLD 1564\n",
      "train [43.56791687011719, 6.591334342956543]\n",
      "val [43.28231430053711, 6.499485969543457]\n",
      "predict val...\n",
      "predict test...\n",
      "128.04799 227.0878\n",
      "98.97168 227.0878 372.59424 1.0\n",
      "FOLD 1565\n",
      "train [41.16783142089844, 6.53124475479126]\n",
      "val [48.0175895690918, 6.661130905151367]\n",
      "predict val...\n",
      "predict test...\n",
      "141.64311 233.87465\n",
      "133.97986 233.87465 401.4414 1.0\n",
      "FOLD 1566\n",
      "train [40.49754333496094, 6.517758369445801]\n",
      "val [45.97551345825195, 6.679165840148926]\n",
      "predict val...\n",
      "predict test...\n",
      "136.14893 247.3494\n",
      "153.578 247.3494 330.47754 1.0\n",
      "FOLD 1567\n",
      "train [41.703468322753906, 6.545899391174316]\n",
      "val [44.61285400390625, 6.65172815322876]\n",
      "predict val...\n",
      "predict test...\n",
      "127.69274 246.88768\n",
      "156.12512 246.88768 394.69287 1.0\n",
      "FOLD 1568\n",
      "train [39.038177490234375, 6.47475528717041]\n",
      "val [55.644874572753906, 6.6836042404174805]\n",
      "predict val...\n",
      "predict test...\n",
      "160.73042 227.67583\n",
      "155.28308 227.67583 296.79492 1.0\n",
      "FOLD 1569\n",
      "train [43.0833740234375, 6.58231258392334]\n",
      "val [41.528865814208984, 6.47989559173584]\n",
      "predict val...\n",
      "predict test...\n",
      "124.61295 227.3362\n",
      "114.650024 227.3362 345.49902 1.0\n",
      "FOLD 1570\n",
      "train [41.49311065673828, 6.537315368652344]\n",
      "val [48.39863204956055, 6.662441730499268]\n",
      "predict val...\n",
      "predict test...\n",
      "143.52675 234.77016\n",
      "166.84998 234.77016 326.2578 1.0\n",
      "FOLD 1571\n",
      "train [39.74501037597656, 6.5109124183654785]\n",
      "val [46.959251403808594, 6.84616756439209]\n",
      "predict val...\n",
      "predict test...\n",
      "136.82594 248.75708\n",
      "83.61865 248.75708 318.55664 1.0\n",
      "FOLD 1572\n",
      "train [38.91004180908203, 6.481245517730713]\n",
      "val [44.54927062988281, 6.55466365814209]\n",
      "predict val...\n",
      "predict test...\n",
      "129.26273 237.55975\n",
      "152.6648 237.55975 287.44092 1.0\n",
      "FOLD 1573\n",
      "train [38.11794662475586, 6.4488205909729]\n",
      "val [56.935630798339844, 6.712044715881348]\n",
      "predict val...\n",
      "predict test...\n",
      "164.30711 223.47903\n",
      "105.211914 223.47903 294.91016 1.0\n",
      "FOLD 1574\n",
      "train [42.531402587890625, 6.567568778991699]\n",
      "val [41.26189422607422, 6.480311393737793]\n",
      "predict val...\n",
      "predict test...\n",
      "124.38609 227.31291\n",
      "108.84424 227.31291 344.53125 1.0\n",
      "FOLD 1575\n",
      "train [40.605674743652344, 6.514395236968994]\n",
      "val [50.46403503417969, 6.719535827636719]\n",
      "predict val...\n",
      "predict test...\n",
      "148.35944 231.91689\n",
      "141.14014 231.91689 310.01465 1.0\n",
      "FOLD 1576\n",
      "train [41.93741989135742, 6.550898551940918]\n",
      "val [46.598350524902344, 6.750260829925537]\n",
      "predict val...\n",
      "predict test...\n",
      "137.62204 253.93982\n",
      "174.66699 253.93982 338.35596 1.0\n",
      "FOLD 1577\n",
      "train [40.87509536743164, 6.540430545806885]\n",
      "val [53.61756896972656, 7.068002700805664]\n",
      "predict val...\n",
      "predict test...\n",
      "152.41327 249.2912\n",
      "161.01978 249.2912 367.94287 1.0\n",
      "FOLD 1578\n",
      "train [38.752906799316406, 6.45464563369751]\n",
      "val [55.80048751831055, 6.743302345275879]\n",
      "predict val...\n",
      "predict test...\n",
      "161.18556 219.62729\n",
      "66.75952 219.62729 280.81396 1.0\n",
      "FOLD 1579\n",
      "train [42.41703414916992, 6.571314334869385]\n",
      "val [41.628684997558594, 6.508833885192871]\n",
      "predict val...\n",
      "predict test...\n",
      "126.306366 236.48872\n",
      "151.47821 236.48872 297.0896 1.0\n",
      "FOLD 1580\n",
      "train [40.384334564208984, 6.512754917144775]\n",
      "val [48.76908493041992, 6.703168869018555]\n",
      "predict val...\n",
      "predict test...\n",
      "143.59978 233.59639\n",
      "138.66943 233.59639 312.2036 1.0\n",
      "FOLD 1581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [41.66191864013672, 6.547392845153809]\n",
      "val [47.16461181640625, 6.744616508483887]\n",
      "predict val...\n",
      "predict test...\n",
      "139.12834 255.82706\n",
      "163.33691 255.82706 344.40332 1.0\n",
      "FOLD 1582\n",
      "train [41.515480041503906, 6.539585113525391]\n",
      "val [44.40576934814453, 6.63056755065918]\n",
      "predict val...\n",
      "predict test...\n",
      "127.515434 245.79947\n",
      "159.11255 245.79947 384.60498 1.0\n",
      "FOLD 1583\n",
      "train [38.33953857421875, 6.451912879943848]\n",
      "val [55.434146881103516, 6.695674896240234]\n",
      "predict val...\n",
      "predict test...\n",
      "160.00377 229.11546\n",
      "129.55322 229.11546 310.15283 1.0\n",
      "FOLD 1584\n",
      "train [42.99165344238281, 6.587180137634277]\n",
      "val [41.03948974609375, 6.485852241516113]\n",
      "predict val...\n",
      "predict test...\n",
      "125.27292 236.06699\n",
      "152.22693 236.06699 321.47217 1.0\n",
      "FOLD 1585\n",
      "train [40.17961883544922, 6.49749755859375]\n",
      "val [51.004852294921875, 6.793404579162598]\n",
      "predict val...\n",
      "predict test...\n",
      "150.38232 235.20453\n",
      "39.15576 235.20453 370.05872 1.0\n",
      "FOLD 1586\n",
      "train [39.81644058227539, 6.503498077392578]\n",
      "val [44.291725158691406, 6.535831451416016]\n",
      "predict val...\n",
      "predict test...\n",
      "130.41043 238.26624\n",
      "43.242676 238.26624 349.73706 1.0\n",
      "FOLD 1587\n",
      "train [38.6900634765625, 6.4674224853515625]\n",
      "val [46.55651092529297, 6.664606094360352]\n",
      "predict val...\n",
      "predict test...\n",
      "135.42474 235.71837\n",
      "126.09216 235.71837 309.1621 1.0\n",
      "FOLD 1588\n",
      "train [38.709068298339844, 6.462011814117432]\n",
      "val [54.49649429321289, 6.684512138366699]\n",
      "predict val...\n",
      "predict test...\n",
      "158.33781 226.16388\n",
      "135.41309 226.16388 288.7041 1.0\n",
      "FOLD 1589\n",
      "train [40.089141845703125, 6.509619235992432]\n",
      "val [41.049644470214844, 6.45737361907959]\n",
      "predict val...\n",
      "predict test...\n",
      "122.28662 224.77095\n",
      "122.59277 224.77095 286.1975 1.0\n",
      "FOLD 1590\n",
      "train [39.646934509277344, 6.510007381439209]\n",
      "val [48.30797576904297, 6.702742099761963]\n",
      "predict val...\n",
      "predict test...\n",
      "143.30963 230.4061\n",
      "159.94055 230.4061 303.86768 1.0\n",
      "FOLD 1591\n",
      "train [40.52550506591797, 6.514662742614746]\n",
      "val [46.05819320678711, 6.763054847717285]\n",
      "predict val...\n",
      "predict test...\n",
      "134.70789 245.05705\n",
      "116.82349 245.05705 324.96875 1.0\n",
      "FOLD 1592\n",
      "train [39.2783088684082, 6.485785484313965]\n",
      "val [44.47148895263672, 6.62587833404541]\n",
      "predict val...\n",
      "predict test...\n",
      "128.79039 227.43231\n",
      "138.18091 227.43231 280.85767 1.0\n",
      "FOLD 1593\n",
      "train [38.22317123413086, 6.438016414642334]\n",
      "val [53.367767333984375, 6.661408424377441]\n",
      "predict val...\n",
      "predict test...\n",
      "156.14488 229.19086\n",
      "67.571045 229.19086 349.9109 1.0\n",
      "FOLD 1594\n",
      "train [42.000511169433594, 6.554445743560791]\n",
      "val [41.70423889160156, 6.532029628753662]\n",
      "predict val...\n",
      "predict test...\n",
      "123.900604 247.77509\n",
      "113.7793 247.77509 385.1328 1.0\n",
      "FOLD 1595\n",
      "train [41.5133171081543, 6.542072296142578]\n",
      "val [48.148311614990234, 6.670992851257324]\n",
      "predict val...\n",
      "predict test...\n",
      "141.88002 239.52242\n",
      "142.60498 239.52242 358.35938 1.0\n",
      "FOLD 1596\n",
      "train [38.97909164428711, 6.481207847595215]\n",
      "val [45.642799377441406, 6.650543689727783]\n",
      "predict val...\n",
      "predict test...\n",
      "134.78036 230.44635\n",
      "130.0476 230.44635 289.55518 1.0\n",
      "FOLD 1597\n",
      "train [41.37240219116211, 6.535965919494629]\n",
      "val [44.5267219543457, 6.614754676818848]\n",
      "predict val...\n",
      "predict test...\n",
      "128.3428 242.18463\n",
      "171.72351 242.18463 340.84375 1.0\n",
      "FOLD 1598\n",
      "train [38.08154296875, 6.4459991455078125]\n",
      "val [55.22500228881836, 6.68687629699707]\n",
      "predict val...\n",
      "predict test...\n",
      "160.59709 229.34578\n",
      "138.82935 229.34578 340.1526 1.0\n",
      "FOLD 1599\n",
      "train [41.13508224487305, 6.524890899658203]\n",
      "val [41.00979995727539, 6.476795196533203]\n",
      "predict val...\n",
      "predict test...\n",
      "123.682335 230.65785\n",
      "98.298096 230.65785 318.96338 1.0\n",
      "FOLD 1600\n",
      "train [40.600711822509766, 6.506749153137207]\n",
      "val [50.75277328491211, 6.752474308013916]\n",
      "predict val...\n",
      "predict test...\n",
      "148.97473 230.81998\n",
      "74.151855 230.81998 345.47534 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1601\n",
      "train [29.09554672241211, 6.558140754699707]\n",
      "val [31.882911682128906, 6.749424934387207]\n",
      "predict val...\n",
      "predict test...\n",
      "138.01285 243.52515\n",
      "118.22217 243.52515 423.85156 1.0\n",
      "FOLD 1602\n",
      "train [29.11680030822754, 6.554746150970459]\n",
      "val [29.572864532470703, 6.578397274017334]\n",
      "predict val...\n",
      "predict test...\n",
      "122.74672 241.62032\n",
      "139.35095 241.62032 404.14795 1.0\n",
      "FOLD 1603\n",
      "train [27.764347076416016, 6.4949140548706055]\n",
      "val [35.84280776977539, 6.670628547668457]\n",
      "predict val...\n",
      "predict test...\n",
      "154.4032 226.53323\n",
      "133.67554 226.53323 384.54785 1.0\n",
      "FOLD 1604\n",
      "train [29.946794509887695, 6.6019182205200195]\n",
      "val [29.26881217956543, 6.512923717498779]\n",
      "predict val...\n",
      "predict test...\n",
      "127.722275 233.0282\n",
      "94.14276 233.0282 385.5498 1.0\n",
      "FOLD 1605\n",
      "train [28.36894416809082, 6.524861812591553]\n",
      "val [32.87200927734375, 6.667133808135986]\n",
      "predict val...\n",
      "predict test...\n",
      "143.57756 221.46396\n",
      "122.16333 221.46396 351.81934 1.0\n",
      "FOLD 1606\n",
      "train [28.413043975830078, 6.546451568603516]\n",
      "val [32.43666458129883, 6.78855562210083]\n",
      "predict val...\n",
      "predict test...\n",
      "140.76178 255.81438\n",
      "137.66577 255.81438 413.63916 1.0\n",
      "FOLD 1607\n",
      "train [28.847211837768555, 6.55014181137085]\n",
      "val [30.58147430419922, 6.600574970245361]\n",
      "predict val...\n",
      "predict test...\n",
      "128.05533 243.20876\n",
      "158.06311 243.20876 364.7627 1.0\n",
      "FOLD 1608\n",
      "train [27.463838577270508, 6.487822532653809]\n",
      "val [37.488975524902344, 6.684859275817871]\n",
      "predict val...\n",
      "predict test...\n",
      "162.05614 224.18602\n",
      "141.57092 224.18602 348.98096 1.0\n",
      "FOLD 1609\n",
      "train [29.433364868164062, 6.586550712585449]\n",
      "val [29.01852035522461, 6.500521659851074]\n",
      "predict val...\n",
      "predict test...\n",
      "126.83416 225.65485\n",
      "91.829956 225.65485 371.60645 1.0\n",
      "FOLD 1610\n",
      "train [28.335376739501953, 6.518521308898926]\n",
      "val [31.839061737060547, 6.662480354309082]\n",
      "predict val...\n",
      "predict test...\n",
      "138.07349 216.7973\n",
      "139.1742 216.7973 303.08838 1.0\n",
      "FOLD 1611\n",
      "train [28.3968505859375, 6.5416717529296875]\n",
      "val [31.412303924560547, 6.688403129577637]\n",
      "predict val...\n",
      "predict test...\n",
      "137.46284 253.04764\n",
      "154.51709 253.04764 360.25977 1.0\n",
      "FOLD 1612\n",
      "train [28.12175178527832, 6.528534889221191]\n",
      "val [29.377010345458984, 6.606922149658203]\n",
      "predict val...\n",
      "predict test...\n",
      "126.560974 240.74942\n",
      "176.45593 240.74942 337.91992 1.0\n",
      "FOLD 1613\n",
      "train [27.09453582763672, 6.486329555511475]\n",
      "val [36.245731353759766, 6.690419673919678]\n",
      "predict val...\n",
      "predict test...\n",
      "156.21822 232.24246\n",
      "151.01709 232.24246 332.09912 1.0\n",
      "FOLD 1614\n",
      "train [30.096542358398438, 6.608405113220215]\n",
      "val [29.217802047729492, 6.513484001159668]\n",
      "predict val...\n",
      "predict test...\n",
      "128.26398 240.68689\n",
      "124.891846 240.68689 347.05176 1.0\n",
      "FOLD 1615\n",
      "train [28.234527587890625, 6.5344085693359375]\n",
      "val [36.74873352050781, 6.754125595092773]\n",
      "predict val...\n",
      "predict test...\n",
      "160.62314 233.19183\n",
      "166.31702 233.19183 320.37793 1.0\n",
      "FOLD 1616\n",
      "train [28.34843635559082, 6.534802436828613]\n",
      "val [31.745927810668945, 6.733696937561035]\n",
      "predict val...\n",
      "predict test...\n",
      "137.05298 246.40575\n",
      "175.74927 246.40575 314.146 1.0\n",
      "FOLD 1617\n",
      "train [27.67803382873535, 6.506031036376953]\n",
      "val [30.07178497314453, 6.61959981918335]\n",
      "predict val...\n",
      "predict test...\n",
      "127.85655 229.19397\n",
      "149.68872 229.19397 303.19482 1.0\n",
      "FOLD 1618\n",
      "train [26.33566665649414, 6.450112342834473]\n",
      "val [36.791908264160156, 6.679530620574951]\n",
      "predict val...\n",
      "predict test...\n",
      "157.58492 230.95125\n",
      "125.866455 230.95125 296.86963 1.0\n",
      "FOLD 1619\n",
      "train [29.706668853759766, 6.5874924659729]\n",
      "val [28.268945693969727, 6.491873264312744]\n",
      "predict val...\n",
      "predict test...\n",
      "125.065834 237.79715\n",
      "143.76685 237.79715 344.55127 1.0\n",
      "FOLD 1620\n",
      "train [27.927059173583984, 6.530203342437744]\n",
      "val [34.7883186340332, 6.711816787719727]\n",
      "predict val...\n",
      "predict test...\n",
      "152.96252 239.4756\n",
      "177.3252 239.4756 332.8379 1.0\n",
      "FOLD 1621\n",
      "train [28.63227081298828, 6.551974296569824]\n",
      "val [31.970022201538086, 6.770545482635498]\n",
      "predict val...\n",
      "predict test...\n",
      "138.82877 253.95323\n",
      "176.6073 253.95323 337.45264 1.0\n",
      "FOLD 1622\n",
      "train [28.498098373413086, 6.546170234680176]\n",
      "val [30.164939880371094, 6.594350814819336]\n",
      "predict val...\n",
      "predict test...\n",
      "126.5371 249.37717\n",
      "168.67053 249.37717 373.24512 1.0\n",
      "FOLD 1623\n",
      "train [26.421205520629883, 6.456149101257324]\n",
      "val [38.674598693847656, 6.756915092468262]\n",
      "predict val...\n",
      "predict test...\n",
      "166.9308 225.2726\n",
      "87.995605 225.2726 283.64795 1.0\n",
      "FOLD 1624\n",
      "train [29.490890502929688, 6.5769362449646]\n",
      "val [28.048757553100586, 6.478374481201172]\n",
      "predict val...\n",
      "predict test...\n",
      "123.92959 232.17287\n",
      "136.22314 232.17287 321.05347 1.0\n",
      "FOLD 1625\n",
      "train [27.810331344604492, 6.519472599029541]\n",
      "val [34.415931701660156, 6.700160980224609]\n",
      "predict val...\n",
      "predict test...\n",
      "148.3898 226.4461\n",
      "162.58545 226.4461 310.6582 1.0\n",
      "FOLD 1626\n",
      "train [27.783903121948242, 6.510939121246338]\n",
      "val [30.989648818969727, 6.695758819580078]\n",
      "predict val...\n",
      "predict test...\n",
      "133.087 235.91014\n",
      "82.17432 235.91014 343.47437 1.0\n",
      "FOLD 1627\n",
      "train [28.27057456970215, 6.537206172943115]\n",
      "val [31.35559844970703, 6.679878234863281]\n",
      "predict val...\n",
      "predict test...\n",
      "133.53621 246.84787\n",
      "172.78796 246.84787 340.42822 1.0\n",
      "FOLD 1628\n",
      "train [26.028635025024414, 6.432711124420166]\n",
      "val [38.09586715698242, 6.693902015686035]\n",
      "predict val...\n",
      "predict test...\n",
      "164.22844 219.44824\n",
      "113.125244 219.44824 301.1543 1.0\n",
      "FOLD 1629\n",
      "train [29.20485496520996, 6.571237087249756]\n",
      "val [28.095670700073242, 6.482086658477783]\n",
      "predict val...\n",
      "predict test...\n",
      "123.66919 239.06245\n",
      "163.88788 239.06245 297.03882 1.0\n",
      "FOLD 1630\n",
      "train [27.370349884033203, 6.4890313148498535]\n",
      "val [35.8853874206543, 6.816643714904785]\n",
      "predict val...\n",
      "predict test...\n",
      "155.78885 227.11655\n",
      "45.481934 227.11655 348.79883 1.0\n",
      "FOLD 1631\n",
      "train [27.229982376098633, 6.484504699707031]\n",
      "val [31.361209869384766, 6.674166679382324]\n",
      "predict val...\n",
      "predict test...\n",
      "135.2053 223.3696\n",
      "132.79053 223.3696 305.55933 1.0\n",
      "FOLD 1632\n",
      "train [28.303380966186523, 6.53555965423584]\n",
      "val [30.556249618530273, 6.579110145568848]\n",
      "predict val...\n",
      "predict test...\n",
      "127.85053 244.6175\n",
      "163.71106 244.6175 350.32764 1.0\n",
      "FOLD 1633\n",
      "train [25.44696617126465, 6.3945207595825195]\n",
      "val [37.96125793457031, 6.699892044067383]\n",
      "predict val...\n",
      "predict test...\n",
      "162.09383 209.19809\n",
      "106.980225 209.19809 281.59863 1.0\n",
      "FOLD 1634\n",
      "train [28.738996505737305, 6.542610168457031]\n",
      "val [28.1251277923584, 6.472894191741943]\n",
      "predict val...\n",
      "predict test...\n",
      "122.67289 238.68852\n",
      "102.020996 238.68852 317.34473 1.0\n",
      "FOLD 1635\n",
      "train [27.938438415527344, 6.513725280761719]\n",
      "val [33.67161560058594, 6.69032096862793]\n",
      "predict val...\n",
      "predict test...\n",
      "147.2037 231.46231\n",
      "166.78369 231.46231 316.29395 1.0\n",
      "FOLD 1636\n",
      "train [26.37852668762207, 6.442590236663818]\n",
      "val [30.1186466217041, 6.525997638702393]\n",
      "predict val...\n",
      "predict test...\n",
      "130.2019 218.04512\n",
      "77.8772 218.04512 360.8213 1.0\n",
      "FOLD 1637\n",
      "train [28.135986328125, 6.538592338562012]\n",
      "val [30.65773582458496, 6.602961540222168]\n",
      "predict val...\n",
      "predict test...\n",
      "129.52785 246.89272\n",
      "162.30469 246.89272 358.4126 1.0\n",
      "FOLD 1638\n",
      "train [25.6547794342041, 6.400380611419678]\n",
      "val [37.629154205322266, 6.712485313415527]\n",
      "predict val...\n",
      "predict test...\n",
      "162.09483 208.9134\n",
      "66.64795 208.9134 304.79932 1.0\n",
      "FOLD 1639\n",
      "train [28.844646453857422, 6.551424503326416]\n",
      "val [28.267301559448242, 6.491747856140137]\n",
      "predict val...\n",
      "predict test...\n",
      "124.4162 228.7189\n",
      "146.6098 228.7189 302.12744 1.0\n",
      "FOLD 1640\n",
      "train [28.111570358276367, 6.511612892150879]\n",
      "val [33.46811294555664, 6.703324317932129]\n",
      "predict val...\n",
      "predict test...\n",
      "146.15648 231.29094\n",
      "115.94849 231.29094 329.0027 1.0\n",
      "FOLD 1641\n",
      "train [27.0306453704834, 6.4907660484313965]\n",
      "val [31.637672424316406, 6.83245849609375]\n",
      "predict val...\n",
      "predict test...\n",
      "136.55887 238.97093\n",
      "78.04224 238.97093 317.5625 1.0\n",
      "FOLD 1642\n",
      "train [27.284500122070312, 6.489202976226807]\n",
      "val [31.770313262939453, 6.69092321395874]\n",
      "predict val...\n",
      "predict test...\n",
      "135.22256 224.31377\n",
      "145.09875 224.31377 306.3838 1.0\n",
      "FOLD 1643\n",
      "train [26.636138916015625, 6.456123352050781]\n",
      "val [36.10974884033203, 6.680380821228027]\n",
      "predict val...\n",
      "predict test...\n",
      "156.25418 222.88658\n",
      "138.43018 222.88658 283.68872 1.0\n",
      "FOLD 1644\n",
      "train [28.05143928527832, 6.526650428771973]\n",
      "val [28.068391799926758, 6.440675735473633]\n",
      "predict val...\n",
      "predict test...\n",
      "121.92938 231.11003\n",
      "44.63672 231.11003 328.13428 1.0\n",
      "FOLD 1645\n",
      "train [26.99040985107422, 6.482332706451416]\n",
      "val [31.990814208984375, 6.719552993774414]\n",
      "predict val...\n",
      "predict test...\n",
      "138.0827 233.45248\n",
      "43.00708 233.45248 360.85742 1.0\n",
      "FOLD 1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [26.1258487701416, 6.452471733093262]\n",
      "val [30.15543556213379, 6.565322399139404]\n",
      "predict val...\n",
      "predict test...\n",
      "129.1974 226.76573\n",
      "126.55176 226.76573 289.68994 1.0\n",
      "FOLD 1647\n",
      "train [28.090158462524414, 6.522883415222168]\n",
      "val [30.050628662109375, 6.541067123413086]\n",
      "predict val...\n",
      "predict test...\n",
      "128.13934 242.38164\n",
      "140.32214 242.38164 330.00342 1.0\n",
      "FOLD 1648\n",
      "train [25.99022102355957, 6.406493186950684]\n",
      "val [36.225589752197266, 6.701535224914551]\n",
      "predict val...\n",
      "predict test...\n",
      "155.90038 210.90637\n",
      "59.99414 210.90637 315.25 1.0\n",
      "FOLD 1649\n",
      "train [28.71791648864746, 6.554293632507324]\n",
      "val [27.524791717529297, 6.487452507019043]\n",
      "predict val...\n",
      "predict test...\n",
      "120.15116 244.84622\n",
      "107.701904 244.84622 400.0337 1.0\n",
      "FOLD 1650\n",
      "train [26.967235565185547, 6.460801601409912]\n",
      "val [33.57652282714844, 6.788131237030029]\n",
      "predict val...\n",
      "predict test...\n",
      "143.33975 243.99445\n",
      "90.77612 243.99445 584.10693 1.0\n",
      "FOLD 1651\n",
      "train [33.304203033447266, 6.557913303375244]\n",
      "val [37.49884796142578, 6.77531623840332]\n",
      "predict val...\n",
      "predict test...\n",
      "140.31084 252.44641\n",
      "125.854126 252.44641 434.792 1.0\n",
      "FOLD 1652\n",
      "train [33.8093147277832, 6.568978786468506]\n",
      "val [34.42170715332031, 6.588818550109863]\n",
      "predict val...\n",
      "predict test...\n",
      "123.26261 252.7389\n",
      "146.41675 252.7389 420.03906 1.0\n",
      "FOLD 1653\n",
      "train [32.192909240722656, 6.511526584625244]\n",
      "val [41.59332275390625, 6.681924819946289]\n",
      "predict val...\n",
      "predict test...\n",
      "155.608 237.733\n",
      "131.51965 237.733 484.84912 1.0\n",
      "FOLD 1654\n",
      "train [34.58841323852539, 6.601320743560791]\n",
      "val [33.282718658447266, 6.5000786781311035]\n",
      "predict val...\n",
      "predict test...\n",
      "125.756805 231.41832\n",
      "92.395996 231.41832 382.2539 1.0\n",
      "FOLD 1655\n",
      "train [32.94184112548828, 6.546200752258301]\n",
      "val [38.499691009521484, 6.693922996520996]\n",
      "predict val...\n",
      "predict test...\n",
      "145.55309 238.03326\n",
      "120.20154 238.03326 403.2207 1.0\n",
      "FOLD 1656\n",
      "train [32.06320571899414, 6.517971038818359]\n",
      "val [36.69660568237305, 6.737128257751465]\n",
      "predict val...\n",
      "predict test...\n",
      "137.78137 243.1107\n",
      "159.27136 243.1107 335.8169 1.0\n",
      "FOLD 1657\n",
      "train [32.88241195678711, 6.538305759429932]\n",
      "val [36.322547912597656, 6.611905574798584]\n",
      "predict val...\n",
      "predict test...\n",
      "131.1287 241.33759\n",
      "143.28235 241.33759 395.11328 1.0\n",
      "FOLD 1658\n",
      "train [30.93941879272461, 6.457706451416016]\n",
      "val [43.226966857910156, 6.6632843017578125]\n",
      "predict val...\n",
      "predict test...\n",
      "161.15965 217.1843\n",
      "116.49072 217.1843 414.35742 1.0\n",
      "FOLD 1659\n",
      "train [34.637489318847656, 6.603832244873047]\n",
      "val [32.58665084838867, 6.481556415557861]\n",
      "predict val...\n",
      "predict test...\n",
      "121.78697 235.43541\n",
      "103.68591 235.43541 373.82715 1.0\n",
      "FOLD 1660\n",
      "train [33.1947135925293, 6.539759159088135]\n",
      "val [38.15055465698242, 6.6811842918396]\n",
      "predict val...\n",
      "predict test...\n",
      "143.22453 227.45961\n",
      "135.60449 227.45961 331.6045 1.0\n",
      "FOLD 1661\n",
      "train [33.07857894897461, 6.544976234436035]\n",
      "val [37.323543548583984, 6.736473083496094]\n",
      "predict val...\n",
      "predict test...\n",
      "140.09265 246.06635\n",
      "119.694824 246.06635 423.00098 1.0\n",
      "FOLD 1662\n",
      "train [33.272491455078125, 6.558973789215088]\n",
      "val [34.472373962402344, 6.6268463134765625]\n",
      "predict val...\n",
      "predict test...\n",
      "125.37696 251.97443\n",
      "159.12622 251.97443 410.8374 1.0\n",
      "FOLD 1663\n",
      "train [30.939504623413086, 6.480673313140869]\n",
      "val [42.04920196533203, 6.700003623962402]\n",
      "predict val...\n",
      "predict test...\n",
      "155.56744 233.1564\n",
      "138.85693 233.1564 307.1797 1.0\n",
      "FOLD 1664\n",
      "train [34.91124725341797, 6.608705043792725]\n",
      "val [34.10566711425781, 6.516927719116211]\n",
      "predict val...\n",
      "predict test...\n",
      "128.16502 237.32812\n",
      "115.01434 237.32812 370.32764 1.0\n",
      "FOLD 1665\n",
      "train [32.743961334228516, 6.541520595550537]\n",
      "val [38.432594299316406, 6.672876358032227]\n",
      "predict val...\n",
      "predict test...\n",
      "143.99529 235.87637\n",
      "158.96533 235.87637 314.94727 1.0\n",
      "FOLD 1666\n",
      "train [32.71475601196289, 6.531627655029297]\n",
      "val [37.66340255737305, 6.7847113609313965]\n",
      "predict val...\n",
      "predict test...\n",
      "141.1127 247.22832\n",
      "169.64282 247.22832 340.66846 1.0\n",
      "FOLD 1667\n",
      "train [33.15767288208008, 6.549943447113037]\n",
      "val [34.34467697143555, 6.602651596069336]\n",
      "predict val...\n",
      "predict test...\n",
      "124.63542 246.88068\n",
      "152.87634 246.88068 396.5166 1.0\n",
      "FOLD 1668\n",
      "train [30.40595054626465, 6.467164516448975]\n",
      "val [44.41709899902344, 6.757077217102051]\n",
      "predict val...\n",
      "predict test...\n",
      "165.59589 232.98564\n",
      "84.09326 232.98564 302.24023 1.0\n",
      "FOLD 1669\n",
      "train [33.131866455078125, 6.556249141693115]\n",
      "val [33.002105712890625, 6.470084190368652]\n",
      "predict val...\n",
      "predict test...\n",
      "125.574844 223.34402\n",
      "112.77936 223.34402 327.9702 1.0\n",
      "FOLD 1670\n",
      "train [32.151241302490234, 6.532807350158691]\n",
      "val [39.378150939941406, 6.714311599731445]\n",
      "predict val...\n",
      "predict test...\n",
      "148.5075 237.29372\n",
      "160.71338 237.29372 328.34375 1.0\n",
      "FOLD 1671\n",
      "train [32.641544342041016, 6.533094882965088]\n",
      "val [37.74187088012695, 6.809861183166504]\n",
      "predict val...\n",
      "predict test...\n",
      "140.34569 247.03229\n",
      "143.79517 247.03229 369.6162 1.0\n",
      "FOLD 1672\n",
      "train [33.37899398803711, 6.5657758712768555]\n",
      "val [34.45094299316406, 6.610825538635254]\n",
      "predict val...\n",
      "predict test...\n",
      "125.175896 253.84708\n",
      "165.37268 253.84708 394.29297 1.0\n",
      "FOLD 1673\n",
      "train [30.168363571166992, 6.441157341003418]\n",
      "val [42.976531982421875, 6.700125694274902]\n",
      "predict val...\n",
      "predict test...\n",
      "158.90506 220.54547\n",
      "110.746826 220.54547 293.63184 1.0\n",
      "FOLD 1674\n",
      "train [33.77739715576172, 6.5695085525512695]\n",
      "val [31.78496551513672, 6.4833149909973145]\n",
      "predict val...\n",
      "predict test...\n",
      "121.58441 234.48196\n",
      "148.29193 234.48196 314.1306 1.0\n",
      "FOLD 1675\n",
      "train [32.39674377441406, 6.514932155609131]\n",
      "val [39.67782211303711, 6.692493438720703]\n",
      "predict val...\n",
      "predict test...\n",
      "147.73155 224.73824\n",
      "164.78796 224.73824 332.85352 1.0\n",
      "FOLD 1676\n",
      "train [31.104549407958984, 6.47647762298584]\n",
      "val [37.26982879638672, 6.699322700500488]\n",
      "predict val...\n",
      "predict test...\n",
      "138.28159 227.41577\n",
      "95.23828 227.41577 320.56372 1.0\n",
      "FOLD 1677\n",
      "train [31.80360221862793, 6.493418216705322]\n",
      "val [37.118980407714844, 6.767922401428223]\n",
      "predict val...\n",
      "predict test...\n",
      "136.10245 237.35628\n",
      "137.30017 237.35628 371.729 1.0\n",
      "FOLD 1678\n",
      "train [29.681655883789062, 6.428872108459473]\n",
      "val [45.177188873291016, 6.705679893493652]\n",
      "predict val...\n",
      "predict test...\n",
      "166.82631 220.64105\n",
      "124.03247 220.64105 273.19556 1.0\n",
      "FOLD 1679\n",
      "train [33.143585205078125, 6.5423583984375]\n",
      "val [32.549861907958984, 6.49739933013916]\n",
      "predict val...\n",
      "predict test...\n",
      "124.12052 234.48708\n",
      "136.91797 234.48708 314.78955 1.0\n",
      "FOLD 1680\n",
      "train [32.051902770996094, 6.518559455871582]\n",
      "val [40.571529388427734, 6.723755359649658]\n",
      "predict val...\n",
      "predict test...\n",
      "153.6566 234.93355\n",
      "170.5542 234.93355 331.67114 1.0\n",
      "FOLD 1681\n",
      "train [31.912487030029297, 6.517397403717041]\n",
      "val [36.907196044921875, 6.764226913452148]\n",
      "predict val...\n",
      "predict test...\n",
      "137.41301 242.19824\n",
      "119.618164 242.19824 330.99854 1.0\n",
      "FOLD 1682\n",
      "train [30.26336097717285, 6.455227851867676]\n",
      "val [39.86701583862305, 6.8719482421875]\n",
      "predict val...\n",
      "predict test...\n",
      "146.44252 229.15689\n",
      "123.749146 229.15689 300.4619 1.0\n",
      "FOLD 1683\n",
      "train [29.949342727661133, 6.4147820472717285]\n",
      "val [42.74552917480469, 6.698030471801758]\n",
      "predict val...\n",
      "predict test...\n",
      "157.55724 215.15416\n",
      "74.57361 215.15416 312.50903 1.0\n",
      "FOLD 1684\n",
      "train [31.108999252319336, 6.498177528381348]\n",
      "val [32.60329055786133, 6.45712423324585]\n",
      "predict val...\n",
      "predict test...\n",
      "121.608955 231.24265\n",
      "102.63794 231.24265 327.07642 1.0\n",
      "FOLD 1685\n",
      "train [31.45363998413086, 6.500002861022949]\n",
      "val [38.225181579589844, 6.721825122833252]\n",
      "predict val...\n",
      "predict test...\n",
      "143.76028 232.76288\n",
      "100.43384 232.76288 295.30957 1.0\n",
      "FOLD 1686\n",
      "train [32.767032623291016, 6.540163516998291]\n",
      "val [36.86300277709961, 6.734811782836914]\n",
      "predict val...\n",
      "predict test...\n",
      "138.21902 250.8832\n",
      "163.56323 250.8832 335.46143 1.0\n",
      "FOLD 1687\n",
      "train [32.6994743347168, 6.544142246246338]\n",
      "val [34.66250228881836, 6.5962419509887695]\n",
      "predict val...\n",
      "predict test...\n",
      "127.61924 252.56606\n",
      "161.67676 252.56606 403.89648 1.0\n",
      "FOLD 1688\n",
      "train [30.332664489746094, 6.436212062835693]\n",
      "val [43.14167022705078, 6.655716419219971]\n",
      "predict val...\n",
      "predict test...\n",
      "159.51247 223.5756\n",
      "109.3938 223.5756 354.54785 1.0\n",
      "FOLD 1689\n",
      "train [33.559776306152344, 6.558723449707031]\n",
      "val [32.40629959106445, 6.469173908233643]\n",
      "predict val...\n",
      "predict test...\n",
      "123.53256 225.1365\n",
      "121.726074 225.1365 302.0913 1.0\n",
      "FOLD 1690\n",
      "train [31.721193313598633, 6.498626708984375]\n",
      "val [38.29452133178711, 6.745474815368652]\n",
      "predict val...\n",
      "predict test...\n",
      "142.50075 228.2934\n",
      "50.698242 228.2934 303.75244 1.0\n",
      "FOLD 1691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [30.799427032470703, 6.471972465515137]\n",
      "val [37.122188568115234, 6.7532196044921875]\n",
      "predict val...\n",
      "predict test...\n",
      "136.98155 231.10251\n",
      "78.44165 231.10251 367.3877 1.0\n",
      "FOLD 1692\n",
      "train [33.28466796875, 6.5513739585876465]\n",
      "val [34.84676742553711, 6.619302749633789]\n",
      "predict val...\n",
      "predict test...\n",
      "126.560875 245.23354\n",
      "163.22144 245.23354 386.44775 1.0\n",
      "FOLD 1693\n",
      "train [28.624048233032227, 6.387317180633545]\n",
      "val [44.91830062866211, 6.714998722076416]\n",
      "predict val...\n",
      "predict test...\n",
      "165.30894 211.69545\n",
      "63.83191 211.69545 300.34253 1.0\n",
      "FOLD 1694\n",
      "train [31.575956344604492, 6.49838924407959]\n",
      "val [31.38968276977539, 6.405426979064941]\n",
      "predict val...\n",
      "predict test...\n",
      "118.85528 224.82808\n",
      "53.159912 224.82808 301.54492 1.0\n",
      "FOLD 1695\n",
      "train [31.309803009033203, 6.483786106109619]\n",
      "val [40.27942657470703, 6.779481887817383]\n",
      "predict val...\n",
      "predict test...\n",
      "150.33168 236.66006\n",
      "58.816406 236.66006 352.7788 1.0\n",
      "FOLD 1696\n",
      "train [32.19857406616211, 6.49709415435791]\n",
      "val [37.050254821777344, 6.792428016662598]\n",
      "predict val...\n",
      "predict test...\n",
      "137.98491 233.66647\n",
      "67.83447 233.66647 501.2495 1.0\n",
      "FOLD 1697\n",
      "train [32.520259857177734, 6.5277910232543945]\n",
      "val [35.33284378051758, 6.5848283767700195]\n",
      "predict val...\n",
      "predict test...\n",
      "128.40211 237.37198\n",
      "157.24146 237.37198 372.76367 1.0\n",
      "FOLD 1698\n",
      "train [28.312379837036133, 6.36771821975708]\n",
      "val [46.040279388427734, 6.71967887878418]\n",
      "predict val...\n",
      "predict test...\n",
      "170.98114 214.2165\n",
      "61.484863 214.2165 428.636 1.0\n",
      "FOLD 1699\n",
      "train [34.17481994628906, 6.582964897155762]\n",
      "val [32.53399658203125, 6.49146842956543]\n",
      "predict val...\n",
      "predict test...\n",
      "123.555046 238.60902\n",
      "146.88434 238.60902 310.17676 1.0\n",
      "FOLD 1700\n",
      "train [32.26054000854492, 6.51541805267334]\n",
      "val [39.757442474365234, 6.721648216247559]\n",
      "predict val...\n",
      "predict test...\n",
      "150.203 229.17786\n",
      "116.6875 229.17786 321.02563 1.0\n",
      "FOLD 1701\n",
      "train [37.932769775390625, 6.557409763336182]\n",
      "val [41.850303649902344, 6.7363691329956055]\n",
      "predict val...\n",
      "predict test...\n",
      "138.01166 246.41592\n",
      "125.79187 246.41592 421.33545 1.0\n",
      "FOLD 1702\n",
      "train [37.64556884765625, 6.545279502868652]\n",
      "val [39.338958740234375, 6.609068393707275]\n",
      "predict val...\n",
      "predict test...\n",
      "125.50934 242.13385\n",
      "133.90845 242.13385 413.12354 1.0\n",
      "FOLD 1703\n",
      "train [35.935569763183594, 6.493602752685547]\n",
      "val [48.9095344543457, 6.721446514129639]\n",
      "predict val...\n",
      "predict test...\n",
      "161.18094 232.10973\n",
      "109.63904 232.10973 503.4541 1.0\n",
      "FOLD 1704\n",
      "train [39.514495849609375, 6.605287075042725]\n",
      "val [38.03102493286133, 6.510989189147949]\n",
      "predict val...\n",
      "predict test...\n",
      "127.022255 233.72766\n",
      "94.32233 233.72766 383.44873 1.0\n",
      "FOLD 1705\n",
      "train [37.453857421875, 6.543059349060059]\n",
      "val [43.70340347290039, 6.667536735534668]\n",
      "predict val...\n",
      "predict test...\n",
      "145.17162 233.44627\n",
      "138.47754 233.44627 361.6001 1.0\n",
      "FOLD 1706\n",
      "train [37.35099792480469, 6.551828861236572]\n",
      "val [42.411033630371094, 6.762823581695557]\n",
      "predict val...\n",
      "predict test...\n",
      "139.59088 256.02933\n",
      "130.5697 256.02933 430.4839 1.0\n",
      "FOLD 1707\n",
      "train [37.97413635253906, 6.557297706604004]\n",
      "val [40.74736022949219, 6.643149375915527]\n",
      "predict val...\n",
      "predict test...\n",
      "129.71457 246.96117\n",
      "152.41418 246.96117 404.7627 1.0\n",
      "FOLD 1708\n",
      "train [36.40592956542969, 6.4973015785217285]\n",
      "val [49.27890396118164, 6.676239967346191]\n",
      "predict val...\n",
      "predict test...\n",
      "162.08607 225.78674\n",
      "121.36597 225.78674 457.34082 1.0\n",
      "FOLD 1709\n",
      "train [38.068328857421875, 6.566806793212891]\n",
      "val [36.27024459838867, 6.456930637359619]\n",
      "predict val...\n",
      "predict test...\n",
      "120.685524 220.11821\n",
      "96.23169 220.11821 352.6123 1.0\n",
      "FOLD 1710\n",
      "train [37.275299072265625, 6.526917934417725]\n",
      "val [42.07897186279297, 6.6539740562438965]\n",
      "predict val...\n",
      "predict test...\n",
      "139.14177 222.49738\n",
      "146.10327 222.49738 305.73535 1.0\n",
      "FOLD 1711\n",
      "train [36.63558578491211, 6.532011985778809]\n",
      "val [42.47500228881836, 6.718496322631836]\n",
      "predict val...\n",
      "predict test...\n",
      "140.80139 251.11075\n",
      "165.04993 251.11075 332.66797 1.0\n",
      "FOLD 1712\n",
      "train [37.779632568359375, 6.5681586265563965]\n",
      "val [38.704612731933594, 6.622788429260254]\n",
      "predict val...\n",
      "predict test...\n",
      "124.35562 260.57086\n",
      "168.5039 260.57086 405.20508 1.0\n",
      "FOLD 1713\n",
      "train [35.33662033081055, 6.4955644607543945]\n",
      "val [48.36269760131836, 6.6728644371032715]\n",
      "predict val...\n",
      "predict test...\n",
      "157.60551 236.46535\n",
      "161.95251 236.46535 334.7295 1.0\n",
      "FOLD 1714\n",
      "train [39.268611907958984, 6.6041669845581055]\n",
      "val [38.188072204589844, 6.511368751525879]\n",
      "predict val...\n",
      "predict test...\n",
      "126.97141 237.7857\n",
      "106.64911 237.7857 383.05762 1.0\n",
      "FOLD 1715\n",
      "train [37.613380432128906, 6.560978889465332]\n",
      "val [45.5473747253418, 6.705837249755859]\n",
      "predict val...\n",
      "predict test...\n",
      "150.40047 243.78944\n",
      "166.90271 243.78944 349.34253 1.0\n",
      "FOLD 1716\n",
      "train [35.798072814941406, 6.5025811195373535]\n",
      "val [42.15151596069336, 6.750842094421387]\n",
      "predict val...\n",
      "predict test...\n",
      "137.879 239.2449\n",
      "165.13354 239.2449 300.16382 1.0\n",
      "FOLD 1717\n",
      "train [35.36872863769531, 6.48974084854126]\n",
      "val [40.83797073364258, 6.718135356903076]\n",
      "predict val...\n",
      "predict test...\n",
      "132.62122 226.75708\n",
      "152.96045 226.75708 314.11523 1.0\n",
      "FOLD 1718\n",
      "train [35.97490692138672, 6.503456115722656]\n",
      "val [49.2202262878418, 6.673493385314941]\n",
      "predict val...\n",
      "predict test...\n",
      "161.25883 237.68953\n",
      "163.26733 237.68953 321.3457 1.0\n",
      "FOLD 1719\n",
      "train [37.88273239135742, 6.572709560394287]\n",
      "val [37.531463623046875, 6.505893707275391]\n",
      "predict val...\n",
      "predict test...\n",
      "127.21216 240.12009\n",
      "143.20923 240.12009 291.87207 1.0\n",
      "FOLD 1720\n",
      "train [35.27136993408203, 6.487334251403809]\n",
      "val [45.50115203857422, 6.732578277587891]\n",
      "predict val...\n",
      "predict test...\n",
      "149.13449 234.50206\n",
      "91.44043 234.50206 348.01587 1.0\n",
      "FOLD 1721\n",
      "train [37.2911376953125, 6.5471954345703125]\n",
      "val [41.96653747558594, 6.755335807800293]\n",
      "predict val...\n",
      "predict test...\n",
      "139.05971 254.6307\n",
      "166.50671 254.6307 343.12842 1.0\n",
      "FOLD 1722\n",
      "train [37.08436965942383, 6.5505242347717285]\n",
      "val [40.31910705566406, 6.638376235961914]\n",
      "predict val...\n",
      "predict test...\n",
      "129.89703 250.2119\n",
      "168.4226 250.2119 347.1504 1.0\n",
      "FOLD 1723\n",
      "train [35.79887771606445, 6.492535591125488]\n",
      "val [48.753021240234375, 6.682806491851807]\n",
      "predict val...\n",
      "predict test...\n",
      "159.23892 232.20923\n",
      "154.91101 232.20923 366.5918 1.0\n",
      "FOLD 1724\n",
      "train [38.59333038330078, 6.5795578956604]\n",
      "val [37.04309844970703, 6.489083766937256]\n",
      "predict val...\n",
      "predict test...\n",
      "124.34575 235.04524\n",
      "133.51495 235.04524 325.55908 1.0\n",
      "FOLD 1725\n",
      "train [35.18971252441406, 6.476955413818359]\n",
      "val [43.324249267578125, 6.741360664367676]\n",
      "predict val...\n",
      "predict test...\n",
      "140.98924 223.6646\n",
      "32.8584 223.6646 321.45386 1.0\n",
      "FOLD 1726\n",
      "train [36.891380310058594, 6.522840976715088]\n",
      "val [42.884124755859375, 6.769688606262207]\n",
      "predict val...\n",
      "predict test...\n",
      "141.39098 243.82777\n",
      "150.02405 243.82777 328.0454 1.0\n",
      "FOLD 1727\n",
      "train [36.117469787597656, 6.516366004943848]\n",
      "val [39.02662658691406, 6.617067337036133]\n",
      "predict val...\n",
      "predict test...\n",
      "127.709526 240.12343\n",
      "140.30444 240.12343 330.02222 1.0\n",
      "FOLD 1728\n",
      "train [34.88666534423828, 6.467047691345215]\n",
      "val [48.45494842529297, 6.700246810913086]\n",
      "predict val...\n",
      "predict test...\n",
      "157.76385 221.15007\n",
      "102.811035 221.15007 269.72754 1.0\n",
      "FOLD 1729\n",
      "train [37.358428955078125, 6.543459892272949]\n",
      "val [37.44135665893555, 6.489584445953369]\n",
      "predict val...\n",
      "predict test...\n",
      "126.021324 230.4958\n",
      "152.14404 230.4958 305.43555 1.0\n",
      "FOLD 1730\n",
      "train [35.90610122680664, 6.514225006103516]\n",
      "val [45.59220504760742, 6.742844581604004]\n",
      "predict val...\n",
      "predict test...\n",
      "151.84932 235.53673\n",
      "147.16162 235.53673 304.89746 1.0\n",
      "FOLD 1731\n",
      "train [34.332523345947266, 6.457476615905762]\n",
      "val [39.71161651611328, 6.517780303955078]\n",
      "predict val...\n",
      "predict test...\n",
      "129.80173 222.21776\n",
      "83.68555 222.21776 354.71924 1.0\n",
      "FOLD 1732\n",
      "train [35.72560119628906, 6.488471031188965]\n",
      "val [39.348026275634766, 6.5764265060424805]\n",
      "predict val...\n",
      "predict test...\n",
      "127.39316 223.12839\n",
      "134.09937 223.12839 277.9707 1.0\n",
      "FOLD 1733\n",
      "train [34.065574645996094, 6.439535617828369]\n",
      "val [48.49687957763672, 6.6810126304626465]\n",
      "predict val...\n",
      "predict test...\n",
      "157.39917 219.99107\n",
      "133.34863 219.99107 279.80542 1.0\n",
      "FOLD 1734\n",
      "train [38.50045394897461, 6.573028564453125]\n",
      "val [36.80017852783203, 6.489566802978516]\n",
      "predict val...\n",
      "predict test...\n",
      "124.43161 234.5341\n",
      "144.97235 234.5341 337.45605 1.0\n",
      "FOLD 1735\n",
      "train [36.10679244995117, 6.51156759262085]\n",
      "val [43.341270446777344, 6.699167251586914]\n",
      "predict val...\n",
      "predict test...\n",
      "143.69447 232.39467\n",
      "122.34131 232.39467 317.3584 1.0\n",
      "FOLD 1736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [34.584014892578125, 6.462063789367676]\n",
      "val [44.49241638183594, 7.071627616882324]\n",
      "predict val...\n",
      "predict test...\n",
      "142.8104 219.68747\n",
      "60.168457 219.68747 363.4568 1.0\n",
      "FOLD 1737\n",
      "train [35.15238571166992, 6.48201847076416]\n",
      "val [41.022796630859375, 6.772239685058594]\n",
      "predict val...\n",
      "predict test...\n",
      "132.52808 226.64836\n",
      "91.06128 226.64836 277.34082 1.0\n",
      "FOLD 1738\n",
      "train [35.67457580566406, 6.478674411773682]\n",
      "val [48.40576171875, 6.659619331359863]\n",
      "predict val...\n",
      "predict test...\n",
      "157.962 227.0752\n",
      "141.5841 227.0752 285.2705 1.0\n",
      "FOLD 1739\n",
      "train [38.306419372558594, 6.562312126159668]\n",
      "val [36.197731018066406, 6.500119686126709]\n",
      "predict val...\n",
      "predict test...\n",
      "121.92035 239.99786\n",
      "140.92883 239.99786 319.3496 1.0\n",
      "FOLD 1740\n",
      "train [34.486595153808594, 6.449342250823975]\n",
      "val [41.415401458740234, 6.7072601318359375]\n",
      "predict val...\n",
      "predict test...\n",
      "136.1566 227.8124\n",
      "62.953613 227.8124 354.156 1.0\n",
      "FOLD 1741\n",
      "train [36.065704345703125, 6.494260311126709]\n",
      "val [42.48753356933594, 6.8726091384887695]\n",
      "predict val...\n",
      "predict test...\n",
      "138.18776 227.75906\n",
      "34.224365 227.75906 340.06128 1.0\n",
      "FOLD 1742\n",
      "train [35.02518844604492, 6.484134674072266]\n",
      "val [40.99660873413086, 6.594654560089111]\n",
      "predict val...\n",
      "predict test...\n",
      "131.91747 228.80583\n",
      "150.92175 228.80583 278.00488 1.0\n",
      "FOLD 1743\n",
      "train [34.4114875793457, 6.444864749908447]\n",
      "val [48.301109313964844, 6.6718878746032715]\n",
      "predict val...\n",
      "predict test...\n",
      "157.40001 224.58215\n",
      "112.64929 224.58215 332.6748 1.0\n",
      "FOLD 1744\n",
      "train [38.073795318603516, 6.556033134460449]\n",
      "val [37.20832443237305, 6.494656562805176]\n",
      "predict val...\n",
      "predict test...\n",
      "125.01871 236.73526\n",
      "124.957275 236.73526 313.3235 1.0\n",
      "FOLD 1745\n",
      "train [34.310306549072266, 6.458492279052734]\n",
      "val [44.42008590698242, 6.760190010070801]\n",
      "predict val...\n",
      "predict test...\n",
      "145.12733 228.22832\n",
      "21.66504 228.22832 401.09424 1.0\n",
      "FOLD 1746\n",
      "train [35.071189880371094, 6.471948146820068]\n",
      "val [39.59345626831055, 6.5551347732543945]\n",
      "predict val...\n",
      "predict test...\n",
      "130.30182 230.96497\n",
      "122.66052 230.96497 449.86694 1.0\n",
      "FOLD 1747\n",
      "train [37.65956115722656, 6.553019046783447]\n",
      "val [38.77168273925781, 6.594954490661621]\n",
      "predict val...\n",
      "predict test...\n",
      "124.514275 248.48906\n",
      "184.0841 248.48906 360.69092 1.0\n",
      "FOLD 1748\n",
      "train [32.9232063293457, 6.3843584060668945]\n",
      "val [51.535865783691406, 6.705964088439941]\n",
      "predict val...\n",
      "predict test...\n",
      "166.6875 210.51662\n",
      "79.0708 210.51662 287.02588 1.0\n",
      "FOLD 1749\n",
      "train [37.00194549560547, 6.529819488525391]\n",
      "val [37.224830627441406, 6.496936798095703]\n",
      "predict val...\n",
      "predict test...\n",
      "124.230965 239.09177\n",
      "57.499023 239.09177 355.8816 1.0\n",
      "FOLD 1750\n",
      "train [35.84340286254883, 6.491579532623291]\n",
      "val [44.95432662963867, 6.740473747253418]\n",
      "predict val...\n",
      "predict test...\n",
      "147.7333 229.8045\n",
      "77.80127 229.8045 296.45068 1.0\n",
      "FOLD 1751\n",
      "train [42.38565444946289, 6.564033508300781]\n",
      "val [47.5907096862793, 6.768733978271484]\n",
      "predict val...\n",
      "predict test...\n",
      "139.69672 253.51216\n",
      "122.295044 253.51216 437.6714 1.0\n",
      "FOLD 1752\n",
      "train [42.83407974243164, 6.565982818603516]\n",
      "val [43.103336334228516, 6.585235595703125]\n",
      "predict val...\n",
      "predict test...\n",
      "121.97681 251.26038\n",
      "144.09973 251.26038 426.74365 1.0\n",
      "FOLD 1753\n",
      "train [40.44440460205078, 6.4943132400512695]\n",
      "val [53.35186767578125, 6.675422668457031]\n",
      "predict val...\n",
      "predict test...\n",
      "155.98586 229.90721\n",
      "119.595215 229.90721 475.8496 1.0\n",
      "FOLD 1754\n",
      "train [44.05351257324219, 6.601405143737793]\n",
      "val [42.57514190673828, 6.515383720397949]\n",
      "predict val...\n",
      "predict test...\n",
      "127.30701 231.7077\n",
      "97.61011 231.7077 382.5122 1.0\n",
      "FOLD 1755\n",
      "train [42.211612701416016, 6.541687965393066]\n",
      "val [48.58005142211914, 6.662391662597656]\n",
      "predict val...\n",
      "predict test...\n",
      "143.74075 228.52097\n",
      "102.87891 228.52097 393.30127 1.0\n",
      "FOLD 1756\n",
      "train [41.22592544555664, 6.5253777503967285]\n",
      "val [48.38500213623047, 6.793984413146973]\n",
      "predict val...\n",
      "predict test...\n",
      "141.59785 237.96295\n",
      "122.83264 237.96295 395.82422 1.0\n",
      "FOLD 1757\n",
      "train [42.68030548095703, 6.5649309158325195]\n",
      "val [45.0950927734375, 6.628464698791504]\n",
      "predict val...\n",
      "predict test...\n",
      "128.19048 251.04094\n",
      "148.86108 251.04094 418.10254 1.0\n",
      "FOLD 1758\n",
      "train [40.72871780395508, 6.496737480163574]\n",
      "val [55.168827056884766, 6.679520606994629]\n",
      "predict val...\n",
      "predict test...\n",
      "161.48286 225.62276\n",
      "121.04468 225.62276 443.1079 1.0\n",
      "FOLD 1759\n",
      "train [44.093528747558594, 6.597245693206787]\n",
      "val [40.977718353271484, 6.479331970214844]\n",
      "predict val...\n",
      "predict test...\n",
      "123.002396 227.66966\n",
      "105.06018 227.66966 362.08057 1.0\n",
      "FOLD 1760\n",
      "train [42.165531158447266, 6.543030738830566]\n",
      "val [50.42489242553711, 6.694907188415527]\n",
      "predict val...\n",
      "predict test...\n",
      "147.76758 226.19269\n",
      "141.34521 226.19269 326.39355 1.0\n",
      "FOLD 1761\n",
      "train [40.44530487060547, 6.534811973571777]\n",
      "val [47.061031341552734, 6.7038893699646]\n",
      "predict val...\n",
      "predict test...\n",
      "138.52118 258.74487\n",
      "152.90674 258.74487 333.84668 1.0\n",
      "FOLD 1762\n",
      "train [42.117244720458984, 6.574256896972656]\n",
      "val [43.720577239990234, 6.624218940734863]\n",
      "predict val...\n",
      "predict test...\n",
      "124.95299 263.5731\n",
      "171.00317 263.5731 397.06982 1.0\n",
      "FOLD 1763\n",
      "train [38.41203308105469, 6.4554290771484375]\n",
      "val [53.73643493652344, 6.679359436035156]\n",
      "predict val...\n",
      "predict test...\n",
      "156.77747 229.34772\n",
      "153.44775 229.34772 318.917 1.0\n",
      "FOLD 1764\n",
      "train [43.66804122924805, 6.599137306213379]\n",
      "val [43.91029357910156, 6.517587661743164]\n",
      "predict val...\n",
      "predict test...\n",
      "130.5216 238.42416\n",
      "121.85156 238.42416 353.44434 1.0\n",
      "FOLD 1765\n",
      "train [41.3521614074707, 6.542112827301025]\n",
      "val [50.64463806152344, 6.707840442657471]\n",
      "predict val...\n",
      "predict test...\n",
      "148.90973 234.50931\n",
      "174.45825 234.50931 332.71924 1.0\n",
      "FOLD 1766\n",
      "train [41.382545471191406, 6.533093452453613]\n",
      "val [49.239864349365234, 6.811387062072754]\n",
      "predict val...\n",
      "predict test...\n",
      "145.09819 248.92584\n",
      "156.47363 248.92584 350.0547 1.0\n",
      "FOLD 1767\n",
      "train [41.38622283935547, 6.547003746032715]\n",
      "val [46.3099479675293, 6.728625774383545]\n",
      "predict val...\n",
      "predict test...\n",
      "132.59586 252.67722\n",
      "177.58423 252.67722 369.94775 1.0\n",
      "FOLD 1768\n",
      "train [39.9299430847168, 6.5008544921875]\n",
      "val [53.86589431762695, 6.668092727661133]\n",
      "predict val...\n",
      "predict test...\n",
      "155.68494 238.38307\n",
      "160.17676 238.38307 323.2246 1.0\n",
      "FOLD 1769\n",
      "train [41.29270553588867, 6.533970832824707]\n",
      "val [40.30567169189453, 6.467348575592041]\n",
      "predict val...\n",
      "predict test...\n",
      "120.52759 231.31392\n",
      "134.32971 231.31392 287.7876 1.0\n",
      "FOLD 1770\n",
      "train [39.08821105957031, 6.485489845275879]\n",
      "val [46.06354904174805, 6.664840221405029]\n",
      "predict val...\n",
      "predict test...\n",
      "137.15382 234.43784\n",
      "81.16211 234.43784 292.46118 1.0\n",
      "FOLD 1771\n",
      "train [40.23373031616211, 6.5141801834106445]\n",
      "val [48.67347717285156, 6.791021347045898]\n",
      "predict val...\n",
      "predict test...\n",
      "142.56342 245.56354\n",
      "158.43408 245.56354 313.07764 1.0\n",
      "FOLD 1772\n",
      "train [41.450077056884766, 6.549433708190918]\n",
      "val [45.057472229003906, 6.592520236968994]\n",
      "predict val...\n",
      "predict test...\n",
      "128.9328 249.66307\n",
      "166.76355 249.66307 374.4624 1.0\n",
      "FOLD 1773\n",
      "train [37.76173782348633, 6.445668697357178]\n",
      "val [54.469512939453125, 6.699317932128906]\n",
      "predict val...\n",
      "predict test...\n",
      "157.64688 224.25632\n",
      "126.52637 224.25632 305.3042 1.0\n",
      "FOLD 1774\n",
      "train [43.5966682434082, 6.588876247406006]\n",
      "val [40.137290954589844, 6.471116065979004]\n",
      "predict val...\n",
      "predict test...\n",
      "120.94403 235.0162\n",
      "132.67651 235.0162 331.17334 1.0\n",
      "FOLD 1775\n",
      "train [41.176536560058594, 6.5291290283203125]\n",
      "val [49.42583084106445, 6.678017616271973]\n",
      "predict val...\n",
      "predict test...\n",
      "145.47585 232.08098\n",
      "157.31995 232.08098 321.27808 1.0\n",
      "FOLD 1776\n",
      "train [39.96055221557617, 6.494509696960449]\n",
      "val [46.259613037109375, 6.688979148864746]\n",
      "predict val...\n",
      "predict test...\n",
      "135.67613 232.80933\n",
      "149.08545 232.80933 295.61426 1.0\n",
      "FOLD 1777\n",
      "train [41.551231384277344, 6.548500061035156]\n",
      "val [49.47884750366211, 6.839761734008789]\n",
      "predict val...\n",
      "predict test...\n",
      "140.36533 245.48819\n",
      "172.58447 245.48819 377.13965 1.0\n",
      "FOLD 1778\n",
      "train [38.4160270690918, 6.443561553955078]\n",
      "val [54.45596694946289, 6.694090843200684]\n",
      "predict val...\n",
      "predict test...\n",
      "158.54765 221.79759\n",
      "132.92114 221.79759 300.114 1.0\n",
      "FOLD 1779\n",
      "train [42.29724884033203, 6.564577579498291]\n",
      "val [41.63459014892578, 6.49847412109375]\n",
      "predict val...\n",
      "predict test...\n",
      "124.2363 237.20404\n",
      "147.00177 237.20404 303.7727 1.0\n",
      "FOLD 1780\n",
      "train [39.95814895629883, 6.5047926902771]\n",
      "val [51.27595138549805, 6.748856067657471]\n",
      "predict val...\n",
      "predict test...\n",
      "150.51442 237.54337\n",
      "115.48804 237.54337 323.95605 1.0\n",
      "FOLD 1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [41.64704895019531, 6.5428147315979]\n",
      "val [47.18107604980469, 6.788027763366699]\n",
      "predict val...\n",
      "predict test...\n",
      "138.80382 251.84685\n",
      "166.35852 251.84685 347.28955 1.0\n",
      "FOLD 1782\n",
      "train [39.67332077026367, 6.483296871185303]\n",
      "val [44.575111389160156, 6.612504005432129]\n",
      "predict val...\n",
      "predict test...\n",
      "129.53677 223.79507\n",
      "161.78662 223.79507 289.39844 1.0\n",
      "FOLD 1783\n",
      "train [36.11944580078125, 6.3839430809021]\n",
      "val [55.87662124633789, 6.712399005889893]\n",
      "predict val...\n",
      "predict test...\n",
      "159.76009 203.1145\n",
      "95.12756 203.1145 272.77246 1.0\n",
      "FOLD 1784\n",
      "train [40.28728485107422, 6.4992356300354]\n",
      "val [40.170310974121094, 6.4555816650390625]\n",
      "predict val...\n",
      "predict test...\n",
      "119.82841 227.29901\n",
      "80.20654 227.29901 322.22778 1.0\n",
      "FOLD 1785\n",
      "train [40.47490692138672, 6.5301513671875]\n",
      "val [51.25374221801758, 6.744585037231445]\n",
      "predict val...\n",
      "predict test...\n",
      "151.64793 237.41817\n",
      "170.02795 237.41817 324.0774 1.0\n",
      "FOLD 1786\n",
      "train [40.051185607910156, 6.505196571350098]\n",
      "val [46.5439453125, 6.688618183135986]\n",
      "predict val...\n",
      "predict test...\n",
      "136.08342 239.86365\n",
      "119.41968 239.86365 335.938 1.0\n",
      "FOLD 1787\n",
      "train [41.37223434448242, 6.552632808685303]\n",
      "val [44.39569091796875, 6.610748291015625]\n",
      "predict val...\n",
      "predict test...\n",
      "127.857285 252.66806\n",
      "175.96008 252.66806 353.58105 1.0\n",
      "FOLD 1788\n",
      "train [39.31085968017578, 6.470376491546631]\n",
      "val [54.5123405456543, 6.6585845947265625]\n",
      "predict val...\n",
      "predict test...\n",
      "157.9742 223.89485\n",
      "120.957886 223.89485 296.6023 1.0\n",
      "FOLD 1789\n",
      "train [42.95438766479492, 6.564898490905762]\n",
      "val [39.57280349731445, 6.488762855529785]\n",
      "predict val...\n",
      "predict test...\n",
      "120.95608 240.05324\n",
      "152.95984 240.05324 320.4646 1.0\n",
      "FOLD 1790\n",
      "train [40.32210159301758, 6.497446537017822]\n",
      "val [49.33129119873047, 6.745334625244141]\n",
      "predict val...\n",
      "predict test...\n",
      "144.23105 231.17253\n",
      "45.853027 231.17253 421.83765 1.0\n",
      "FOLD 1791\n",
      "train [40.60467529296875, 6.50921630859375]\n",
      "val [47.485103607177734, 6.756974220275879]\n",
      "predict val...\n",
      "predict test...\n",
      "138.38301 237.91098\n",
      "78.09839 237.91098 403.9077 1.0\n",
      "FOLD 1792\n",
      "train [40.083621978759766, 6.512967109680176]\n",
      "val [45.39869689941406, 6.626731872558594]\n",
      "predict val...\n",
      "predict test...\n",
      "131.80095 234.56529\n",
      "123.32666 234.56529 315.41064 1.0\n",
      "FOLD 1793\n",
      "train [39.43844985961914, 6.4675092697143555]\n",
      "val [53.20414352416992, 6.652615547180176]\n",
      "predict val...\n",
      "predict test...\n",
      "155.03273 231.98732\n",
      "108.84534 231.98732 347.67017 1.0\n",
      "FOLD 1794\n",
      "train [43.468196868896484, 6.589199066162109]\n",
      "val [40.77360153198242, 6.49006462097168]\n",
      "predict val...\n",
      "predict test...\n",
      "123.96199 239.22157\n",
      "153.85345 239.22157 340.6914 1.0\n",
      "FOLD 1795\n",
      "train [40.08229446411133, 6.5143723487854]\n",
      "val [49.4755744934082, 6.764437675476074]\n",
      "predict val...\n",
      "predict test...\n",
      "145.10281 240.18277\n",
      "46.85962 240.18277 334.22485 1.0\n",
      "FOLD 1796\n",
      "train [39.639583587646484, 6.492766380310059]\n",
      "val [44.97391128540039, 6.589504718780518]\n",
      "predict val...\n",
      "predict test...\n",
      "131.67068 235.33315\n",
      "119.502686 235.33315 331.43726 1.0\n",
      "FOLD 1797\n",
      "train [41.8122444152832, 6.548978328704834]\n",
      "val [43.15193176269531, 6.590163707733154]\n",
      "predict val...\n",
      "predict test...\n",
      "126.17293 249.1298\n",
      "181.01074 249.1298 334.43115 1.0\n",
      "FOLD 1798\n",
      "train [38.860652923583984, 6.461354732513428]\n",
      "val [55.12919998168945, 6.68638801574707]\n",
      "predict val...\n",
      "predict test...\n",
      "158.76 236.14012\n",
      "89.034424 236.14012 331.29712 1.0\n",
      "FOLD 1799\n",
      "train [42.496761322021484, 6.556872367858887]\n",
      "val [39.90714645385742, 6.485245227813721]\n",
      "predict val...\n",
      "predict test...\n",
      "119.34884 247.52504\n",
      "120.6604 247.52504 451.65405 1.0\n",
      "FOLD 1800\n",
      "train [39.64590072631836, 6.496009826660156]\n",
      "val [55.05442810058594, 6.793364524841309]\n",
      "predict val...\n",
      "predict test...\n",
      "160.08383 226.6578\n",
      "156.72119 226.6578 283.62817 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1801\n",
      "train [28.869844436645508, 6.547556400299072]\n",
      "val [31.99428367614746, 6.737257480621338]\n",
      "predict val...\n",
      "predict test...\n",
      "138.67479 241.75815\n",
      "138.32544 241.75815 381.1958 1.0\n",
      "FOLD 1802\n",
      "train [28.781740188598633, 6.542751312255859]\n",
      "val [29.727275848388672, 6.578729629516602]\n",
      "predict val...\n",
      "predict test...\n",
      "123.31366 240.21529\n",
      "136.89929 240.21529 401.896 1.0\n",
      "FOLD 1803\n",
      "train [27.842145919799805, 6.5003156661987305]\n",
      "val [35.466976165771484, 6.67132043838501]\n",
      "predict val...\n",
      "predict test...\n",
      "154.00317 231.32466\n",
      "116.013794 231.32466 486.30127 1.0\n",
      "FOLD 1804\n",
      "train [29.65568733215332, 6.613668918609619]\n",
      "val [27.94300651550293, 6.5126471519470215]\n",
      "predict val...\n",
      "predict test...\n",
      "122.536224 251.59311\n",
      "118.35809 251.59311 389.36768 1.0\n",
      "FOLD 1805\n",
      "train [27.99135398864746, 6.523573398590088]\n",
      "val [32.45045471191406, 6.683019638061523]\n",
      "predict val...\n",
      "predict test...\n",
      "143.26993 228.87355\n",
      "126.24524 228.87355 348.96045 1.0\n",
      "FOLD 1806\n",
      "train [27.41668128967285, 6.509110927581787]\n",
      "val [31.697818756103516, 6.738533020019531]\n",
      "predict val...\n",
      "predict test...\n",
      "136.8824 247.2548\n",
      "164.30933 247.2548 331.07373 1.0\n",
      "FOLD 1807\n",
      "train [28.348819732666016, 6.531518459320068]\n",
      "val [31.632570266723633, 6.652338981628418]\n",
      "predict val...\n",
      "predict test...\n",
      "133.9616 238.45854\n",
      "144.05322 238.45854 378.92236 1.0\n",
      "FOLD 1808\n",
      "train [27.438404083251953, 6.483174800872803]\n",
      "val [38.096900939941406, 6.6974334716796875]\n",
      "predict val...\n",
      "predict test...\n",
      "164.32562 221.82278\n",
      "141.005 221.82278 332.5962 1.0\n",
      "FOLD 1809\n",
      "train [29.27533721923828, 6.574521064758301]\n",
      "val [28.430187225341797, 6.488162040710449]\n",
      "predict val...\n",
      "predict test...\n",
      "124.43009 220.45457\n",
      "89.594604 220.45457 354.2959 1.0\n",
      "FOLD 1810\n",
      "train [28.635051727294922, 6.53174352645874]\n",
      "val [32.34203338623047, 6.664812088012695]\n",
      "predict val...\n",
      "predict test...\n",
      "141.58006 223.93529\n",
      "138.97595 223.93529 319.58252 1.0\n",
      "FOLD 1811\n",
      "train [27.979333877563477, 6.534399509429932]\n",
      "val [32.63973617553711, 6.756512641906738]\n",
      "predict val...\n",
      "predict test...\n",
      "142.03503 254.45676\n",
      "159.82434 254.45676 322.68408 1.0\n",
      "FOLD 1812\n",
      "train [28.83675193786621, 6.565210819244385]\n",
      "val [29.79595184326172, 6.627492427825928]\n",
      "predict val...\n",
      "predict test...\n",
      "125.23781 256.88028\n",
      "161.68298 256.88028 414.11133 1.0\n",
      "FOLD 1813\n",
      "train [27.758556365966797, 6.5141096115112305]\n",
      "val [36.199710845947266, 6.690701484680176]\n",
      "predict val...\n",
      "predict test...\n",
      "158.11333 244.12663\n",
      "151.62573 244.12663 411.10645 1.0\n",
      "FOLD 1814\n",
      "train [28.873117446899414, 6.5629563331604]\n",
      "val [28.735183715820312, 6.479263782501221]\n",
      "predict val...\n",
      "predict test...\n",
      "126.41187 237.30934\n",
      "150.3742 237.30934 313.29346 1.0\n",
      "FOLD 1815\n",
      "train [27.796112060546875, 6.5178542137146]\n",
      "val [33.10590744018555, 6.688414573669434]\n",
      "predict val...\n",
      "predict test...\n",
      "143.25397 227.63452\n",
      "155.4591 227.63452 324.2339 1.0\n",
      "FOLD 1816\n",
      "train [28.620054244995117, 6.540132999420166]\n",
      "val [32.241519927978516, 6.777859210968018]\n",
      "predict val...\n",
      "predict test...\n",
      "140.44485 246.563\n",
      "170.84253 246.563 336.72412 1.0\n",
      "FOLD 1817\n",
      "train [27.96372413635254, 6.523264408111572]\n",
      "val [29.327402114868164, 6.571145057678223]\n",
      "predict val...\n",
      "predict test...\n",
      "124.58573 243.73956\n",
      "159.52356 243.73956 319.87695 1.0\n",
      "FOLD 1818\n",
      "train [25.56311798095703, 6.42781925201416]\n",
      "val [37.7508659362793, 6.717018127441406]\n",
      "predict val...\n",
      "predict test...\n",
      "162.79958 224.51048\n",
      "135.94922 224.51048 282.88892 1.0\n",
      "FOLD 1819\n",
      "train [29.776294708251953, 6.589499473571777]\n",
      "val [28.15654182434082, 6.487561225891113]\n",
      "predict val...\n",
      "predict test...\n",
      "125.2216 233.1253\n",
      "135.30457 233.1253 327.73633 1.0\n",
      "FOLD 1820\n",
      "train [27.68012237548828, 6.517920017242432]\n",
      "val [34.08711242675781, 6.720293045043945]\n",
      "predict val...\n",
      "predict test...\n",
      "149.65622 240.29897\n",
      "151.15332 240.29897 319.823 1.0\n",
      "FOLD 1821\n",
      "train [27.00811767578125, 6.490052223205566]\n",
      "val [31.00904655456543, 6.599357604980469]\n",
      "predict val...\n",
      "predict test...\n",
      "134.19037 241.27748\n",
      "149.31848 241.27748 322.4082 1.0\n",
      "FOLD 1822\n",
      "train [28.31546401977539, 6.53954553604126]\n",
      "val [30.186403274536133, 6.648475646972656]\n",
      "predict val...\n",
      "predict test...\n",
      "127.70357 247.29402\n",
      "163.78699 247.29402 371.12402 1.0\n",
      "FOLD 1823\n",
      "train [26.52123260498047, 6.4385881423950195]\n",
      "val [36.908729553222656, 6.692174911499023]\n",
      "predict val...\n",
      "predict test...\n",
      "157.69333 208.15657\n",
      "79.04199 208.15657 273.6714 1.0\n",
      "FOLD 1824\n",
      "train [28.631227493286133, 6.53778076171875]\n",
      "val [27.749332427978516, 6.422314167022705]\n",
      "predict val...\n",
      "predict test...\n",
      "122.39061 220.2223\n",
      "106.950195 220.2223 273.2256 1.0\n",
      "FOLD 1825\n",
      "train [26.535659790039062, 6.454035758972168]\n",
      "val [32.530052185058594, 6.690141677856445]\n",
      "predict val...\n",
      "predict test...\n",
      "141.52135 215.59467\n",
      "26.65503 215.59467 266.05273 1.0\n",
      "FOLD 1826\n",
      "train [26.905805587768555, 6.469825744628906]\n",
      "val [32.17973709106445, 6.7510552406311035]\n",
      "predict val...\n",
      "predict test...\n",
      "138.24484 221.26926\n",
      "65.37305 221.26926 331.9663 1.0\n",
      "FOLD 1827\n",
      "train [25.900634765625, 6.411969184875488]\n",
      "val [34.23310089111328, 6.978681564331055]\n",
      "predict val...\n",
      "predict test...\n",
      "147.14665 218.8212\n",
      "59.887695 218.8212 292.82568 1.0\n",
      "FOLD 1828\n",
      "train [26.651994705200195, 6.451285362243652]\n",
      "val [36.69175338745117, 6.6690473556518555]\n",
      "predict val...\n",
      "predict test...\n",
      "157.82964 223.14249\n",
      "104.059814 223.14249 311.76636 1.0\n",
      "FOLD 1829\n",
      "train [29.442626953125, 6.564478874206543]\n",
      "val [27.50830841064453, 6.494953155517578]\n",
      "predict val...\n",
      "predict test...\n",
      "121.221985 239.86533\n",
      "136.53918 239.86533 380.20312 1.0\n",
      "FOLD 1830\n",
      "train [27.563295364379883, 6.508556365966797]\n",
      "val [33.61516189575195, 6.722131729125977]\n",
      "predict val...\n",
      "predict test...\n",
      "145.9969 229.77553\n",
      "106.60156 229.77553 298.53418 1.0\n",
      "FOLD 1831\n",
      "train [27.401716232299805, 6.501646995544434]\n",
      "val [30.304744720458984, 6.537184715270996]\n",
      "predict val...\n",
      "predict test...\n",
      "130.76804 239.27896\n",
      "87.76904 239.27896 313.25342 1.0\n",
      "FOLD 1832\n",
      "train [26.825605392456055, 6.469708442687988]\n",
      "val [31.0399112701416, 6.680161476135254]\n",
      "predict val...\n",
      "predict test...\n",
      "132.74341 225.12592\n",
      "141.4458 225.12592 281.64478 1.0\n",
      "FOLD 1833\n",
      "train [26.230955123901367, 6.442015647888184]\n",
      "val [38.02618408203125, 6.734126091003418]\n",
      "predict val...\n",
      "predict test...\n",
      "163.5568 216.92165\n",
      "112.618164 216.92165 273.23706 1.0\n",
      "FOLD 1834\n",
      "train [28.761743545532227, 6.54940128326416]\n",
      "val [27.710689544677734, 6.464064598083496]\n",
      "predict val...\n",
      "predict test...\n",
      "121.33744 236.85683\n",
      "146.64185 236.85683 306.99316 1.0\n",
      "FOLD 1835\n",
      "train [27.827510833740234, 6.499047756195068]\n",
      "val [34.39466857910156, 6.72818660736084]\n",
      "predict val...\n",
      "predict test...\n",
      "149.4407 226.99115\n",
      "89.03662 226.99115 366.917 1.0\n",
      "FOLD 1836\n",
      "train [27.461029052734375, 6.489491939544678]\n",
      "val [32.47412109375, 6.855640411376953]\n",
      "predict val...\n",
      "predict test...\n",
      "139.06363 238.08601\n",
      "90.99414 238.08601 483.49707 1.0\n",
      "FOLD 1837\n",
      "train [26.611732482910156, 6.46567440032959]\n",
      "val [31.08612823486328, 6.624456405639648]\n",
      "predict val...\n",
      "predict test...\n",
      "133.14893 222.74356\n",
      "145.2854 222.74356 273.74243 1.0\n",
      "FOLD 1838\n",
      "train [25.530588150024414, 6.4124555587768555]\n",
      "val [38.51961135864258, 6.683166980743408]\n",
      "predict val...\n",
      "predict test...\n",
      "165.16396 218.6029\n",
      "91.92944 218.6029 286.90332 1.0\n",
      "FOLD 1839\n",
      "train [29.206836700439453, 6.5632524490356445]\n",
      "val [27.220142364501953, 6.501062393188477]\n",
      "predict val...\n",
      "predict test...\n",
      "120.25392 248.74107\n",
      "125.82617 248.74107 418.01123 1.0\n",
      "FOLD 1840\n",
      "train [26.483036041259766, 6.4539594650268555]\n",
      "val [31.70063018798828, 6.698594093322754]\n",
      "predict val...\n",
      "predict test...\n",
      "137.52869 224.82985\n",
      "6.8774414 224.82985 428.82056 1.0\n",
      "FOLD 1841\n",
      "train [26.83388900756836, 6.4749345779418945]\n",
      "val [30.797657012939453, 6.701879024505615]\n",
      "predict val...\n",
      "predict test...\n",
      "134.83893 226.45187\n",
      "114.29126 226.45187 298.21118 1.0\n",
      "FOLD 1842\n",
      "train [26.561695098876953, 6.457134246826172]\n",
      "val [30.276514053344727, 6.61555290222168]\n",
      "predict val...\n",
      "predict test...\n",
      "130.34319 228.24196\n",
      "142.41235 228.24196 302.4568 1.0\n",
      "FOLD 1843\n",
      "train [25.763505935668945, 6.425174713134766]\n",
      "val [38.0816535949707, 6.708449363708496]\n",
      "predict val...\n",
      "predict test...\n",
      "164.06987 220.3893\n",
      "93.24878 220.3893 372.77075 1.0\n",
      "FOLD 1844\n",
      "train [27.924222946166992, 6.510032653808594]\n",
      "val [29.782325744628906, 6.525955677032471]\n",
      "predict val...\n",
      "predict test...\n",
      "128.88632 238.15675\n",
      "41.17627 238.15675 376.02832 1.0\n",
      "FOLD 1845\n",
      "train [26.3743896484375, 6.456143856048584]\n",
      "val [33.89909362792969, 6.726131439208984]\n",
      "predict val...\n",
      "predict test...\n",
      "146.64513 226.21791\n",
      "-42.318604 226.21791 363.5984 0.9771986970684039\n",
      "FOLD 1846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [27.177339553833008, 6.47968053817749]\n",
      "val [31.691539764404297, 6.667067050933838]\n",
      "predict val...\n",
      "predict test...\n",
      "136.21527 224.27255\n",
      "-17.495605 224.27255 373.25684 0.993485342019544\n",
      "FOLD 1847\n",
      "train [27.377391815185547, 6.483758449554443]\n",
      "val [29.728233337402344, 6.5592193603515625]\n",
      "predict val...\n",
      "predict test...\n",
      "127.317474 243.44737\n",
      "117.8916 243.44737 416.09912 1.0\n",
      "FOLD 1848\n",
      "train [27.031293869018555, 6.459046840667725]\n",
      "val [36.9731559753418, 6.658288955688477]\n",
      "predict val...\n",
      "predict test...\n",
      "159.57051 222.85902\n",
      "134.21228 222.85902 352.2683 1.0\n",
      "FOLD 1849\n",
      "train [28.92862892150879, 6.563875675201416]\n",
      "val [27.79804229736328, 6.482751846313477]\n",
      "predict val...\n",
      "predict test...\n",
      "120.0782 244.97897\n",
      "134.08862 244.97897 333.20312 1.0\n",
      "FOLD 1850\n",
      "train [27.510637283325195, 6.4906721115112305]\n",
      "val [32.34743881225586, 6.721844673156738]\n",
      "predict val...\n",
      "predict test...\n",
      "138.56354 226.1874\n",
      "-1.9589844 226.1874 397.00098 0.996742671009772\n",
      "FOLD 1851\n",
      "train [33.266029357910156, 6.558968544006348]\n",
      "val [36.911842346191406, 6.734597206115723]\n",
      "predict val...\n",
      "predict test...\n",
      "138.492 252.42682\n",
      "131.31104 252.42682 426.34766 1.0\n",
      "FOLD 1852\n",
      "train [33.616676330566406, 6.554492950439453]\n",
      "val [34.01531219482422, 6.572403907775879]\n",
      "predict val...\n",
      "predict test...\n",
      "121.93737 243.16862\n",
      "133.5326 243.16862 412.85352 1.0\n",
      "FOLD 1853\n",
      "train [31.338590621948242, 6.475816249847412]\n",
      "val [43.0712890625, 6.709296226501465]\n",
      "predict val...\n",
      "predict test...\n",
      "159.92804 222.6213\n",
      "132.83533 222.6213 329.38477 1.0\n",
      "FOLD 1854\n",
      "train [33.819862365722656, 6.585896968841553]\n",
      "val [31.687685012817383, 6.4830708503723145]\n",
      "predict val...\n",
      "predict test...\n",
      "120.52614 231.52142\n",
      "93.71619 231.52142 372.28076 1.0\n",
      "FOLD 1855\n",
      "train [32.8293342590332, 6.546411037445068]\n",
      "val [36.61501693725586, 6.661901473999023]\n",
      "predict val...\n",
      "predict test...\n",
      "137.71097 240.89082\n",
      "138.95544 240.89082 364.02832 1.0\n",
      "FOLD 1856\n",
      "train [33.033538818359375, 6.556436061859131]\n",
      "val [37.85799789428711, 6.808925628662109]\n",
      "predict val...\n",
      "predict test...\n",
      "142.61324 261.90494\n",
      "159.41772 261.90494 396.29785 1.0\n",
      "FOLD 1857\n",
      "train [33.67125701904297, 6.565852165222168]\n",
      "val [37.89323806762695, 6.671286582946777]\n",
      "predict val...\n",
      "predict test...\n",
      "140.30392 243.57233\n",
      "151.67566 243.57233 385.7129 1.0\n",
      "FOLD 1858\n",
      "train [31.810894012451172, 6.48781681060791]\n",
      "val [43.19286346435547, 6.675654411315918]\n",
      "predict val...\n",
      "predict test...\n",
      "160.55948 221.85313\n",
      "120.76538 221.85313 427.27637 1.0\n",
      "FOLD 1859\n",
      "train [34.77802276611328, 6.593149662017822]\n",
      "val [31.87448501586914, 6.471174240112305]\n",
      "predict val...\n",
      "predict test...\n",
      "122.00524 221.60884\n",
      "99.89734 221.60884 356.0996 1.0\n",
      "FOLD 1860\n",
      "train [33.537452697753906, 6.548264980316162]\n",
      "val [38.16503143310547, 6.675302982330322]\n",
      "predict val...\n",
      "predict test...\n",
      "143.84811 224.55603\n",
      "150.9242 224.55603 325.29663 1.0\n",
      "FOLD 1861\n",
      "train [31.039934158325195, 6.484291076660156]\n",
      "val [38.60212326049805, 6.768746852874756]\n",
      "predict val...\n",
      "predict test...\n",
      "144.21745 232.22043\n",
      "143.09424 232.22043 293.32617 1.0\n",
      "FOLD 1862\n",
      "train [32.01417922973633, 6.539904594421387]\n",
      "val [33.24300765991211, 6.544680595397949]\n",
      "predict val...\n",
      "predict test...\n",
      "120.4419 254.81815\n",
      "177.37122 254.81815 364.67334 1.0\n",
      "FOLD 1863\n",
      "train [29.357736587524414, 6.4127302169799805]\n",
      "val [43.41019058227539, 6.7118940353393555]\n",
      "predict val...\n",
      "predict test...\n",
      "160.14197 215.6772\n",
      "113.289795 215.6772 314.60547 1.0\n",
      "FOLD 1864\n",
      "train [33.98480987548828, 6.580789089202881]\n",
      "val [34.34797668457031, 6.48775577545166]\n",
      "predict val...\n",
      "predict test...\n",
      "129.30267 239.06929\n",
      "137.10876 239.06929 314.05762 1.0\n",
      "FOLD 1865\n",
      "train [32.3730354309082, 6.534675598144531]\n",
      "val [38.660091400146484, 6.695668697357178]\n",
      "predict val...\n",
      "predict test...\n",
      "144.9072 237.58861\n",
      "164.98303 237.58861 328.24658 1.0\n",
      "FOLD 1866\n",
      "train [32.06315231323242, 6.509903907775879]\n",
      "val [38.409053802490234, 6.796173095703125]\n",
      "predict val...\n",
      "predict test...\n",
      "143.98587 236.69493\n",
      "136.16492 236.69493 358.53174 1.0\n",
      "FOLD 1867\n",
      "train [32.48286819458008, 6.530571937561035]\n",
      "val [35.574981689453125, 6.651378154754639]\n",
      "predict val...\n",
      "predict test...\n",
      "130.0443 243.10902\n",
      "153.19885 243.10902 378.36963 1.0\n",
      "FOLD 1868\n",
      "train [30.984827041625977, 6.465358734130859]\n",
      "val [43.71574401855469, 6.7052483558654785]\n",
      "predict val...\n",
      "predict test...\n",
      "163.23817 222.14558\n",
      "119.06531 222.14558 418.62256 1.0\n",
      "FOLD 1869\n",
      "train [34.21780776977539, 6.593935489654541]\n",
      "val [32.37433624267578, 6.491277694702148]\n",
      "predict val...\n",
      "predict test...\n",
      "123.92818 241.80344\n",
      "138.29382 241.80344 336.44214 1.0\n",
      "FOLD 1870\n",
      "train [32.290191650390625, 6.532620906829834]\n",
      "val [39.2746467590332, 6.69805908203125]\n",
      "predict val...\n",
      "predict test...\n",
      "147.67842 237.7796\n",
      "171.1477 237.7796 331.14575 1.0\n",
      "FOLD 1871\n",
      "train [30.555150985717773, 6.471104621887207]\n",
      "val [35.90138244628906, 6.659510135650635]\n",
      "predict val...\n",
      "predict test...\n",
      "134.8323 234.22084\n",
      "125.86279 234.22084 312.29395 1.0\n",
      "FOLD 1872\n",
      "train [31.330249786376953, 6.499080657958984]\n",
      "val [34.61650466918945, 6.608046531677246]\n",
      "predict val...\n",
      "predict test...\n",
      "128.60297 236.37622\n",
      "158.41211 236.37622 307.11206 1.0\n",
      "FOLD 1873\n",
      "train [28.76602554321289, 6.393321990966797]\n",
      "val [44.44459533691406, 6.6961822509765625]\n",
      "predict val...\n",
      "predict test...\n",
      "163.40794 219.0843\n",
      "101.690186 219.0843 283.07812 1.0\n",
      "FOLD 1874\n",
      "train [32.381099700927734, 6.528485298156738]\n",
      "val [32.13481521606445, 6.479523658752441]\n",
      "predict val...\n",
      "predict test...\n",
      "122.15027 226.03426\n",
      "138.72449 226.03426 282.45142 1.0\n",
      "FOLD 1875\n",
      "train [31.123781204223633, 6.4837493896484375]\n",
      "val [38.30751037597656, 6.709698677062988]\n",
      "predict val...\n",
      "predict test...\n",
      "143.58138 223.97942\n",
      "121.37427 223.97942 289.40625 1.0\n",
      "FOLD 1876\n",
      "train [30.225217819213867, 6.461431980133057]\n",
      "val [36.203697204589844, 6.620583534240723]\n",
      "predict val...\n",
      "predict test...\n",
      "134.31943 233.17137\n",
      "100.65845 233.17137 301.17358 1.0\n",
      "FOLD 1877\n",
      "train [32.689430236816406, 6.542048454284668]\n",
      "val [34.1746940612793, 6.579601287841797]\n",
      "predict val...\n",
      "predict test...\n",
      "123.6093 245.48856\n",
      "158.47046 245.48856 387.34863 1.0\n",
      "FOLD 1878\n",
      "train [28.95208740234375, 6.391701698303223]\n",
      "val [44.90498733520508, 6.685489654541016]\n",
      "predict val...\n",
      "predict test...\n",
      "164.96928 214.04959\n",
      "77.34717 214.04959 307.2202 1.0\n",
      "FOLD 1879\n",
      "train [32.34089279174805, 6.526434898376465]\n",
      "val [32.417110443115234, 6.451139450073242]\n",
      "predict val...\n",
      "predict test...\n",
      "122.94307 225.30289\n",
      "105.73779 225.30289 279.60913 1.0\n",
      "FOLD 1880\n",
      "train [31.48757553100586, 6.492908477783203]\n",
      "val [39.80979919433594, 6.792904853820801]\n",
      "predict val...\n",
      "predict test...\n",
      "149.53706 231.29378\n",
      "73.265625 231.29378 365.65894 1.0\n",
      "FOLD 1881\n",
      "train [32.78124237060547, 6.540188789367676]\n",
      "val [37.42589569091797, 6.781121253967285]\n",
      "predict val...\n",
      "predict test...\n",
      "139.80458 246.11719\n",
      "162.95007 246.11719 326.58838 1.0\n",
      "FOLD 1882\n",
      "train [32.4310302734375, 6.534065246582031]\n",
      "val [34.09575271606445, 6.563784599304199]\n",
      "predict val...\n",
      "predict test...\n",
      "126.04209 256.4814\n",
      "138.11328 256.4814 362.94873 1.0\n",
      "FOLD 1883\n",
      "train [29.431373596191406, 6.4103264808654785]\n",
      "val [44.371585845947266, 6.702667236328125]\n",
      "predict val...\n",
      "predict test...\n",
      "163.81476 218.08865\n",
      "110.76953 218.08865 305.73853 1.0\n",
      "FOLD 1884\n",
      "train [32.97206115722656, 6.559581756591797]\n",
      "val [31.70831298828125, 6.507013320922852]\n",
      "predict val...\n",
      "predict test...\n",
      "120.615814 251.89478\n",
      "146.65674 251.89478 355.3462 1.0\n",
      "FOLD 1885\n",
      "train [31.540245056152344, 6.504034996032715]\n",
      "val [39.29822540283203, 6.742486953735352]\n",
      "predict val...\n",
      "predict test...\n",
      "148.33719 236.77824\n",
      "86.839355 236.77824 312.9895 1.0\n",
      "FOLD 1886\n",
      "train [31.170822143554688, 6.482710361480713]\n",
      "val [35.66362762451172, 6.563086986541748]\n",
      "predict val...\n",
      "predict test...\n",
      "133.06989 231.99806\n",
      "-45.780518 231.99806 409.82666 0.9804560260586319\n",
      "FOLD 1887\n",
      "train [33.23103713989258, 6.557623863220215]\n",
      "val [34.71935272216797, 6.618361949920654]\n",
      "predict val...\n",
      "predict test...\n",
      "127.49023 252.88829\n",
      "174.85596 252.88829 374.9712 1.0\n",
      "FOLD 1888\n",
      "train [31.33070182800293, 6.481456756591797]\n",
      "val [43.53071594238281, 6.6839094161987305]\n",
      "predict val...\n",
      "predict test...\n",
      "161.1913 225.40424\n",
      "159.92957 225.40424 279.29224 1.0\n",
      "FOLD 1889\n",
      "train [32.556182861328125, 6.524311065673828]\n",
      "val [31.093582153320312, 6.460091590881348]\n",
      "predict val...\n",
      "predict test...\n",
      "118.16822 241.96959\n",
      "75.23633 241.96959 319.16772 1.0\n",
      "FOLD 1890\n",
      "train [31.512958526611328, 6.495015621185303]\n",
      "val [39.08242416381836, 6.769423007965088]\n",
      "predict val...\n",
      "predict test...\n",
      "146.30449 231.64474\n",
      "77.16382 231.64474 303.95044 1.0\n",
      "FOLD 1891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [30.3592472076416, 6.445200443267822]\n",
      "val [36.016807556152344, 6.631760597229004]\n",
      "predict val...\n",
      "predict test...\n",
      "132.26582 218.73048\n",
      "88.97876 218.73048 342.14624 1.0\n",
      "FOLD 1892\n",
      "train [30.983579635620117, 6.479037284851074]\n",
      "val [35.661949157714844, 6.640228271484375]\n",
      "predict val...\n",
      "predict test...\n",
      "133.58759 231.19608\n",
      "155.43103 231.19608 293.7224 1.0\n",
      "FOLD 1893\n",
      "train [28.357173919677734, 6.365813255310059]\n",
      "val [42.27914810180664, 6.6557817459106445]\n",
      "predict val...\n",
      "predict test...\n",
      "154.67278 212.66821\n",
      "87.99341 212.66821 320.88892 1.0\n",
      "FOLD 1894\n",
      "train [32.71251678466797, 6.533900260925293]\n",
      "val [32.953704833984375, 6.533360958099365]\n",
      "predict val...\n",
      "predict test...\n",
      "125.05749 237.86838\n",
      "74.28833 237.86838 320.50366 1.0\n",
      "FOLD 1895\n",
      "train [31.40118980407715, 6.492364406585693]\n",
      "val [48.34233474731445, 7.156120300292969]\n",
      "predict val...\n",
      "predict test...\n",
      "178.43309 222.81609\n",
      "-56.10205 222.81609 345.99756 0.9609120521172638\n",
      "FOLD 1896\n",
      "train [30.200780868530273, 6.446600914001465]\n",
      "val [33.59416198730469, 6.477479457855225]\n",
      "predict val...\n",
      "predict test...\n",
      "126.14691 221.51292\n",
      "19.287842 221.51292 345.78076 1.0\n",
      "FOLD 1897\n",
      "train [32.69143295288086, 6.536401271820068]\n",
      "val [34.847232818603516, 6.5985941886901855]\n",
      "predict val...\n",
      "predict test...\n",
      "127.02033 241.2401\n",
      "161.76929 241.2401 365.86768 1.0\n",
      "FOLD 1898\n",
      "train [29.96932601928711, 6.421450138092041]\n",
      "val [42.403114318847656, 6.691170692443848]\n",
      "predict val...\n",
      "predict test...\n",
      "156.30473 216.04637\n",
      "76.88574 216.04637 326.34888 1.0\n",
      "FOLD 1899\n",
      "train [32.654991149902344, 6.531369209289551]\n",
      "val [33.33247756958008, 6.485862731933594]\n",
      "predict val...\n",
      "predict test...\n",
      "126.69208 236.86215\n",
      "123.29541 236.86215 343.63904 1.0\n",
      "FOLD 1900\n",
      "train [32.140968322753906, 6.497279167175293]\n",
      "val [38.34713363647461, 6.713627338409424]\n",
      "predict val...\n",
      "predict test...\n",
      "143.90948 229.49348\n",
      "52.23242 229.49348 360.55127 1.0\n",
      "FOLD 1901\n",
      "train [37.980491638183594, 6.5650315284729]\n",
      "val [41.752437591552734, 6.7159833908081055]\n",
      "predict val...\n",
      "predict test...\n",
      "138.47447 250.32533\n",
      "119.74927 250.32533 438.91406 1.0\n",
      "FOLD 1902\n",
      "train [38.36024475097656, 6.565939903259277]\n",
      "val [38.37364196777344, 6.570478439331055]\n",
      "predict val...\n",
      "predict test...\n",
      "121.06133 245.86668\n",
      "149.35718 245.86668 406.73096 1.0\n",
      "FOLD 1903\n",
      "train [35.999916076660156, 6.491666316986084]\n",
      "val [47.539817810058594, 6.677834510803223]\n",
      "predict val...\n",
      "predict test...\n",
      "156.46619 229.93335\n",
      "105.01697 229.93335 515.29346 1.0\n",
      "FOLD 1904\n",
      "train [39.41395568847656, 6.631039619445801]\n",
      "val [36.87655258178711, 6.5256805419921875]\n",
      "predict val...\n",
      "predict test...\n",
      "122.50692 255.22621\n",
      "101.78534 255.22621 422.28027 1.0\n",
      "FOLD 1905\n",
      "train [37.43757247924805, 6.537438869476318]\n",
      "val [43.785274505615234, 6.677895545959473]\n",
      "predict val...\n",
      "predict test...\n",
      "145.90033 236.01608\n",
      "144.7168 236.01608 342.43066 1.0\n",
      "FOLD 1906\n",
      "train [37.09553909301758, 6.544039726257324]\n",
      "val [42.34770584106445, 6.765012741088867]\n",
      "predict val...\n",
      "predict test...\n",
      "140.05676 257.02682\n",
      "142.31104 257.02682 409.52393 1.0\n",
      "FOLD 1907\n",
      "train [37.34856414794922, 6.542210578918457]\n",
      "val [39.860496520996094, 6.58976936340332]\n",
      "predict val...\n",
      "predict test...\n",
      "126.424965 242.91165\n",
      "150.59558 242.91165 384.93506 1.0\n",
      "FOLD 1908\n",
      "train [36.75916290283203, 6.512557029724121]\n",
      "val [50.20433807373047, 6.691928386688232]\n",
      "predict val...\n",
      "predict test...\n",
      "164.7155 228.82863\n",
      "131.15088 228.82863 420.99023 1.0\n",
      "FOLD 1909\n",
      "train [38.82893753051758, 6.5812883377075195]\n",
      "val [35.984378814697266, 6.471334457397461]\n",
      "predict val...\n",
      "predict test...\n",
      "121.04046 222.37535\n",
      "103.15515 222.37535 340.45264 1.0\n",
      "FOLD 1910\n",
      "train [37.66573715209961, 6.538662910461426]\n",
      "val [41.70939254760742, 6.659425735473633]\n",
      "predict val...\n",
      "predict test...\n",
      "138.40259 224.88385\n",
      "133.94556 224.88385 334.98535 1.0\n",
      "FOLD 1911\n",
      "train [37.573516845703125, 6.557529449462891]\n",
      "val [42.958011627197266, 6.763415336608887]\n",
      "predict val...\n",
      "predict test...\n",
      "142.99605 261.2017\n",
      "156.87122 261.2017 393.48633 1.0\n",
      "FOLD 1912\n",
      "train [37.72199630737305, 6.563958644866943]\n",
      "val [38.95768737792969, 6.617870807647705]\n",
      "predict val...\n",
      "predict test...\n",
      "125.32603 256.86014\n",
      "163.76575 256.86014 397.88672 1.0\n",
      "FOLD 1913\n",
      "train [33.30377960205078, 6.431215763092041]\n",
      "val [50.541259765625, 6.732427597045898]\n",
      "predict val...\n",
      "predict test...\n",
      "163.14444 223.05481\n",
      "105.207275 223.05481 324.1582 1.0\n",
      "FOLD 1914\n",
      "train [38.46681213378906, 6.590482234954834]\n",
      "val [37.6954460144043, 6.503912925720215]\n",
      "predict val...\n",
      "predict test...\n",
      "126.8975 240.96848\n",
      "124.42743 240.96848 331.5027 1.0\n",
      "FOLD 1915\n",
      "train [36.815834045410156, 6.532771110534668]\n",
      "val [44.47791290283203, 6.698629379272461]\n",
      "predict val...\n",
      "predict test...\n",
      "146.47606 231.80214\n",
      "142.72449 231.80214 326.4038 1.0\n",
      "FOLD 1916\n",
      "train [35.657169342041016, 6.49831485748291]\n",
      "val [41.557167053222656, 6.729001045227051]\n",
      "predict val...\n",
      "predict test...\n",
      "135.92313 238.99577\n",
      "169.9685 238.99577 297.4917 1.0\n",
      "FOLD 1917\n",
      "train [35.49775695800781, 6.491419792175293]\n",
      "val [42.415809631347656, 6.730522155761719]\n",
      "predict val...\n",
      "predict test...\n",
      "137.00179 230.45338\n",
      "149.70496 230.45338 338.42822 1.0\n",
      "FOLD 1918\n",
      "train [34.6318359375, 6.4619269371032715]\n",
      "val [50.11458969116211, 6.725799560546875]\n",
      "predict val...\n",
      "predict test...\n",
      "163.14163 226.99794\n",
      "109.191895 226.99794 283.69165 1.0\n",
      "FOLD 1919\n",
      "train [38.527679443359375, 6.5826239585876465]\n",
      "val [38.25379180908203, 6.5143208503723145]\n",
      "predict val...\n",
      "predict test...\n",
      "127.87599 238.77408\n",
      "129.41705 238.77408 341.2495 1.0\n",
      "FOLD 1920\n",
      "train [35.436649322509766, 6.5182905197143555]\n",
      "val [43.48563003540039, 6.690965175628662]\n",
      "predict val...\n",
      "predict test...\n",
      "144.21146 246.49089\n",
      "158.29883 246.49089 306.40454 1.0\n",
      "FOLD 1921\n",
      "train [36.29666519165039, 6.521615505218506]\n",
      "val [43.041481018066406, 6.798081398010254]\n",
      "predict val...\n",
      "predict test...\n",
      "141.4603 244.94939\n",
      "139.57983 244.94939 330.28223 1.0\n",
      "FOLD 1922\n",
      "train [37.32607650756836, 6.5424323081970215]\n",
      "val [39.77553939819336, 6.63748836517334]\n",
      "predict val...\n",
      "predict test...\n",
      "128.88152 246.26208\n",
      "158.9541 246.26208 392.02637 1.0\n",
      "FOLD 1923\n",
      "train [33.772605895996094, 6.431443691253662]\n",
      "val [49.32137680053711, 6.774254322052002]\n",
      "predict val...\n",
      "predict test...\n",
      "159.16348 216.76059\n",
      "84.16406 216.76059 278.37036 1.0\n",
      "FOLD 1924\n",
      "train [38.835506439208984, 6.583527565002441]\n",
      "val [36.149269104003906, 6.4818291664123535]\n",
      "predict val...\n",
      "predict test...\n",
      "122.53815 235.79138\n",
      "141.5592 235.79138 318.4546 1.0\n",
      "FOLD 1925\n",
      "train [36.83921813964844, 6.536656379699707]\n",
      "val [44.264766693115234, 6.683164119720459]\n",
      "predict val...\n",
      "predict test...\n",
      "145.91182 238.00992\n",
      "159.38843 238.00992 336.8042 1.0\n",
      "FOLD 1926\n",
      "train [36.032405853271484, 6.516792297363281]\n",
      "val [40.31315612792969, 6.616453647613525]\n",
      "predict val...\n",
      "predict test...\n",
      "132.59709 244.86429\n",
      "131.08862 244.86429 326.33423 1.0\n",
      "FOLD 1927\n",
      "train [36.09101486206055, 6.511414527893066]\n",
      "val [41.81959533691406, 6.699058532714844]\n",
      "predict val...\n",
      "predict test...\n",
      "137.23479 239.68776\n",
      "130.3999 239.68776 360.09863 1.0\n",
      "FOLD 1928\n",
      "train [33.04728698730469, 6.406742095947266]\n",
      "val [51.45940017700195, 6.687607765197754]\n",
      "predict val...\n",
      "predict test...\n",
      "166.54779 215.39246\n",
      "96.613525 215.39246 297.43945 1.0\n",
      "FOLD 1929\n",
      "train [36.9962158203125, 6.527958869934082]\n",
      "val [36.82253646850586, 6.442238807678223]\n",
      "predict val...\n",
      "predict test...\n",
      "123.49992 228.33937\n",
      "96.76196 228.33937 294.32275 1.0\n",
      "FOLD 1930\n",
      "train [35.37089157104492, 6.490122318267822]\n",
      "val [43.7807502746582, 6.716760635375977]\n",
      "predict val...\n",
      "predict test...\n",
      "144.11967 225.24013\n",
      "100.41992 225.24013 280.28784 1.0\n",
      "FOLD 1931\n",
      "train [36.83285140991211, 6.52829647064209]\n",
      "val [42.51042175292969, 6.812710762023926]\n",
      "predict val...\n",
      "predict test...\n",
      "139.37123 243.21243\n",
      "147.9956 243.21243 331.208 1.0\n",
      "FOLD 1932\n",
      "train [36.666900634765625, 6.536383628845215]\n",
      "val [45.4150505065918, 6.953454971313477]\n",
      "predict val...\n",
      "predict test...\n",
      "145.69302 244.69803\n",
      "169.61963 244.69803 357.0669 1.0\n",
      "FOLD 1933\n",
      "train [32.814002990722656, 6.395535945892334]\n",
      "val [51.544315338134766, 6.7036824226379395]\n",
      "predict val...\n",
      "predict test...\n",
      "165.95593 209.60555\n",
      "113.45093 209.60555 276.64062 1.0\n",
      "FOLD 1934\n",
      "train [37.57816696166992, 6.561413764953613]\n",
      "val [37.32258987426758, 6.505052089691162]\n",
      "predict val...\n",
      "predict test...\n",
      "126.36042 239.46094\n",
      "158.80377 239.46094 299.66895 1.0\n",
      "FOLD 1935\n",
      "train [34.97719192504883, 6.460292816162109]\n",
      "val [41.94663619995117, 6.697137832641602]\n",
      "predict val...\n",
      "predict test...\n",
      "138.4184 212.89738\n",
      "-39.427734 212.89738 320.44702 0.9771986970684039\n",
      "FOLD 1936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.67270278930664, 6.525881290435791]\n",
      "val [41.27177047729492, 6.715706825256348]\n",
      "predict val...\n",
      "predict test...\n",
      "135.29185 249.57428\n",
      "151.71826 249.57428 342.12598 1.0\n",
      "FOLD 1937\n",
      "train [37.168670654296875, 6.549307823181152]\n",
      "val [39.77714157104492, 6.58119010925293]\n",
      "predict val...\n",
      "predict test...\n",
      "128.004 249.12051\n",
      "164.91321 249.12051 371.18213 1.0\n",
      "FOLD 1938\n",
      "train [35.083431243896484, 6.467909812927246]\n",
      "val [50.50642013549805, 6.712654113769531]\n",
      "predict val...\n",
      "predict test...\n",
      "164.40016 223.70807\n",
      "118.194824 223.70807 284.87476 1.0\n",
      "FOLD 1939\n",
      "train [37.21392059326172, 6.5205278396606445]\n",
      "val [36.21634292602539, 6.486804008483887]\n",
      "predict val...\n",
      "predict test...\n",
      "121.74125 242.02824\n",
      "19.93457 242.02824 396.6499 1.0\n",
      "FOLD 1940\n",
      "train [36.06764221191406, 6.513857841491699]\n",
      "val [46.46955108642578, 6.74740743637085]\n",
      "predict val...\n",
      "predict test...\n",
      "155.0398 234.5898\n",
      "171.41846 234.5898 313.06348 1.0\n",
      "FOLD 1941\n",
      "train [36.61970520019531, 6.508077144622803]\n",
      "val [43.11003875732422, 6.94610071182251]\n",
      "predict val...\n",
      "predict test...\n",
      "140.37492 231.97697\n",
      "55.45337 231.97697 360.94995 1.0\n",
      "FOLD 1942\n",
      "train [36.86665344238281, 6.535845756530762]\n",
      "val [40.56218719482422, 6.615416526794434]\n",
      "predict val...\n",
      "predict test...\n",
      "130.3726 242.42467\n",
      "168.22888 242.42467 353.9756 1.0\n",
      "FOLD 1943\n",
      "train [33.72207260131836, 6.419031620025635]\n",
      "val [48.517967224121094, 6.708850860595703]\n",
      "predict val...\n",
      "predict test...\n",
      "156.47894 224.31268\n",
      "90.46094 224.31268 342.73315 1.0\n",
      "FOLD 1944\n",
      "train [35.59425735473633, 6.491663932800293]\n",
      "val [36.62852096557617, 6.448923110961914]\n",
      "predict val...\n",
      "predict test...\n",
      "121.80324 236.10983\n",
      "27.441162 236.10983 354.89417 1.0\n",
      "FOLD 1945\n",
      "train [34.764244079589844, 6.470501899719238]\n",
      "val [44.53792190551758, 6.7761383056640625]\n",
      "predict val...\n",
      "predict test...\n",
      "146.14287 236.38737\n",
      "8.57251 236.38737 356.90552 1.0\n",
      "FOLD 1946\n",
      "train [35.46563720703125, 6.478353977203369]\n",
      "val [44.63343048095703, 7.177418231964111]\n",
      "predict val...\n",
      "predict test...\n",
      "146.29039 224.86906\n",
      "27.447266 224.86906 392.2334 1.0\n",
      "FOLD 1947\n",
      "train [36.30684280395508, 6.504236698150635]\n",
      "val [40.29085922241211, 6.683478355407715]\n",
      "predict val...\n",
      "predict test...\n",
      "131.01466 247.52092\n",
      "96.58154 247.52092 344.24463 1.0\n",
      "FOLD 1948\n",
      "train [33.84756851196289, 6.425324440002441]\n",
      "val [49.62212371826172, 6.718467712402344]\n",
      "predict val...\n",
      "predict test...\n",
      "161.24939 217.84782\n",
      "110.3501 217.84782 310.7412 1.0\n",
      "FOLD 1949\n",
      "train [35.932003021240234, 6.508890628814697]\n",
      "val [35.74589538574219, 6.436616897583008]\n",
      "predict val...\n",
      "predict test...\n",
      "119.59029 230.5846\n",
      "92.965576 230.5846 343.16992 1.0\n",
      "FOLD 1950\n",
      "train [34.979305267333984, 6.471884727478027]\n",
      "val [43.83784484863281, 6.7339677810668945]\n",
      "predict val...\n",
      "predict test...\n",
      "145.90044 232.63411\n",
      "87.02905 232.63411 343.33252 1.0\n",
      "FOLD 1951\n",
      "train [42.087215423583984, 6.5583977699279785]\n",
      "val [47.08352279663086, 6.748989105224609]\n",
      "predict val...\n",
      "predict test...\n",
      "138.64752 256.3573\n",
      "138.25977 256.3573 424.68994 1.0\n",
      "FOLD 1952\n",
      "train [42.331581115722656, 6.555438041687012]\n",
      "val [43.13285827636719, 6.581697463989258]\n",
      "predict val...\n",
      "predict test...\n",
      "121.55008 249.99706\n",
      "131.47778 249.99706 430.36572 1.0\n",
      "FOLD 1953\n",
      "train [40.64252853393555, 6.49893856048584]\n",
      "val [53.59794998168945, 6.679391860961914]\n",
      "predict val...\n",
      "predict test...\n",
      "156.81192 228.14246\n",
      "124.83911 228.14246 470.15186 1.0\n",
      "FOLD 1954\n",
      "train [44.357906341552734, 6.618147850036621]\n",
      "val [42.74246597290039, 6.523669719696045]\n",
      "predict val...\n",
      "predict test...\n",
      "125.94386 240.83551\n",
      "91.636475 240.83551 405.36035 1.0\n",
      "FOLD 1955\n",
      "train [41.24162292480469, 6.546269416809082]\n",
      "val [47.183170318603516, 6.671047210693359]\n",
      "predict val...\n",
      "predict test...\n",
      "139.29929 243.70944\n",
      "154.45044 243.70944 347.4912 1.0\n",
      "FOLD 1956\n",
      "train [42.008609771728516, 6.556532859802246]\n",
      "val [47.15896224975586, 6.764885425567627]\n",
      "predict val...\n",
      "predict test...\n",
      "138.60313 258.94022\n",
      "146.09851 258.94022 387.0088 1.0\n",
      "FOLD 1957\n",
      "train [41.931922912597656, 6.55401086807251]\n",
      "val [45.77295684814453, 6.681480407714844]\n",
      "predict val...\n",
      "predict test...\n",
      "133.42842 245.41277\n",
      "148.35535 245.41277 371.99072 1.0\n",
      "FOLD 1958\n",
      "train [40.68009567260742, 6.503222465515137]\n",
      "val [55.37028503417969, 6.6723198890686035]\n",
      "predict val...\n",
      "predict test...\n",
      "161.16219 228.43872\n",
      "141.89172 228.43872 370.5547 1.0\n",
      "FOLD 1959\n",
      "train [43.27667236328125, 6.5792999267578125]\n",
      "val [38.93031692504883, 6.443976402282715]\n",
      "predict val...\n",
      "predict test...\n",
      "116.59998 220.33673\n",
      "98.79053 220.33673 358.63232 1.0\n",
      "FOLD 1960\n",
      "train [42.07174301147461, 6.543067932128906]\n",
      "val [48.80752182006836, 6.675466537475586]\n",
      "predict val...\n",
      "predict test...\n",
      "144.6197 231.29611\n",
      "166.00671 231.29611 331.16187 1.0\n",
      "FOLD 1961\n",
      "train [41.078025817871094, 6.535516262054443]\n",
      "val [47.40306854248047, 6.726490020751953]\n",
      "predict val...\n",
      "predict test...\n",
      "139.62956 251.7131\n",
      "163.93567 251.7131 354.6006 1.0\n",
      "FOLD 1962\n",
      "train [41.97303009033203, 6.55697774887085]\n",
      "val [43.69599151611328, 6.611753463745117]\n",
      "predict val...\n",
      "predict test...\n",
      "125.62788 252.4604\n",
      "147.97998 252.4604 408.92285 1.0\n",
      "FOLD 1963\n",
      "train [38.469181060791016, 6.467244625091553]\n",
      "val [55.83770751953125, 6.752881050109863]\n",
      "predict val...\n",
      "predict test...\n",
      "161.94107 229.44879\n",
      "91.45386 229.44879 305.80322 1.0\n",
      "FOLD 1964\n",
      "train [42.08184814453125, 6.569338321685791]\n",
      "val [41.11724853515625, 6.468008041381836]\n",
      "predict val...\n",
      "predict test...\n",
      "121.97325 242.30919\n",
      "144.46924 242.30919 315.12012 1.0\n",
      "FOLD 1965\n",
      "train [41.22186279296875, 6.535867214202881]\n",
      "val [50.85157012939453, 6.699251174926758]\n",
      "predict val...\n",
      "predict test...\n",
      "150.0817 239.70302\n",
      "176.7771 239.70302 341.5459 1.0\n",
      "FOLD 1966\n",
      "train [41.251094818115234, 6.530767917633057]\n",
      "val [47.34888458251953, 6.760388374328613]\n",
      "predict val...\n",
      "predict test...\n",
      "138.62183 245.57474\n",
      "148.84204 245.57474 318.10986 1.0\n",
      "FOLD 1967\n",
      "train [41.55343246459961, 6.549334526062012]\n",
      "val [45.246402740478516, 6.61469030380249]\n",
      "predict val...\n",
      "predict test...\n",
      "129.2623 250.96646\n",
      "157.24817 250.96646 391.48047 1.0\n",
      "FOLD 1968\n",
      "train [38.78883361816406, 6.476328372955322]\n",
      "val [54.802459716796875, 6.704440116882324]\n",
      "predict val...\n",
      "predict test...\n",
      "159.56989 234.28091\n",
      "148.5896 234.28091 289.5503 1.0\n",
      "FOLD 1969\n",
      "train [42.85321044921875, 6.578895568847656]\n",
      "val [42.3640251159668, 6.509161472320557]\n",
      "predict val...\n",
      "predict test...\n",
      "127.860214 242.39969\n",
      "156.21106 242.39969 319.87793 1.0\n",
      "FOLD 1970\n",
      "train [40.44276428222656, 6.516153812408447]\n",
      "val [49.17820739746094, 6.703389644622803]\n",
      "predict val...\n",
      "predict test...\n",
      "143.58055 238.37215\n",
      "132.4668 238.37215 352.19922 1.0\n",
      "FOLD 1971\n",
      "train [39.784996032714844, 6.505302429199219]\n",
      "val [46.95750427246094, 6.791859149932861]\n",
      "predict val...\n",
      "predict test...\n",
      "136.63301 243.4547\n",
      "94.32129 243.4547 314.0791 1.0\n",
      "FOLD 1972\n",
      "train [40.829498291015625, 6.526608467102051]\n",
      "val [44.10053634643555, 6.572662353515625]\n",
      "predict val...\n",
      "predict test...\n",
      "126.22957 240.3362\n",
      "154.99268 240.3362 368.93018 1.0\n",
      "FOLD 1973\n",
      "train [36.60448455810547, 6.416003227233887]\n",
      "val [56.417808532714844, 6.68996524810791]\n",
      "predict val...\n",
      "predict test...\n",
      "163.18948 220.42699\n",
      "118.27588 220.42699 331.43774 1.0\n",
      "FOLD 1974\n",
      "train [42.042781829833984, 6.5464935302734375]\n",
      "val [39.872039794921875, 6.48380184173584]\n",
      "predict val...\n",
      "predict test...\n",
      "120.16393 230.29085\n",
      "119.83008 230.29085 398.50684 1.0\n",
      "FOLD 1975\n",
      "train [40.027565002441406, 6.509480953216553]\n",
      "val [48.404701232910156, 6.690247535705566]\n",
      "predict val...\n",
      "predict test...\n",
      "142.16055 230.06146\n",
      "134.09229 230.06146 304.97607 1.0\n",
      "FOLD 1976\n",
      "train [41.5683708190918, 6.5371856689453125]\n",
      "val [46.79948425292969, 6.748796463012695]\n",
      "predict val...\n",
      "predict test...\n",
      "137.12419 243.70226\n",
      "164.198 243.70226 308.83984 1.0\n",
      "FOLD 1977\n",
      "train [39.16477584838867, 6.473642826080322]\n",
      "val [48.545387268066406, 6.8297624588012695]\n",
      "predict val...\n",
      "predict test...\n",
      "140.43224 225.28665\n",
      "165.5022 225.28665 276.93848 1.0\n",
      "FOLD 1978\n",
      "train [36.378421783447266, 6.391025543212891]\n",
      "val [56.66147994995117, 6.706336498260498]\n",
      "predict val...\n",
      "predict test...\n",
      "162.84128 209.27206\n",
      "79.190674 209.27206 289.79248 1.0\n",
      "FOLD 1979\n",
      "train [39.82788848876953, 6.489079475402832]\n",
      "val [41.940608978271484, 6.457022190093994]\n",
      "predict val...\n",
      "predict test...\n",
      "125.63088 221.00076\n",
      "36.62329 221.00076 305.5664 1.0\n",
      "FOLD 1980\n",
      "train [40.95490264892578, 6.516943454742432]\n",
      "val [48.93671798706055, 6.685120582580566]\n",
      "predict val...\n",
      "predict test...\n",
      "145.31749 235.30072\n",
      "163.95947 235.30072 306.33838 1.0\n",
      "FOLD 1981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [39.00349807739258, 6.4861159324646]\n",
      "val [48.98538589477539, 6.8202128410339355]\n",
      "predict val...\n",
      "predict test...\n",
      "142.89714 237.91035\n",
      "112.864746 237.91035 334.82422 1.0\n",
      "FOLD 1982\n",
      "train [41.42902374267578, 6.541454315185547]\n",
      "val [44.45631408691406, 6.616892337799072]\n",
      "predict val...\n",
      "predict test...\n",
      "129.20961 250.97911\n",
      "161.7002 250.97911 370.53955 1.0\n",
      "FOLD 1983\n",
      "train [39.688255310058594, 6.47980260848999]\n",
      "val [54.18135452270508, 6.661965370178223]\n",
      "predict val...\n",
      "predict test...\n",
      "157.39238 232.51726\n",
      "149.79822 232.51726 322.66724 1.0\n",
      "FOLD 1984\n",
      "train [41.35841369628906, 6.5349578857421875]\n",
      "val [40.991554260253906, 6.453919410705566]\n",
      "predict val...\n",
      "predict test...\n",
      "120.823166 237.37918\n",
      "88.11719 237.37918 329.73828 1.0\n",
      "FOLD 1985\n",
      "train [40.196807861328125, 6.515563011169434]\n",
      "val [48.20138168334961, 6.729862689971924]\n",
      "predict val...\n",
      "predict test...\n",
      "142.34193 238.41333\n",
      "86.703125 238.41333 320.01392 1.0\n",
      "FOLD 1986\n",
      "train [40.934715270996094, 6.52011775970459]\n",
      "val [46.954345703125, 6.765476226806641]\n",
      "predict val...\n",
      "predict test...\n",
      "137.64523 241.404\n",
      "145.3822 241.404 336.156 1.0\n",
      "FOLD 1987\n",
      "train [41.86236572265625, 6.549289703369141]\n",
      "val [44.587135314941406, 6.623247146606445]\n",
      "predict val...\n",
      "predict test...\n",
      "128.71298 249.69788\n",
      "167.104 249.69788 373.3767 1.0\n",
      "FOLD 1988\n",
      "train [38.41472244262695, 6.427011966705322]\n",
      "val [54.59446334838867, 6.641860008239746]\n",
      "predict val...\n",
      "predict test...\n",
      "158.77713 220.0667\n",
      "85.07092 220.0667 367.83887 1.0\n",
      "FOLD 1989\n",
      "train [41.812034606933594, 6.545894622802734]\n",
      "val [40.99174880981445, 6.500228404998779]\n",
      "predict val...\n",
      "predict test...\n",
      "123.60286 238.9633\n",
      "130.823 238.9633 360.17212 1.0\n",
      "FOLD 1990\n",
      "train [39.782833099365234, 6.498110771179199]\n",
      "val [51.28435516357422, 6.773224830627441]\n",
      "predict val...\n",
      "predict test...\n",
      "148.89816 236.32939\n",
      "51.490234 236.32939 389.5852 1.0\n",
      "FOLD 1991\n",
      "train [38.81961441040039, 6.473393440246582]\n",
      "val [48.11045837402344, 6.868132591247559]\n",
      "predict val...\n",
      "predict test...\n",
      "140.76253 233.53343\n",
      "69.70166 233.53343 364.0852 1.0\n",
      "FOLD 1992\n",
      "train [39.851417541503906, 6.499240875244141]\n",
      "val [54.680667877197266, 7.114201068878174]\n",
      "predict val...\n",
      "predict test...\n",
      "156.5262 229.67903\n",
      "171.26343 229.67903 320.31348 1.0\n",
      "FOLD 1993\n",
      "train [37.42039108276367, 6.422827243804932]\n",
      "val [57.094844818115234, 6.726590156555176]\n",
      "predict val...\n",
      "predict test...\n",
      "165.16444 228.58704\n",
      "73.50293 228.58704 368.19043 1.0\n",
      "FOLD 1994\n",
      "train [40.04573440551758, 6.490122318267822]\n",
      "val [41.906429290771484, 6.5665130615234375]\n",
      "predict val...\n",
      "predict test...\n",
      "124.91302 244.58902\n",
      "59.73633 244.58902 336.4624 1.0\n",
      "FOLD 1995\n",
      "train [39.470943450927734, 6.475850582122803]\n",
      "val [47.565467834472656, 6.702973365783691]\n",
      "predict val...\n",
      "predict test...\n",
      "138.0808 227.64212\n",
      "-14.599609 227.64212 365.214 0.993485342019544\n",
      "FOLD 1996\n",
      "train [40.41326904296875, 6.506197929382324]\n",
      "val [48.63276290893555, 6.822646141052246]\n",
      "predict val...\n",
      "predict test...\n",
      "142.19951 238.85698\n",
      "83.93652 238.85698 379.53857 1.0\n",
      "FOLD 1997\n",
      "train [40.472591400146484, 6.518751621246338]\n",
      "val [52.379390716552734, 6.917827606201172]\n",
      "predict val...\n",
      "predict test...\n",
      "147.72366 238.74924\n",
      "168.24072 238.74924 353.6787 1.0\n",
      "FOLD 1998\n",
      "train [38.620121002197266, 6.44302225112915]\n",
      "val [54.82905960083008, 6.669604301452637]\n",
      "predict val...\n",
      "predict test...\n",
      "159.98334 225.9971\n",
      "96.74512 225.9971 353.84668 1.0\n",
      "FOLD 1999\n",
      "train [41.43107604980469, 6.535399436950684]\n",
      "val [41.184146881103516, 6.503165245056152]\n",
      "predict val...\n",
      "predict test...\n",
      "123.08121 243.31612\n",
      "115.2594 243.31612 383.22266 1.0\n",
      "FOLD 2000\n",
      "train [38.86512756347656, 6.462101936340332]\n",
      "val [48.4571647644043, 6.735167503356934]\n",
      "predict val...\n",
      "predict test...\n",
      "139.12282 225.61777\n",
      "-84.55176 225.61777 399.85156 0.9543973941368078\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2001\n",
      "train [28.573862075805664, 6.5411057472229]\n",
      "val [31.666912078857422, 6.735123157501221]\n",
      "predict val...\n",
      "predict test...\n",
      "137.66667 245.56566\n",
      "144.50903 245.56566 373.86328 1.0\n",
      "FOLD 2002\n",
      "train [29.301481246948242, 6.570613861083984]\n",
      "val [29.289587020874023, 6.576027870178223]\n",
      "predict val...\n",
      "predict test...\n",
      "121.79876 247.22246\n",
      "149.14807 247.22246 407.27344 1.0\n",
      "FOLD 2003\n",
      "train [27.81003761291504, 6.495179653167725]\n",
      "val [36.23601531982422, 6.679059028625488]\n",
      "predict val...\n",
      "predict test...\n",
      "157.94621 227.28537\n",
      "112.93909 227.28537 480.57812 1.0\n",
      "FOLD 2004\n",
      "train [30.012752532958984, 6.606241703033447]\n",
      "val [29.118497848510742, 6.513971328735352]\n",
      "predict val...\n",
      "predict test...\n",
      "126.85269 235.2006\n",
      "93.8949 235.2006 395.104 1.0\n",
      "FOLD 2005\n",
      "train [28.453754425048828, 6.550945281982422]\n",
      "val [32.94591522216797, 6.680078029632568]\n",
      "predict val...\n",
      "predict test...\n",
      "144.00542 246.68654\n",
      "154.2091 246.68654 359.72363 1.0\n",
      "FOLD 2006\n",
      "train [28.748760223388672, 6.552615165710449]\n",
      "val [31.24363136291504, 6.723353385925293]\n",
      "predict val...\n",
      "predict test...\n",
      "135.50696 252.23148\n",
      "135.80566 252.23148 403.54102 1.0\n",
      "FOLD 2007\n",
      "train [28.79584503173828, 6.553617000579834]\n",
      "val [33.12565994262695, 6.744717597961426]\n",
      "predict val...\n",
      "predict test...\n",
      "142.27382 239.96707\n",
      "159.38708 239.96707 367.62256 1.0\n",
      "FOLD 2008\n",
      "train [27.28304100036621, 6.476853847503662]\n",
      "val [38.17854309082031, 6.701188087463379]\n",
      "predict val...\n",
      "predict test...\n",
      "164.80313 219.74634\n",
      "136.39307 219.74634 364.44482 1.0\n",
      "FOLD 2009\n",
      "train [29.38744354248047, 6.572681427001953]\n",
      "val [27.24321174621582, 6.461481094360352]\n",
      "predict val...\n",
      "predict test...\n",
      "119.587326 219.6909\n",
      "97.58801 219.6909 336.7295 1.0\n",
      "FOLD 2010\n",
      "train [28.642745971679688, 6.5340704917907715]\n",
      "val [32.72346878051758, 6.666260719299316]\n",
      "predict val...\n",
      "predict test...\n",
      "142.2909 223.83514\n",
      "130.56445 223.83514 323.24316 1.0\n",
      "FOLD 2011\n",
      "train [28.96997833251953, 6.578476905822754]\n",
      "val [31.987791061401367, 6.740351676940918]\n",
      "predict val...\n",
      "predict test...\n",
      "139.87779 269.4407\n",
      "170.19617 269.4407 365.86035 1.0\n",
      "FOLD 2012\n",
      "train [29.03058433532715, 6.571169853210449]\n",
      "val [29.135698318481445, 6.595628261566162]\n",
      "predict val...\n",
      "predict test...\n",
      "122.45511 261.6105\n",
      "183.54285 261.6105 407.91602 1.0\n",
      "FOLD 2013\n",
      "train [27.100906372070312, 6.486016273498535]\n",
      "val [35.63264083862305, 6.6685967445373535]\n",
      "predict val...\n",
      "predict test...\n",
      "153.78574 233.09654\n",
      "139.9165 233.09654 288.1455 1.0\n",
      "FOLD 2014\n",
      "train [29.97822380065918, 6.599146366119385]\n",
      "val [29.38782501220703, 6.511714935302734]\n",
      "predict val...\n",
      "predict test...\n",
      "128.64932 233.34859\n",
      "117.87402 233.34859 351.61865 1.0\n",
      "FOLD 2015\n",
      "train [28.218387603759766, 6.5359978675842285]\n",
      "val [34.7418327331543, 6.704069137573242]\n",
      "predict val...\n",
      "predict test...\n",
      "150.92271 233.64851\n",
      "162.5697 233.64851 329.00195 1.0\n",
      "FOLD 2016\n",
      "train [25.83146858215332, 6.4449944496154785]\n",
      "val [30.870607376098633, 6.635278701782227]\n",
      "predict val...\n",
      "predict test...\n",
      "133.89273 231.21504\n",
      "152.86377 231.21504 288.36865 1.0\n",
      "FOLD 2017\n",
      "train [28.307884216308594, 6.5452880859375]\n",
      "val [29.8432674407959, 6.6059651374816895]\n",
      "predict val...\n",
      "predict test...\n",
      "127.40322 252.30266\n",
      "170.7439 252.30266 374.4541 1.0\n",
      "FOLD 2018\n",
      "train [26.550128936767578, 6.4682297706604]\n",
      "val [36.89859390258789, 6.708080291748047]\n",
      "predict val...\n",
      "predict test...\n",
      "158.67154 229.85403\n",
      "137.12134 229.85403 302.23242 1.0\n",
      "FOLD 2019\n",
      "train [28.73729133605957, 6.554673671722412]\n",
      "val [27.638219833374023, 6.446390628814697]\n",
      "predict val...\n",
      "predict test...\n",
      "120.56566 230.93373\n",
      "136.4748 230.93373 316.75195 1.0\n",
      "FOLD 2020\n",
      "train [28.259021759033203, 6.536879062652588]\n",
      "val [33.093257904052734, 6.680132865905762]\n",
      "predict val...\n",
      "predict test...\n",
      "144.89832 239.29143\n",
      "179.13965 239.29143 332.86743 1.0\n",
      "FOLD 2021\n",
      "train [26.653905868530273, 6.4708709716796875]\n",
      "val [33.68450164794922, 6.850907325744629]\n",
      "predict val...\n",
      "predict test...\n",
      "145.13222 225.29688\n",
      "121.57385 225.29688 312.68872 1.0\n",
      "FOLD 2022\n",
      "train [27.09339714050293, 6.484574317932129]\n",
      "val [29.576980590820312, 6.575592041015625]\n",
      "predict val...\n",
      "predict test...\n",
      "125.677345 231.53366\n",
      "149.00098 231.53366 299.11035 1.0\n",
      "FOLD 2023\n",
      "train [26.790983200073242, 6.471275329589844]\n",
      "val [36.20460891723633, 6.693151473999023]\n",
      "predict val...\n",
      "predict test...\n",
      "157.06055 229.72466\n",
      "130.75684 229.72466 281.948 1.0\n",
      "FOLD 2024\n",
      "train [28.167695999145508, 6.513667106628418]\n",
      "val [26.05729866027832, 6.380032062530518]\n",
      "predict val...\n",
      "predict test...\n",
      "113.11732 209.1657\n",
      "121.256226 209.1657 283.33252 1.0\n",
      "FOLD 2025\n",
      "train [27.494455337524414, 6.49657678604126]\n",
      "val [31.254467010498047, 6.656163215637207]\n",
      "predict val...\n",
      "predict test...\n",
      "136.118 221.16699\n",
      "115.6438 221.16699 288.9043 1.0\n",
      "FOLD 2026\n",
      "train [28.392953872680664, 6.543070316314697]\n",
      "val [32.019920349121094, 6.749573707580566]\n",
      "predict val...\n",
      "predict test...\n",
      "139.03226 252.44543\n",
      "167.95044 252.44543 339.76807 1.0\n",
      "FOLD 2027\n",
      "train [26.93442726135254, 6.48000431060791]\n",
      "val [32.32528305053711, 6.755678176879883]\n",
      "predict val...\n",
      "predict test...\n",
      "137.91754 230.77988\n",
      "132.81396 230.77988 290.3667 1.0\n",
      "FOLD 2028\n",
      "train [26.359121322631836, 6.446743965148926]\n",
      "val [38.8320198059082, 6.741461753845215]\n",
      "predict val...\n",
      "predict test...\n",
      "167.41142 223.6478\n",
      "100.97742 223.6478 294.47607 1.0\n",
      "FOLD 2029\n",
      "train [29.357215881347656, 6.568785190582275]\n",
      "val [27.766902923583984, 6.48459529876709]\n",
      "predict val...\n",
      "predict test...\n",
      "122.82515 237.10141\n",
      "154.72498 237.10141 325.69287 1.0\n",
      "FOLD 2030\n",
      "train [27.333112716674805, 6.493987083435059]\n",
      "val [34.33308029174805, 6.7199578285217285]\n",
      "predict val...\n",
      "predict test...\n",
      "149.97925 229.6758\n",
      "130.3877 229.6758 347.36377 1.0\n",
      "FOLD 2031\n",
      "train [28.05294418334961, 6.514814853668213]\n",
      "val [32.548255920410156, 6.838512420654297]\n",
      "predict val...\n",
      "predict test...\n",
      "140.37396 236.73763\n",
      "112.84375 236.73763 355.48413 1.0\n",
      "FOLD 2032\n",
      "train [26.395301818847656, 6.439257621765137]\n",
      "val [31.177391052246094, 6.666818618774414]\n",
      "predict val...\n",
      "predict test...\n",
      "134.04295 227.83678\n",
      "104.59888 227.83678 326.50415 1.0\n",
      "FOLD 2033\n",
      "train [25.808122634887695, 6.426998138427734]\n",
      "val [37.980499267578125, 6.678865432739258]\n",
      "predict val...\n",
      "predict test...\n",
      "163.29092 223.45297\n",
      "93.97949 223.45297 303.05737 1.0\n",
      "FOLD 2034\n",
      "train [28.46108055114746, 6.531055450439453]\n",
      "val [27.783607482910156, 6.439201354980469]\n",
      "predict val...\n",
      "predict test...\n",
      "120.34958 227.4516\n",
      "88.92554 227.4516 304.11426 1.0\n",
      "FOLD 2035\n",
      "train [27.20743179321289, 6.48987340927124]\n",
      "val [32.50701904296875, 6.736393928527832]\n",
      "predict val...\n",
      "predict test...\n",
      "141.62625 233.68175\n",
      "61.651367 233.68175 338.89282 1.0\n",
      "FOLD 2036\n",
      "train [28.084264755249023, 6.514631748199463]\n",
      "val [32.72394943237305, 6.80457878112793]\n",
      "predict val...\n",
      "predict test...\n",
      "140.74585 236.89372\n",
      "124.482056 236.89372 354.531 1.0\n",
      "FOLD 2037\n",
      "train [28.366840362548828, 6.544142723083496]\n",
      "val [30.552825927734375, 6.598374366760254]\n",
      "predict val...\n",
      "predict test...\n",
      "128.88162 249.82379\n",
      "165.66138 249.82379 363.125 1.0\n",
      "FOLD 2038\n",
      "train [25.339557647705078, 6.405442714691162]\n",
      "val [39.437225341796875, 6.731167793273926]\n",
      "predict val...\n",
      "predict test...\n",
      "169.33566 217.53857\n",
      "91.40283 217.53857 348.56763 1.0\n",
      "FOLD 2039\n",
      "train [28.167835235595703, 6.516037940979004]\n",
      "val [27.41608238220215, 6.444925308227539]\n",
      "predict val...\n",
      "predict test...\n",
      "118.74981 228.1165\n",
      "109.29321 228.1165 337.67432 1.0\n",
      "FOLD 2040\n",
      "train [26.631526947021484, 6.463387489318848]\n",
      "val [34.493743896484375, 6.744780540466309]\n",
      "predict val...\n",
      "predict test...\n",
      "151.7395 228.3635\n",
      "108.601074 228.3635 360.37524 1.0\n",
      "FOLD 2041\n",
      "train [25.92770004272461, 6.421326637268066]\n",
      "val [30.15349578857422, 6.730528831481934]\n",
      "predict val...\n",
      "predict test...\n",
      "130.59976 216.4633\n",
      "60.325195 216.4633 340.6577 1.0\n",
      "FOLD 2042\n",
      "train [28.04881477355957, 6.526060581207275]\n",
      "val [30.305831909179688, 6.558506011962891]\n",
      "predict val...\n",
      "predict test...\n",
      "128.66164 240.03313\n",
      "130.08911 240.03313 341.72314 1.0\n",
      "FOLD 2043\n",
      "train [26.005441665649414, 6.431601047515869]\n",
      "val [37.03768539428711, 6.696043968200684]\n",
      "predict val...\n",
      "predict test...\n",
      "159.76703 220.81131\n",
      "109.42969 220.81131 323.37988 1.0\n",
      "FOLD 2044\n",
      "train [28.078563690185547, 6.515555381774902]\n",
      "val [27.865324020385742, 6.458765506744385]\n",
      "predict val...\n",
      "predict test...\n",
      "123.487915 229.967\n",
      "48.907715 229.967 316.55798 1.0\n",
      "FOLD 2045\n",
      "train [27.02574920654297, 6.490429878234863]\n",
      "val [33.72026062011719, 6.787067413330078]\n",
      "predict val...\n",
      "predict test...\n",
      "145.59332 231.45715\n",
      "41.907227 231.45715 365.333 1.0\n",
      "FOLD 2046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [27.777204513549805, 6.492079734802246]\n",
      "val [33.319969177246094, 7.000439643859863]\n",
      "predict val...\n",
      "predict test...\n",
      "143.39355 229.27194\n",
      "60.919434 229.27194 489.5078 1.0\n",
      "FOLD 2047\n",
      "train [27.108163833618164, 6.488990783691406]\n",
      "val [31.35385513305664, 6.600017070770264]\n",
      "predict val...\n",
      "predict test...\n",
      "133.44978 235.33301\n",
      "151.84619 235.33301 326.2378 1.0\n",
      "FOLD 2048\n",
      "train [24.567920684814453, 6.353325366973877]\n",
      "val [37.483009338378906, 6.703444480895996]\n",
      "predict val...\n",
      "predict test...\n",
      "159.51604 198.08818\n",
      "63.856567 198.08818 288.94653 1.0\n",
      "FOLD 2049\n",
      "train [26.65284538269043, 6.466709136962891]\n",
      "val [28.75551986694336, 6.491412162780762]\n",
      "predict val...\n",
      "predict test...\n",
      "124.85983 224.42058\n",
      "69.70679 224.42058 321.55737 1.0\n",
      "FOLD 2050\n",
      "train [26.474288940429688, 6.439140319824219]\n",
      "val [32.55504608154297, 6.733829498291016]\n",
      "predict val...\n",
      "predict test...\n",
      "141.20715 236.50784\n",
      "82.78076 236.50784 523.8694 1.0\n",
      "FOLD 2051\n",
      "train [33.539798736572266, 6.56435489654541]\n",
      "val [37.01033020019531, 6.730634689331055]\n",
      "predict val...\n",
      "predict test...\n",
      "139.24867 251.10286\n",
      "123.98584 251.10286 431.00098 1.0\n",
      "FOLD 2052\n",
      "train [33.85343933105469, 6.575384616851807]\n",
      "val [33.91850280761719, 6.590249061584473]\n",
      "predict val...\n",
      "predict test...\n",
      "121.65994 255.93495\n",
      "139.27307 255.93495 434.02637 1.0\n",
      "FOLD 2053\n",
      "train [31.206777572631836, 6.473696231842041]\n",
      "val [43.216556549072266, 6.741003513336182]\n",
      "predict val...\n",
      "predict test...\n",
      "160.97246 223.43578\n",
      "97.036865 223.43578 455.9375 1.0\n",
      "FOLD 2054\n",
      "train [34.562984466552734, 6.605133056640625]\n",
      "val [33.18408203125, 6.503524303436279]\n",
      "predict val...\n",
      "predict test...\n",
      "124.64587 234.17436\n",
      "90.30255 234.17436 396.94385 1.0\n",
      "FOLD 2055\n",
      "train [32.62470245361328, 6.535693168640137]\n",
      "val [37.259700775146484, 6.665371894836426]\n",
      "predict val...\n",
      "predict test...\n",
      "140.31744 237.45427\n",
      "124.550415 237.45427 408.45508 1.0\n",
      "FOLD 2056\n",
      "train [32.4394416809082, 6.535791873931885]\n",
      "val [37.30284118652344, 6.785015106201172]\n",
      "predict val...\n",
      "predict test...\n",
      "139.74391 251.42274\n",
      "157.42322 251.42274 363.92236 1.0\n",
      "FOLD 2057\n",
      "train [33.577823638916016, 6.55333948135376]\n",
      "val [37.0595817565918, 6.639503479003906]\n",
      "predict val...\n",
      "predict test...\n",
      "135.1793 236.7672\n",
      "141.01404 236.7672 376.9536 1.0\n",
      "FOLD 2058\n",
      "train [30.117212295532227, 6.4402265548706055]\n",
      "val [43.6180419921875, 6.7110819816589355]\n",
      "predict val...\n",
      "predict test...\n",
      "161.27455 221.45241\n",
      "125.02002 221.45241 270.67725 1.0\n",
      "FOLD 2059\n",
      "train [34.74745178222656, 6.597867012023926]\n",
      "val [31.390758514404297, 6.466518402099609]\n",
      "predict val...\n",
      "predict test...\n",
      "119.688286 228.05872\n",
      "109.35272 228.05872 350.61572 1.0\n",
      "FOLD 2060\n",
      "train [33.24040603637695, 6.5383758544921875]\n",
      "val [36.62944793701172, 6.670892715454102]\n",
      "predict val...\n",
      "predict test...\n",
      "136.86237 218.52089\n",
      "137.25366 218.52089 299.24414 1.0\n",
      "FOLD 2061\n",
      "train [32.59280014038086, 6.552805423736572]\n",
      "val [37.15172576904297, 6.732485771179199]\n",
      "predict val...\n",
      "predict test...\n",
      "140.51443 259.72415\n",
      "173.92407 259.72415 323.98804 1.0\n",
      "FOLD 2062\n",
      "train [31.881391525268555, 6.52756404876709]\n",
      "val [34.378761291503906, 6.57966947555542]\n",
      "predict val...\n",
      "predict test...\n",
      "126.29815 248.35548\n",
      "179.2201 248.35548 346.74854 1.0\n",
      "FOLD 2063\n",
      "train [30.488786697387695, 6.463953971862793]\n",
      "val [41.36813735961914, 6.7042670249938965]\n",
      "predict val...\n",
      "predict test...\n",
      "153.03448 224.50473\n",
      "150.46558 224.50473 282.4353 1.0\n",
      "FOLD 2064\n",
      "train [34.459228515625, 6.606816291809082]\n",
      "val [34.14524841308594, 6.524198532104492]\n",
      "predict val...\n",
      "predict test...\n",
      "130.63164 245.52249\n",
      "134.5863 245.52249 348.0166 1.0\n",
      "FOLD 2065\n",
      "train [31.91460609436035, 6.514156341552734]\n",
      "val [39.2673454284668, 6.717866897583008]\n",
      "predict val...\n",
      "predict test...\n",
      "147.18037 230.18948\n",
      "175.49585 230.18948 310.2439 1.0\n",
      "FOLD 2066\n",
      "train [32.7418327331543, 6.537496089935303]\n",
      "val [37.19678497314453, 6.7478837966918945]\n",
      "predict val...\n",
      "predict test...\n",
      "139.04832 248.20175\n",
      "168.13757 248.20175 324.9961 1.0\n",
      "FOLD 2067\n",
      "train [32.5514030456543, 6.540116786956787]\n",
      "val [35.11710739135742, 6.59941291809082]\n",
      "predict val...\n",
      "predict test...\n",
      "127.00886 245.35225\n",
      "164.12085 245.35225 356.28076 1.0\n",
      "FOLD 2068\n",
      "train [31.032346725463867, 6.478517055511475]\n",
      "val [43.06907272338867, 6.712312698364258]\n",
      "predict val...\n",
      "predict test...\n",
      "160.15215 228.3182\n",
      "119.57471 228.3182 285.41748 1.0\n",
      "FOLD 2069\n",
      "train [34.169551849365234, 6.590287208557129]\n",
      "val [32.70996856689453, 6.504162788391113]\n",
      "predict val...\n",
      "predict test...\n",
      "125.09281 244.47842\n",
      "146.01215 244.47842 330.64966 1.0\n",
      "FOLD 2070\n",
      "train [32.30339431762695, 6.530358791351318]\n",
      "val [38.708335876464844, 6.686960220336914]\n",
      "predict val...\n",
      "predict test...\n",
      "145.70396 240.07698\n",
      "179.12683 240.07698 314.46753 1.0\n",
      "FOLD 2071\n",
      "train [30.977705001831055, 6.48431921005249]\n",
      "val [35.752532958984375, 6.591273307800293]\n",
      "predict val...\n",
      "predict test...\n",
      "132.64519 239.25453\n",
      "117.194336 239.25453 310.56738 1.0\n",
      "FOLD 2072\n",
      "train [31.148212432861328, 6.482956886291504]\n",
      "val [35.442176818847656, 6.64426851272583]\n",
      "predict val...\n",
      "predict test...\n",
      "131.56831 233.87428\n",
      "146.50708 233.87428 283.8203 1.0\n",
      "FOLD 2073\n",
      "train [30.334016799926758, 6.443846702575684]\n",
      "val [41.822113037109375, 6.677761077880859]\n",
      "predict val...\n",
      "predict test...\n",
      "154.89616 219.50533\n",
      "120.23535 219.50533 300.33838 1.0\n",
      "FOLD 2074\n",
      "train [32.513938903808594, 6.532917022705078]\n",
      "val [31.89310646057129, 6.43380880355835]\n",
      "predict val...\n",
      "predict test...\n",
      "122.304054 223.18347\n",
      "93.93579 223.18347 273.77588 1.0\n",
      "FOLD 2075\n",
      "train [31.611875534057617, 6.4844770431518555]\n",
      "val [40.19797897338867, 6.775184631347656]\n",
      "predict val...\n",
      "predict test...\n",
      "150.95758 218.55533\n",
      "73.793945 218.55533 329.21826 1.0\n",
      "FOLD 2076\n",
      "train [30.146059036254883, 6.4481096267700195]\n",
      "val [34.92919921875, 6.562166213989258]\n",
      "predict val...\n",
      "predict test...\n",
      "130.33554 221.2394\n",
      "102.13428 221.2394 318.68555 1.0\n",
      "FOLD 2077\n",
      "train [32.72246170043945, 6.546530723571777]\n",
      "val [35.060279846191406, 6.57674503326416]\n",
      "predict val...\n",
      "predict test...\n",
      "128.84909 250.43073\n",
      "165.85901 250.43073 352.32275 1.0\n",
      "FOLD 2078\n",
      "train [29.830020904541016, 6.443800926208496]\n",
      "val [46.02878189086914, 6.747696876525879]\n",
      "predict val...\n",
      "predict test...\n",
      "170.35228 222.28624\n",
      "115.86865 222.28624 278.14624 1.0\n",
      "FOLD 2079\n",
      "train [31.52545166015625, 6.495241641998291]\n",
      "val [31.810794830322266, 6.4413981437683105]\n",
      "predict val...\n",
      "predict test...\n",
      "118.68359 221.33743\n",
      "84.61084 221.33743 288.09668 1.0\n",
      "FOLD 2080\n",
      "train [31.629573822021484, 6.501412868499756]\n",
      "val [37.90559387207031, 6.713297367095947]\n",
      "predict val...\n",
      "predict test...\n",
      "143.66647 232.64671\n",
      "101.267334 232.64671 301.21997 1.0\n",
      "FOLD 2081\n",
      "train [31.164718627929688, 6.503844261169434]\n",
      "val [37.47630310058594, 6.747134208679199]\n",
      "predict val...\n",
      "predict test...\n",
      "139.71768 248.67139\n",
      "168.14111 248.67139 333.23096 1.0\n",
      "FOLD 2082\n",
      "train [32.34074020385742, 6.5312371253967285]\n",
      "val [35.72410202026367, 6.652718544006348]\n",
      "predict val...\n",
      "predict test...\n",
      "132.75159 255.02138\n",
      "173.13892 255.02138 381.94043 1.0\n",
      "FOLD 2083\n",
      "train [30.146188735961914, 6.4278435707092285]\n",
      "val [41.426753997802734, 6.680267333984375]\n",
      "predict val...\n",
      "predict test...\n",
      "153.19106 222.5368\n",
      "75.326416 222.5368 333.91284 1.0\n",
      "FOLD 2084\n",
      "train [34.064613342285156, 6.580349922180176]\n",
      "val [32.2837028503418, 6.492264747619629]\n",
      "predict val...\n",
      "predict test...\n",
      "122.68651 242.0447\n",
      "150.79016 242.0447 317.50366 1.0\n",
      "FOLD 2085\n",
      "train [30.917863845825195, 6.481915473937988]\n",
      "val [37.0181999206543, 6.702541351318359]\n",
      "predict val...\n",
      "predict test...\n",
      "140.27669 238.34741\n",
      "110.81885 238.34741 382.89282 1.0\n",
      "FOLD 2086\n",
      "train [31.603652954101562, 6.490224361419678]\n",
      "val [35.92498779296875, 6.6072797775268555]\n",
      "predict val...\n",
      "predict test...\n",
      "134.18541 228.33194\n",
      "-14.686523 228.33194 410.18945 0.993485342019544\n",
      "FOLD 2087\n",
      "train [30.221485137939453, 6.448904514312744]\n",
      "val [35.19285202026367, 6.650084495544434]\n",
      "predict val...\n",
      "predict test...\n",
      "130.345 233.12161\n",
      "141.64368 233.12161 309.12378 1.0\n",
      "FOLD 2088\n",
      "train [28.516782760620117, 6.378457546234131]\n",
      "val [43.87029266357422, 6.6812214851379395]\n",
      "predict val...\n",
      "predict test...\n",
      "161.8663 213.23586\n",
      "71.64038 213.23586 301.04663 1.0\n",
      "FOLD 2089\n",
      "train [31.403778076171875, 6.488916873931885]\n",
      "val [32.03110122680664, 6.455855369567871]\n",
      "predict val...\n",
      "predict test...\n",
      "120.34463 221.62256\n",
      "45.436523 221.62256 297.19336 1.0\n",
      "FOLD 2090\n",
      "train [30.417312622070312, 6.4553728103637695]\n",
      "val [40.18839645385742, 6.797146797180176]\n",
      "predict val...\n",
      "predict test...\n",
      "147.54109 227.25374\n",
      "-6.814453 227.25374 405.41455 0.9869706840390879\n",
      "FOLD 2091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [30.953487396240234, 6.477329254150391]\n",
      "val [37.88029479980469, 6.7538042068481445]\n",
      "predict val...\n",
      "predict test...\n",
      "141.14467 234.53568\n",
      "114.37549 234.53568 366.17725 1.0\n",
      "FOLD 2092\n",
      "train [32.02439498901367, 6.5080413818359375]\n",
      "val [34.77741622924805, 6.598063945770264]\n",
      "predict val...\n",
      "predict test...\n",
      "127.55756 245.54723\n",
      "147.23389 245.54723 346.7036 1.0\n",
      "FOLD 2093\n",
      "train [27.937856674194336, 6.346050262451172]\n",
      "val [42.791412353515625, 6.685613632202148]\n",
      "predict val...\n",
      "predict test...\n",
      "155.59854 204.205\n",
      "82.78552 204.205 295.09595 1.0\n",
      "FOLD 2094\n",
      "train [32.07817840576172, 6.506031036376953]\n",
      "val [31.903526306152344, 6.453035354614258]\n",
      "predict val...\n",
      "predict test...\n",
      "119.983345 233.93655\n",
      "42.74121 233.93655 378.72656 1.0\n",
      "FOLD 2095\n",
      "train [30.88768196105957, 6.471304416656494]\n",
      "val [38.36151123046875, 6.759063243865967]\n",
      "predict val...\n",
      "predict test...\n",
      "145.56366 229.06383\n",
      "-1.2231445 229.06383 322.28345 0.993485342019544\n",
      "FOLD 2096\n",
      "train [31.4223690032959, 6.4806108474731445]\n",
      "val [38.842491149902344, 7.121663570404053]\n",
      "predict val...\n",
      "predict test...\n",
      "144.0293 230.38422\n",
      "32.321533 230.38422 519.0342 1.0\n",
      "FOLD 2097\n",
      "train [32.25812911987305, 6.523220062255859]\n",
      "val [35.4537239074707, 6.567868709564209]\n",
      "predict val...\n",
      "predict test...\n",
      "130.34795 239.61803\n",
      "140.32324 239.61803 336.81836 1.0\n",
      "FOLD 2098\n",
      "train [30.083194732666016, 6.4237060546875]\n",
      "val [43.388916015625, 6.673529624938965]\n",
      "predict val...\n",
      "predict test...\n",
      "161.98329 223.13884\n",
      "64.36304 223.13884 331.55786 1.0\n",
      "FOLD 2099\n",
      "train [31.9516544342041, 6.502830505371094]\n",
      "val [32.47747039794922, 6.4970903396606445]\n",
      "predict val...\n",
      "predict test...\n",
      "123.12205 240.60446\n",
      "12.880371 240.60446 376.0901 1.0\n",
      "FOLD 2100\n",
      "train [31.029722213745117, 6.477611541748047]\n",
      "val [39.759239196777344, 6.739209175109863]\n",
      "predict val...\n",
      "predict test...\n",
      "148.39424 224.57706\n",
      "86.231445 224.57706 286.84253 1.0\n",
      "FOLD 2101\n",
      "train [37.18232727050781, 6.552608489990234]\n",
      "val [42.16327667236328, 6.750657081604004]\n",
      "predict val...\n",
      "predict test...\n",
      "139.16179 257.30313\n",
      "135.40735 257.30313 426.30713 1.0\n",
      "FOLD 2102\n",
      "train [37.32483673095703, 6.540415287017822]\n",
      "val [39.50558853149414, 6.598871231079102]\n",
      "predict val...\n",
      "predict test...\n",
      "125.43016 244.6337\n",
      "134.68005 244.6337 411.58984 1.0\n",
      "FOLD 2103\n",
      "train [36.066802978515625, 6.484137535095215]\n",
      "val [48.78639221191406, 6.68006706237793]\n",
      "predict val...\n",
      "predict test...\n",
      "159.37007 219.6338\n",
      "118.891235 219.6338 426.94824 1.0\n",
      "FOLD 2104\n",
      "train [39.495826721191406, 6.631965637207031]\n",
      "val [37.562255859375, 6.534388542175293]\n",
      "predict val...\n",
      "predict test...\n",
      "124.08123 256.81735\n",
      "105.875244 256.81735 421.42578 1.0\n",
      "FOLD 2105\n",
      "train [37.16447830200195, 6.542668342590332]\n",
      "val [41.63328170776367, 6.652838230133057]\n",
      "predict val...\n",
      "predict test...\n",
      "136.92328 237.21628\n",
      "133.44653 237.21628 376.99414 1.0\n",
      "FOLD 2106\n",
      "train [37.09195327758789, 6.54239559173584]\n",
      "val [41.78474426269531, 6.7819037437438965]\n",
      "predict val...\n",
      "predict test...\n",
      "136.80301 256.6701\n",
      "145.25476 256.6701 364.6123 1.0\n",
      "FOLD 2107\n",
      "train [38.54667282104492, 6.573603630065918]\n",
      "val [41.86101150512695, 6.666626453399658]\n",
      "predict val...\n",
      "predict test...\n",
      "134.76582 249.36821\n",
      "151.26453 249.36821 407.76855 1.0\n",
      "FOLD 2108\n",
      "train [35.297508239746094, 6.481183052062988]\n",
      "val [48.33933639526367, 6.692121982574463]\n",
      "predict val...\n",
      "predict test...\n",
      "159.41068 229.66357\n",
      "137.90002 229.66357 400.59717 1.0\n",
      "FOLD 2109\n",
      "train [38.18113708496094, 6.571442604064941]\n",
      "val [35.59149932861328, 6.475294589996338]\n",
      "predict val...\n",
      "predict test...\n",
      "120.60001 229.75089\n",
      "114.598206 229.75089 326.72168 1.0\n",
      "FOLD 2110\n",
      "train [37.295562744140625, 6.52960729598999]\n",
      "val [44.10452651977539, 6.686634063720703]\n",
      "predict val...\n",
      "predict test...\n",
      "146.95636 223.93198\n",
      "136.25354 223.93198 320.80273 1.0\n",
      "FOLD 2111\n",
      "train [36.50505828857422, 6.523857116699219]\n",
      "val [41.68307876586914, 6.696340560913086]\n",
      "predict val...\n",
      "predict test...\n",
      "138.18945 242.46611\n",
      "162.6604 242.46611 318.3662 1.0\n",
      "FOLD 2112\n",
      "train [37.83701705932617, 6.562577724456787]\n",
      "val [38.680789947509766, 6.596940994262695]\n",
      "predict val...\n",
      "predict test...\n",
      "124.36179 255.86665\n",
      "158.92236 255.86665 412.44727 1.0\n",
      "FOLD 2113\n",
      "train [34.42184066772461, 6.468695163726807]\n",
      "val [49.75898361206055, 6.723696708679199]\n",
      "predict val...\n",
      "predict test...\n",
      "162.21927 232.38025\n",
      "152.14233 232.38025 300.9707 1.0\n",
      "FOLD 2114\n",
      "train [37.935768127441406, 6.558010101318359]\n",
      "val [38.59126281738281, 6.468563079833984]\n",
      "predict val...\n",
      "predict test...\n",
      "128.45044 228.37253\n",
      "124.0827 228.37253 297.55762 1.0\n",
      "FOLD 2115\n",
      "train [35.67264938354492, 6.505114555358887]\n",
      "val [45.154808044433594, 6.727033615112305]\n",
      "predict val...\n",
      "predict test...\n",
      "149.12633 231.28197\n",
      "157.2876 231.28197 305.59692 1.0\n",
      "FOLD 2116\n",
      "train [35.2662353515625, 6.502248287200928]\n",
      "val [43.59069061279297, 6.816841125488281]\n",
      "predict val...\n",
      "predict test...\n",
      "142.0908 246.47012\n",
      "176.3894 246.47012 300.91553 1.0\n",
      "FOLD 2117\n",
      "train [37.324241638183594, 6.551445007324219]\n",
      "val [39.86096954345703, 6.600679874420166]\n",
      "predict val...\n",
      "predict test...\n",
      "127.15783 253.42146\n",
      "152.46997 253.42146 406.6797 1.0\n",
      "FOLD 2118\n",
      "train [33.70884323120117, 6.441340446472168]\n",
      "val [50.39288330078125, 6.682558059692383]\n",
      "predict val...\n",
      "predict test...\n",
      "163.008 227.50964\n",
      "136.92883 227.50964 283.64697 1.0\n",
      "FOLD 2119\n",
      "train [37.82439041137695, 6.554882049560547]\n",
      "val [37.885982513427734, 6.489215850830078]\n",
      "predict val...\n",
      "predict test...\n",
      "126.42769 235.95216\n",
      "133.70801 235.95216 303.12354 1.0\n",
      "FOLD 2120\n",
      "train [35.13348388671875, 6.49847412109375]\n",
      "val [43.47376251220703, 6.69534969329834]\n",
      "predict val...\n",
      "predict test...\n",
      "144.66002 243.19055\n",
      "157.00293 243.19055 334.68237 1.0\n",
      "FOLD 2121\n",
      "train [36.89242172241211, 6.534975528717041]\n",
      "val [41.519046783447266, 6.760064125061035]\n",
      "predict val...\n",
      "predict test...\n",
      "136.46152 250.08168\n",
      "165.00256 250.08168 343.7959 1.0\n",
      "FOLD 2122\n",
      "train [35.387939453125, 6.495794773101807]\n",
      "val [41.08342361450195, 6.662940502166748]\n",
      "predict val...\n",
      "predict test...\n",
      "133.21924 246.95822\n",
      "143.83862 246.95822 385.63696 1.0\n",
      "FOLD 2123\n",
      "train [34.52101516723633, 6.4563140869140625]\n",
      "val [49.460330963134766, 6.683774948120117]\n",
      "predict val...\n",
      "predict test...\n",
      "162.3152 227.22366\n",
      "119.34436 227.22366 327.05298 1.0\n",
      "FOLD 2124\n",
      "train [37.23244094848633, 6.526256561279297]\n",
      "val [36.56401062011719, 6.475131511688232]\n",
      "predict val...\n",
      "predict test...\n",
      "123.62089 230.831\n",
      "43.270752 230.831 326.5741 1.0\n",
      "FOLD 2125\n",
      "train [35.810302734375, 6.5014328956604]\n",
      "val [48.1587028503418, 6.745375633239746]\n",
      "predict val...\n",
      "predict test...\n",
      "159.15144 222.2125\n",
      "151.0874 222.2125 300.2146 1.0\n",
      "FOLD 2126\n",
      "train [36.29891586303711, 6.5205535888671875]\n",
      "val [40.96836853027344, 6.6321001052856445]\n",
      "predict val...\n",
      "predict test...\n",
      "134.8205 243.16223\n",
      "98.45557 243.16223 321.21484 1.0\n",
      "FOLD 2127\n",
      "train [37.367462158203125, 6.546929836273193]\n",
      "val [39.952598571777344, 6.6268110275268555]\n",
      "predict val...\n",
      "predict test...\n",
      "128.84946 243.48763\n",
      "173.4071 243.48763 361.2085 1.0\n",
      "FOLD 2128\n",
      "train [34.70451354980469, 6.455988883972168]\n",
      "val [50.13812255859375, 6.7028117179870605]\n",
      "predict val...\n",
      "predict test...\n",
      "163.91434 225.58209\n",
      "142.28882 225.58209 296.76855 1.0\n",
      "FOLD 2129\n",
      "train [37.6098518371582, 6.55593729019165]\n",
      "val [37.50888442993164, 6.488123893737793]\n",
      "predict val...\n",
      "predict test...\n",
      "126.01155 237.80568\n",
      "153.4845 237.80568 299.82935 1.0\n",
      "FOLD 2130\n",
      "train [36.29777526855469, 6.520804405212402]\n",
      "val [45.08121871948242, 6.714615821838379]\n",
      "predict val...\n",
      "predict test...\n",
      "150.02914 230.96379\n",
      "143.92896 230.96379 318.9087 1.0\n",
      "FOLD 2131\n",
      "train [35.36590576171875, 6.499852180480957]\n",
      "val [41.77420425415039, 6.714014053344727]\n",
      "predict val...\n",
      "predict test...\n",
      "137.41473 245.82579\n",
      "162.68164 245.82579 323.12695 1.0\n",
      "FOLD 2132\n",
      "train [36.18915557861328, 6.507551670074463]\n",
      "val [42.68040084838867, 6.716064453125]\n",
      "predict val...\n",
      "predict test...\n",
      "135.22607 231.37021\n",
      "159.34741 231.37021 353.82568 1.0\n",
      "FOLD 2133\n",
      "train [34.715118408203125, 6.451943397521973]\n",
      "val [48.28807067871094, 6.682727336883545]\n",
      "predict val...\n",
      "predict test...\n",
      "156.6646 219.80843\n",
      "141.26538 219.80843 287.23975 1.0\n",
      "FOLD 2134\n",
      "train [35.82068634033203, 6.491671562194824]\n",
      "val [36.92570495605469, 6.450822830200195]\n",
      "predict val...\n",
      "predict test...\n",
      "122.76896 220.86617\n",
      "78.11621 220.86617 321.82397 1.0\n",
      "FOLD 2135\n",
      "train [35.30625915527344, 6.48483419418335]\n",
      "val [44.9478759765625, 6.794690132141113]\n",
      "predict val...\n",
      "predict test...\n",
      "147.23067 232.50381\n",
      "40.27539 232.50381 359.75 1.0\n",
      "FOLD 2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.59209060668945, 6.520974636077881]\n",
      "val [42.93463897705078, 6.759773254394531]\n",
      "predict val...\n",
      "predict test...\n",
      "141.68132 244.7122\n",
      "133.3523 244.7122 333.7246 1.0\n",
      "FOLD 2137\n",
      "train [35.17070770263672, 6.491052150726318]\n",
      "val [40.148921966552734, 6.546173095703125]\n",
      "predict val...\n",
      "predict test...\n",
      "130.21326 234.14473\n",
      "156.8512 234.14473 288.87866 1.0\n",
      "FOLD 2138\n",
      "train [33.03204345703125, 6.407240390777588]\n",
      "val [51.4511604309082, 6.667695999145508]\n",
      "predict val...\n",
      "predict test...\n",
      "166.18752 229.66086\n",
      "72.39038 229.66086 356.0537 1.0\n",
      "FOLD 2139\n",
      "train [35.85342025756836, 6.504205226898193]\n",
      "val [36.26536560058594, 6.484742164611816]\n",
      "predict val...\n",
      "predict test...\n",
      "121.83258 235.37994\n",
      "117.980225 235.37994 338.97607 1.0\n",
      "FOLD 2140\n",
      "train [36.05850601196289, 6.505962371826172]\n",
      "val [45.87663269042969, 6.763617515563965]\n",
      "predict val...\n",
      "predict test...\n",
      "150.77904 231.45663\n",
      "94.04492 231.45663 325.37817 1.0\n",
      "FOLD 2141\n",
      "train [36.072120666503906, 6.492877960205078]\n",
      "val [43.25520324707031, 6.919976711273193]\n",
      "predict val...\n",
      "predict test...\n",
      "141.26813 232.79951\n",
      "60.628418 232.79951 337.57153 1.0\n",
      "FOLD 2142\n",
      "train [37.07970428466797, 6.547059059143066]\n",
      "val [39.755672454833984, 6.600419044494629]\n",
      "predict val...\n",
      "predict test...\n",
      "128.0091 245.64546\n",
      "175.69775 245.64546 354.55273 1.0\n",
      "FOLD 2143\n",
      "train [34.74614334106445, 6.454872131347656]\n",
      "val [48.516258239746094, 6.6591105461120605]\n",
      "predict val...\n",
      "predict test...\n",
      "159.21414 226.94753\n",
      "103.29126 226.94753 319.4912 1.0\n",
      "FOLD 2144\n",
      "train [34.61808395385742, 6.457139015197754]\n",
      "val [36.38967514038086, 6.44406795501709]\n",
      "predict val...\n",
      "predict test...\n",
      "121.41438 226.46051\n",
      "25.085205 226.46051 341.09082 1.0\n",
      "FOLD 2145\n",
      "train [34.393680572509766, 6.448054313659668]\n",
      "val [45.281864166259766, 6.824823379516602]\n",
      "predict val...\n",
      "predict test...\n",
      "148.22145 231.05995\n",
      "-2.0739746 231.05995 370.2417 0.996742671009772\n",
      "FOLD 2146\n",
      "train [35.74589157104492, 6.491039276123047]\n",
      "val [41.15926742553711, 6.663632392883301]\n",
      "predict val...\n",
      "predict test...\n",
      "134.74332 233.37772\n",
      "-42.946777 233.37772 452.08887 0.9804560260586319\n",
      "FOLD 2147\n",
      "train [36.764427185058594, 6.529664516448975]\n",
      "val [39.872314453125, 6.572432994842529]\n",
      "predict val...\n",
      "predict test...\n",
      "128.75891 250.13536\n",
      "105.05994 250.13536 371.63428 1.0\n",
      "FOLD 2148\n",
      "train [34.804908752441406, 6.45544958114624]\n",
      "val [48.132869720458984, 6.654302597045898]\n",
      "predict val...\n",
      "predict test...\n",
      "156.5588 227.91562\n",
      "123.83826 227.91562 311.45947 1.0\n",
      "FOLD 2149\n",
      "train [37.64689636230469, 6.5570502281188965]\n",
      "val [37.34577178955078, 6.51669454574585]\n",
      "predict val...\n",
      "predict test...\n",
      "124.82609 242.18529\n",
      "138.61072 242.18529 338.32202 1.0\n",
      "FOLD 2150\n",
      "train [34.9321403503418, 6.466000556945801]\n",
      "val [43.13728332519531, 6.737586498260498]\n",
      "predict val...\n",
      "predict test...\n",
      "141.96196 228.27339\n",
      "71.358154 228.27339 404.48242 1.0\n",
      "FOLD 2151\n",
      "train [42.30553436279297, 6.552149772644043]\n",
      "val [47.306846618652344, 6.748163223266602]\n",
      "predict val...\n",
      "predict test...\n",
      "139.42139 244.62729\n",
      "133.65686 244.62729 389.21924 1.0\n",
      "FOLD 2152\n",
      "train [42.83941650390625, 6.557102203369141]\n",
      "val [43.19335174560547, 6.567043304443359]\n",
      "predict val...\n",
      "predict test...\n",
      "121.76219 238.49074\n",
      "132.37927 238.49074 402.9629 1.0\n",
      "FOLD 2153\n",
      "train [40.10422897338867, 6.476380825042725]\n",
      "val [54.17414093017578, 6.665068626403809]\n",
      "predict val...\n",
      "predict test...\n",
      "156.93417 215.95598\n",
      "108.70276 215.95598 441.1421 1.0\n",
      "FOLD 2154\n",
      "train [43.69089889526367, 6.6077752113342285]\n",
      "val [42.35663604736328, 6.511310577392578]\n",
      "predict val...\n",
      "predict test...\n",
      "125.88092 238.63261\n",
      "93.51758 238.63261 402.11816 1.0\n",
      "FOLD 2155\n",
      "train [42.14772033691406, 6.56597375869751]\n",
      "val [48.14848709106445, 6.672144889831543]\n",
      "predict val...\n",
      "predict test...\n",
      "142.59294 250.15515\n",
      "133.71497 250.15515 409.4922 1.0\n",
      "FOLD 2156\n",
      "train [41.97737503051758, 6.553320407867432]\n",
      "val [47.05345153808594, 6.784787654876709]\n",
      "predict val...\n",
      "predict test...\n",
      "138.58748 254.81512\n",
      "161.35596 254.81512 382.25928 1.0\n",
      "FOLD 2157\n",
      "train [41.89601135253906, 6.537666320800781]\n",
      "val [46.78290557861328, 6.6631574630737305]\n",
      "predict val...\n",
      "predict test...\n",
      "134.58017 231.34573\n",
      "140.15356 231.34573 372.04492 1.0\n",
      "FOLD 2158\n",
      "train [39.968265533447266, 6.48016357421875]\n",
      "val [56.65028381347656, 6.717553615570068]\n",
      "predict val...\n",
      "predict test...\n",
      "164.56139 219.15587\n",
      "117.11072 219.15587 427.35938 1.0\n",
      "FOLD 2159\n",
      "train [44.43369674682617, 6.596958160400391]\n",
      "val [40.37586212158203, 6.468664169311523]\n",
      "predict val...\n",
      "predict test...\n",
      "121.188644 225.97809\n",
      "102.920166 225.97809 352.5625 1.0\n",
      "FOLD 2160\n",
      "train [42.18172836303711, 6.541755676269531]\n",
      "val [46.52448272705078, 6.66628360748291]\n",
      "predict val...\n",
      "predict test...\n",
      "136.7404 221.92809\n",
      "139.66272 221.92809 313.3999 1.0\n",
      "FOLD 2161\n",
      "train [41.59714889526367, 6.5547943115234375]\n",
      "val [46.457191467285156, 6.713785171508789]\n",
      "predict val...\n",
      "predict test...\n",
      "137.00175 260.14398\n",
      "167.40015 260.14398 344.81836 1.0\n",
      "FOLD 2162\n",
      "train [40.71656036376953, 6.529173374176025]\n",
      "val [43.22139358520508, 6.612970352172852]\n",
      "predict val...\n",
      "predict test...\n",
      "125.77161 244.29138\n",
      "167.23914 244.29138 360.08398 1.0\n",
      "FOLD 2163\n",
      "train [37.702640533447266, 6.445065498352051]\n",
      "val [56.4543342590332, 6.710648536682129]\n",
      "predict val...\n",
      "predict test...\n",
      "162.72005 223.72476\n",
      "135.20142 223.72476 334.56104 1.0\n",
      "FOLD 2164\n",
      "train [41.42848587036133, 6.550323486328125]\n",
      "val [41.60969543457031, 6.480704307556152]\n",
      "predict val...\n",
      "predict test...\n",
      "124.80581 231.99318\n",
      "129.3855 231.99318 297.63965 1.0\n",
      "FOLD 2165\n",
      "train [39.96649932861328, 6.500451564788818]\n",
      "val [50.43754196166992, 6.706100940704346]\n",
      "predict val...\n",
      "predict test...\n",
      "148.05714 229.91692\n",
      "164.97144 229.91692 313.29614 1.0\n",
      "FOLD 2166\n",
      "train [40.954376220703125, 6.518988609313965]\n",
      "val [45.77048110961914, 6.679409027099609]\n",
      "predict val...\n",
      "predict test...\n",
      "135.46982 237.7758\n",
      "122.59082 237.7758 384.71875 1.0\n",
      "FOLD 2167\n",
      "train [40.88279342651367, 6.538259983062744]\n",
      "val [44.649314880371094, 6.616787910461426]\n",
      "predict val...\n",
      "predict test...\n",
      "128.72102 249.18936\n",
      "167.9768 249.18936 362.2417 1.0\n",
      "FOLD 2168\n",
      "train [38.56261444091797, 6.467654228210449]\n",
      "val [55.22395324707031, 6.726919174194336]\n",
      "predict val...\n",
      "predict test...\n",
      "160.13792 232.56795\n",
      "101.68848 232.56795 322.3689 1.0\n",
      "FOLD 2169\n",
      "train [42.645381927490234, 6.586060523986816]\n",
      "val [42.162818908691406, 6.510117530822754]\n",
      "predict val...\n",
      "predict test...\n",
      "127.389046 244.7756\n",
      "150.02832 244.7756 309.31177 1.0\n",
      "FOLD 2170\n",
      "train [40.24188232421875, 6.524102210998535]\n",
      "val [48.92402648925781, 6.692774772644043]\n",
      "predict val...\n",
      "predict test...\n",
      "144.74422 249.0725\n",
      "167.28442 249.0725 322.43262 1.0\n",
      "FOLD 2171\n",
      "train [40.26818084716797, 6.511950492858887]\n",
      "val [45.692108154296875, 6.680324077606201]\n",
      "predict val...\n",
      "predict test...\n",
      "134.38464 241.67046\n",
      "167.24792 241.67046 306.66553 1.0\n",
      "FOLD 2172\n",
      "train [41.72769546508789, 6.548548698425293]\n",
      "val [43.56181335449219, 6.606863021850586]\n",
      "predict val...\n",
      "predict test...\n",
      "126.31869 251.54123\n",
      "179.9331 251.54123 346.875 1.0\n",
      "FOLD 2173\n",
      "train [39.524925231933594, 6.488146781921387]\n",
      "val [54.85529708862305, 6.67518424987793]\n",
      "predict val...\n",
      "predict test...\n",
      "160.0437 235.03003\n",
      "165.79285 235.03003 307.3662 1.0\n",
      "FOLD 2174\n",
      "train [41.784244537353516, 6.541639804840088]\n",
      "val [40.92910385131836, 6.475459098815918]\n",
      "predict val...\n",
      "predict test...\n",
      "124.35388 233.79485\n",
      "127.10571 233.79485 309.2683 1.0\n",
      "FOLD 2175\n",
      "train [40.002532958984375, 6.505605220794678]\n",
      "val [48.438446044921875, 6.70753288269043]\n",
      "predict val...\n",
      "predict test...\n",
      "141.80705 228.9995\n",
      "108.3916 228.9995 304.5232 1.0\n",
      "FOLD 2176\n",
      "train [40.309879302978516, 6.500073432922363]\n",
      "val [48.75162124633789, 7.068746566772461]\n",
      "predict val...\n",
      "predict test...\n",
      "142.46208 230.80121\n",
      "39.495605 230.80121 463.58105 1.0\n",
      "FOLD 2177\n",
      "train [39.929237365722656, 6.511709690093994]\n",
      "val [43.959720611572266, 6.624896049499512]\n",
      "predict val...\n",
      "predict test...\n",
      "126.45268 240.9891\n",
      "122.45361 240.9891 316.88623 1.0\n",
      "FOLD 2178\n",
      "train [38.121482849121094, 6.433005332946777]\n",
      "val [53.719085693359375, 6.690052032470703]\n",
      "predict val...\n",
      "predict test...\n",
      "155.83691 212.16414\n",
      "116.737305 212.16414 274.41382 1.0\n",
      "FOLD 2179\n",
      "train [40.7874641418457, 6.534143924713135]\n",
      "val [40.82819747924805, 6.479617118835449]\n",
      "predict val...\n",
      "predict test...\n",
      "122.3867 237.71056\n",
      "129.66187 237.71056 321.01172 1.0\n",
      "FOLD 2180\n",
      "train [39.899192810058594, 6.494402885437012]\n",
      "val [49.104122161865234, 6.735905647277832]\n",
      "predict val...\n",
      "predict test...\n",
      "145.2691 229.20872\n",
      "82.72949 229.20872 330.97705 1.0\n",
      "FOLD 2181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [38.812232971191406, 6.473865509033203]\n",
      "val [44.282657623291016, 6.623631477355957]\n",
      "predict val...\n",
      "predict test...\n",
      "130.37703 239.11003\n",
      "63.22534 239.11003 405.75977 1.0\n",
      "FOLD 2182\n",
      "train [38.62290573120117, 6.472398281097412]\n",
      "val [47.334930419921875, 6.715024471282959]\n",
      "predict val...\n",
      "predict test...\n",
      "136.40408 228.99353\n",
      "140.00732 228.99353 275.27173 1.0\n",
      "FOLD 2183\n",
      "train [35.72507858276367, 6.357064723968506]\n",
      "val [54.63157653808594, 6.65757417678833]\n",
      "predict val...\n",
      "predict test...\n",
      "157.45961 202.42046\n",
      "65.86841 202.42046 309.78247 1.0\n",
      "FOLD 2184\n",
      "train [40.95154571533203, 6.529658317565918]\n",
      "val [40.14179611206055, 6.432612419128418]\n",
      "predict val...\n",
      "predict test...\n",
      "120.113754 235.60872\n",
      "87.69751 235.60872 364.4431 1.0\n",
      "FOLD 2185\n",
      "train [39.04780197143555, 6.466423034667969]\n",
      "val [50.603294372558594, 6.814177989959717]\n",
      "predict val...\n",
      "predict test...\n",
      "149.16304 230.54677\n",
      "-16.11792 230.54677 349.18628 0.9869706840390879\n",
      "FOLD 2186\n",
      "train [39.86086654663086, 6.515351295471191]\n",
      "val [48.2425422668457, 6.788654804229736]\n",
      "predict val...\n",
      "predict test...\n",
      "141.9176 245.37994\n",
      "157.80054 245.37994 372.11267 1.0\n",
      "FOLD 2187\n",
      "train [40.49207305908203, 6.518240928649902]\n",
      "val [44.06726837158203, 6.603281021118164]\n",
      "predict val...\n",
      "predict test...\n",
      "127.0556 255.50233\n",
      "145.34583 255.50233 385.81738 1.0\n",
      "FOLD 2188\n",
      "train [36.308189392089844, 6.400434970855713]\n",
      "val [58.85288619995117, 6.7167887687683105]\n",
      "predict val...\n",
      "predict test...\n",
      "168.8866 220.95415\n",
      "101.826904 220.95415 330.761 1.0\n",
      "FOLD 2189\n",
      "train [39.891357421875, 6.50714111328125]\n",
      "val [41.89060974121094, 6.517705917358398]\n",
      "predict val...\n",
      "predict test...\n",
      "122.93603 230.31683\n",
      "96.749756 230.31683 311.9474 1.0\n",
      "FOLD 2190\n",
      "train [40.13006591796875, 6.509312629699707]\n",
      "val [49.05198669433594, 6.713852405548096]\n",
      "predict val...\n",
      "predict test...\n",
      "144.82407 227.92368\n",
      "150.81567 227.92368 293.9348 1.0\n",
      "FOLD 2191\n",
      "train [38.18878173828125, 6.459290981292725]\n",
      "val [46.24797821044922, 6.662725448608398]\n",
      "predict val...\n",
      "predict test...\n",
      "134.24295 228.52377\n",
      "65.535645 228.52377 390.60986 1.0\n",
      "FOLD 2192\n",
      "train [39.81471252441406, 6.49648904800415]\n",
      "val [43.73980712890625, 6.590828895568848]\n",
      "predict val...\n",
      "predict test...\n",
      "127.33118 233.77953\n",
      "127.31543 233.77953 319.27148 1.0\n",
      "FOLD 2193\n",
      "train [36.79324722290039, 6.405458927154541]\n",
      "val [57.079410552978516, 6.680820465087891]\n",
      "predict val...\n",
      "predict test...\n",
      "164.0803 219.75005\n",
      "76.70691 219.75005 313.39844 1.0\n",
      "FOLD 2194\n",
      "train [42.155033111572266, 6.556623935699463]\n",
      "val [41.4716911315918, 6.50347900390625]\n",
      "predict val...\n",
      "predict test...\n",
      "124.11828 241.10268\n",
      "150.79028 241.10268 332.354 1.0\n",
      "FOLD 2195\n",
      "train [39.242313385009766, 6.493995666503906]\n",
      "val [55.39093780517578, 6.906255722045898]\n",
      "predict val...\n",
      "predict test...\n",
      "160.204 237.53734\n",
      "35.0459 237.53734 389.81665 1.0\n",
      "FOLD 2196\n",
      "train [38.03720474243164, 6.443545341491699]\n",
      "val [48.91657257080078, 6.893925666809082]\n",
      "predict val...\n",
      "predict test...\n",
      "140.89085 221.23419\n",
      "87.440674 221.23419 432.21045 1.0\n",
      "FOLD 2197\n",
      "train [40.4962043762207, 6.519400119781494]\n",
      "val [45.69832992553711, 6.663810729980469]\n",
      "predict val...\n",
      "predict test...\n",
      "132.1231 253.21152\n",
      "132.04407 253.21152 397.3423 1.0\n",
      "FOLD 2198\n",
      "train [36.47673034667969, 6.393233299255371]\n",
      "val [56.66347122192383, 6.730913162231445]\n",
      "predict val...\n",
      "predict test...\n",
      "162.09558 208.83138\n",
      "103.17493 208.83138 309.56274 1.0\n",
      "FOLD 2199\n",
      "train [39.923362731933594, 6.4907379150390625]\n",
      "val [41.100833892822266, 6.467702865600586]\n",
      "predict val...\n",
      "predict test...\n",
      "122.63729 225.75954\n",
      "38.113525 225.75954 330.313 1.0\n",
      "FOLD 2200\n",
      "train [39.152801513671875, 6.475536346435547]\n",
      "val [49.343955993652344, 6.748242378234863]\n",
      "predict val...\n",
      "predict test...\n",
      "143.28532 227.63951\n",
      "35.604492 227.63951 325.11133 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2201\n",
      "train [28.384607315063477, 6.547825813293457]\n",
      "val [31.950138092041016, 6.765663146972656]\n",
      "predict val...\n",
      "predict test...\n",
      "137.85382 254.03156\n",
      "135.57434 254.03156 413.8828 1.0\n",
      "FOLD 2202\n",
      "train [29.246692657470703, 6.566744804382324]\n",
      "val [29.220008850097656, 6.566047191619873]\n",
      "predict val...\n",
      "predict test...\n",
      "121.70983 246.31158\n",
      "154.3429 246.31158 399.06104 1.0\n",
      "FOLD 2203\n",
      "train [27.40013885498047, 6.477783203125]\n",
      "val [37.08058547973633, 6.670680046081543]\n",
      "predict val...\n",
      "predict test...\n",
      "161.14638 220.79562\n",
      "111.05444 220.79562 463.45508 1.0\n",
      "FOLD 2204\n",
      "train [29.945388793945312, 6.61367130279541]\n",
      "val [27.955734252929688, 6.505993843078613]\n",
      "predict val...\n",
      "predict test...\n",
      "122.40009 241.80222\n",
      "96.021545 241.80222 404.67676 1.0\n",
      "FOLD 2205\n",
      "train [28.8104190826416, 6.556158542633057]\n",
      "val [32.76901626586914, 6.678378582000732]\n",
      "predict val...\n",
      "predict test...\n",
      "143.1771 239.90582\n",
      "139.76648 239.90582 361.12158 1.0\n",
      "FOLD 2206\n",
      "train [28.871999740600586, 6.5687689781188965]\n",
      "val [32.292747497558594, 6.8097734451293945]\n",
      "predict val...\n",
      "predict test...\n",
      "140.176 262.4923\n",
      "162.62976 262.4923 358.96777 1.0\n",
      "FOLD 2207\n",
      "train [27.606489181518555, 6.513955116271973]\n",
      "val [31.612327575683594, 6.65641975402832]\n",
      "predict val...\n",
      "predict test...\n",
      "133.87021 236.38968\n",
      "158.55176 236.38968 337.5083 1.0\n",
      "FOLD 2208\n",
      "train [27.71186637878418, 6.487888336181641]\n",
      "val [36.79450988769531, 6.663601875305176]\n",
      "predict val...\n",
      "predict test...\n",
      "159.57446 220.67065\n",
      "157.63196 220.67065 301.28613 1.0\n",
      "FOLD 2209\n",
      "train [29.45241928100586, 6.588347434997559]\n",
      "val [28.75806999206543, 6.492744445800781]\n",
      "predict val...\n",
      "predict test...\n",
      "125.49374 236.10953\n",
      "115.808655 236.10953 348.60156 1.0\n",
      "FOLD 2210\n",
      "train [28.507688522338867, 6.526331424713135]\n",
      "val [32.75971984863281, 6.670883655548096]\n",
      "predict val...\n",
      "predict test...\n",
      "142.8522 221.15858\n",
      "169.69873 221.15858 322.86475 1.0\n",
      "FOLD 2211\n",
      "train [27.944936752319336, 6.5285444259643555]\n",
      "val [32.0494270324707, 6.771100044250488]\n",
      "predict val...\n",
      "predict test...\n",
      "139.31693 247.65846\n",
      "127.0791 247.65846 332.40186 1.0\n",
      "FOLD 2212\n",
      "train [27.687963485717773, 6.514411926269531]\n",
      "val [29.912256240844727, 6.589829444885254]\n",
      "predict val...\n",
      "predict test...\n",
      "128.41135 234.045\n",
      "141.09985 234.045 329.13965 1.0\n",
      "FOLD 2213\n",
      "train [27.027938842773438, 6.485769748687744]\n",
      "val [36.5941276550293, 6.716581344604492]\n",
      "predict val...\n",
      "predict test...\n",
      "158.19925 233.45992\n",
      "131.95312 233.45992 296.72803 1.0\n",
      "FOLD 2214\n",
      "train [29.270511627197266, 6.587460517883301]\n",
      "val [29.22707748413086, 6.485165596008301]\n",
      "predict val...\n",
      "predict test...\n",
      "126.83314 240.23479\n",
      "131.50305 240.23479 326.61182 1.0\n",
      "FOLD 2215\n",
      "train [27.312610626220703, 6.509486198425293]\n",
      "val [32.40952682495117, 6.683985233306885]\n",
      "predict val...\n",
      "predict test...\n",
      "140.51149 230.7174\n",
      "148.2572 230.7174 326.813 1.0\n",
      "FOLD 2216\n",
      "train [27.56260871887207, 6.5057830810546875]\n",
      "val [30.533161163330078, 6.556787490844727]\n",
      "predict val...\n",
      "predict test...\n",
      "132.03142 230.39925\n",
      "42.29956 230.39925 335.42285 1.0\n",
      "FOLD 2217\n",
      "train [27.317398071289062, 6.5059099197387695]\n",
      "val [29.864999771118164, 6.593478202819824]\n",
      "predict val...\n",
      "predict test...\n",
      "128.1314 240.24748\n",
      "138.93726 240.24748 316.885 1.0\n",
      "FOLD 2218\n",
      "train [26.04866600036621, 6.425972938537598]\n",
      "val [36.37935256958008, 6.706788063049316]\n",
      "predict val...\n",
      "predict test...\n",
      "155.67032 212.60579\n",
      "116.18677 212.60579 274.04492 1.0\n",
      "FOLD 2219\n",
      "train [29.203340530395508, 6.576837062835693]\n",
      "val [28.865930557250977, 6.509989261627197]\n",
      "predict val...\n",
      "predict test...\n",
      "126.20854 251.03624\n",
      "146.82703 251.03624 339.2495 1.0\n",
      "FOLD 2220\n",
      "train [27.929039001464844, 6.547728061676025]\n",
      "val [32.9969482421875, 6.6882524490356445]\n",
      "predict val...\n",
      "predict test...\n",
      "143.62294 254.3893\n",
      "187.92773 254.3893 344.9204 1.0\n",
      "FOLD 2221\n",
      "train [26.57605743408203, 6.459874629974365]\n",
      "val [30.15389633178711, 6.535702705383301]\n",
      "predict val...\n",
      "predict test...\n",
      "131.23679 224.02896\n",
      "37.644775 224.02896 334.01318 1.0\n",
      "FOLD 2222\n",
      "train [27.90989875793457, 6.526064395904541]\n",
      "val [31.069446563720703, 6.591424465179443]\n",
      "predict val...\n",
      "predict test...\n",
      "132.585 242.27626\n",
      "146.60986 242.27626 318.22705 1.0\n",
      "FOLD 2223\n",
      "train [26.195714950561523, 6.4419264793396]\n",
      "val [38.18006134033203, 6.719064712524414]\n",
      "predict val...\n",
      "predict test...\n",
      "165.25356 223.20038\n",
      "109.36621 223.20038 310.5437 1.0\n",
      "FOLD 2224\n",
      "train [28.69060707092285, 6.537995338439941]\n",
      "val [27.731346130371094, 6.427001953125]\n",
      "predict val...\n",
      "predict test...\n",
      "120.4339 226.51582\n",
      "114.01514 226.51582 315.40918 1.0\n",
      "FOLD 2225\n",
      "train [26.451671600341797, 6.453469276428223]\n",
      "val [34.152626037597656, 6.739182472229004]\n",
      "predict val...\n",
      "predict test...\n",
      "148.52528 216.79967\n",
      "109.24756 216.79967 296.46655 1.0\n",
      "FOLD 2226\n",
      "train [27.61574935913086, 6.5194878578186035]\n",
      "val [31.561819076538086, 6.7856035232543945]\n",
      "predict val...\n",
      "predict test...\n",
      "134.7824 243.06255\n",
      "96.69287 243.06255 333.146 1.0\n",
      "FOLD 2227\n",
      "train [27.105379104614258, 6.48403263092041]\n",
      "val [31.401275634765625, 6.781708717346191]\n",
      "predict val...\n",
      "predict test...\n",
      "133.52785 234.33296\n",
      "132.4082 234.33296 304.72632 1.0\n",
      "FOLD 2228\n",
      "train [26.639324188232422, 6.441189765930176]\n",
      "val [36.241905212402344, 6.662064075469971]\n",
      "predict val...\n",
      "predict test...\n",
      "155.05812 214.14368\n",
      "122.30652 214.14368 299.26953 1.0\n",
      "FOLD 2229\n",
      "train [27.837865829467773, 6.505898952484131]\n",
      "val [27.797603607177734, 6.438047885894775]\n",
      "predict val...\n",
      "predict test...\n",
      "120.57351 230.67911\n",
      "99.08496 230.67911 322.33655 1.0\n",
      "FOLD 2230\n",
      "train [26.119476318359375, 6.458305358886719]\n",
      "val [31.144794464111328, 6.638671875]\n",
      "predict val...\n",
      "predict test...\n",
      "134.25716 233.32309\n",
      "116.24609 233.32309 350.26416 1.0\n",
      "FOLD 2231\n",
      "train [27.640602111816406, 6.493155002593994]\n",
      "val [32.654449462890625, 7.011453628540039]\n",
      "predict val...\n",
      "predict test...\n",
      "139.63364 227.27657\n",
      "41.97754 227.27657 335.1172 1.0\n",
      "FOLD 2232\n",
      "train [28.11903953552246, 6.530673027038574]\n",
      "val [30.12160873413086, 6.575943470001221]\n",
      "predict val...\n",
      "predict test...\n",
      "126.904076 251.2442\n",
      "120.496826 251.2442 345.5249 1.0\n",
      "FOLD 2233\n",
      "train [25.574222564697266, 6.397678852081299]\n",
      "val [36.83735275268555, 6.7275896072387695]\n",
      "predict val...\n",
      "predict test...\n",
      "157.1337 209.52419\n",
      "11.662109 209.52419 298.72778 1.0\n",
      "FOLD 2234\n",
      "train [28.899147033691406, 6.5461578369140625]\n",
      "val [28.407249450683594, 6.47451114654541]\n",
      "predict val...\n",
      "predict test...\n",
      "124.75025 242.2741\n",
      "122.31445 242.2741 323.34375 1.0\n",
      "FOLD 2235\n",
      "train [26.49947166442871, 6.447985649108887]\n",
      "val [33.37804412841797, 6.732203483581543]\n",
      "predict val...\n",
      "predict test...\n",
      "145.08664 223.0112\n",
      "88.6709 223.0112 385.85962 1.0\n",
      "FOLD 2236\n",
      "train [26.671371459960938, 6.4632673263549805]\n",
      "val [31.528791427612305, 6.669833183288574]\n",
      "predict val...\n",
      "predict test...\n",
      "135.6513 219.46478\n",
      "27.1792 219.46478 366.667 1.0\n",
      "FOLD 2237\n",
      "train [28.180583953857422, 6.542975425720215]\n",
      "val [31.992401123046875, 6.727923393249512]\n",
      "predict val...\n",
      "predict test...\n",
      "137.84584 254.92451\n",
      "180.62329 254.92451 356.29785 1.0\n",
      "FOLD 2238\n",
      "train [26.318750381469727, 6.4392523765563965]\n",
      "val [36.82447814941406, 6.681836128234863]\n",
      "predict val...\n",
      "predict test...\n",
      "160.19992 216.63684\n",
      "113.98218 216.63684 317.06494 1.0\n",
      "FOLD 2239\n",
      "train [27.80221176147461, 6.504933834075928]\n",
      "val [28.080307006835938, 6.5080156326293945]\n",
      "predict val...\n",
      "predict test...\n",
      "122.688774 243.26399\n",
      "34.40503 243.26399 389.90088 1.0\n",
      "FOLD 2240\n",
      "train [27.659931182861328, 6.48553991317749]\n",
      "val [33.808502197265625, 6.795315265655518]\n",
      "predict val...\n",
      "predict test...\n",
      "146.3475 226.08868\n",
      "28.832031 226.08868 411.1604 1.0\n",
      "FOLD 2241\n",
      "train [27.82553482055664, 6.496140956878662]\n",
      "val [33.141632080078125, 6.8682355880737305]\n",
      "predict val...\n",
      "predict test...\n",
      "142.30563 238.32446\n",
      "74.98572 238.32446 528.5088 1.0\n",
      "FOLD 2242\n",
      "train [26.511131286621094, 6.458220481872559]\n",
      "val [31.00877571105957, 6.618968963623047]\n",
      "predict val...\n",
      "predict test...\n",
      "134.09451 228.61604\n",
      "145.74854 228.61604 286.1858 1.0\n",
      "FOLD 2243\n",
      "train [26.55146598815918, 6.4421234130859375]\n",
      "val [36.142276763916016, 6.67992639541626]\n",
      "predict val...\n",
      "predict test...\n",
      "156.73067 223.2838\n",
      "77.234985 223.2838 355.3335 1.0\n",
      "FOLD 2244\n",
      "train [28.229488372802734, 6.532042503356934]\n",
      "val [28.540014266967773, 6.467372894287109]\n",
      "predict val...\n",
      "predict test...\n",
      "123.98493 239.11624\n",
      "62.052734 239.11624 346.63818 1.0\n",
      "FOLD 2245\n",
      "train [27.15705108642578, 6.496949195861816]\n",
      "val [32.822235107421875, 6.7193098068237305]\n",
      "predict val...\n",
      "predict test...\n",
      "142.74928 243.32103\n",
      "93.02173 243.32103 339.187 1.0\n",
      "FOLD 2246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [27.5526065826416, 6.483027458190918]\n",
      "val [32.41807556152344, 6.834442138671875]\n",
      "predict val...\n",
      "predict test...\n",
      "139.73518 221.97859\n",
      "25.785156 221.97859 449.81152 1.0\n",
      "FOLD 2247\n",
      "train [27.037261962890625, 6.489067077636719]\n",
      "val [31.372270584106445, 6.698430061340332]\n",
      "predict val...\n",
      "predict test...\n",
      "133.69252 237.45683\n",
      "124.59949 237.45683 368.4253 1.0\n",
      "FOLD 2248\n",
      "train [24.527984619140625, 6.358126163482666]\n",
      "val [39.599578857421875, 6.727376937866211]\n",
      "predict val...\n",
      "predict test...\n",
      "170.48128 211.76108\n",
      "80.876465 211.76108 454.73413 1.0\n",
      "FOLD 2249\n",
      "train [27.41539192199707, 6.498291969299316]\n",
      "val [28.627378463745117, 6.479287624359131]\n",
      "predict val...\n",
      "predict test...\n",
      "124.577385 229.52286\n",
      "71.174805 229.52286 299.09546 1.0\n",
      "FOLD 2250\n",
      "train [26.833118438720703, 6.458611965179443]\n",
      "val [32.55634689331055, 6.745884418487549]\n",
      "predict val...\n",
      "predict test...\n",
      "141.13795 224.32515\n",
      "-10.591553 224.32515 379.2439 0.9869706840390879\n",
      "FOLD 2251\n",
      "train [33.38713455200195, 6.5568742752075195]\n",
      "val [37.221946716308594, 6.762961387634277]\n",
      "predict val...\n",
      "predict test...\n",
      "139.53046 250.10031\n",
      "135.96875 250.10031 409.17432 1.0\n",
      "FOLD 2252\n",
      "train [33.63184356689453, 6.5654778480529785]\n",
      "val [33.5560188293457, 6.575233459472656]\n",
      "predict val...\n",
      "predict test...\n",
      "120.28577 253.68494\n",
      "141.30933 253.68494 426.29004 1.0\n",
      "FOLD 2253\n",
      "train [31.516128540039062, 6.493390083312988]\n",
      "val [44.36553192138672, 6.713517665863037]\n",
      "predict val...\n",
      "predict test...\n",
      "166.52785 230.72086\n",
      "129.22937 230.72086 452.2915 1.0\n",
      "FOLD 2254\n",
      "train [34.8232421875, 6.624320983886719]\n",
      "val [32.57038879394531, 6.519197463989258]\n",
      "predict val...\n",
      "predict test...\n",
      "123.13597 247.98708\n",
      "101.81531 247.98708 403.05127 1.0\n",
      "FOLD 2255\n",
      "train [32.495975494384766, 6.539351463317871]\n",
      "val [37.56135177612305, 6.674365043640137]\n",
      "predict val...\n",
      "predict test...\n",
      "141.16455 240.93289\n",
      "126.96118 240.93289 391.36377 1.0\n",
      "FOLD 2256\n",
      "train [33.002288818359375, 6.55044412612915]\n",
      "val [37.09956359863281, 6.77739143371582]\n",
      "predict val...\n",
      "predict test...\n",
      "138.52939 255.83769\n",
      "165.58472 255.83769 343.9453 1.0\n",
      "FOLD 2257\n",
      "train [32.931541442871094, 6.541522979736328]\n",
      "val [36.80394744873047, 6.669393062591553]\n",
      "predict val...\n",
      "predict test...\n",
      "135.46548 237.64847\n",
      "141.62231 237.64847 382.6631 1.0\n",
      "FOLD 2258\n",
      "train [31.525527954101562, 6.486392974853516]\n",
      "val [43.51765441894531, 6.688895225524902]\n",
      "predict val...\n",
      "predict test...\n",
      "163.46494 226.63022\n",
      "117.787476 226.63022 440.1006 1.0\n",
      "FOLD 2259\n",
      "train [34.718482971191406, 6.599823951721191]\n",
      "val [32.39848709106445, 6.473043441772461]\n",
      "predict val...\n",
      "predict test...\n",
      "121.72923 228.73453\n",
      "96.879944 228.73453 365.85986 1.0\n",
      "FOLD 2260\n",
      "train [32.97422409057617, 6.5337419509887695]\n",
      "val [38.079463958740234, 6.685492038726807]\n",
      "predict val...\n",
      "predict test...\n",
      "142.6547 222.97023\n",
      "153.32251 222.97023 326.7173 1.0\n",
      "FOLD 2261\n",
      "train [33.06924057006836, 6.561795234680176]\n",
      "val [37.031883239746094, 6.729007720947266]\n",
      "predict val...\n",
      "predict test...\n",
      "139.8263 261.85712\n",
      "170.85156 261.85712 355.81494 1.0\n",
      "FOLD 2262\n",
      "train [33.064022064208984, 6.555868625640869]\n",
      "val [34.368492126464844, 6.600121974945068]\n",
      "predict val...\n",
      "predict test...\n",
      "124.92423 252.33784\n",
      "164.76367 252.33784 389.8247 1.0\n",
      "FOLD 2263\n",
      "train [29.583049774169922, 6.426762580871582]\n",
      "val [43.36314392089844, 6.721685886383057]\n",
      "predict val...\n",
      "predict test...\n",
      "159.70438 214.93578\n",
      "113.28174 214.93578 304.0913 1.0\n",
      "FOLD 2264\n",
      "train [34.24028396606445, 6.595654487609863]\n",
      "val [33.776527404785156, 6.516314506530762]\n",
      "predict val...\n",
      "predict test...\n",
      "130.43373 239.81721\n",
      "138.30792 239.81721 318.35547 1.0\n",
      "FOLD 2265\n",
      "train [32.35312271118164, 6.537413120269775]\n",
      "val [39.53640365600586, 6.731785297393799]\n",
      "predict val...\n",
      "predict test...\n",
      "148.87129 239.56596\n",
      "156.11597 239.56596 329.6084 1.0\n",
      "FOLD 2266\n",
      "train [31.701196670532227, 6.506070137023926]\n",
      "val [36.457027435302734, 6.684360504150391]\n",
      "predict val...\n",
      "predict test...\n",
      "136.69792 241.34535\n",
      "152.99756 241.34535 310.25 1.0\n",
      "FOLD 2267\n",
      "train [32.56346130371094, 6.538442134857178]\n",
      "val [34.917694091796875, 6.600268363952637]\n",
      "predict val...\n",
      "predict test...\n",
      "127.318886 244.4033\n",
      "165.2771 244.4033 357.24658 1.0\n",
      "FOLD 2268\n",
      "train [28.932270050048828, 6.406093597412109]\n",
      "val [44.02168273925781, 6.670440196990967]\n",
      "predict val...\n",
      "predict test...\n",
      "163.41394 224.56024\n",
      "129.11646 224.56024 324.21436 1.0\n",
      "FOLD 2269\n",
      "train [33.345726013183594, 6.578112602233887]\n",
      "val [34.26479721069336, 6.551057815551758]\n",
      "predict val...\n",
      "predict test...\n",
      "131.24109 255.20178\n",
      "152.3352 255.20178 336.58008 1.0\n",
      "FOLD 2270\n",
      "train [31.828886032104492, 6.52548885345459]\n",
      "val [40.38230895996094, 6.729992866516113]\n",
      "predict val...\n",
      "predict test...\n",
      "153.14241 244.13849\n",
      "188.9126 244.13849 332.71558 1.0\n",
      "FOLD 2271\n",
      "train [32.242347717285156, 6.514675140380859]\n",
      "val [38.99525833129883, 6.915385723114014]\n",
      "predict val...\n",
      "predict test...\n",
      "144.70206 238.44885\n",
      "115.46265 238.44885 334.42334 1.0\n",
      "FOLD 2272\n",
      "train [32.60047912597656, 6.542330741882324]\n",
      "val [35.623287200927734, 6.622086048126221]\n",
      "predict val...\n",
      "predict test...\n",
      "130.9003 246.4877\n",
      "173.83533 246.4877 351.5205 1.0\n",
      "FOLD 2273\n",
      "train [30.16297149658203, 6.439711093902588]\n",
      "val [42.167545318603516, 6.654707908630371]\n",
      "predict val...\n",
      "predict test...\n",
      "155.79692 227.25652\n",
      "88.667114 227.25652 323.44263 1.0\n",
      "FOLD 2274\n",
      "train [33.673946380615234, 6.5527448654174805]\n",
      "val [31.740524291992188, 6.4816389083862305]\n",
      "predict val...\n",
      "predict test...\n",
      "121.21333 229.13544\n",
      "134.7251 229.13544 316.86206 1.0\n",
      "FOLD 2275\n",
      "train [31.302066802978516, 6.474342346191406]\n",
      "val [39.15288162231445, 6.785158157348633]\n",
      "predict val...\n",
      "predict test...\n",
      "146.13667 219.41058\n",
      "52.416504 219.41058 309.24146 1.0\n",
      "FOLD 2276\n",
      "train [31.598228454589844, 6.499733924865723]\n",
      "val [37.66462326049805, 6.944026470184326]\n",
      "predict val...\n",
      "predict test...\n",
      "140.26025 235.95831\n",
      "65.06372 235.95831 382.3081 1.0\n",
      "FOLD 2277\n",
      "train [32.47695541381836, 6.53265380859375]\n",
      "val [35.22420120239258, 6.580272674560547]\n",
      "predict val...\n",
      "predict test...\n",
      "128.7905 240.17279\n",
      "167.29504 240.17279 352.62598 1.0\n",
      "FOLD 2278\n",
      "train [29.870012283325195, 6.434487342834473]\n",
      "val [44.39313888549805, 6.681994438171387]\n",
      "predict val...\n",
      "predict test...\n",
      "164.28966 225.7966\n",
      "87.43164 225.7966 322.2754 1.0\n",
      "FOLD 2279\n",
      "train [32.13966751098633, 6.5069451332092285]\n",
      "val [30.916643142700195, 6.4224653244018555]\n",
      "predict val...\n",
      "predict test...\n",
      "117.062805 226.62123\n",
      "71.6062 226.62123 301.9214 1.0\n",
      "FOLD 2280\n",
      "train [31.488828659057617, 6.481316566467285]\n",
      "val [39.41915512084961, 6.779351234436035]\n",
      "predict val...\n",
      "predict test...\n",
      "148.00777 231.14711\n",
      "77.35986 231.14711 378.94336 1.0\n",
      "FOLD 2281\n",
      "train [30.923194885253906, 6.466556549072266]\n",
      "val [36.31496047973633, 6.707695007324219]\n",
      "predict val...\n",
      "predict test...\n",
      "134.58632 219.31764\n",
      "88.36963 219.31764 342.94482 1.0\n",
      "FOLD 2282\n",
      "train [31.92140769958496, 6.515545845031738]\n",
      "val [36.015541076660156, 6.648131370544434]\n",
      "predict val...\n",
      "predict test...\n",
      "134.09235 248.73091\n",
      "149.7052 248.73091 383.03125 1.0\n",
      "FOLD 2283\n",
      "train [31.168106079101562, 6.465272426605225]\n",
      "val [42.10845184326172, 6.658784866333008]\n",
      "predict val...\n",
      "predict test...\n",
      "156.08401 226.44516\n",
      "124.85974 226.44516 329.80493 1.0\n",
      "FOLD 2284\n",
      "train [32.37217712402344, 6.518023490905762]\n",
      "val [32.44939041137695, 6.509090423583984]\n",
      "predict val...\n",
      "predict test...\n",
      "123.569916 242.583\n",
      "58.6687 242.583 368.2932 1.0\n",
      "FOLD 2285\n",
      "train [30.67720603942871, 6.455362796783447]\n",
      "val [39.439693450927734, 6.7831645011901855]\n",
      "predict val...\n",
      "predict test...\n",
      "148.59372 223.91043\n",
      "35.63257 223.91043 319.94946 1.0\n",
      "FOLD 2286\n",
      "train [29.67974853515625, 6.434575080871582]\n",
      "val [39.672306060791016, 6.9029436111450195]\n",
      "predict val...\n",
      "predict test...\n",
      "146.49722 224.81723\n",
      "88.35791 224.81723 387.29785 1.0\n",
      "FOLD 2287\n",
      "train [30.211313247680664, 6.451336860656738]\n",
      "val [36.82281494140625, 6.681392192840576]\n",
      "predict val...\n",
      "predict test...\n",
      "137.87358 229.23903\n",
      "131.59949 229.23903 299.87524 1.0\n",
      "FOLD 2288\n",
      "train [30.082725524902344, 6.428487300872803]\n",
      "val [44.99537658691406, 6.704835891723633]\n",
      "predict val...\n",
      "predict test...\n",
      "168.04568 220.28833\n",
      "91.04114 220.28833 342.1167 1.0\n",
      "FOLD 2289\n",
      "train [33.563411712646484, 6.564028739929199]\n",
      "val [31.617868423461914, 6.479484558105469]\n",
      "predict val...\n",
      "predict test...\n",
      "120.71478 234.47493\n",
      "172.07385 234.47493 300.25977 1.0\n",
      "FOLD 2290\n",
      "train [30.111042022705078, 6.438702583312988]\n",
      "val [41.44890213012695, 6.773762226104736]\n",
      "predict val...\n",
      "predict test...\n",
      "152.38832 213.61623\n",
      "81.295166 213.61623 345.37646 1.0\n",
      "FOLD 2291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [31.20587730407715, 6.476171970367432]\n",
      "val [35.14789962768555, 6.5631937980651855]\n",
      "predict val...\n",
      "predict test...\n",
      "131.5529 228.35175\n",
      "37.76709 228.35175 405.75488 1.0\n",
      "FOLD 2292\n",
      "train [30.505788803100586, 6.45989990234375]\n",
      "val [37.95254135131836, 6.739832878112793]\n",
      "predict val...\n",
      "predict test...\n",
      "141.49725 247.70256\n",
      "118.28955 247.70256 424.4214 1.0\n",
      "FOLD 2293\n",
      "train [30.483251571655273, 6.440939903259277]\n",
      "val [42.469688415527344, 6.67317008972168]\n",
      "predict val...\n",
      "predict test...\n",
      "157.68776 222.6245\n",
      "109.29126 222.6245 340.62207 1.0\n",
      "FOLD 2294\n",
      "train [31.99795150756836, 6.499951362609863]\n",
      "val [34.594970703125, 6.618376731872559]\n",
      "predict val...\n",
      "predict test...\n",
      "131.0921 235.21152\n",
      "30.3833 235.21152 336.5935 1.0\n",
      "FOLD 2295\n",
      "train [30.27328109741211, 6.440810203552246]\n",
      "val [38.05918502807617, 6.750887870788574]\n",
      "predict val...\n",
      "predict test...\n",
      "142.85997 227.14912\n",
      "-62.63623 227.14912 401.9724 0.9674267100977199\n",
      "FOLD 2296\n",
      "train [30.768598556518555, 6.46892786026001]\n",
      "val [38.79119873046875, 6.856510639190674]\n",
      "predict val...\n",
      "predict test...\n",
      "143.3141 221.98376\n",
      "133.65967 221.98376 305.35132 1.0\n",
      "FOLD 2297\n",
      "train [29.740724563598633, 6.423896789550781]\n",
      "val [37.1770133972168, 6.740146636962891]\n",
      "predict val...\n",
      "predict test...\n",
      "137.96535 221.32767\n",
      "131.9978 221.32767 318.40625 1.0\n",
      "FOLD 2298\n",
      "train [30.42367935180664, 6.454010009765625]\n",
      "val [42.78289794921875, 6.660038948059082]\n",
      "predict val...\n",
      "predict test...\n",
      "159.21362 227.70705\n",
      "141.12708 227.70705 298.43115 1.0\n",
      "FOLD 2299\n",
      "train [33.75385665893555, 6.563832759857178]\n",
      "val [32.01594161987305, 6.500577926635742]\n",
      "predict val...\n",
      "predict test...\n",
      "121.07573 247.52206\n",
      "126.79736 247.52206 360.53027 1.0\n",
      "FOLD 2300\n",
      "train [31.411155700683594, 6.474551200866699]\n",
      "val [37.11779022216797, 6.715699195861816]\n",
      "predict val...\n",
      "predict test...\n",
      "139.43 228.22461\n",
      "-43.025635 228.22461 348.65674 0.9804560260586319\n",
      "FOLD 2301\n",
      "train [37.92549514770508, 6.577221870422363]\n",
      "val [42.19837188720703, 6.75601053237915]\n",
      "predict val...\n",
      "predict test...\n",
      "138.6962 267.5523\n",
      "127.960205 267.5523 470.27686 1.0\n",
      "FOLD 2302\n",
      "train [38.29767608642578, 6.5750555992126465]\n",
      "val [38.39827346801758, 6.5891218185424805]\n",
      "predict val...\n",
      "predict test...\n",
      "121.92719 258.1416\n",
      "150.30042 258.1416 432.10645 1.0\n",
      "FOLD 2303\n",
      "train [35.485740661621094, 6.468771457672119]\n",
      "val [48.744895935058594, 6.669639587402344]\n",
      "predict val...\n",
      "predict test...\n",
      "158.49448 216.43822\n",
      "124.1792 216.43822 384.40332 1.0\n",
      "FOLD 2304\n",
      "train [39.388526916503906, 6.607830047607422]\n",
      "val [37.72856140136719, 6.511537551879883]\n",
      "predict val...\n",
      "predict test...\n",
      "126.02491 241.4167\n",
      "112.17096 241.4167 372.93213 1.0\n",
      "FOLD 2305\n",
      "train [37.10881042480469, 6.546004295349121]\n",
      "val [44.00692367553711, 6.695600986480713]\n",
      "predict val...\n",
      "predict test...\n",
      "146.77136 242.67702\n",
      "130.24121 242.67702 356.80273 1.0\n",
      "FOLD 2306\n",
      "train [37.1639404296875, 6.543871879577637]\n",
      "val [42.76323318481445, 6.80386209487915]\n",
      "predict val...\n",
      "predict test...\n",
      "141.29555 255.97653\n",
      "149.84912 255.97653 371.63965 1.0\n",
      "FOLD 2307\n",
      "train [37.342952728271484, 6.53265380859375]\n",
      "val [41.32294845581055, 6.630719184875488]\n",
      "predict val...\n",
      "predict test...\n",
      "132.83354 229.97588\n",
      "147.02954 229.97588 358.94238 1.0\n",
      "FOLD 2308\n",
      "train [35.741085052490234, 6.466357231140137]\n",
      "val [49.82542037963867, 6.680671691894531]\n",
      "predict val...\n",
      "predict test...\n",
      "161.03351 211.87346\n",
      "124.7168 211.87346 352.2422 1.0\n",
      "FOLD 2309\n",
      "train [39.23192596435547, 6.592005729675293]\n",
      "val [35.80485534667969, 6.473766326904297]\n",
      "predict val...\n",
      "predict test...\n",
      "121.12647 235.02489\n",
      "139.86786 235.02489 328.91333 1.0\n",
      "FOLD 2310\n",
      "train [37.177852630615234, 6.531060218811035]\n",
      "val [43.80364990234375, 6.691636085510254]\n",
      "predict val...\n",
      "predict test...\n",
      "144.2793 218.92877\n",
      "137.54541 218.92877 297.76123 1.0\n",
      "FOLD 2311\n",
      "train [35.82059860229492, 6.512763023376465]\n",
      "val [42.79773712158203, 6.776279449462891]\n",
      "predict val...\n",
      "predict test...\n",
      "140.85574 245.17459\n",
      "172.87512 245.17459 304.61572 1.0\n",
      "FOLD 2312\n",
      "train [37.465579986572266, 6.55654239654541]\n",
      "val [39.765846252441406, 6.653626441955566]\n",
      "predict val...\n",
      "predict test...\n",
      "127.826126 257.81717\n",
      "145.7948 257.81717 432.0454 1.0\n",
      "FOLD 2313\n",
      "train [35.820552825927734, 6.499688625335693]\n",
      "val [48.08131408691406, 6.685181617736816]\n",
      "predict val...\n",
      "predict test...\n",
      "157.11195 233.80685\n",
      "164.1532 233.80685 301.1787 1.0\n",
      "FOLD 2314\n",
      "train [38.432186126708984, 6.58029842376709]\n",
      "val [39.20186996459961, 6.499103546142578]\n",
      "predict val...\n",
      "predict test...\n",
      "130.55527 232.72725\n",
      "120.4483 232.72725 341.94287 1.0\n",
      "FOLD 2315\n",
      "train [36.716712951660156, 6.531223297119141]\n",
      "val [45.71157455444336, 6.702764511108398]\n",
      "predict val...\n",
      "predict test...\n",
      "151.54286 238.09555\n",
      "175.01086 238.09555 338.45557 1.0\n",
      "FOLD 2316\n",
      "train [37.231876373291016, 6.5438103675842285]\n",
      "val [42.25678634643555, 6.759332656860352]\n",
      "predict val...\n",
      "predict test...\n",
      "138.89848 251.54352\n",
      "167.68726 251.54352 340.04834 1.0\n",
      "FOLD 2317\n",
      "train [37.5450439453125, 6.558679103851318]\n",
      "val [39.65388870239258, 6.638453960418701]\n",
      "predict val...\n",
      "predict test...\n",
      "127.952324 254.87129\n",
      "173.02869 254.87129 366.1548 1.0\n",
      "FOLD 2318\n",
      "train [34.86235809326172, 6.471005439758301]\n",
      "val [47.782745361328125, 6.70889139175415]\n",
      "predict val...\n",
      "predict test...\n",
      "155.6654 226.60497\n",
      "108.81128 226.60497 319.64844 1.0\n",
      "FOLD 2319\n",
      "train [36.88885498046875, 6.530256748199463]\n",
      "val [38.569236755371094, 6.501837730407715]\n",
      "predict val...\n",
      "predict test...\n",
      "128.9293 248.85796\n",
      "44.152832 248.85796 336.52734 1.0\n",
      "FOLD 2320\n",
      "train [35.48386764526367, 6.510593414306641]\n",
      "val [42.93363952636719, 6.6821417808532715]\n",
      "predict val...\n",
      "predict test...\n",
      "142.18513 234.20888\n",
      "153.81213 234.20888 326.90967 1.0\n",
      "FOLD 2321\n",
      "train [36.83131408691406, 6.518337249755859]\n",
      "val [42.67527770996094, 6.7440900802612305]\n",
      "predict val...\n",
      "predict test...\n",
      "140.1494 243.92961\n",
      "112.03162 243.92961 420.39258 1.0\n",
      "FOLD 2322\n",
      "train [35.2707405090332, 6.507489204406738]\n",
      "val [39.686500549316406, 6.592550277709961]\n",
      "predict val...\n",
      "predict test...\n",
      "128.82526 245.20442\n",
      "163.51721 245.20442 318.74512 1.0\n",
      "FOLD 2323\n",
      "train [32.12321090698242, 6.379644870758057]\n",
      "val [49.48528289794922, 6.694047927856445]\n",
      "predict val...\n",
      "predict test...\n",
      "158.72256 215.07808\n",
      "68.90027 215.07808 304.91846 1.0\n",
      "FOLD 2324\n",
      "train [37.73324966430664, 6.537709712982178]\n",
      "val [37.19166564941406, 6.482773303985596]\n",
      "predict val...\n",
      "predict test...\n",
      "125.471054 229.49756\n",
      "93.01538 229.49756 299.23743 1.0\n",
      "FOLD 2325\n",
      "train [36.10780334472656, 6.525569915771484]\n",
      "val [43.06830978393555, 6.691118240356445]\n",
      "predict val...\n",
      "predict test...\n",
      "141.90138 237.65567\n",
      "168.23877 237.65567 325.46826 1.0\n",
      "FOLD 2326\n",
      "train [34.4688720703125, 6.470503330230713]\n",
      "val [41.99842834472656, 6.696808815002441]\n",
      "predict val...\n",
      "predict test...\n",
      "136.86472 233.7904\n",
      "139.31104 233.7904 295.95068 1.0\n",
      "FOLD 2327\n",
      "train [35.188045501708984, 6.487107276916504]\n",
      "val [39.04732131958008, 6.592237949371338]\n",
      "predict val...\n",
      "predict test...\n",
      "127.288506 235.72073\n",
      "141.12012 235.72073 293.50366 1.0\n",
      "FOLD 2328\n",
      "train [33.9181022644043, 6.421536922454834]\n",
      "val [48.426292419433594, 6.692079544067383]\n",
      "predict val...\n",
      "predict test...\n",
      "157.9993 213.30077\n",
      "57.225586 213.30077 318.5952 1.0\n",
      "FOLD 2329\n",
      "train [36.018218994140625, 6.511480808258057]\n",
      "val [35.86553955078125, 6.474628448486328]\n",
      "predict val...\n",
      "predict test...\n",
      "120.55642 232.63103\n",
      "54.82202 232.63103 323.90344 1.0\n",
      "FOLD 2330\n",
      "train [35.55984878540039, 6.49332332611084]\n",
      "val [44.66305923461914, 6.782923221588135]\n",
      "predict val...\n",
      "predict test...\n",
      "146.68779 229.48636\n",
      "58.65625 229.48636 313.62866 1.0\n",
      "FOLD 2331\n",
      "train [36.33829116821289, 6.512277126312256]\n",
      "val [40.69784927368164, 6.667971611022949]\n",
      "predict val...\n",
      "predict test...\n",
      "133.31226 235.38994\n",
      "93.12402 235.38994 318.6045 1.0\n",
      "FOLD 2332\n",
      "train [34.98109436035156, 6.477345943450928]\n",
      "val [40.29282760620117, 6.628078460693359]\n",
      "predict val...\n",
      "predict test...\n",
      "130.94167 229.55542\n",
      "140.03467 229.55542 277.79224 1.0\n",
      "FOLD 2333\n",
      "train [31.707759857177734, 6.365454196929932]\n",
      "val [51.63021469116211, 6.7208757400512695]\n",
      "predict val...\n",
      "predict test...\n",
      "166.05833 208.46213\n",
      "80.970825 208.46213 322.42676 1.0\n",
      "FOLD 2334\n",
      "train [36.2011604309082, 6.51543664932251]\n",
      "val [36.18860626220703, 6.473729133605957]\n",
      "predict val...\n",
      "predict test...\n",
      "118.920044 234.89526\n",
      "119.31738 234.89526 331.38428 1.0\n",
      "FOLD 2335\n",
      "train [36.16834259033203, 6.50066614151001]\n",
      "val [46.0484733581543, 6.761375427246094]\n",
      "predict val...\n",
      "predict test...\n",
      "152.01625 237.64688\n",
      "83.53027 237.64688 364.57935 1.0\n",
      "FOLD 2336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [34.40712356567383, 6.477810859680176]\n",
      "val [41.58223342895508, 6.645864963531494]\n",
      "predict val...\n",
      "predict test...\n",
      "135.53198 239.60535\n",
      "96.069336 239.60535 347.7561 1.0\n",
      "FOLD 2337\n",
      "train [35.3498649597168, 6.4898786544799805]\n",
      "val [41.49068832397461, 6.7045793533325195]\n",
      "predict val...\n",
      "predict test...\n",
      "134.57973 234.6205\n",
      "131.55835 234.6205 293.5017 1.0\n",
      "FOLD 2338\n",
      "train [32.74070358276367, 6.410401821136475]\n",
      "val [50.57465362548828, 6.700281143188477]\n",
      "predict val...\n",
      "predict test...\n",
      "164.73863 224.40614\n",
      "111.50452 224.40614 386.39722 1.0\n",
      "FOLD 2339\n",
      "train [38.186092376708984, 6.5599188804626465]\n",
      "val [35.885047912597656, 6.482741355895996]\n",
      "predict val...\n",
      "predict test...\n",
      "120.319115 235.8124\n",
      "147.70032 235.8124 311.01343 1.0\n",
      "FOLD 2340\n",
      "train [35.899986267089844, 6.485189914703369]\n",
      "val [42.93570327758789, 6.731553077697754]\n",
      "predict val...\n",
      "predict test...\n",
      "141.89642 226.85474\n",
      "43.760254 226.85474 374.13525 1.0\n",
      "FOLD 2341\n",
      "train [34.855377197265625, 6.46826171875]\n",
      "val [41.12548828125, 6.598447799682617]\n",
      "predict val...\n",
      "predict test...\n",
      "134.66559 223.29247\n",
      "40.621094 223.29247 354.68506 1.0\n",
      "FOLD 2342\n",
      "train [35.32872772216797, 6.478659152984619]\n",
      "val [40.4007453918457, 6.629842758178711]\n",
      "predict val...\n",
      "predict test...\n",
      "132.26144 226.55698\n",
      "156.14355 226.55698 350.69556 1.0\n",
      "FOLD 2343\n",
      "train [32.514488220214844, 6.392202854156494]\n",
      "val [47.63264846801758, 6.687377452850342]\n",
      "predict val...\n",
      "predict test...\n",
      "155.2508 216.9941\n",
      "93.84119 216.9941 322.85254 1.0\n",
      "FOLD 2344\n",
      "train [37.39198303222656, 6.546402931213379]\n",
      "val [37.167213439941406, 6.519773960113525]\n",
      "predict val...\n",
      "predict test...\n",
      "123.70877 241.9501\n",
      "109.69861 241.9501 374.8025 1.0\n",
      "FOLD 2345\n",
      "train [34.866432189941406, 6.4688873291015625]\n",
      "val [44.78989028930664, 6.866390228271484]\n",
      "predict val...\n",
      "predict test...\n",
      "146.23145 227.7227\n",
      "-125.33496 227.7227 448.82446 0.9739413680781759\n",
      "FOLD 2346\n",
      "train [35.92279052734375, 6.498423099517822]\n",
      "val [42.907894134521484, 6.829689025878906]\n",
      "predict val...\n",
      "predict test...\n",
      "139.58057 233.99619\n",
      "44.717773 233.99619 483.0415 1.0\n",
      "FOLD 2347\n",
      "train [34.55897521972656, 6.456685543060303]\n",
      "val [41.52402877807617, 6.712353706359863]\n",
      "predict val...\n",
      "predict test...\n",
      "136.12787 232.52234\n",
      "149.7384 232.52234 323.3806 1.0\n",
      "FOLD 2348\n",
      "train [34.100303649902344, 6.423897743225098]\n",
      "val [49.216766357421875, 6.6569318771362305]\n",
      "predict val...\n",
      "predict test...\n",
      "161.20827 221.10129\n",
      "91.74475 221.10129 355.51245 1.0\n",
      "FOLD 2349\n",
      "train [35.99713897705078, 6.508437156677246]\n",
      "val [36.291385650634766, 6.45671272277832]\n",
      "predict val...\n",
      "predict test...\n",
      "120.96865 237.94412\n",
      "41.11792 237.94412 321.62793 1.0\n",
      "FOLD 2350\n",
      "train [34.53677749633789, 6.4620490074157715]\n",
      "val [48.786338806152344, 6.815221309661865]\n",
      "predict val...\n",
      "predict test...\n",
      "156.20152 225.76456\n",
      "-23.269043 225.76456 357.24878 0.9869706840390879\n",
      "FOLD 2351\n",
      "train [42.5048713684082, 6.559385776519775]\n",
      "val [48.53553009033203, 6.816765785217285]\n",
      "predict val...\n",
      "predict test...\n",
      "141.33258 248.21162\n",
      "123.03247 248.21162 428.14453 1.0\n",
      "FOLD 2352\n",
      "train [42.82007598876953, 6.567800045013428]\n",
      "val [42.95563507080078, 6.593822956085205]\n",
      "predict val...\n",
      "predict test...\n",
      "123.27441 251.36485\n",
      "152.05334 251.36485 411.62646 1.0\n",
      "FOLD 2353\n",
      "train [40.528568267822266, 6.496349334716797]\n",
      "val [54.50526809692383, 6.683072090148926]\n",
      "predict val...\n",
      "predict test...\n",
      "159.09135 228.92636\n",
      "109.15686 228.92636 497.5537 1.0\n",
      "FOLD 2354\n",
      "train [44.028018951416016, 6.630772590637207]\n",
      "val [41.535518646240234, 6.524780750274658]\n",
      "predict val...\n",
      "predict test...\n",
      "123.25611 255.17126\n",
      "104.02496 255.17126 420.85693 1.0\n",
      "FOLD 2355\n",
      "train [41.88381576538086, 6.555277347564697]\n",
      "val [47.81093978881836, 6.684276103973389]\n",
      "predict val...\n",
      "predict test...\n",
      "142.06468 242.64017\n",
      "126.48645 242.64017 383.2837 1.0\n",
      "FOLD 2356\n",
      "train [40.37995147705078, 6.522718906402588]\n",
      "val [46.939693450927734, 6.738466262817383]\n",
      "predict val...\n",
      "predict test...\n",
      "138.46448 252.02916\n",
      "150.33765 252.02916 368.23633 1.0\n",
      "FOLD 2357\n",
      "train [43.203453063964844, 6.5718255043029785]\n",
      "val [45.9227294921875, 6.642313003540039]\n",
      "predict val...\n",
      "predict test...\n",
      "131.13733 248.12065\n",
      "151.95923 248.12065 409.312 1.0\n",
      "FOLD 2358\n",
      "train [40.09575271606445, 6.495718955993652]\n",
      "val [55.61744689941406, 6.680394172668457]\n",
      "predict val...\n",
      "predict test...\n",
      "161.82394 229.19923\n",
      "141.56335 229.19923 343.47998 1.0\n",
      "FOLD 2359\n",
      "train [42.86027908325195, 6.566922187805176]\n",
      "val [39.30647659301758, 6.427834510803223]\n",
      "predict val...\n",
      "predict test...\n",
      "117.70215 228.90039\n",
      "129.01343 228.90039 308.05347 1.0\n",
      "FOLD 2360\n",
      "train [41.731773376464844, 6.529374599456787]\n",
      "val [48.8934326171875, 6.685268878936768]\n",
      "predict val...\n",
      "predict test...\n",
      "144.77115 223.9835\n",
      "134.96033 223.9835 328.39307 1.0\n",
      "FOLD 2361\n",
      "train [42.20721435546875, 6.559360504150391]\n",
      "val [46.701805114746094, 6.7316484451293945]\n",
      "predict val...\n",
      "predict test...\n",
      "137.9091 254.6986\n",
      "140.7091 254.6986 409.82812 1.0\n",
      "FOLD 2362\n",
      "train [40.580169677734375, 6.532004356384277]\n",
      "val [47.09720230102539, 6.759395122528076]\n",
      "predict val...\n",
      "predict test...\n",
      "137.54893 248.82199\n",
      "170.02527 248.82199 367.58252 1.0\n",
      "FOLD 2363\n",
      "train [37.59086608886719, 6.441738128662109]\n",
      "val [56.36994171142578, 6.715479850769043]\n",
      "predict val...\n",
      "predict test...\n",
      "162.22035 224.71387\n",
      "93.35205 224.71387 333.0254 1.0\n",
      "FOLD 2364\n",
      "train [43.61066436767578, 6.599844932556152]\n",
      "val [42.50773239135742, 6.503427505493164]\n",
      "predict val...\n",
      "predict test...\n",
      "128.48839 241.45027\n",
      "138.823 241.45027 317.66162 1.0\n",
      "FOLD 2365\n",
      "train [39.88639831542969, 6.511990547180176]\n",
      "val [47.37723922729492, 6.65567684173584]\n",
      "predict val...\n",
      "predict test...\n",
      "137.98291 226.69398\n",
      "144.271 226.69398 331.31055 1.0\n",
      "FOLD 2366\n",
      "train [41.14248275756836, 6.536105155944824]\n",
      "val [47.447845458984375, 6.772152900695801]\n",
      "predict val...\n",
      "predict test...\n",
      "139.0738 250.90378\n",
      "171.30127 250.90378 340.10254 1.0\n",
      "FOLD 2367\n",
      "train [40.799049377441406, 6.520530700683594]\n",
      "val [45.95162582397461, 6.655889511108398]\n",
      "predict val...\n",
      "predict test...\n",
      "133.02753 241.44336\n",
      "149.93152 241.44336 354.6543 1.0\n",
      "FOLD 2368\n",
      "train [37.7296028137207, 6.437899112701416]\n",
      "val [55.947723388671875, 6.681737899780273]\n",
      "predict val...\n",
      "predict test...\n",
      "162.15805 225.05258\n",
      "144.94226 225.05258 286.24902 1.0\n",
      "FOLD 2369\n",
      "train [40.92332077026367, 6.532866477966309]\n",
      "val [42.05174255371094, 6.485589981079102]\n",
      "predict val...\n",
      "predict test...\n",
      "125.76153 233.9383\n",
      "127.51587 233.9383 305.75195 1.0\n",
      "FOLD 2370\n",
      "train [40.3731575012207, 6.522673606872559]\n",
      "val [52.20846939086914, 6.731350421905518]\n",
      "predict val...\n",
      "predict test...\n",
      "153.3094 245.42\n",
      "159.9292 245.42 376.98267 1.0\n",
      "FOLD 2371\n",
      "train [38.279869079589844, 6.467215061187744]\n",
      "val [45.93366241455078, 6.66337251663208]\n",
      "predict val...\n",
      "predict test...\n",
      "133.10965 231.1051\n",
      "108.61865 231.1051 290.083 1.0\n",
      "FOLD 2372\n",
      "train [41.60173416137695, 6.547990322113037]\n",
      "val [44.24557876586914, 6.612072467803955]\n",
      "predict val...\n",
      "predict test...\n",
      "128.25797 258.29062\n",
      "178.56055 258.29062 417.85767 1.0\n",
      "FOLD 2373\n",
      "train [37.22419738769531, 6.415935516357422]\n",
      "val [50.94742965698242, 6.6799468994140625]\n",
      "predict val...\n",
      "predict test...\n",
      "147.40244 217.13103\n",
      "-1.2797852 217.13103 303.8706 0.996742671009772\n",
      "FOLD 2374\n",
      "train [40.389217376708984, 6.497437477111816]\n",
      "val [40.64516067504883, 6.435558319091797]\n",
      "predict val...\n",
      "predict test...\n",
      "122.10265 224.10841\n",
      "32.70166 224.10841 291.0454 1.0\n",
      "FOLD 2375\n",
      "train [40.24507522583008, 6.498176574707031]\n",
      "val [54.715389251708984, 6.747136116027832]\n",
      "predict val...\n",
      "predict test...\n",
      "158.80533 229.70644\n",
      "150.15137 229.70644 328.3047 1.0\n",
      "FOLD 2376\n",
      "train [40.962371826171875, 6.527608394622803]\n",
      "val [49.23699188232422, 6.887243270874023]\n",
      "predict val...\n",
      "predict test...\n",
      "143.54568 246.98605\n",
      "111.802734 246.98605 377.24707 1.0\n",
      "FOLD 2377\n",
      "train [39.129661560058594, 6.480810642242432]\n",
      "val [43.69147491455078, 6.507372856140137]\n",
      "predict val...\n",
      "predict test...\n",
      "127.78788 237.93953\n",
      "112.072876 237.93953 309.2627 1.0\n",
      "FOLD 2378\n",
      "train [37.185062408447266, 6.41650915145874]\n",
      "val [57.54439926147461, 6.72027587890625]\n",
      "predict val...\n",
      "predict test...\n",
      "165.73697 214.60251\n",
      "123.95984 214.60251 318.51 1.0\n",
      "FOLD 2379\n",
      "train [40.231449127197266, 6.504293918609619]\n",
      "val [42.09563446044922, 6.508019924163818]\n",
      "predict val...\n",
      "predict test...\n",
      "125.669586 248.56685\n",
      "43.093018 248.56685 382.4109 1.0\n",
      "FOLD 2380\n",
      "train [38.61958312988281, 6.463919162750244]\n",
      "val [52.27471160888672, 6.815849781036377]\n",
      "predict val...\n",
      "predict test...\n",
      "151.12856 226.66174\n",
      "46.23877 226.66174 386.82617 1.0\n",
      "FOLD 2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [40.03009033203125, 6.499777793884277]\n",
      "val [46.94694137573242, 6.7471184730529785]\n",
      "predict val...\n",
      "predict test...\n",
      "136.92348 232.06291\n",
      "105.03589 232.06291 345.86304 1.0\n",
      "FOLD 2382\n",
      "train [40.98583984375, 6.5319414138793945]\n",
      "val [44.689727783203125, 6.567007064819336]\n",
      "predict val...\n",
      "predict test...\n",
      "127.867516 242.81125\n",
      "164.62671 242.81125 346.09668 1.0\n",
      "FOLD 2383\n",
      "train [37.901981353759766, 6.429683685302734]\n",
      "val [55.33659362792969, 6.720756530761719]\n",
      "predict val...\n",
      "predict test...\n",
      "160.14479 220.67816\n",
      "87.447266 220.67816 330.22705 1.0\n",
      "FOLD 2384\n",
      "train [41.85638427734375, 6.552267551422119]\n",
      "val [41.481048583984375, 6.509919166564941]\n",
      "predict val...\n",
      "predict test...\n",
      "125.88186 243.99614\n",
      "152.04187 243.99614 331.48047 1.0\n",
      "FOLD 2385\n",
      "train [39.3964729309082, 6.498038291931152]\n",
      "val [48.130191802978516, 6.706769943237305]\n",
      "predict val...\n",
      "predict test...\n",
      "141.37009 234.59749\n",
      "130.76172 234.59749 318.47876 1.0\n",
      "FOLD 2386\n",
      "train [40.77381134033203, 6.51583194732666]\n",
      "val [47.23270034790039, 6.8463134765625]\n",
      "predict val...\n",
      "predict test...\n",
      "138.43437 240.89764\n",
      "102.96826 240.89764 393.39844 1.0\n",
      "FOLD 2387\n",
      "train [39.333587646484375, 6.483587741851807]\n",
      "val [45.40947723388672, 6.615285873413086]\n",
      "predict val...\n",
      "predict test...\n",
      "132.14827 232.807\n",
      "135.81335 232.807 306.00732 1.0\n",
      "FOLD 2388\n",
      "train [38.02406311035156, 6.411401271820068]\n",
      "val [54.087406158447266, 6.6718244552612305]\n",
      "predict val...\n",
      "predict test...\n",
      "157.35648 215.14748\n",
      "90.818726 215.14748 376.76685 1.0\n",
      "FOLD 2389\n",
      "train [38.866268157958984, 6.451693534851074]\n",
      "val [39.002174377441406, 6.40091609954834]\n",
      "predict val...\n",
      "predict test...\n",
      "116.82352 222.89932\n",
      "34.061035 222.89932 379.3838 1.0\n",
      "FOLD 2390\n",
      "train [38.744163513183594, 6.4603071212768555]\n",
      "val [49.95930480957031, 6.801570892333984]\n",
      "predict val...\n",
      "predict test...\n",
      "145.69705 225.60912\n",
      "-64.69385 225.60912 407.63965 0.9771986970684039\n",
      "FOLD 2391\n",
      "train [39.10271453857422, 6.487978458404541]\n",
      "val [45.318641662597656, 6.675657272338867]\n",
      "predict val...\n",
      "predict test...\n",
      "131.78357 237.23045\n",
      "126.0647 237.23045 350.43335 1.0\n",
      "FOLD 2392\n",
      "train [38.87879180908203, 6.474952697753906]\n",
      "val [44.9814338684082, 6.565674781799316]\n",
      "predict val...\n",
      "predict test...\n",
      "130.57092 236.24768\n",
      "113.034424 236.24768 328.45508 1.0\n",
      "FOLD 2393\n",
      "train [37.918739318847656, 6.42584753036499]\n",
      "val [55.163719177246094, 6.701964378356934]\n",
      "predict val...\n",
      "predict test...\n",
      "159.45615 219.29048\n",
      "103.822266 219.29048 352.1089 1.0\n",
      "FOLD 2394\n",
      "train [41.65347671508789, 6.548029899597168]\n",
      "val [42.628868103027344, 6.542756080627441]\n",
      "predict val...\n",
      "predict test...\n",
      "126.64375 256.42746\n",
      "96.02197 256.42746 434.01758 1.0\n",
      "FOLD 2395\n",
      "train [39.6176872253418, 6.5008063316345215]\n",
      "val [49.643009185791016, 6.725616455078125]\n",
      "predict val...\n",
      "predict test...\n",
      "145.5644 233.41531\n",
      "95.315186 233.41531 287.55835 1.0\n",
      "FOLD 2396\n",
      "train [37.76102828979492, 6.431516170501709]\n",
      "val [49.91495895385742, 6.84730339050293]\n",
      "predict val...\n",
      "predict test...\n",
      "146.62921 215.26334\n",
      "99.76697 215.26334 374.9956 1.0\n",
      "FOLD 2397\n",
      "train [41.24186325073242, 6.543226718902588]\n",
      "val [46.52647399902344, 6.722689628601074]\n",
      "predict val...\n",
      "predict test...\n",
      "135.94368 249.43948\n",
      "159.8324 249.43948 383.89502 1.0\n",
      "FOLD 2398\n",
      "train [36.40665817260742, 6.382193565368652]\n",
      "val [58.23737716674805, 6.71673583984375]\n",
      "predict val...\n",
      "predict test...\n",
      "167.13232 211.86388\n",
      "86.137695 211.86388 311.31128 1.0\n",
      "FOLD 2399\n",
      "train [40.34412384033203, 6.510308742523193]\n",
      "val [41.95030212402344, 6.503527641296387]\n",
      "predict val...\n",
      "predict test...\n",
      "126.07986 240.1006\n",
      "8.031982 240.1006 367.7334 1.0\n",
      "FOLD 2400\n",
      "train [40.077640533447266, 6.491961479187012]\n",
      "val [49.99701690673828, 6.732001781463623]\n",
      "predict val...\n",
      "predict test...\n",
      "146.85945 231.60754\n",
      "88.50195 231.60754 357.5813 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2401\n",
      "train [28.65472984313965, 6.534079551696777]\n",
      "val [31.914949417114258, 6.771212577819824]\n",
      "predict val...\n",
      "predict test...\n",
      "138.37335 237.24162\n",
      "139.68347 237.24162 351.5376 1.0\n",
      "FOLD 2402\n",
      "train [28.855173110961914, 6.554037570953369]\n",
      "val [30.146732330322266, 6.589653015136719]\n",
      "predict val...\n",
      "predict test...\n",
      "125.03752 248.81693\n",
      "144.17285 248.81693 417.6294 1.0\n",
      "FOLD 2403\n",
      "train [27.052059173583984, 6.472533226013184]\n",
      "val [36.97590637207031, 6.6779069900512695]\n",
      "predict val...\n",
      "predict test...\n",
      "160.86917 221.85551\n",
      "117.09619 221.85551 442.64502 1.0\n",
      "FOLD 2404\n",
      "train [29.77627182006836, 6.61093807220459]\n",
      "val [28.132530212402344, 6.495607376098633]\n",
      "predict val...\n",
      "predict test...\n",
      "121.562805 244.80028\n",
      "102.76007 244.80028 397.2251 1.0\n",
      "FOLD 2405\n",
      "train [28.966920852661133, 6.557763576507568]\n",
      "val [32.21660614013672, 6.658719539642334]\n",
      "predict val...\n",
      "predict test...\n",
      "140.40315 238.51349\n",
      "116.25525 238.51349 390.1006 1.0\n",
      "FOLD 2406\n",
      "train [28.6422061920166, 6.554169654846191]\n",
      "val [32.27312469482422, 6.785717964172363]\n",
      "predict val...\n",
      "predict test...\n",
      "140.41895 257.05078\n",
      "135.32812 257.05078 425.81543 1.0\n",
      "FOLD 2407\n",
      "train [29.373085021972656, 6.56499719619751]\n",
      "val [31.596755981445312, 6.652652740478516]\n",
      "predict val...\n",
      "predict test...\n",
      "132.70038 242.38925\n",
      "150.22949 242.38925 392.3213 1.0\n",
      "FOLD 2408\n",
      "train [26.783802032470703, 6.467259407043457]\n",
      "val [37.0701789855957, 6.721128940582275]\n",
      "predict val...\n",
      "predict test...\n",
      "161.05354 226.14276\n",
      "125.50537 226.14276 352.94385 1.0\n",
      "FOLD 2409\n",
      "train [29.531253814697266, 6.574383735656738]\n",
      "val [26.544158935546875, 6.431048393249512]\n",
      "predict val...\n",
      "predict test...\n",
      "116.211716 217.97389\n",
      "101.93585 217.97389 342.3506 1.0\n",
      "FOLD 2410\n",
      "train [28.478511810302734, 6.530141353607178]\n",
      "val [31.640552520751953, 6.664414405822754]\n",
      "predict val...\n",
      "predict test...\n",
      "137.46257 224.62077\n",
      "165.23462 224.62077 309.51978 1.0\n",
      "FOLD 2411\n",
      "train [28.653854370117188, 6.561486721038818]\n",
      "val [31.645008087158203, 6.715031623840332]\n",
      "predict val...\n",
      "predict test...\n",
      "138.67084 265.71912\n",
      "167.625 265.71912 369.3247 1.0\n",
      "FOLD 2412\n",
      "train [27.206764221191406, 6.494225978851318]\n",
      "val [30.2340030670166, 6.616764068603516]\n",
      "predict val...\n",
      "predict test...\n",
      "129.07564 230.97215\n",
      "156.72925 230.97215 293.05762 1.0\n",
      "FOLD 2413\n",
      "train [25.553834915161133, 6.421271324157715]\n",
      "val [36.962318420410156, 6.690581321716309]\n",
      "predict val...\n",
      "predict test...\n",
      "158.90062 218.99629\n",
      "129.09375 218.99629 270.3081 1.0\n",
      "FOLD 2414\n",
      "train [29.082740783691406, 6.581640720367432]\n",
      "val [29.407455444335938, 6.518435478210449]\n",
      "predict val...\n",
      "predict test...\n",
      "129.70468 243.12794\n",
      "141.42023 243.12794 307.74194 1.0\n",
      "FOLD 2415\n",
      "train [27.756065368652344, 6.503973960876465]\n",
      "val [35.189292907714844, 6.741848945617676]\n",
      "predict val...\n",
      "predict test...\n",
      "153.37495 222.24039\n",
      "153.021 222.24039 306.1665 1.0\n",
      "FOLD 2416\n",
      "train [28.03577423095703, 6.515303611755371]\n",
      "val [32.12377166748047, 6.809630393981934]\n",
      "predict val...\n",
      "predict test...\n",
      "138.22925 236.8806\n",
      "89.818115 236.8806 369.10107 1.0\n",
      "FOLD 2417\n",
      "train [28.468454360961914, 6.542816162109375]\n",
      "val [29.72587776184082, 6.578216075897217]\n",
      "predict val...\n",
      "predict test...\n",
      "123.23743 246.7902\n",
      "146.96094 246.7902 406.96143 1.0\n",
      "FOLD 2418\n",
      "train [25.664804458618164, 6.412896156311035]\n",
      "val [38.04901123046875, 6.6790666580200195]\n",
      "predict val...\n",
      "predict test...\n",
      "162.89436 220.26765\n",
      "89.82922 220.26765 301.677 1.0\n",
      "FOLD 2419\n",
      "train [28.42433738708496, 6.5471391677856445]\n",
      "val [29.895450592041016, 6.525783538818359]\n",
      "predict val...\n",
      "predict test...\n",
      "131.59235 242.72424\n",
      "147.96265 242.72424 320.17285 1.0\n",
      "FOLD 2420\n",
      "train [27.39337921142578, 6.511146545410156]\n",
      "val [36.94451141357422, 6.803220748901367]\n",
      "predict val...\n",
      "predict test...\n",
      "160.77623 233.05473\n",
      "138.7168 233.05473 286.5647 1.0\n",
      "FOLD 2421\n",
      "train [25.510324478149414, 6.42331075668335]\n",
      "val [32.20480728149414, 6.897708892822266]\n",
      "predict val...\n",
      "predict test...\n",
      "140.0741 217.01749\n",
      "28.679688 217.01749 311.30835 1.0\n",
      "FOLD 2422\n",
      "train [27.92043113708496, 6.522716522216797]\n",
      "val [30.20923614501953, 6.554927825927734]\n",
      "predict val...\n",
      "predict test...\n",
      "128.53142 238.24683\n",
      "154.2102 238.24683 333.10645 1.0\n",
      "FOLD 2423\n",
      "train [26.543869018554688, 6.458399295806885]\n",
      "val [37.70721435546875, 6.7280778884887695]\n",
      "predict val...\n",
      "predict test...\n",
      "163.09814 225.50157\n",
      "116.39697 225.50157 291.76465 1.0\n",
      "FOLD 2424\n",
      "train [28.81850814819336, 6.529247283935547]\n",
      "val [28.465124130249023, 6.47310733795166]\n",
      "predict val...\n",
      "predict test...\n",
      "126.80428 230.4573\n",
      "129.79932 230.4573 306.9148 1.0\n",
      "FOLD 2425\n",
      "train [26.645235061645508, 6.462267875671387]\n",
      "val [32.350521087646484, 6.717864513397217]\n",
      "predict val...\n",
      "predict test...\n",
      "139.08298 220.54117\n",
      "-35.69922 220.54117 336.21045 0.9641693811074918\n",
      "FOLD 2426\n",
      "train [27.25105857849121, 6.4999284744262695]\n",
      "val [30.766448974609375, 6.5491132736206055]\n",
      "predict val...\n",
      "predict test...\n",
      "133.07686 239.00348\n",
      "75.30151 239.00348 347.5879 1.0\n",
      "FOLD 2427\n",
      "train [26.97602081298828, 6.467681884765625]\n",
      "val [31.3947696685791, 6.755691051483154]\n",
      "predict val...\n",
      "predict test...\n",
      "132.15813 224.6269\n",
      "120.2439 224.6269 304.02637 1.0\n",
      "FOLD 2428\n",
      "train [26.739810943603516, 6.455800533294678]\n",
      "val [37.39105987548828, 6.693902015686035]\n",
      "predict val...\n",
      "predict test...\n",
      "162.27881 223.4034\n",
      "129.10876 223.4034 297.261 1.0\n",
      "FOLD 2429\n",
      "train [28.505126953125, 6.5374956130981445]\n",
      "val [27.509613037109375, 6.408120155334473]\n",
      "predict val...\n",
      "predict test...\n",
      "119.42399 220.40747\n",
      "128.9707 220.40747 285.09277 1.0\n",
      "FOLD 2430\n",
      "train [27.244287490844727, 6.501773834228516]\n",
      "val [33.28192901611328, 6.697846412658691]\n",
      "predict val...\n",
      "predict test...\n",
      "144.35403 230.00336\n",
      "149.40869 230.00336 289.90283 1.0\n",
      "FOLD 2431\n",
      "train [25.487871170043945, 6.423619747161865]\n",
      "val [30.21459197998047, 6.696660995483398]\n",
      "predict val...\n",
      "predict test...\n",
      "130.31737 222.87381\n",
      "9.553711 222.87381 331.1421 1.0\n",
      "FOLD 2432\n",
      "train [28.239635467529297, 6.535763740539551]\n",
      "val [30.471145629882812, 6.577231407165527]\n",
      "predict val...\n",
      "predict test...\n",
      "128.38632 243.37164\n",
      "162.74976 243.37164 341.0996 1.0\n",
      "FOLD 2433\n",
      "train [24.85255241394043, 6.361343860626221]\n",
      "val [38.28242874145508, 6.698861598968506]\n",
      "predict val...\n",
      "predict test...\n",
      "163.41624 205.56334\n",
      "87.08179 205.56334 297.3152 1.0\n",
      "FOLD 2434\n",
      "train [28.392927169799805, 6.532845497131348]\n",
      "val [27.884864807128906, 6.439034461975098]\n",
      "predict val...\n",
      "predict test...\n",
      "121.53763 233.21219\n",
      "58.45703 233.21219 339.2644 1.0\n",
      "FOLD 2435\n",
      "train [26.682037353515625, 6.45752477645874]\n",
      "val [34.82168197631836, 6.777543544769287]\n",
      "predict val...\n",
      "predict test...\n",
      "151.74567 230.49776\n",
      "74.75 230.49776 401.53198 1.0\n",
      "FOLD 2436\n",
      "train [27.6441650390625, 6.493372917175293]\n",
      "val [31.262977600097656, 6.822449684143066]\n",
      "predict val...\n",
      "predict test...\n",
      "133.54008 227.35367\n",
      "-1.3491211 227.35367 393.50146 0.996742671009772\n",
      "FOLD 2437\n",
      "train [27.784099578857422, 6.503655910491943]\n",
      "val [30.608861923217773, 6.5777587890625]\n",
      "predict val...\n",
      "predict test...\n",
      "130.98648 247.77432\n",
      "142.60999 247.77432 373.70044 1.0\n",
      "FOLD 2438\n",
      "train [24.88925552368164, 6.380199909210205]\n",
      "val [38.02384948730469, 6.702461242675781]\n",
      "predict val...\n",
      "predict test...\n",
      "163.74725 213.87709\n",
      "89.04712 213.87709 339.86108 1.0\n",
      "FOLD 2439\n",
      "train [29.006858825683594, 6.543477535247803]\n",
      "val [27.682479858398438, 6.475001335144043]\n",
      "predict val...\n",
      "predict test...\n",
      "121.19112 230.70758\n",
      "76.64673 230.70758 339.6963 1.0\n",
      "FOLD 2440\n",
      "train [27.730560302734375, 6.500836372375488]\n",
      "val [34.797760009765625, 6.766477108001709]\n",
      "predict val...\n",
      "predict test...\n",
      "151.96895 229.01176\n",
      "82.333984 229.01176 324.36914 1.0\n",
      "FOLD 2441\n",
      "train [26.04384422302246, 6.429947853088379]\n",
      "val [31.481245040893555, 6.665450572967529]\n",
      "predict val...\n",
      "predict test...\n",
      "134.74652 214.2217\n",
      "100.031494 214.2217 339.60474 1.0\n",
      "FOLD 2442\n",
      "train [28.44095230102539, 6.533416748046875]\n",
      "val [30.096303939819336, 6.598421096801758]\n",
      "predict val...\n",
      "predict test...\n",
      "129.18282 247.2152\n",
      "143.22168 247.2152 349.31226 1.0\n",
      "FOLD 2443\n",
      "train [25.251264572143555, 6.394659042358398]\n",
      "val [38.403873443603516, 6.719326972961426]\n",
      "predict val...\n",
      "predict test...\n",
      "165.38194 219.17177\n",
      "85.18164 219.17177 321.15894 1.0\n",
      "FOLD 2444\n",
      "train [27.478134155273438, 6.492737770080566]\n",
      "val [27.66142463684082, 6.4507036209106445]\n",
      "predict val...\n",
      "predict test...\n",
      "119.44482 234.08368\n",
      "14.687988 234.08368 365.25317 1.0\n",
      "FOLD 2445\n",
      "train [26.725400924682617, 6.465479850769043]\n",
      "val [32.949649810791016, 6.709868431091309]\n",
      "predict val...\n",
      "predict test...\n",
      "144.3622 230.40549\n",
      "18.379639 230.40549 336.16577 1.0\n",
      "FOLD 2446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [27.941139221191406, 6.490649223327637]\n",
      "val [31.975685119628906, 6.8275065422058105]\n",
      "predict val...\n",
      "predict test...\n",
      "137.84259 225.6417\n",
      "66.9646 225.6417 425.41943 1.0\n",
      "FOLD 2447\n",
      "train [27.492502212524414, 6.483192443847656]\n",
      "val [30.0341854095459, 6.611316680908203]\n",
      "predict val...\n",
      "predict test...\n",
      "129.51091 235.6864\n",
      "100.34509 235.6864 403.29346 1.0\n",
      "FOLD 2448\n",
      "train [26.174190521240234, 6.427937984466553]\n",
      "val [38.24925231933594, 6.689903736114502]\n",
      "predict val...\n",
      "predict test...\n",
      "166.00804 221.14648\n",
      "106.63818 221.14648 355.14038 1.0\n",
      "FOLD 2449\n",
      "train [27.362951278686523, 6.501777648925781]\n",
      "val [27.77400016784668, 6.526979923248291]\n",
      "predict val...\n",
      "predict test...\n",
      "119.60426 230.068\n",
      "64.261475 230.068 376.68848 1.0\n",
      "FOLD 2450\n",
      "train [27.149141311645508, 6.466272830963135]\n",
      "val [33.271690368652344, 6.75289249420166]\n",
      "predict val...\n",
      "predict test...\n",
      "143.44908 218.04631\n",
      "-49.725098 218.04631 392.57007 0.9804560260586319\n",
      "FOLD 2451\n",
      "train [33.225364685058594, 6.551611423492432]\n",
      "val [37.5543327331543, 6.780807018280029]\n",
      "predict val...\n",
      "predict test...\n",
      "140.20193 248.89912\n",
      "124.56006 248.89912 426.7661 1.0\n",
      "FOLD 2452\n",
      "train [32.849037170410156, 6.531907558441162]\n",
      "val [35.30546188354492, 6.592600345611572]\n",
      "predict val...\n",
      "predict test...\n",
      "127.587364 238.61163\n",
      "132.23792 238.61163 399.05273 1.0\n",
      "FOLD 2453\n",
      "train [31.616825103759766, 6.486489772796631]\n",
      "val [44.18962860107422, 6.725383758544922]\n",
      "predict val...\n",
      "predict test...\n",
      "165.48738 222.77382\n",
      "122.24512 222.77382 440.7788 1.0\n",
      "FOLD 2454\n",
      "train [34.93679428100586, 6.632048606872559]\n",
      "val [32.816410064697266, 6.522387504577637]\n",
      "predict val...\n",
      "predict test...\n",
      "122.64401 252.68056\n",
      "98.07922 252.68056 423.97168 1.0\n",
      "FOLD 2455\n",
      "train [33.496543884277344, 6.573904514312744]\n",
      "val [37.29298782348633, 6.673528671264648]\n",
      "predict val...\n",
      "predict test...\n",
      "140.8556 249.7279\n",
      "155.65356 249.7279 347.0918 1.0\n",
      "FOLD 2456\n",
      "train [33.429832458496094, 6.571215629577637]\n",
      "val [37.080413818359375, 6.786362648010254]\n",
      "predict val...\n",
      "predict test...\n",
      "138.81372 261.768\n",
      "160.06592 261.768 384.479 1.0\n",
      "FOLD 2457\n",
      "train [33.51993942260742, 6.552199363708496]\n",
      "val [36.214324951171875, 6.635732650756836]\n",
      "predict val...\n",
      "predict test...\n",
      "131.5898 242.5771\n",
      "139.79395 242.5771 405.90576 1.0\n",
      "FOLD 2458\n",
      "train [30.750858306884766, 6.468125820159912]\n",
      "val [41.52056884765625, 6.701284408569336]\n",
      "predict val...\n",
      "predict test...\n",
      "155.04807 229.95409\n",
      "136.3623 229.95409 322.57275 1.0\n",
      "FOLD 2459\n",
      "train [33.14885330200195, 6.561888694763184]\n",
      "val [32.57716369628906, 6.493896484375]\n",
      "predict val...\n",
      "predict test...\n",
      "125.06359 230.91348\n",
      "125.8927 230.91348 306.5166 1.0\n",
      "FOLD 2460\n",
      "train [33.54814147949219, 6.549290657043457]\n",
      "val [37.581661224365234, 6.664514541625977]\n",
      "predict val...\n",
      "predict test...\n",
      "142.59691 229.29063\n",
      "152.73193 229.29063 327.41382 1.0\n",
      "FOLD 2461\n",
      "train [33.195552825927734, 6.563943386077881]\n",
      "val [36.91773986816406, 6.718400955200195]\n",
      "predict val...\n",
      "predict test...\n",
      "138.98544 260.36813\n",
      "169.9519 260.36813 353.04346 1.0\n",
      "FOLD 2462\n",
      "train [31.415786743164062, 6.503596305847168]\n",
      "val [37.21992492675781, 6.822701454162598]\n",
      "predict val...\n",
      "predict test...\n",
      "135.88806 239.76654\n",
      "149.24512 239.76654 355.1328 1.0\n",
      "FOLD 2463\n",
      "train [29.907432556152344, 6.443262577056885]\n",
      "val [43.804203033447266, 6.722437381744385]\n",
      "predict val...\n",
      "predict test...\n",
      "162.32741 222.62363\n",
      "133.03516 222.62363 278.6006 1.0\n",
      "FOLD 2464\n",
      "train [33.78883743286133, 6.581170082092285]\n",
      "val [34.15727996826172, 6.485047340393066]\n",
      "predict val...\n",
      "predict test...\n",
      "126.470825 239.2777\n",
      "127.403564 239.2777 329.16943 1.0\n",
      "FOLD 2465\n",
      "train [31.600439071655273, 6.492857456207275]\n",
      "val [40.10124588012695, 6.7296552658081055]\n",
      "predict val...\n",
      "predict test...\n",
      "150.83871 229.61662\n",
      "142.49658 229.61662 321.93604 1.0\n",
      "FOLD 2466\n",
      "train [30.844453811645508, 6.469974517822266]\n",
      "val [36.43123245239258, 6.670491695404053]\n",
      "predict val...\n",
      "predict test...\n",
      "135.85233 227.27412\n",
      "104.88086 227.27412 300.05225 1.0\n",
      "FOLD 2467\n",
      "train [31.886791229248047, 6.512574195861816]\n",
      "val [35.214569091796875, 6.719990253448486]\n",
      "predict val...\n",
      "predict test...\n",
      "129.56873 234.94745\n",
      "129.4209 234.94745 305.58594 1.0\n",
      "FOLD 2468\n",
      "train [30.6953067779541, 6.462904453277588]\n",
      "val [41.47121810913086, 6.685555458068848]\n",
      "predict val...\n",
      "predict test...\n",
      "154.06633 231.66113\n",
      "146.99683 231.66113 296.71094 1.0\n",
      "FOLD 2469\n",
      "train [32.582366943359375, 6.538142204284668]\n",
      "val [33.03425216674805, 6.48681640625]\n",
      "predict val...\n",
      "predict test...\n",
      "124.825195 243.0341\n",
      "146.45654 243.0341 324.81006 1.0\n",
      "FOLD 2470\n",
      "train [32.125980377197266, 6.530338287353516]\n",
      "val [39.671390533447266, 6.701708793640137]\n",
      "predict val...\n",
      "predict test...\n",
      "150.70497 242.0715\n",
      "180.48364 242.0715 324.44678 1.0\n",
      "FOLD 2471\n",
      "train [30.771116256713867, 6.472271919250488]\n",
      "val [35.78881072998047, 6.560894966125488]\n",
      "predict val...\n",
      "predict test...\n",
      "132.68771 223.6705\n",
      "65.73779 223.6705 316.60278 1.0\n",
      "FOLD 2472\n",
      "train [31.361305236816406, 6.492581844329834]\n",
      "val [35.67977523803711, 6.714866638183594]\n",
      "predict val...\n",
      "predict test...\n",
      "132.23932 240.68231\n",
      "141.39539 240.68231 309.7058 1.0\n",
      "FOLD 2473\n",
      "train [29.095951080322266, 6.4045209884643555]\n",
      "val [42.566768646240234, 6.662873268127441]\n",
      "predict val...\n",
      "predict test...\n",
      "158.82208 223.05649\n",
      "94.565674 223.05649 317.95825 1.0\n",
      "FOLD 2474\n",
      "train [32.7303466796875, 6.535541534423828]\n",
      "val [31.64275550842285, 6.483295440673828]\n",
      "predict val...\n",
      "predict test...\n",
      "119.750725 230.94153\n",
      "146.22217 230.94153 321.07202 1.0\n",
      "FOLD 2475\n",
      "train [31.076923370361328, 6.461453914642334]\n",
      "val [37.32188034057617, 6.67720365524292]\n",
      "predict val...\n",
      "predict test...\n",
      "139.70526 215.2414\n",
      "-14.330322 215.2414 327.79028 0.9869706840390879\n",
      "FOLD 2476\n",
      "train [30.875410079956055, 6.468640327453613]\n",
      "val [36.98851013183594, 6.745114803314209]\n",
      "predict val...\n",
      "predict test...\n",
      "135.93785 225.5823\n",
      "89.999756 225.5823 336.23486 1.0\n",
      "FOLD 2477\n",
      "train [32.3675537109375, 6.525113105773926]\n",
      "val [35.61284637451172, 6.596530914306641]\n",
      "predict val...\n",
      "predict test...\n",
      "130.64809 238.2875\n",
      "161.43384 238.2875 342.21924 1.0\n",
      "FOLD 2478\n",
      "train [30.333751678466797, 6.44536828994751]\n",
      "val [43.14529800415039, 6.6716837882995605]\n",
      "predict val...\n",
      "predict test...\n",
      "160.56989 226.1821\n",
      "92.72046 226.1821 292.3606 1.0\n",
      "FOLD 2479\n",
      "train [33.84383010864258, 6.566442966461182]\n",
      "val [31.95722198486328, 6.480955123901367]\n",
      "predict val...\n",
      "predict test...\n",
      "121.45856 237.1248\n",
      "165.82666 237.1248 307.90527 1.0\n",
      "FOLD 2480\n",
      "train [31.166410446166992, 6.485838413238525]\n",
      "val [42.21781921386719, 6.802678108215332]\n",
      "predict val...\n",
      "predict test...\n",
      "158.65727 226.99644\n",
      "100.56787 226.99644 301.14282 1.0\n",
      "FOLD 2481\n",
      "train [31.842063903808594, 6.506903648376465]\n",
      "val [38.3679084777832, 7.099822044372559]\n",
      "predict val...\n",
      "predict test...\n",
      "142.36098 237.03465\n",
      "27.937256 237.03465 420.12695 1.0\n",
      "FOLD 2482\n",
      "train [30.364347457885742, 6.458587646484375]\n",
      "val [36.45901107788086, 6.620617389678955]\n",
      "predict val...\n",
      "predict test...\n",
      "134.41434 229.71259\n",
      "106.043335 229.71259 323.04028 1.0\n",
      "FOLD 2483\n",
      "train [28.810646057128906, 6.384777069091797]\n",
      "val [43.18633270263672, 6.7120866775512695]\n",
      "predict val...\n",
      "predict test...\n",
      "158.6194 211.64993\n",
      "107.124146 211.64993 292.97925 1.0\n",
      "FOLD 2484\n",
      "train [32.69987106323242, 6.529974937438965]\n",
      "val [32.421749114990234, 6.492648124694824]\n",
      "predict val...\n",
      "predict test...\n",
      "123.2996 234.58449\n",
      "108.59668 234.58449 352.93286 1.0\n",
      "FOLD 2485\n",
      "train [29.81419563293457, 6.454532623291016]\n",
      "val [37.15046691894531, 6.678112030029297]\n",
      "predict val...\n",
      "predict test...\n",
      "140.74997 231.95569\n",
      "70.71289 231.95569 348.4685 1.0\n",
      "FOLD 2486\n",
      "train [29.081787109375, 6.390988349914551]\n",
      "val [35.700374603271484, 6.639190673828125]\n",
      "predict val...\n",
      "predict test...\n",
      "130.2006 202.5724\n",
      "-30.442383 202.5724 361.43018 0.9804560260586319\n",
      "FOLD 2487\n",
      "train [32.023075103759766, 6.521368980407715]\n",
      "val [34.4266471862793, 6.54594087600708]\n",
      "predict val...\n",
      "predict test...\n",
      "126.8463 253.4023\n",
      "120.49463 253.4023 339.09424 1.0\n",
      "FOLD 2488\n",
      "train [28.483564376831055, 6.390671730041504]\n",
      "val [43.31852722167969, 6.631502151489258]\n",
      "predict val...\n",
      "predict test...\n",
      "160.68625 223.99664\n",
      "45.04541 223.99664 335.6223 1.0\n",
      "FOLD 2489\n",
      "train [32.20758056640625, 6.5265631675720215]\n",
      "val [33.36225128173828, 6.519258499145508]\n",
      "predict val...\n",
      "predict test...\n",
      "127.44087 247.8415\n",
      "64.47949 247.8415 396.81494 1.0\n",
      "FOLD 2490\n",
      "train [30.62639045715332, 6.467470645904541]\n",
      "val [40.113548278808594, 6.821687698364258]\n",
      "predict val...\n",
      "predict test...\n",
      "151.20009 230.46193\n",
      "-7.864746 230.46193 404.5083 0.996742671009772\n",
      "FOLD 2491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [32.258182525634766, 6.5127692222595215]\n",
      "val [36.5416145324707, 6.794940948486328]\n",
      "predict val...\n",
      "predict test...\n",
      "134.57181 232.33551\n",
      "82.72583 232.33551 345.09216 1.0\n",
      "FOLD 2492\n",
      "train [31.451114654541016, 6.503640651702881]\n",
      "val [35.703582763671875, 6.618740081787109]\n",
      "predict val...\n",
      "predict test...\n",
      "132.19081 239.4604\n",
      "128.23828 239.4604 335.0747 1.0\n",
      "FOLD 2493\n",
      "train [29.32106590270996, 6.395016670227051]\n",
      "val [40.77665328979492, 6.641852378845215]\n",
      "predict val...\n",
      "predict test...\n",
      "150.38422 216.80511\n",
      "74.007324 216.80511 332.9165 1.0\n",
      "FOLD 2494\n",
      "train [31.321565628051758, 6.479305267333984]\n",
      "val [31.62943458557129, 6.415281295776367]\n",
      "predict val...\n",
      "predict test...\n",
      "118.22241 224.41425\n",
      "35.36548 224.41425 337.72632 1.0\n",
      "FOLD 2495\n",
      "train [31.442005157470703, 6.489412784576416]\n",
      "val [38.44160461425781, 6.77164363861084]\n",
      "predict val...\n",
      "predict test...\n",
      "143.45924 230.78995\n",
      "-1.1743164 230.78995 410.34497 0.996742671009772\n",
      "FOLD 2496\n",
      "train [29.436796188354492, 6.396939277648926]\n",
      "val [35.6660270690918, 6.653414726257324]\n",
      "predict val...\n",
      "predict test...\n",
      "132.02611 199.26859\n",
      "30.26001 199.26859 395.06396 1.0\n",
      "FOLD 2497\n",
      "train [31.702219009399414, 6.4995927810668945]\n",
      "val [36.925506591796875, 6.653255939483643]\n",
      "predict val...\n",
      "predict test...\n",
      "136.21703 238.85019\n",
      "123.48743 238.85019 328.69775 1.0\n",
      "FOLD 2498\n",
      "train [30.07351303100586, 6.430291652679443]\n",
      "val [42.870357513427734, 6.6683125495910645]\n",
      "predict val...\n",
      "predict test...\n",
      "159.70659 224.05573\n",
      "74.82959 224.05573 350.7085 1.0\n",
      "FOLD 2499\n",
      "train [33.167415618896484, 6.555137634277344]\n",
      "val [31.39041519165039, 6.521615982055664]\n",
      "predict val...\n",
      "predict test...\n",
      "119.41302 249.3641\n",
      "69.44995 249.3641 428.14453 1.0\n",
      "FOLD 2500\n",
      "train [31.315767288208008, 6.477417945861816]\n",
      "val [38.236724853515625, 6.784769535064697]\n",
      "predict val...\n",
      "predict test...\n",
      "141.87177 226.17374\n",
      "-21.565918 226.17374 402.26758 0.9804560260586319\n",
      "FOLD 2501\n",
      "train [37.903350830078125, 6.565989017486572]\n",
      "val [42.56233596801758, 6.795648574829102]\n",
      "predict val...\n",
      "predict test...\n",
      "138.91315 255.31255\n",
      "125.54407 255.31255 443.33203 1.0\n",
      "FOLD 2502\n",
      "train [37.901126861572266, 6.5503435134887695]\n",
      "val [39.196563720703125, 6.568026542663574]\n",
      "predict val...\n",
      "predict test...\n",
      "123.78079 237.19427\n",
      "146.64124 237.19427 379.42236 1.0\n",
      "FOLD 2503\n",
      "train [36.180694580078125, 6.499608516693115]\n",
      "val [47.753997802734375, 6.651593208312988]\n",
      "predict val...\n",
      "predict test...\n",
      "158.24602 231.18195\n",
      "115.62622 231.18195 468.1753 1.0\n",
      "FOLD 2504\n",
      "train [40.21505355834961, 6.645195007324219]\n",
      "val [35.810516357421875, 6.521711349487305]\n",
      "predict val...\n",
      "predict test...\n",
      "120.49168 252.71646\n",
      "105.26581 252.71646 414.99805 1.0\n",
      "FOLD 2505\n",
      "train [37.58088302612305, 6.565289497375488]\n",
      "val [42.96879577636719, 6.675920486450195]\n",
      "predict val...\n",
      "predict test...\n",
      "143.01456 253.4729\n",
      "126.385254 253.4729 426.06738 1.0\n",
      "FOLD 2506\n",
      "train [37.90291976928711, 6.566760063171387]\n",
      "val [42.74953079223633, 6.8091936111450195]\n",
      "predict val...\n",
      "predict test...\n",
      "139.9787 260.12515\n",
      "159.38965 260.12515 362.13818 1.0\n",
      "FOLD 2507\n",
      "train [37.7478141784668, 6.554595947265625]\n",
      "val [42.54429244995117, 6.654349327087402]\n",
      "predict val...\n",
      "predict test...\n",
      "137.10783 243.1769\n",
      "149.55444 243.1769 395.52686 1.0\n",
      "FOLD 2508\n",
      "train [35.328372955322266, 6.476031303405762]\n",
      "val [48.15139389038086, 6.670990467071533]\n",
      "predict val...\n",
      "predict test...\n",
      "158.02333 221.43256\n",
      "133.43213 221.43256 330.44385 1.0\n",
      "FOLD 2509\n",
      "train [38.83279037475586, 6.580750942230225]\n",
      "val [35.41025924682617, 6.457175254821777]\n",
      "predict val...\n",
      "predict test...\n",
      "119.84072 230.79535\n",
      "142.86108 230.79535 297.87793 1.0\n",
      "FOLD 2510\n",
      "train [36.60681915283203, 6.519541263580322]\n",
      "val [41.4892463684082, 6.658998012542725]\n",
      "predict val...\n",
      "predict test...\n",
      "136.9635 227.66257\n",
      "147.72241 227.66257 319.35498 1.0\n",
      "FOLD 2511\n",
      "train [37.38125991821289, 6.560338497161865]\n",
      "val [42.38229751586914, 6.744567394256592]\n",
      "predict val...\n",
      "predict test...\n",
      "140.52747 264.3805\n",
      "176.79224 264.3805 367.05127 1.0\n",
      "FOLD 2512\n",
      "train [35.90704345703125, 6.512280464172363]\n",
      "val [39.45635223388672, 6.603900909423828]\n",
      "predict val...\n",
      "predict test...\n",
      "128.53246 234.07202\n",
      "154.87329 234.07202 315.14648 1.0\n",
      "FOLD 2513\n",
      "train [34.137451171875, 6.445253849029541]\n",
      "val [47.369529724121094, 6.680248737335205]\n",
      "predict val...\n",
      "predict test...\n",
      "153.94131 225.51685\n",
      "137.65125 225.51685 276.02808 1.0\n",
      "FOLD 2514\n",
      "train [37.42115783691406, 6.559668064117432]\n",
      "val [38.62778091430664, 6.493741989135742]\n",
      "predict val...\n",
      "predict test...\n",
      "130.44725 231.44081\n",
      "134.56 231.44081 307.61816 1.0\n",
      "FOLD 2515\n",
      "train [36.18498611450195, 6.511837959289551]\n",
      "val [45.82270431518555, 6.71463680267334]\n",
      "predict val...\n",
      "predict test...\n",
      "151.26498 230.31464\n",
      "186.21631 230.31464 315.19092 1.0\n",
      "FOLD 2516\n",
      "train [36.69228744506836, 6.523293495178223]\n",
      "val [43.46892166137695, 6.825007438659668]\n",
      "predict val...\n",
      "predict test...\n",
      "142.28166 243.12119\n",
      "152.24475 243.12119 332.4702 1.0\n",
      "FOLD 2517\n",
      "train [36.51585388183594, 6.532304286956787]\n",
      "val [39.44573211669922, 6.591302871704102]\n",
      "predict val...\n",
      "predict test...\n",
      "126.88331 245.96703\n",
      "167.21387 245.96703 346.25146 1.0\n",
      "FOLD 2518\n",
      "train [34.58241653442383, 6.457178592681885]\n",
      "val [48.19088363647461, 6.682134628295898]\n",
      "predict val...\n",
      "predict test...\n",
      "157.40628 232.62793\n",
      "146.69482 232.62793 303.86694 1.0\n",
      "FOLD 2519\n",
      "train [38.162899017333984, 6.5760498046875]\n",
      "val [36.80295181274414, 6.481389999389648]\n",
      "predict val...\n",
      "predict test...\n",
      "123.9976 235.3604\n",
      "131.51074 235.3604 334.5127 1.0\n",
      "FOLD 2520\n",
      "train [36.2056999206543, 6.523016452789307]\n",
      "val [45.42957305908203, 6.707949638366699]\n",
      "predict val...\n",
      "predict test...\n",
      "150.56178 238.20163\n",
      "177.05286 238.20163 338.7959 1.0\n",
      "FOLD 2521\n",
      "train [34.32878494262695, 6.451011657714844]\n",
      "val [41.797611236572266, 6.731375694274902]\n",
      "predict val...\n",
      "predict test...\n",
      "138.18121 230.81868\n",
      "143.03027 230.81868 312.813 1.0\n",
      "FOLD 2522\n",
      "train [37.119590759277344, 6.5494513511657715]\n",
      "val [39.70359420776367, 6.580228805541992]\n",
      "predict val...\n",
      "predict test...\n",
      "128.45612 249.7557\n",
      "166.42981 249.7557 363.91797 1.0\n",
      "FOLD 2523\n",
      "train [32.51033020019531, 6.4053544998168945]\n",
      "val [48.339622497558594, 6.694123268127441]\n",
      "predict val...\n",
      "predict test...\n",
      "156.85637 217.15652\n",
      "124.04761 217.15652 271.0476 1.0\n",
      "FOLD 2524\n",
      "train [36.576576232910156, 6.526486396789551]\n",
      "val [35.95863723754883, 6.487481594085693]\n",
      "predict val...\n",
      "predict test...\n",
      "120.11277 238.88437\n",
      "98.41284 238.88437 328.05176 1.0\n",
      "FOLD 2525\n",
      "train [36.12220764160156, 6.492314338684082]\n",
      "val [46.00628662109375, 6.793249607086182]\n",
      "predict val...\n",
      "predict test...\n",
      "152.09232 228.24374\n",
      "49.96289 228.24374 341.5027 1.0\n",
      "FOLD 2526\n",
      "train [35.601226806640625, 6.502437591552734]\n",
      "val [42.2065544128418, 6.7568278312683105]\n",
      "predict val...\n",
      "predict test...\n",
      "137.9944 241.26695\n",
      "142.73071 241.26695 332.13867 1.0\n",
      "FOLD 2527\n",
      "train [36.46792984008789, 6.527516841888428]\n",
      "val [41.066402435302734, 6.622637748718262]\n",
      "predict val...\n",
      "predict test...\n",
      "131.9333 246.11201\n",
      "150.4248 246.11201 337.7461 1.0\n",
      "FOLD 2528\n",
      "train [32.44691467285156, 6.381610870361328]\n",
      "val [51.026607513427734, 6.678309440612793]\n",
      "predict val...\n",
      "predict test...\n",
      "164.84969 208.36847\n",
      "89.79443 208.36847 304.97437 1.0\n",
      "FOLD 2529\n",
      "train [36.19611358642578, 6.514151096343994]\n",
      "val [35.9908561706543, 6.448962211608887]\n",
      "predict val...\n",
      "predict test...\n",
      "120.69265 239.39622\n",
      "24.447266 239.39622 324.0852 1.0\n",
      "FOLD 2530\n",
      "train [34.463375091552734, 6.4637603759765625]\n",
      "val [42.791847229003906, 6.719509124755859]\n",
      "predict val...\n",
      "predict test...\n",
      "139.98746 234.87566\n",
      "-19.539062 234.87566 364.9436 0.9837133550488599\n",
      "FOLD 2531\n",
      "train [35.71615982055664, 6.492002964019775]\n",
      "val [41.797027587890625, 6.981218338012695]\n",
      "predict val...\n",
      "predict test...\n",
      "135.61742 233.64265\n",
      "24.236328 233.64265 433.20654 1.0\n",
      "FOLD 2532\n",
      "train [34.798316955566406, 6.459322929382324]\n",
      "val [47.045597076416016, 7.152711868286133]\n",
      "predict val...\n",
      "predict test...\n",
      "148.73613 240.1356\n",
      "94.93042 240.1356 326.54102 1.0\n",
      "FOLD 2533\n",
      "train [32.317352294921875, 6.3928327560424805]\n",
      "val [50.786930084228516, 6.703164100646973]\n",
      "predict val...\n",
      "predict test...\n",
      "164.09288 213.95389\n",
      "107.88281 213.95389 291.54297 1.0\n",
      "FOLD 2534\n",
      "train [35.443199157714844, 6.483948707580566]\n",
      "val [37.183929443359375, 6.489646911621094]\n",
      "predict val...\n",
      "predict test...\n",
      "123.179 230.33217\n",
      "37.8042 230.33217 307.8213 1.0\n",
      "FOLD 2535\n",
      "train [34.27430725097656, 6.45220947265625]\n",
      "val [46.96469497680664, 6.801325798034668]\n",
      "predict val...\n",
      "predict test...\n",
      "153.93787 226.4491\n",
      "23.333496 226.4491 323.8767 1.0\n",
      "FOLD 2536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [36.236473083496094, 6.507533073425293]\n",
      "val [43.17403793334961, 6.928705215454102]\n",
      "predict val...\n",
      "predict test...\n",
      "141.92105 241.06406\n",
      "55.714355 241.06406 489.48584 1.0\n",
      "FOLD 2537\n",
      "train [36.43009948730469, 6.510453701019287]\n",
      "val [38.03525161743164, 6.542791366577148]\n",
      "predict val...\n",
      "predict test...\n",
      "124.88908 249.71727\n",
      "118.71936 249.71727 453.52393 1.0\n",
      "FOLD 2538\n",
      "train [33.55706787109375, 6.414671421051025]\n",
      "val [49.85099411010742, 6.713030815124512]\n",
      "predict val...\n",
      "predict test...\n",
      "163.22737 220.8242\n",
      "77.66968 220.8242 337.92017 1.0\n",
      "FOLD 2539\n",
      "train [35.30937957763672, 6.475264072418213]\n",
      "val [36.75348663330078, 6.458307266235352]\n",
      "predict val...\n",
      "predict test...\n",
      "122.270386 230.56456\n",
      "27.858887 230.56456 319.7744 1.0\n",
      "FOLD 2540\n",
      "train [36.85860061645508, 6.532339572906494]\n",
      "val [44.51825714111328, 6.6924614906311035]\n",
      "predict val...\n",
      "predict test...\n",
      "147.54936 234.33484\n",
      "174.00708 234.33484 319.18213 1.0\n",
      "FOLD 2541\n",
      "train [34.015594482421875, 6.438181400299072]\n",
      "val [43.5241813659668, 6.90929651260376]\n",
      "predict val...\n",
      "predict test...\n",
      "141.81732 218.63454\n",
      "86.95703 218.63454 390.67676 1.0\n",
      "FOLD 2542\n",
      "train [37.424095153808594, 6.5450286865234375]\n",
      "val [39.459991455078125, 6.613738059997559]\n",
      "predict val...\n",
      "predict test...\n",
      "128.84048 251.30374\n",
      "157.57312 251.30374 370.3452 1.0\n",
      "FOLD 2543\n",
      "train [31.79076385498047, 6.379733562469482]\n",
      "val [49.10454559326172, 6.71641206741333]\n",
      "predict val...\n",
      "predict test...\n",
      "158.63815 209.13174\n",
      "75.245605 209.13174 292.05884 1.0\n",
      "FOLD 2544\n",
      "train [36.32382583618164, 6.503838539123535]\n",
      "val [37.82258605957031, 6.489241600036621]\n",
      "predict val...\n",
      "predict test...\n",
      "127.298454 235.82416\n",
      "42.594482 235.82416 342.03564 1.0\n",
      "FOLD 2545\n",
      "train [34.25388717651367, 6.450716972351074]\n",
      "val [44.80672836303711, 6.755408763885498]\n",
      "predict val...\n",
      "predict test...\n",
      "148.34924 235.85458\n",
      "30.800781 235.85458 366.46924 1.0\n",
      "FOLD 2546\n",
      "train [36.11653137207031, 6.495352268218994]\n",
      "val [44.22950744628906, 7.020275592803955]\n",
      "predict val...\n",
      "predict test...\n",
      "144.30467 237.11472\n",
      "53.89258 237.11472 512.1626 1.0\n",
      "FOLD 2547\n",
      "train [36.21563720703125, 6.503293037414551]\n",
      "val [38.000518798828125, 6.4774580001831055]\n",
      "predict val...\n",
      "predict test...\n",
      "123.494606 247.66006\n",
      "105.984985 247.66006 434.07812 1.0\n",
      "FOLD 2548\n",
      "train [32.94416046142578, 6.383664131164551]\n",
      "val [48.38545227050781, 6.676292896270752]\n",
      "predict val...\n",
      "predict test...\n",
      "157.8539 208.95854\n",
      "76.98535 208.95854 336.67993 1.0\n",
      "FOLD 2549\n",
      "train [35.37199401855469, 6.483004093170166]\n",
      "val [35.68511199951172, 6.433357238769531]\n",
      "predict val...\n",
      "predict test...\n",
      "118.898056 227.11737\n",
      "18.552734 227.11737 317.4702 1.0\n",
      "FOLD 2550\n",
      "train [34.153865814208984, 6.441208839416504]\n",
      "val [42.57537841796875, 6.704889297485352]\n",
      "predict val...\n",
      "predict test...\n",
      "140.37949 227.20766\n",
      "-14.965576 227.20766 369.8203 0.9869706840390879\n",
      "FOLD 2551\n",
      "train [42.11505889892578, 6.558696746826172]\n",
      "val [47.05379867553711, 6.7585248947143555]\n",
      "predict val...\n",
      "predict test...\n",
      "138.24799 255.29759\n",
      "135.41797 255.29759 426.5503 1.0\n",
      "FOLD 2552\n",
      "train [42.04921340942383, 6.548488616943359]\n",
      "val [44.16239547729492, 6.607624053955078]\n",
      "predict val...\n",
      "predict test...\n",
      "125.48257 246.81215\n",
      "133.31177 246.81215 419.14844 1.0\n",
      "FOLD 2553\n",
      "train [40.76113510131836, 6.498218536376953]\n",
      "val [53.744571685791016, 6.6768341064453125]\n",
      "predict val...\n",
      "predict test...\n",
      "157.48335 227.02847\n",
      "108.972534 227.02847 492.64258 1.0\n",
      "FOLD 2554\n",
      "train [43.77305603027344, 6.595783233642578]\n",
      "val [41.42075729370117, 6.4851460456848145]\n",
      "predict val...\n",
      "predict test...\n",
      "124.13108 225.69237\n",
      "91.177246 225.69237 376.11133 1.0\n",
      "FOLD 2555\n",
      "train [42.298423767089844, 6.559405326843262]\n",
      "val [47.58057403564453, 6.665707588195801]\n",
      "predict val...\n",
      "predict test...\n",
      "140.96794 243.15388\n",
      "132.39258 243.15388 407.1045 1.0\n",
      "FOLD 2556\n",
      "train [42.105690002441406, 6.559364318847656]\n",
      "val [46.92207336425781, 6.786350727081299]\n",
      "predict val...\n",
      "predict test...\n",
      "137.51967 256.14877\n",
      "140.52087 256.14877 392.93555 1.0\n",
      "FOLD 2557\n",
      "train [42.15987014770508, 6.544949531555176]\n",
      "val [47.480045318603516, 6.642313003540039]\n",
      "predict val...\n",
      "predict test...\n",
      "136.32497 234.76596\n",
      "149.41553 234.76596 370.95117 1.0\n",
      "FOLD 2558\n",
      "train [39.76719284057617, 6.477400302886963]\n",
      "val [55.706077575683594, 6.695191383361816]\n",
      "predict val...\n",
      "predict test...\n",
      "161.62006 217.90797\n",
      "136.7727 217.90797 277.92188 1.0\n",
      "FOLD 2559\n",
      "train [43.95594787597656, 6.610345363616943]\n",
      "val [42.474056243896484, 6.50242280960083]\n",
      "predict val...\n",
      "predict test...\n",
      "125.04026 238.11699\n",
      "95.06781 238.11699 394.66357 1.0\n",
      "FOLD 2560\n",
      "train [42.81103515625, 6.541989326477051]\n",
      "val [47.747413635253906, 6.655223846435547]\n",
      "predict val...\n",
      "predict test...\n",
      "142.11209 219.40004\n",
      "133.89075 219.40004 311.7119 1.0\n",
      "FOLD 2561\n",
      "train [42.11935806274414, 6.5651140213012695]\n",
      "val [47.04584884643555, 6.73863410949707]\n",
      "predict val...\n",
      "predict test...\n",
      "138.53229 261.9643\n",
      "184.16089 261.9643 355.1172 1.0\n",
      "FOLD 2562\n",
      "train [42.10784149169922, 6.571966648101807]\n",
      "val [43.37256622314453, 6.6197099685668945]\n",
      "predict val...\n",
      "predict test...\n",
      "125.02331 263.81186\n",
      "175.50488 263.81186 399.4165 1.0\n",
      "FOLD 2563\n",
      "train [38.598934173583984, 6.4590349197387695]\n",
      "val [53.7119255065918, 6.689970970153809]\n",
      "predict val...\n",
      "predict test...\n",
      "154.61078 226.97298\n",
      "139.36768 226.97298 322.5127 1.0\n",
      "FOLD 2564\n",
      "train [40.29803466796875, 6.513472557067871]\n",
      "val [42.76785659790039, 6.539877891540527]\n",
      "predict val...\n",
      "predict test...\n",
      "126.44129 229.88261\n",
      "88.79126 229.88261 282.52563 1.0\n",
      "FOLD 2565\n",
      "train [40.13371658325195, 6.508578300476074]\n",
      "val [50.82242965698242, 6.703460693359375]\n",
      "predict val...\n",
      "predict test...\n",
      "147.82054 229.03488\n",
      "167.08179 229.03488 303.75342 1.0\n",
      "FOLD 2566\n",
      "train [41.436668395996094, 6.538498878479004]\n",
      "val [47.43633270263672, 6.780752182006836]\n",
      "predict val...\n",
      "predict test...\n",
      "139.41312 251.45226\n",
      "167.58154 251.45226 347.38916 1.0\n",
      "FOLD 2567\n",
      "train [39.75920486450195, 6.504412651062012]\n",
      "val [43.91673278808594, 6.579164505004883]\n",
      "predict val...\n",
      "predict test...\n",
      "128.04506 233.39455\n",
      "125.26172 233.39455 301.7163 1.0\n",
      "FOLD 2568\n",
      "train [39.17985916137695, 6.482798099517822]\n",
      "val [54.3063850402832, 6.718812942504883]\n",
      "predict val...\n",
      "predict test...\n",
      "158.12816 235.28186\n",
      "117.728516 235.28186 292.94434 1.0\n",
      "FOLD 2569\n",
      "train [43.46963882446289, 6.598971366882324]\n",
      "val [42.625125885009766, 6.531229019165039]\n",
      "predict val...\n",
      "predict test...\n",
      "130.53677 244.46284\n",
      "141.2909 244.46284 348.91382 1.0\n",
      "FOLD 2570\n",
      "train [40.19449996948242, 6.522904396057129]\n",
      "val [52.53364181518555, 6.740553855895996]\n",
      "predict val...\n",
      "predict test...\n",
      "154.68451 239.6253\n",
      "180.12903 239.6253 319.00952 1.0\n",
      "FOLD 2571\n",
      "train [39.44449234008789, 6.494843482971191]\n",
      "val [46.92509460449219, 6.685238361358643]\n",
      "predict val...\n",
      "predict test...\n",
      "137.39005 232.39139\n",
      "147.1958 232.39139 312.21362 1.0\n",
      "FOLD 2572\n",
      "train [39.89140319824219, 6.506070613861084]\n",
      "val [44.96941375732422, 6.633425235748291]\n",
      "predict val...\n",
      "predict test...\n",
      "131.0928 244.19196\n",
      "127.489746 244.19196 309.4214 1.0\n",
      "FOLD 2573\n",
      "train [39.56052017211914, 6.48513650894165]\n",
      "val [53.23382568359375, 6.652812957763672]\n",
      "predict val...\n",
      "predict test...\n",
      "154.93156 232.21924\n",
      "152.18005 232.21924 277.938 1.0\n",
      "FOLD 2574\n",
      "train [41.999996185302734, 6.548012733459473]\n",
      "val [41.238983154296875, 6.491099834442139]\n",
      "predict val...\n",
      "predict test...\n",
      "124.832375 235.28374\n",
      "97.26831 235.28374 306.60547 1.0\n",
      "FOLD 2575\n",
      "train [40.0306510925293, 6.4992523193359375]\n",
      "val [52.29066467285156, 6.758294105529785]\n",
      "predict val...\n",
      "predict test...\n",
      "153.31575 219.5971\n",
      "67.48828 219.5971 345.2693 1.0\n",
      "FOLD 2576\n",
      "train [37.86708068847656, 6.4448699951171875]\n",
      "val [45.15049362182617, 6.791773796081543]\n",
      "predict val...\n",
      "predict test...\n",
      "132.23932 226.31316\n",
      "52.348877 226.31316 315.38428 1.0\n",
      "FOLD 2577\n",
      "train [39.32779312133789, 6.492156982421875]\n",
      "val [53.47653579711914, 7.1413187980651855]\n",
      "predict val...\n",
      "predict test...\n",
      "152.20984 244.29912\n",
      "129.84644 244.29912 345.5913 1.0\n",
      "FOLD 2578\n",
      "train [36.452667236328125, 6.391932964324951]\n",
      "val [56.60643005371094, 6.670879364013672]\n",
      "predict val...\n",
      "predict test...\n",
      "162.73012 210.60918\n",
      "98.247925 210.60918 271.34204 1.0\n",
      "FOLD 2579\n",
      "train [42.171207427978516, 6.546141624450684]\n",
      "val [40.76316452026367, 6.511587142944336]\n",
      "predict val...\n",
      "predict test...\n",
      "122.63107 243.65645\n",
      "114.495605 243.65645 371.49805 1.0\n",
      "FOLD 2580\n",
      "train [39.2846565246582, 6.472367286682129]\n",
      "val [48.852821350097656, 6.7021565437316895]\n",
      "predict val...\n",
      "predict test...\n",
      "145.06433 232.72385\n",
      "-69.34253 232.72385 342.95508 0.9804560260586319\n",
      "FOLD 2581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [39.999168395996094, 6.498484134674072]\n",
      "val [53.41801452636719, 7.751524448394775]\n",
      "predict val...\n",
      "predict test...\n",
      "152.49443 237.5607\n",
      "-75.67456 237.5607 386.36475 0.9739413680781759\n",
      "FOLD 2582\n",
      "train [41.41556930541992, 6.545237064361572]\n",
      "val [45.19972229003906, 6.601789474487305]\n",
      "predict val...\n",
      "predict test...\n",
      "129.93427 247.34222\n",
      "161.29431 247.34222 384.53223 1.0\n",
      "FOLD 2583\n",
      "train [38.075443267822266, 6.429600715637207]\n",
      "val [55.121158599853516, 6.674887657165527]\n",
      "predict val...\n",
      "predict test...\n",
      "160.09703 225.99162\n",
      "93.41406 225.99162 355.85474 1.0\n",
      "FOLD 2584\n",
      "train [41.53175735473633, 6.540380001068115]\n",
      "val [41.711708068847656, 6.50046968460083]\n",
      "predict val...\n",
      "predict test...\n",
      "126.55031 240.03426\n",
      "35.367676 240.03426 338.03125 1.0\n",
      "FOLD 2585\n",
      "train [40.57893753051758, 6.500269889831543]\n",
      "val [49.448246002197266, 6.780055999755859]\n",
      "predict val...\n",
      "predict test...\n",
      "144.6874 235.09065\n",
      "21.338867 235.09065 426.57178 1.0\n",
      "FOLD 2586\n",
      "train [40.03166198730469, 6.495597839355469]\n",
      "val [47.38450622558594, 6.7863006591796875]\n",
      "predict val...\n",
      "predict test...\n",
      "138.1037 232.98886\n",
      "-7.440918 232.98886 382.62354 0.996742671009772\n",
      "FOLD 2587\n",
      "train [38.26237106323242, 6.462609767913818]\n",
      "val [47.985042572021484, 6.772308826446533]\n",
      "predict val...\n",
      "predict test...\n",
      "138.60788 229.07954\n",
      "131.68433 229.07954 305.75586 1.0\n",
      "FOLD 2588\n",
      "train [38.07468795776367, 6.4290008544921875]\n",
      "val [55.76584243774414, 6.66091251373291]\n",
      "predict val...\n",
      "predict test...\n",
      "162.26735 217.55013\n",
      "92.80994 217.55013 334.78076 1.0\n",
      "FOLD 2589\n",
      "train [41.54482650756836, 6.5303053855896]\n",
      "val [39.501930236816406, 6.453037738800049]\n",
      "predict val...\n",
      "predict test...\n",
      "118.76063 233.62825\n",
      "138.60974 233.62825 350.7107 1.0\n",
      "FOLD 2590\n",
      "train [39.534915924072266, 6.480654716491699]\n",
      "val [49.38775634765625, 6.738951683044434]\n",
      "predict val...\n",
      "predict test...\n",
      "145.53458 232.17233\n",
      "35.79883 232.17233 368.18506 1.0\n",
      "FOLD 2591\n",
      "train [39.75883102416992, 6.4887375831604]\n",
      "val [45.50428009033203, 6.599185943603516]\n",
      "predict val...\n",
      "predict test...\n",
      "132.92378 230.46341\n",
      "18.539795 230.46341 367.2339 1.0\n",
      "FOLD 2592\n",
      "train [41.322418212890625, 6.54088830947876]\n",
      "val [45.17557144165039, 6.587259292602539]\n",
      "predict val...\n",
      "predict test...\n",
      "129.89157 246.78334\n",
      "161.19348 246.78334 343.16162 1.0\n",
      "FOLD 2593\n",
      "train [35.40633773803711, 6.379448890686035]\n",
      "val [54.849830627441406, 6.711498737335205]\n",
      "predict val...\n",
      "predict test...\n",
      "157.48128 213.45018\n",
      "37.484375 213.45018 310.4026 1.0\n",
      "FOLD 2594\n",
      "train [39.52510070800781, 6.502300262451172]\n",
      "val [43.03313446044922, 6.499275207519531]\n",
      "predict val...\n",
      "predict test...\n",
      "128.16855 243.9572\n",
      "11.579834 243.9572 350.8025 1.0\n",
      "FOLD 2595\n",
      "train [38.69522476196289, 6.469043731689453]\n",
      "val [48.046390533447266, 6.738175392150879]\n",
      "predict val...\n",
      "predict test...\n",
      "141.65042 232.60843\n",
      "-8.064453 232.60843 375.8667 0.9869706840390879\n",
      "FOLD 2596\n",
      "train [38.0669059753418, 6.448063850402832]\n",
      "val [48.296024322509766, 6.817078590393066]\n",
      "predict val...\n",
      "predict test...\n",
      "139.5538 222.25517\n",
      "33.63916 222.25517 381.00342 1.0\n",
      "FOLD 2597\n",
      "train [41.558319091796875, 6.537872314453125]\n",
      "val [44.16592788696289, 6.613559722900391]\n",
      "predict val...\n",
      "predict test...\n",
      "127.60339 244.74982\n",
      "163.05627 244.74982 351.32617 1.0\n",
      "FOLD 2598\n",
      "train [35.96893310546875, 6.361172676086426]\n",
      "val [54.373313903808594, 6.689167499542236]\n",
      "predict val...\n",
      "predict test...\n",
      "155.13582 205.32188\n",
      "-38.123047 205.32188 372.90552 0.996742671009772\n",
      "FOLD 2599\n",
      "train [42.073734283447266, 6.5499067306518555]\n",
      "val [40.36278533935547, 6.512264251708984]\n",
      "predict val...\n",
      "predict test...\n",
      "120.64551 246.31586\n",
      "108.601074 246.31586 393.36035 1.0\n",
      "FOLD 2600\n",
      "train [40.051090240478516, 6.495331764221191]\n",
      "val [48.20441818237305, 6.752162933349609]\n",
      "predict val...\n",
      "predict test...\n",
      "140.94347 231.62378\n",
      "26.815674 231.62378 364.61475 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2601\n",
      "train [28.79023551940918, 6.55869197845459]\n",
      "val [32.051876068115234, 6.763440132141113]\n",
      "predict val...\n",
      "predict test...\n",
      "139.52771 255.09831\n",
      "139.71191 255.09831 416.4922 1.0\n",
      "FOLD 2602\n",
      "train [29.210962295532227, 6.566061973571777]\n",
      "val [29.53026008605957, 6.598511695861816]\n",
      "predict val...\n",
      "predict test...\n",
      "122.62566 251.57217\n",
      "139.83594 251.57217 428.1621 1.0\n",
      "FOLD 2603\n",
      "train [27.001771926879883, 6.470405578613281]\n",
      "val [37.40245056152344, 6.7353997230529785]\n",
      "predict val...\n",
      "predict test...\n",
      "161.33041 223.2983\n",
      "105.80835 223.2983 407.7417 1.0\n",
      "FOLD 2604\n",
      "train [29.965900421142578, 6.617769718170166]\n",
      "val [27.90172576904297, 6.510166645050049]\n",
      "predict val...\n",
      "predict test...\n",
      "121.9392 245.09486\n",
      "105.21307 245.09486 397.67676 1.0\n",
      "FOLD 2605\n",
      "train [28.774213790893555, 6.546341896057129]\n",
      "val [32.545440673828125, 6.656665325164795]\n",
      "predict val...\n",
      "predict test...\n",
      "142.78049 234.11125\n",
      "107.996765 234.11125 395.48438 1.0\n",
      "FOLD 2606\n",
      "train [28.305660247802734, 6.544921875]\n",
      "val [31.38532829284668, 6.739830493927002]\n",
      "predict val...\n",
      "predict test...\n",
      "135.83305 252.16112\n",
      "158.03772 252.16112 329.6665 1.0\n",
      "FOLD 2607\n",
      "train [28.906888961791992, 6.551042079925537]\n",
      "val [31.298276901245117, 6.623147010803223]\n",
      "predict val...\n",
      "predict test...\n",
      "131.95984 240.75732\n",
      "158.81201 240.75732 363.7915 1.0\n",
      "FOLD 2608\n",
      "train [26.82925796508789, 6.461256980895996]\n",
      "val [37.636966705322266, 6.757229804992676]\n",
      "predict val...\n",
      "predict test...\n",
      "161.65073 218.15024\n",
      "63.618164 218.15024 298.43408 1.0\n",
      "FOLD 2609\n",
      "train [30.13747215270996, 6.597496032714844]\n",
      "val [27.29637908935547, 6.466402053833008]\n",
      "predict val...\n",
      "predict test...\n",
      "120.22455 224.4409\n",
      "101.90454 224.4409 352.0664 1.0\n",
      "FOLD 2610\n",
      "train [27.670211791992188, 6.505893707275391]\n",
      "val [33.55522537231445, 6.708813190460205]\n",
      "predict val...\n",
      "predict test...\n",
      "145.96043 224.20515\n",
      "167.8695 224.20515 310.54565 1.0\n",
      "FOLD 2611\n",
      "train [28.4175968170166, 6.543703556060791]\n",
      "val [32.483734130859375, 6.744368553161621]\n",
      "predict val...\n",
      "predict test...\n",
      "141.45009 250.75003\n",
      "151.17432 250.75003 351.55664 1.0\n",
      "FOLD 2612\n",
      "train [28.512699127197266, 6.554388523101807]\n",
      "val [29.69643783569336, 6.568296432495117]\n",
      "predict val...\n",
      "predict test...\n",
      "124.78245 253.04454\n",
      "159.63611 253.04454 384.06006 1.0\n",
      "FOLD 2613\n",
      "train [26.59680938720703, 6.465439796447754]\n",
      "val [37.4100341796875, 6.729133605957031]\n",
      "predict val...\n",
      "predict test...\n",
      "161.37032 228.82477\n",
      "134.52832 228.82477 286.2666 1.0\n",
      "FOLD 2614\n",
      "train [28.523853302001953, 6.557441711425781]\n",
      "val [28.24634552001953, 6.458879470825195]\n",
      "predict val...\n",
      "predict test...\n",
      "120.574715 243.3607\n",
      "142.61426 243.3607 316.21875 1.0\n",
      "FOLD 2615\n",
      "train [27.244277954101562, 6.49774694442749]\n",
      "val [33.926963806152344, 6.738400459289551]\n",
      "predict val...\n",
      "predict test...\n",
      "149.26665 231.72339\n",
      "139.21338 231.72339 293.3318 1.0\n",
      "FOLD 2616\n",
      "train [27.526742935180664, 6.489166259765625]\n",
      "val [33.62860870361328, 7.166754722595215]\n",
      "predict val...\n",
      "predict test...\n",
      "144.32265 228.21165\n",
      "36.973633 228.21165 368.53418 1.0\n",
      "FOLD 2617\n",
      "train [27.643939971923828, 6.518025875091553]\n",
      "val [28.823219299316406, 6.518055438995361]\n",
      "predict val...\n",
      "predict test...\n",
      "122.71137 244.35645\n",
      "133.66797 244.35645 322.34668 1.0\n",
      "FOLD 2618\n",
      "train [26.146663665771484, 6.446805477142334]\n",
      "val [35.75056076049805, 6.671645164489746]\n",
      "predict val...\n",
      "predict test...\n",
      "153.5665 228.7274\n",
      "101.23389 228.7274 294.96924 1.0\n",
      "FOLD 2619\n",
      "train [28.592512130737305, 6.570565700531006]\n",
      "val [29.941635131835938, 6.513902187347412]\n",
      "predict val...\n",
      "predict test...\n",
      "131.65048 238.91144\n",
      "91.08838 238.91144 303.2622 1.0\n",
      "FOLD 2620\n",
      "train [27.50129508972168, 6.5217084884643555]\n",
      "val [33.98426818847656, 6.735418796539307]\n",
      "predict val...\n",
      "predict test...\n",
      "148.65996 250.42546\n",
      "156.77246 250.42546 315.11084 1.0\n",
      "FOLD 2621\n",
      "train [27.23992347717285, 6.474448204040527]\n",
      "val [31.51642608642578, 6.715764045715332]\n",
      "predict val...\n",
      "predict test...\n",
      "135.57663 225.97063\n",
      "65.1604 225.97063 377.96436 1.0\n",
      "FOLD 2622\n",
      "train [28.268192291259766, 6.535198211669922]\n",
      "val [29.783960342407227, 6.602863311767578]\n",
      "predict val...\n",
      "predict test...\n",
      "126.36795 244.04132\n",
      "167.68872 244.04132 353.01318 1.0\n",
      "FOLD 2623\n",
      "train [25.965818405151367, 6.4382734298706055]\n",
      "val [37.237640380859375, 6.683126926422119]\n",
      "predict val...\n",
      "predict test...\n",
      "159.64601 225.94214\n",
      "111.818115 225.94214 316.42188 1.0\n",
      "FOLD 2624\n",
      "train [27.999080657958984, 6.517394065856934]\n",
      "val [27.704368591308594, 6.447558403015137]\n",
      "predict val...\n",
      "predict test...\n",
      "120.95348 222.93286\n",
      "116.69165 222.93286 300.3872 1.0\n",
      "FOLD 2625\n",
      "train [26.792882919311523, 6.451082706451416]\n",
      "val [34.18328094482422, 6.804949760437012]\n",
      "predict val...\n",
      "predict test...\n",
      "148.13506 218.57695\n",
      "43.711914 218.57695 362.06836 1.0\n",
      "FOLD 2626\n",
      "train [27.182973861694336, 6.470555305480957]\n",
      "val [32.18284606933594, 6.924173355102539]\n",
      "predict val...\n",
      "predict test...\n",
      "137.41663 229.37627\n",
      "33.983887 229.37627 490.61914 1.0\n",
      "FOLD 2627\n",
      "train [27.8706111907959, 6.519082546234131]\n",
      "val [30.629648208618164, 6.611181259155273]\n",
      "predict val...\n",
      "predict test...\n",
      "131.62166 250.12775\n",
      "139.25488 250.12775 327.4829 1.0\n",
      "FOLD 2628\n",
      "train [26.100257873535156, 6.437160491943359]\n",
      "val [37.05908203125, 6.664926528930664]\n",
      "predict val...\n",
      "predict test...\n",
      "160.80042 224.45781\n",
      "102.3927 224.45781 309.95215 1.0\n",
      "FOLD 2629\n",
      "train [28.04409408569336, 6.517897129058838]\n",
      "val [28.764558792114258, 6.482658863067627]\n",
      "predict val...\n",
      "predict test...\n",
      "126.12117 231.62381\n",
      "39.816895 231.62381 310.23438 1.0\n",
      "FOLD 2630\n",
      "train [26.915191650390625, 6.472762107849121]\n",
      "val [33.685306549072266, 6.780424118041992]\n",
      "predict val...\n",
      "predict test...\n",
      "145.94684 224.5836\n",
      "37.520996 224.5836 342.83813 1.0\n",
      "FOLD 2631\n",
      "train [27.648618698120117, 6.517927646636963]\n",
      "val [30.66961669921875, 6.587800979614258]\n",
      "predict val...\n",
      "predict test...\n",
      "132.75111 240.65108\n",
      "99.17212 240.65108 359.00452 1.0\n",
      "FOLD 2632\n",
      "train [28.12577247619629, 6.531609535217285]\n",
      "val [30.83600425720215, 6.595077037811279]\n",
      "predict val...\n",
      "predict test...\n",
      "130.96071 241.48781\n",
      "160.61511 241.48781 337.1128 1.0\n",
      "FOLD 2633\n",
      "train [25.37329864501953, 6.400130271911621]\n",
      "val [37.736209869384766, 6.672993183135986]\n",
      "predict val...\n",
      "predict test...\n",
      "162.46921 220.54593\n",
      "85.21326 220.54593 323.239 1.0\n",
      "FOLD 2634\n",
      "train [28.970203399658203, 6.550082206726074]\n",
      "val [27.927396774291992, 6.472722053527832]\n",
      "predict val...\n",
      "predict test...\n",
      "121.67386 237.12523\n",
      "121.85791 237.12523 358.58765 1.0\n",
      "FOLD 2635\n",
      "train [26.334550857543945, 6.4587578773498535]\n",
      "val [35.86863708496094, 6.847416877746582]\n",
      "predict val...\n",
      "predict test...\n",
      "157.02446 230.05986\n",
      "61.617676 230.05986 338.6787 1.0\n",
      "FOLD 2636\n",
      "train [26.455839157104492, 6.440917015075684]\n",
      "val [32.1642951965332, 6.872589111328125]\n",
      "predict val...\n",
      "predict test...\n",
      "138.13945 225.7364\n",
      "57.976807 225.7364 534.42725 1.0\n",
      "FOLD 2637\n",
      "train [27.768051147460938, 6.517128944396973]\n",
      "val [31.89028549194336, 6.6662726402282715]\n",
      "predict val...\n",
      "predict test...\n",
      "135.20992 240.02657\n",
      "145.54932 240.02657 344.59277 1.0\n",
      "FOLD 2638\n",
      "train [24.677974700927734, 6.360823631286621]\n",
      "val [37.80899429321289, 6.6576619148254395]\n",
      "predict val...\n",
      "predict test...\n",
      "164.55476 215.64017\n",
      "37.007935 215.64017 346.7544 1.0\n",
      "FOLD 2639\n",
      "train [28.735193252563477, 6.533486843109131]\n",
      "val [28.031370162963867, 6.4675140380859375]\n",
      "predict val...\n",
      "predict test...\n",
      "121.83413 235.35258\n",
      "27.902832 235.35258 355.23364 1.0\n",
      "FOLD 2640\n",
      "train [27.208717346191406, 6.470416069030762]\n",
      "val [33.67326736450195, 6.804343223571777]\n",
      "predict val...\n",
      "predict test...\n",
      "145.30464 226.22435\n",
      "-3.2451172 226.22435 385.47827 0.996742671009772\n",
      "FOLD 2641\n",
      "train [27.105072021484375, 6.4688262939453125]\n",
      "val [31.085575103759766, 6.6507110595703125]\n",
      "predict val...\n",
      "predict test...\n",
      "133.94775 231.1604\n",
      "78.6355 231.1604 509.81885 1.0\n",
      "FOLD 2642\n",
      "train [27.53125, 6.501727104187012]\n",
      "val [29.62730598449707, 6.5900678634643555]\n",
      "predict val...\n",
      "predict test...\n",
      "125.50461 239.8577\n",
      "120.890625 239.8577 341.80176 1.0\n",
      "FOLD 2643\n",
      "train [25.569002151489258, 6.396023750305176]\n",
      "val [37.29929733276367, 6.706464767456055]\n",
      "predict val...\n",
      "predict test...\n",
      "160.46234 221.30222\n",
      "51.924072 221.30222 448.33813 1.0\n",
      "FOLD 2644\n",
      "train [27.180055618286133, 6.4842376708984375]\n",
      "val [29.344911575317383, 6.48886775970459]\n",
      "predict val...\n",
      "predict test...\n",
      "126.93811 234.64189\n",
      "11.172363 234.64189 381.0835 1.0\n",
      "FOLD 2645\n",
      "train [26.220722198486328, 6.453713417053223]\n",
      "val [33.494842529296875, 6.786749839782715]\n",
      "predict val...\n",
      "predict test...\n",
      "144.98294 238.63068\n",
      "-51.039062 238.63068 444.10156 0.9804560260586319\n",
      "FOLD 2646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [26.531494140625, 6.44785213470459]\n",
      "val [31.409290313720703, 6.709972381591797]\n",
      "predict val...\n",
      "predict test...\n",
      "132.97783 213.72923\n",
      "44.279297 213.72923 349.40723 1.0\n",
      "FOLD 2647\n",
      "train [27.42707633972168, 6.498363494873047]\n",
      "val [32.14415740966797, 6.695441246032715]\n",
      "predict val...\n",
      "predict test...\n",
      "138.3247 239.6545\n",
      "111.08362 239.6545 334.11133 1.0\n",
      "FOLD 2648\n",
      "train [25.749807357788086, 6.390530109405518]\n",
      "val [35.92491149902344, 6.647496223449707]\n",
      "predict val...\n",
      "predict test...\n",
      "154.52318 208.28761\n",
      "70.791504 208.28761 342.74048 1.0\n",
      "FOLD 2649\n",
      "train [27.218725204467773, 6.477681636810303]\n",
      "val [27.919479370117188, 6.472171306610107]\n",
      "predict val...\n",
      "predict test...\n",
      "123.610306 232.46796\n",
      "38.059814 232.46796 404.8789 1.0\n",
      "FOLD 2650\n",
      "train [25.929567337036133, 6.433154106140137]\n",
      "val [34.751686096191406, 6.859968185424805]\n",
      "predict val...\n",
      "predict test...\n",
      "146.8142 225.33122\n",
      "-221.51953 225.33122 434.1626 0.9641693811074918\n",
      "FOLD 2651\n",
      "train [33.34911346435547, 6.5679216384887695]\n",
      "val [36.822025299072266, 6.7426438331604]\n",
      "predict val...\n",
      "predict test...\n",
      "137.45427 260.96378\n",
      "131.38 260.96378 449.3755 1.0\n",
      "FOLD 2652\n",
      "train [33.41688537597656, 6.551445007324219]\n",
      "val [33.992515563964844, 6.5551652908325195]\n",
      "predict val...\n",
      "predict test...\n",
      "122.21459 243.61966\n",
      "142.43872 243.61966 400.3589 1.0\n",
      "FOLD 2653\n",
      "train [31.823904037475586, 6.4909796714782715]\n",
      "val [41.10469436645508, 6.662871360778809]\n",
      "predict val...\n",
      "predict test...\n",
      "153.44025 228.07156\n",
      "113.74219 228.07156 470.8711 1.0\n",
      "FOLD 2654\n",
      "train [34.89833068847656, 6.629670143127441]\n",
      "val [32.294437408447266, 6.513577461242676]\n",
      "predict val...\n",
      "predict test...\n",
      "120.936226 250.31085\n",
      "98.20538 250.31085 418.44043 1.0\n",
      "FOLD 2655\n",
      "train [32.66950988769531, 6.560849666595459]\n",
      "val [37.0623664855957, 6.679451942443848]\n",
      "predict val...\n",
      "predict test...\n",
      "138.83163 254.69972\n",
      "148.72595 254.69972 385.20605 1.0\n",
      "FOLD 2656\n",
      "train [32.11112976074219, 6.531622886657715]\n",
      "val [36.565574645996094, 6.730930328369141]\n",
      "predict val...\n",
      "predict test...\n",
      "137.03056 256.25296\n",
      "165.40503 256.25296 340.2998 1.0\n",
      "FOLD 2657\n",
      "train [32.45733642578125, 6.533219814300537]\n",
      "val [35.42232131958008, 6.624037742614746]\n",
      "predict val...\n",
      "predict test...\n",
      "130.61229 240.84726\n",
      "157.69373 240.84726 352.87695 1.0\n",
      "FOLD 2658\n",
      "train [30.701648712158203, 6.45947790145874]\n",
      "val [43.93171691894531, 6.763405799865723]\n",
      "predict val...\n",
      "predict test...\n",
      "162.66782 219.91862\n",
      "75.31421 219.91862 277.27832 1.0\n",
      "FOLD 2659\n",
      "train [33.96905517578125, 6.570906639099121]\n",
      "val [31.04346466064453, 6.443168640136719]\n",
      "predict val...\n",
      "predict test...\n",
      "117.892685 222.94954\n",
      "123.07855 222.94954 313.2041 1.0\n",
      "FOLD 2660\n",
      "train [31.520036697387695, 6.517302513122559]\n",
      "val [37.23483657836914, 6.677443504333496]\n",
      "predict val...\n",
      "predict test...\n",
      "140.56064 237.18124\n",
      "153.92883 237.18124 333.3506 1.0\n",
      "FOLD 2661\n",
      "train [32.60090255737305, 6.5469069480896]\n",
      "val [36.48025131225586, 6.724393844604492]\n",
      "predict val...\n",
      "predict test...\n",
      "136.90262 260.02106\n",
      "158.42407 260.02106 358.8081 1.0\n",
      "FOLD 2662\n",
      "train [31.622560501098633, 6.512065887451172]\n",
      "val [34.272884368896484, 6.556756973266602]\n",
      "predict val...\n",
      "predict test...\n",
      "125.36591 246.78868\n",
      "166.01624 246.78868 314.69043 1.0\n",
      "FOLD 2663\n",
      "train [30.521265029907227, 6.468058109283447]\n",
      "val [44.314788818359375, 6.7497100830078125]\n",
      "predict val...\n",
      "predict test...\n",
      "164.84178 231.9944\n",
      "112.061035 231.9944 299.99365 1.0\n",
      "FOLD 2664\n",
      "train [33.41151428222656, 6.564266204833984]\n",
      "val [32.93873977661133, 6.481479644775391]\n",
      "predict val...\n",
      "predict test...\n",
      "124.26078 244.65994\n",
      "141.83813 244.65994 323.58447 1.0\n",
      "FOLD 2665\n",
      "train [31.454957962036133, 6.509016513824463]\n",
      "val [38.17918395996094, 6.698747634887695]\n",
      "predict val...\n",
      "predict test...\n",
      "143.64496 236.29729\n",
      "139.39844 236.29729 323.79858 1.0\n",
      "FOLD 2666\n",
      "train [32.34079360961914, 6.525012016296387]\n",
      "val [36.6062126159668, 6.751299858093262]\n",
      "predict val...\n",
      "predict test...\n",
      "135.95735 240.14648\n",
      "112.31885 240.14648 332.70068 1.0\n",
      "FOLD 2667\n",
      "train [32.69636917114258, 6.541479587554932]\n",
      "val [35.82963180541992, 6.716763496398926]\n",
      "predict val...\n",
      "predict test...\n",
      "133.59929 253.3575\n",
      "182.38513 253.3575 369.86572 1.0\n",
      "FOLD 2668\n",
      "train [31.36821746826172, 6.501856803894043]\n",
      "val [42.310855865478516, 6.684515953063965]\n",
      "predict val...\n",
      "predict test...\n",
      "157.6955 244.86937\n",
      "163.26758 244.86937 337.81055 1.0\n",
      "FOLD 2669\n",
      "train [33.06951904296875, 6.554585933685303]\n",
      "val [32.6666374206543, 6.475728988647461]\n",
      "predict val...\n",
      "predict test...\n",
      "123.0754 241.31483\n",
      "134.8916 241.31483 315.9353 1.0\n",
      "FOLD 2670\n",
      "train [31.758350372314453, 6.512877464294434]\n",
      "val [39.144710540771484, 6.752457141876221]\n",
      "predict val...\n",
      "predict test...\n",
      "147.07999 240.79454\n",
      "94.76904 240.79454 328.3391 1.0\n",
      "FOLD 2671\n",
      "train [31.608036041259766, 6.515638828277588]\n",
      "val [36.798057556152344, 6.707220077514648]\n",
      "predict val...\n",
      "predict test...\n",
      "137.72595 252.69687\n",
      "161.78589 252.69687 334.1621 1.0\n",
      "FOLD 2672\n",
      "train [30.881498336791992, 6.479162693023682]\n",
      "val [35.61503219604492, 6.7224016189575195]\n",
      "predict val...\n",
      "predict test...\n",
      "131.44894 235.75606\n",
      "129.91895 235.75606 304.2688 1.0\n",
      "FOLD 2673\n",
      "train [29.847103118896484, 6.445047855377197]\n",
      "val [45.03095626831055, 6.721687316894531]\n",
      "predict val...\n",
      "predict test...\n",
      "166.95453 229.39352\n",
      "132.74817 229.39352 319.02563 1.0\n",
      "FOLD 2674\n",
      "train [30.963115692138672, 6.471712589263916]\n",
      "val [32.687744140625, 6.492029190063477]\n",
      "predict val...\n",
      "predict test...\n",
      "123.27529 221.89287\n",
      "25.044922 221.89287 309.50708 1.0\n",
      "FOLD 2675\n",
      "train [31.341840744018555, 6.473852634429932]\n",
      "val [39.26697540283203, 6.786876678466797]\n",
      "predict val...\n",
      "predict test...\n",
      "146.31065 222.37396\n",
      "-0.27392578 222.37396 384.60547 0.996742671009772\n",
      "FOLD 2676\n",
      "train [32.155494689941406, 6.523871421813965]\n",
      "val [37.0384407043457, 6.888131618499756]\n",
      "predict val...\n",
      "predict test...\n",
      "136.34256 244.21529\n",
      "7.520752 244.21529 393.40918 1.0\n",
      "FOLD 2677\n",
      "train [29.82402801513672, 6.4343695640563965]\n",
      "val [38.393253326416016, 6.858138561248779]\n",
      "predict val...\n",
      "predict test...\n",
      "141.89055 222.33655\n",
      "112.843506 222.33655 309.84424 1.0\n",
      "FOLD 2678\n",
      "train [31.27743911743164, 6.483881950378418]\n",
      "val [42.912437438964844, 6.674832820892334]\n",
      "predict val...\n",
      "predict test...\n",
      "159.70953 232.24725\n",
      "139.80518 232.24725 300.01758 1.0\n",
      "FOLD 2679\n",
      "train [33.13352966308594, 6.541712284088135]\n",
      "val [32.65132522583008, 6.495109558105469]\n",
      "predict val...\n",
      "predict test...\n",
      "124.143654 232.80634\n",
      "136.35938 232.80634 316.52954 1.0\n",
      "FOLD 2680\n",
      "train [31.0047550201416, 6.481542110443115]\n",
      "val [38.84212112426758, 6.718415260314941]\n",
      "predict val...\n",
      "predict test...\n",
      "147.05652 238.06154\n",
      "111.66821 238.06154 320.1726 1.0\n",
      "FOLD 2681\n",
      "train [30.31780242919922, 6.446839809417725]\n",
      "val [38.93973922729492, 7.182809829711914]\n",
      "predict val...\n",
      "predict test...\n",
      "142.25626 212.88899\n",
      "19.216553 212.88899 363.94434 1.0\n",
      "FOLD 2682\n",
      "train [32.142616271972656, 6.516417026519775]\n",
      "val [35.297000885009766, 6.5712385177612305]\n",
      "predict val...\n",
      "predict test...\n",
      "129.24672 245.0963\n",
      "135.57642 245.0963 356.40625 1.0\n",
      "FOLD 2683\n",
      "train [28.9085750579834, 6.399794578552246]\n",
      "val [45.67095947265625, 6.733707904815674]\n",
      "predict val...\n",
      "predict test...\n",
      "168.13354 215.4373\n",
      "108.51318 215.4373 307.81372 1.0\n",
      "FOLD 2684\n",
      "train [31.236499786376953, 6.47701358795166]\n",
      "val [32.58831787109375, 6.54600715637207]\n",
      "predict val...\n",
      "predict test...\n",
      "124.44989 235.45454\n",
      "20.304932 235.45454 330.49805 1.0\n",
      "FOLD 2685\n",
      "train [32.149383544921875, 6.5119194984436035]\n",
      "val [38.9813232421875, 6.709442138671875]\n",
      "predict val...\n",
      "predict test...\n",
      "147.36465 230.29752\n",
      "141.62402 230.29752 319.6831 1.0\n",
      "FOLD 2686\n",
      "train [30.82169532775879, 6.458982944488525]\n",
      "val [35.269161224365234, 6.535159111022949]\n",
      "predict val...\n",
      "predict test...\n",
      "131.33734 229.30904\n",
      "59.03833 229.30904 493.58643 1.0\n",
      "FOLD 2687\n",
      "train [32.28108596801758, 6.530146598815918]\n",
      "val [36.49440002441406, 6.6653289794921875]\n",
      "predict val...\n",
      "predict test...\n",
      "133.81093 247.9357\n",
      "156.16675 247.9357 344.89014 1.0\n",
      "FOLD 2688\n",
      "train [29.683530807495117, 6.405403137207031]\n",
      "val [42.95243453979492, 6.665533065795898]\n",
      "predict val...\n",
      "predict test...\n",
      "158.08305 212.55592\n",
      "68.2749 212.55592 344.0337 1.0\n",
      "FOLD 2689\n",
      "train [31.197011947631836, 6.482546806335449]\n",
      "val [30.95240020751953, 6.446977615356445]\n",
      "predict val...\n",
      "predict test...\n",
      "117.177895 234.23396\n",
      "6.0771484 234.23396 341.34277 1.0\n",
      "FOLD 2690\n",
      "train [30.900575637817383, 6.474789619445801]\n",
      "val [37.835411071777344, 6.687151908874512]\n",
      "predict val...\n",
      "predict test...\n",
      "141.07349 232.79768\n",
      "89.593994 232.79768 317.7561 1.0\n",
      "FOLD 2691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [29.1010799407959, 6.397587776184082]\n",
      "val [34.62441635131836, 6.6341471672058105]\n",
      "predict val...\n",
      "predict test...\n",
      "129.07617 214.2526\n",
      "19.970703 214.2526 415.7212 1.0\n",
      "FOLD 2692\n",
      "train [29.987628936767578, 6.421269416809082]\n",
      "val [35.33584213256836, 6.643789291381836]\n",
      "predict val...\n",
      "predict test...\n",
      "132.08438 229.50102\n",
      "76.03638 229.50102 322.1665 1.0\n",
      "FOLD 2693\n",
      "train [29.732908248901367, 6.414823055267334]\n",
      "val [44.21738052368164, 6.72799015045166]\n",
      "predict val...\n",
      "predict test...\n",
      "164.46393 227.4543\n",
      "74.910645 227.4543 438.80298 1.0\n",
      "FOLD 2694\n",
      "train [31.552366256713867, 6.484236717224121]\n",
      "val [32.334739685058594, 6.465845108032227]\n",
      "predict val...\n",
      "predict test...\n",
      "121.32186 235.28087\n",
      "14.944824 235.28087 376.16943 1.0\n",
      "FOLD 2695\n",
      "train [30.21602439880371, 6.455292701721191]\n",
      "val [36.84951400756836, 6.684595108032227]\n",
      "predict val...\n",
      "predict test...\n",
      "137.42844 226.91449\n",
      "-84.595215 226.91449 368.3286 0.9674267100977199\n",
      "FOLD 2696\n",
      "train [32.05356979370117, 6.499230861663818]\n",
      "val [37.92335891723633, 6.981141090393066]\n",
      "predict val...\n",
      "predict test...\n",
      "140.60278 234.33362\n",
      "30.29834 234.33362 537.9092 1.0\n",
      "FOLD 2697\n",
      "train [30.44770050048828, 6.443052768707275]\n",
      "val [35.79240417480469, 6.669157028198242]\n",
      "predict val...\n",
      "predict test...\n",
      "132.8613 227.63507\n",
      "99.58447 227.63507 313.06958 1.0\n",
      "FOLD 2698\n",
      "train [29.533451080322266, 6.413186550140381]\n",
      "val [43.68741226196289, 6.64982271194458]\n",
      "predict val...\n",
      "predict test...\n",
      "164.02838 228.58286\n",
      "65.92859 228.58286 366.29224 1.0\n",
      "FOLD 2699\n",
      "train [32.456783294677734, 6.533898830413818]\n",
      "val [31.068679809570312, 6.461474418640137]\n",
      "predict val...\n",
      "predict test...\n",
      "116.95414 241.04509\n",
      "64.19995 241.04509 394.89453 1.0\n",
      "FOLD 2700\n",
      "train [31.28536605834961, 6.476590633392334]\n",
      "val [38.383060455322266, 6.760087490081787]\n",
      "predict val...\n",
      "predict test...\n",
      "143.87427 245.75267\n",
      "109.92993 245.75267 535.103 1.0\n",
      "FOLD 2701\n",
      "train [37.84259796142578, 6.558160305023193]\n",
      "val [42.54247283935547, 6.789257526397705]\n",
      "predict val...\n",
      "predict test...\n",
      "139.41452 251.96216\n",
      "134.69861 251.96216 418.62744 1.0\n",
      "FOLD 2702\n",
      "train [37.986698150634766, 6.557945251464844]\n",
      "val [37.951515197753906, 6.549411773681641]\n",
      "predict val...\n",
      "predict test...\n",
      "119.50364 246.3984\n",
      "140.64124 246.3984 420.77148 1.0\n",
      "FOLD 2703\n",
      "train [36.259971618652344, 6.500128746032715]\n",
      "val [48.339881896972656, 6.685811519622803]\n",
      "predict val...\n",
      "predict test...\n",
      "159.09349 232.01608\n",
      "111.82788 232.01608 508.27637 1.0\n",
      "FOLD 2704\n",
      "train [39.382450103759766, 6.617759704589844]\n",
      "val [36.2112922668457, 6.511451721191406]\n",
      "predict val...\n",
      "predict test...\n",
      "121.86057 238.5229\n",
      "96.95264 238.5229 394.80225 1.0\n",
      "FOLD 2705\n",
      "train [37.4501838684082, 6.559210777282715]\n",
      "val [42.26524353027344, 6.660045623779297]\n",
      "predict val...\n",
      "predict test...\n",
      "140.04753 247.70312\n",
      "145.82678 247.70312 369.01172 1.0\n",
      "FOLD 2706\n",
      "train [36.60269546508789, 6.535706996917725]\n",
      "val [42.10361099243164, 6.76569938659668]\n",
      "predict val...\n",
      "predict test...\n",
      "139.15045 257.62347\n",
      "147.88293 257.62347 383.14404 1.0\n",
      "FOLD 2707\n",
      "train [38.63893127441406, 6.576611518859863]\n",
      "val [41.369773864746094, 6.644458770751953]\n",
      "predict val...\n",
      "predict test...\n",
      "132.67836 252.0287\n",
      "166.77234 252.0287 369.59033 1.0\n",
      "FOLD 2708\n",
      "train [35.23908233642578, 6.478135585784912]\n",
      "val [47.79202651977539, 6.660897731781006]\n",
      "predict val...\n",
      "predict test...\n",
      "156.2111 227.5227\n",
      "154.79333 227.5227 307.98584 1.0\n",
      "FOLD 2709\n",
      "train [37.826141357421875, 6.560925483703613]\n",
      "val [35.32284927368164, 6.435586929321289]\n",
      "predict val...\n",
      "predict test...\n",
      "118.47515 230.1772\n",
      "130.51581 230.1772 308.16504 1.0\n",
      "FOLD 2710\n",
      "train [36.78478240966797, 6.52286434173584]\n",
      "val [43.855709075927734, 6.693284034729004]\n",
      "predict val...\n",
      "predict test...\n",
      "144.31242 224.57915\n",
      "155.48193 224.57915 309.68433 1.0\n",
      "FOLD 2711\n",
      "train [36.69890213012695, 6.541767120361328]\n",
      "val [41.63017272949219, 6.694533348083496]\n",
      "predict val...\n",
      "predict test...\n",
      "136.74562 254.97244\n",
      "168.58838 254.97244 335.66406 1.0\n",
      "FOLD 2712\n",
      "train [37.007606506347656, 6.5408935546875]\n",
      "val [39.94148635864258, 6.636445045471191]\n",
      "predict val...\n",
      "predict test...\n",
      "128.61472 247.96117\n",
      "162.01953 247.96117 389.0298 1.0\n",
      "FOLD 2713\n",
      "train [34.71607971191406, 6.4611945152282715]\n",
      "val [47.643821716308594, 6.666344165802002]\n",
      "predict val...\n",
      "predict test...\n",
      "154.53328 224.36261\n",
      "131.35034 224.36261 292.34082 1.0\n",
      "FOLD 2714\n",
      "train [39.4039421081543, 6.622868537902832]\n",
      "val [38.797645568847656, 6.558985710144043]\n",
      "predict val...\n",
      "predict test...\n",
      "131.90645 262.78424\n",
      "151.46619 262.78424 383.61353 1.0\n",
      "FOLD 2715\n",
      "train [35.805397033691406, 6.514981269836426]\n",
      "val [45.244075775146484, 6.71558952331543]\n",
      "predict val...\n",
      "predict test...\n",
      "149.24901 235.35754\n",
      "163.30457 235.35754 324.67407 1.0\n",
      "FOLD 2716\n",
      "train [34.543601989746094, 6.479927062988281]\n",
      "val [43.40596389770508, 6.804286956787109]\n",
      "predict val...\n",
      "predict test...\n",
      "142.8491 238.27995\n",
      "161.59302 238.27995 303.29614 1.0\n",
      "FOLD 2717\n",
      "train [35.392845153808594, 6.499425411224365]\n",
      "val [39.983734130859375, 6.668190002441406]\n",
      "predict val...\n",
      "predict test...\n",
      "131.91272 241.5197\n",
      "148.36133 241.5197 315.0005 1.0\n",
      "FOLD 2718\n",
      "train [33.4497184753418, 6.4244513511657715]\n",
      "val [48.51689910888672, 6.687745094299316]\n",
      "predict val...\n",
      "predict test...\n",
      "156.95981 221.55438\n",
      "124.43945 221.55438 289.94775 1.0\n",
      "FOLD 2719\n",
      "train [38.29233169555664, 6.5859270095825195]\n",
      "val [38.17350387573242, 6.510319709777832]\n",
      "predict val...\n",
      "predict test...\n",
      "128.67278 235.69681\n",
      "125.62103 235.69681 332.8623 1.0\n",
      "FOLD 2720\n",
      "train [35.81365203857422, 6.517722129821777]\n",
      "val [45.314273834228516, 6.716817855834961]\n",
      "predict val...\n",
      "predict test...\n",
      "151.24678 246.21426\n",
      "81.43384 246.21426 329.271 1.0\n",
      "FOLD 2721\n",
      "train [34.23846435546875, 6.457005500793457]\n",
      "val [40.62919998168945, 6.566756248474121]\n",
      "predict val...\n",
      "predict test...\n",
      "131.46799 219.06737\n",
      "71.35889 219.06737 316.80322 1.0\n",
      "FOLD 2722\n",
      "train [36.077213287353516, 6.512284755706787]\n",
      "val [40.660369873046875, 6.692615509033203]\n",
      "predict val...\n",
      "predict test...\n",
      "131.81474 245.15935\n",
      "155.67969 245.15935 351.0376 1.0\n",
      "FOLD 2723\n",
      "train [32.52671432495117, 6.406221866607666]\n",
      "val [50.99843215942383, 6.724207878112793]\n",
      "predict val...\n",
      "predict test...\n",
      "165.85095 224.91121\n",
      "109.208984 224.91121 312.32275 1.0\n",
      "FOLD 2724\n",
      "train [37.9527702331543, 6.5442633628845215]\n",
      "val [36.36921310424805, 6.479698181152344]\n",
      "predict val...\n",
      "predict test...\n",
      "122.78769 232.47949\n",
      "127.82239 232.47949 318.90186 1.0\n",
      "FOLD 2725\n",
      "train [34.391624450683594, 6.449108123779297]\n",
      "val [49.350807189941406, 6.819103240966797]\n",
      "predict val...\n",
      "predict test...\n",
      "162.41708 234.63808\n",
      "125.56372 234.63808 386.1504 1.0\n",
      "FOLD 2726\n",
      "train [36.469871520996094, 6.530091285705566]\n",
      "val [40.937557220458984, 6.651177883148193]\n",
      "predict val...\n",
      "predict test...\n",
      "134.87166 245.00748\n",
      "126.475586 245.00748 340.2744 1.0\n",
      "FOLD 2727\n",
      "train [36.85856246948242, 6.535184383392334]\n",
      "val [40.127750396728516, 6.578042507171631]\n",
      "predict val...\n",
      "predict test...\n",
      "128.75276 242.29219\n",
      "166.74902 242.29219 353.04248 1.0\n",
      "FOLD 2728\n",
      "train [32.30513000488281, 6.38037109375]\n",
      "val [50.39834213256836, 6.690432548522949]\n",
      "predict val...\n",
      "predict test...\n",
      "162.95415 210.96991\n",
      "98.34546 210.96991 293.24927 1.0\n",
      "FOLD 2729\n",
      "train [37.78178024291992, 6.553142547607422]\n",
      "val [35.64508056640625, 6.4885149002075195]\n",
      "predict val...\n",
      "predict test...\n",
      "119.30602 244.02214\n",
      "141.05493 244.02214 359.52173 1.0\n",
      "FOLD 2730\n",
      "train [34.6380729675293, 6.460862159729004]\n",
      "val [44.91036605834961, 6.791444778442383]\n",
      "predict val...\n",
      "predict test...\n",
      "146.93544 225.426\n",
      "37.446533 225.426 330.34985 1.0\n",
      "FOLD 2731\n",
      "train [35.694068908691406, 6.501716613769531]\n",
      "val [40.98867416381836, 6.72019624710083]\n",
      "predict val...\n",
      "predict test...\n",
      "134.45715 236.78864\n",
      "25.07959 236.78864 397.57227 1.0\n",
      "FOLD 2732\n",
      "train [34.660987854003906, 6.45766544342041]\n",
      "val [40.12495040893555, 6.637126922607422]\n",
      "predict val...\n",
      "predict test...\n",
      "131.08105 230.5231\n",
      "137.99048 230.5231 296.9729 1.0\n",
      "FOLD 2733\n",
      "train [34.27820587158203, 6.439705848693848]\n",
      "val [50.1977424621582, 6.709875583648682]\n",
      "predict val...\n",
      "predict test...\n",
      "163.30872 222.35458\n",
      "112.32837 222.35458 327.87866 1.0\n",
      "FOLD 2734\n",
      "train [36.73488235473633, 6.520230293273926]\n",
      "val [36.66511154174805, 6.5603790283203125]\n",
      "predict val...\n",
      "predict test...\n",
      "124.152306 248.39162\n",
      "84.01221 248.39162 459.46533 1.0\n",
      "FOLD 2735\n",
      "train [35.74336242675781, 6.495304107666016]\n",
      "val [46.389408111572266, 6.781458377838135]\n",
      "predict val...\n",
      "predict test...\n",
      "153.22598 234.18898\n",
      "91.41235 234.18898 351.59277 1.0\n",
      "FOLD 2736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [35.261329650878906, 6.481501579284668]\n",
      "val [40.321285247802734, 6.514071464538574]\n",
      "predict val...\n",
      "predict test...\n",
      "132.50824 234.11708\n",
      "-3.6625977 234.11708 487.36914 0.996742671009772\n",
      "FOLD 2737\n",
      "train [36.23959732055664, 6.512594699859619]\n",
      "val [43.30131530761719, 6.718597412109375]\n",
      "predict val...\n",
      "predict test...\n",
      "140.59256 244.9426\n",
      "129.56494 244.9426 350.84766 1.0\n",
      "FOLD 2738\n",
      "train [34.49280548095703, 6.433831691741943]\n",
      "val [49.61153030395508, 6.69619083404541]\n",
      "predict val...\n",
      "predict test...\n",
      "162.45222 226.4728\n",
      "81.282715 226.4728 395.9309 1.0\n",
      "FOLD 2739\n",
      "train [36.73527526855469, 6.5260009765625]\n",
      "val [37.216094970703125, 6.494070053100586]\n",
      "predict val...\n",
      "predict test...\n",
      "124.95188 239.86151\n",
      "30.22705 239.86151 361.66748 1.0\n",
      "FOLD 2740\n",
      "train [34.66998291015625, 6.464182376861572]\n",
      "val [45.59941482543945, 6.752883434295654]\n",
      "predict val...\n",
      "predict test...\n",
      "150.59448 230.55843\n",
      "82.27881 230.55843 354.5039 1.0\n",
      "FOLD 2741\n",
      "train [35.99394226074219, 6.489270210266113]\n",
      "val [43.40006637573242, 6.934205532073975]\n",
      "predict val...\n",
      "predict test...\n",
      "142.33575 228.79166\n",
      "-0.7001953 228.79166 437.95898 0.996742671009772\n",
      "FOLD 2742\n",
      "train [35.45816421508789, 6.479887962341309]\n",
      "val [48.80149841308594, 7.030778884887695]\n",
      "predict val...\n",
      "predict test...\n",
      "157.18105 246.97185\n",
      "111.22974 246.97185 413.73975 1.0\n",
      "FOLD 2743\n",
      "train [32.62653350830078, 6.390697479248047]\n",
      "val [49.50625991821289, 6.701700687408447]\n",
      "predict val...\n",
      "predict test...\n",
      "160.21785 215.39322\n",
      "61.868774 215.39322 366.33545 1.0\n",
      "FOLD 2744\n",
      "train [37.19697189331055, 6.53125524520874]\n",
      "val [36.68947219848633, 6.476107597351074]\n",
      "predict val...\n",
      "predict test...\n",
      "122.44933 234.95447\n",
      "95.99646 234.95447 362.50928 1.0\n",
      "FOLD 2745\n",
      "train [32.72467803955078, 6.412860870361328]\n",
      "val [46.90119171142578, 6.773124694824219]\n",
      "predict val...\n",
      "predict test...\n",
      "153.56146 222.36238\n",
      "55.018555 222.36238 332.13428 1.0\n",
      "FOLD 2746\n",
      "train [36.14413833618164, 6.5019073486328125]\n",
      "val [41.68799591064453, 6.821348190307617]\n",
      "predict val...\n",
      "predict test...\n",
      "135.78325 234.11162\n",
      "38.54248 234.11162 433.7256 1.0\n",
      "FOLD 2747\n",
      "train [36.61286544799805, 6.523320198059082]\n",
      "val [39.88502502441406, 6.570224761962891]\n",
      "predict val...\n",
      "predict test...\n",
      "129.07266 244.35704\n",
      "139.51831 244.35704 361.90332 1.0\n",
      "FOLD 2748\n",
      "train [34.517005920410156, 6.432966709136963]\n",
      "val [47.63138961791992, 6.638357162475586]\n",
      "predict val...\n",
      "predict test...\n",
      "157.05971 230.72812\n",
      "62.010376 230.72812 419.12402 1.0\n",
      "FOLD 2749\n",
      "train [35.79190444946289, 6.494808197021484]\n",
      "val [36.846195220947266, 6.4770612716674805]\n",
      "predict val...\n",
      "predict test...\n",
      "123.19165 231.45338\n",
      "-13.29248 231.45338 354.85938 0.996742671009772\n",
      "FOLD 2750\n",
      "train [34.46221160888672, 6.456373691558838]\n",
      "val [43.19325256347656, 6.688943386077881]\n",
      "predict val...\n",
      "predict test...\n",
      "142.65263 241.09624\n",
      "131.62 241.09624 543.71045 1.0\n",
      "FOLD 2751\n",
      "train [41.57330322265625, 6.5417280197143555]\n",
      "val [46.106468200683594, 6.72506046295166]\n",
      "predict val...\n",
      "predict test...\n",
      "135.77371 246.4971\n",
      "127.340454 246.4971 411.5669 1.0\n",
      "FOLD 2752\n",
      "train [42.374969482421875, 6.555279731750488]\n",
      "val [43.548221588134766, 6.580474853515625]\n",
      "predict val...\n",
      "predict test...\n",
      "123.29398 248.78308\n",
      "132.48145 248.78308 425.2544 1.0\n",
      "FOLD 2753\n",
      "train [39.90861511230469, 6.4925537109375]\n",
      "val [53.712406158447266, 6.667180061340332]\n",
      "predict val...\n",
      "predict test...\n",
      "157.95776 234.10564\n",
      "128.91199 234.10564 427.50586 1.0\n",
      "FOLD 2754\n",
      "train [43.95018005371094, 6.6271071434021]\n",
      "val [39.548946380615234, 6.507744789123535]\n",
      "predict val...\n",
      "predict test...\n",
      "118.858665 251.79184\n",
      "107.90155 251.79184 399.6953 1.0\n",
      "FOLD 2755\n",
      "train [41.53767395019531, 6.548151969909668]\n",
      "val [48.03736114501953, 6.670317649841309]\n",
      "predict val...\n",
      "predict test...\n",
      "141.02982 242.19534\n",
      "134.5315 242.19534 386.97705 1.0\n",
      "FOLD 2756\n",
      "train [42.07619094848633, 6.559163570404053]\n",
      "val [47.29692459106445, 6.786192417144775]\n",
      "predict val...\n",
      "predict test...\n",
      "139.0668 257.07486\n",
      "154.76831 257.07486 379.52686 1.0\n",
      "FOLD 2757\n",
      "train [40.42578887939453, 6.523948669433594]\n",
      "val [45.98636245727539, 6.631987571716309]\n",
      "predict val...\n",
      "predict test...\n",
      "132.76363 242.59105\n",
      "164.33972 242.59105 345.56055 1.0\n",
      "FOLD 2758\n",
      "train [39.073509216308594, 6.482601165771484]\n",
      "val [52.840274810791016, 6.708575248718262]\n",
      "predict val...\n",
      "predict test...\n",
      "155.06503 237.43236\n",
      "135.63477 237.43236 373.25244 1.0\n",
      "FOLD 2759\n",
      "train [42.31744384765625, 6.559719085693359]\n",
      "val [41.56987762451172, 6.478550434112549]\n",
      "predict val...\n",
      "predict test...\n",
      "125.082146 232.7558\n",
      "128.04388 232.7558 312.03394 1.0\n",
      "FOLD 2760\n",
      "train [41.75690460205078, 6.529946804046631]\n",
      "val [46.69353103637695, 6.679465293884277]\n",
      "predict val...\n",
      "predict test...\n",
      "138.03331 219.52962\n",
      "145.61157 219.52962 307.9585 1.0\n",
      "FOLD 2761\n",
      "train [40.20053482055664, 6.516211032867432]\n",
      "val [46.93595886230469, 6.664030075073242]\n",
      "predict val...\n",
      "predict test...\n",
      "138.04668 244.56662\n",
      "158.79736 244.56662 315.36523 1.0\n",
      "FOLD 2762\n",
      "train [41.38102722167969, 6.5497331619262695]\n",
      "val [45.252620697021484, 6.640613555908203]\n",
      "predict val...\n",
      "predict test...\n",
      "130.69957 252.58723\n",
      "173.03918 252.58723 364.7744 1.0\n",
      "FOLD 2763\n",
      "train [38.37610626220703, 6.452182769775391]\n",
      "val [54.006866455078125, 6.680375576019287]\n",
      "predict val...\n",
      "predict test...\n",
      "157.67819 225.01543\n",
      "131.49683 225.01543 307.4712 1.0\n",
      "FOLD 2764\n",
      "train [42.227298736572266, 6.555804252624512]\n",
      "val [43.18254852294922, 6.469294548034668]\n",
      "predict val...\n",
      "predict test...\n",
      "128.7092 229.05522\n",
      "128.90295 229.05522 307.11914 1.0\n",
      "FOLD 2765\n",
      "train [39.80714797973633, 6.494884490966797]\n",
      "val [48.990909576416016, 6.727899551391602]\n",
      "predict val...\n",
      "predict test...\n",
      "144.34447 226.96852\n",
      "85.41699 226.96852 292.9873 1.0\n",
      "FOLD 2766\n",
      "train [41.34364318847656, 6.536268711090088]\n",
      "val [47.0166130065918, 6.759561061859131]\n",
      "predict val...\n",
      "predict test...\n",
      "137.46077 243.30457\n",
      "124.48584 243.30457 331.2046 1.0\n",
      "FOLD 2767\n",
      "train [39.98135757446289, 6.519874572753906]\n",
      "val [43.3243293762207, 6.56572151184082]\n",
      "predict val...\n",
      "predict test...\n",
      "126.16906 245.55301\n",
      "145.9436 245.55301 317.99902 1.0\n",
      "FOLD 2768\n",
      "train [37.852989196777344, 6.426198482513428]\n",
      "val [53.379058837890625, 6.656088829040527]\n",
      "predict val...\n",
      "predict test...\n",
      "153.03365 220.08621\n",
      "141.36194 220.08621 295.7605 1.0\n",
      "FOLD 2769\n",
      "train [42.687923431396484, 6.578670501708984]\n",
      "val [40.49404525756836, 6.499490737915039]\n",
      "predict val...\n",
      "predict test...\n",
      "121.19093 248.05365\n",
      "148.90771 248.05365 344.85278 1.0\n",
      "FOLD 2770\n",
      "train [39.28330993652344, 6.4995574951171875]\n",
      "val [49.60038375854492, 6.706981658935547]\n",
      "predict val...\n",
      "predict test...\n",
      "145.40987 243.22417\n",
      "106.81763 243.22417 337.4912 1.0\n",
      "FOLD 2771\n",
      "train [40.79240798950195, 6.5173492431640625]\n",
      "val [48.089054107666016, 6.802696228027344]\n",
      "predict val...\n",
      "predict test...\n",
      "140.58878 241.54207\n",
      "93.81885 241.54207 337.00586 1.0\n",
      "FOLD 2772\n",
      "train [39.6903190612793, 6.496476173400879]\n",
      "val [44.65338897705078, 6.617037773132324]\n",
      "predict val...\n",
      "predict test...\n",
      "129.56473 252.55756\n",
      "145.03394 252.55756 380.45264 1.0\n",
      "FOLD 2773\n",
      "train [37.45256042480469, 6.42983865737915]\n",
      "val [54.59989547729492, 6.743332862854004]\n",
      "predict val...\n",
      "predict test...\n",
      "157.68983 218.08014\n",
      "91.45801 218.08014 283.58887 1.0\n",
      "FOLD 2774\n",
      "train [42.89176559448242, 6.553704261779785]\n",
      "val [40.29631042480469, 6.4857563972473145]\n",
      "predict val...\n",
      "predict test...\n",
      "121.80957 229.95415\n",
      "143.27771 229.95415 304.2107 1.0\n",
      "FOLD 2775\n",
      "train [39.63743209838867, 6.491020202636719]\n",
      "val [50.61526107788086, 6.731992244720459]\n",
      "predict val...\n",
      "predict test...\n",
      "148.80904 226.99277\n",
      "141.71704 226.99277 289.61426 1.0\n",
      "FOLD 2776\n",
      "train [39.860023498535156, 6.497755527496338]\n",
      "val [45.60846710205078, 6.722372055053711]\n",
      "predict val...\n",
      "predict test...\n",
      "134.43304 239.87874\n",
      "111.125244 239.87874 350.7959 1.0\n",
      "FOLD 2777\n",
      "train [38.51308822631836, 6.460541725158691]\n",
      "val [49.40099334716797, 6.972662925720215]\n",
      "predict val...\n",
      "predict test...\n",
      "142.17453 228.36258\n",
      "114.25 228.36258 288.26538 1.0\n",
      "FOLD 2778\n",
      "train [37.94331741333008, 6.439146518707275]\n",
      "val [57.70893478393555, 6.70806360244751]\n",
      "predict val...\n",
      "predict test...\n",
      "167.01045 229.6546\n",
      "107.18567 229.6546 330.77002 1.0\n",
      "FOLD 2779\n",
      "train [41.9993782043457, 6.558016777038574]\n",
      "val [41.47091293334961, 6.511801719665527]\n",
      "predict val...\n",
      "predict test...\n",
      "125.00659 242.84299\n",
      "160.72998 242.84299 318.41797 1.0\n",
      "FOLD 2780\n",
      "train [39.79335403442383, 6.496694087982178]\n",
      "val [50.27011489868164, 6.723045349121094]\n",
      "predict val...\n",
      "predict test...\n",
      "148.53636 229.50832\n",
      "125.69873 229.50832 299.0603 1.0\n",
      "FOLD 2781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [40.4967041015625, 6.508606910705566]\n",
      "val [47.45072937011719, 6.907375335693359]\n",
      "predict val...\n",
      "predict test...\n",
      "136.99387 238.55382\n",
      "23.470703 238.55382 449.69873 1.0\n",
      "FOLD 2782\n",
      "train [38.94483184814453, 6.474557399749756]\n",
      "val [55.25033187866211, 7.593179702758789]\n",
      "predict val...\n",
      "predict test...\n",
      "156.45819 237.23758\n",
      "103.97412 237.23758 352.53857 1.0\n",
      "FOLD 2783\n",
      "train [34.74364471435547, 6.337918758392334]\n",
      "val [55.67123794555664, 6.683741569519043]\n",
      "predict val...\n",
      "predict test...\n",
      "159.03397 198.4596\n",
      "51.16211 198.4596 302.6936 1.0\n",
      "FOLD 2784\n",
      "train [40.71084976196289, 6.5201520919799805]\n",
      "val [41.24143981933594, 6.47824239730835]\n",
      "predict val...\n",
      "predict test...\n",
      "122.51153 235.68195\n",
      "74.91162 235.68195 320.96704 1.0\n",
      "FOLD 2785\n",
      "train [38.527809143066406, 6.470895290374756]\n",
      "val [47.66590881347656, 6.716320037841797]\n",
      "predict val...\n",
      "predict test...\n",
      "141.75378 234.3038\n",
      "42.531982 234.3038 363.95728 1.0\n",
      "FOLD 2786\n",
      "train [36.722808837890625, 6.405248165130615]\n",
      "val [45.74485778808594, 6.9628095626831055]\n",
      "predict val...\n",
      "predict test...\n",
      "133.94606 216.50076\n",
      "7.1853027 216.50076 443.2046 1.0\n",
      "FOLD 2787\n",
      "train [36.931549072265625, 6.418680667877197]\n",
      "val [48.80638122558594, 7.024366855621338]\n",
      "predict val...\n",
      "predict test...\n",
      "141.65582 222.13762\n",
      "115.21484 222.13762 276.1255 1.0\n",
      "FOLD 2788\n",
      "train [37.912845611572266, 6.422881126403809]\n",
      "val [54.54294967651367, 6.643441200256348]\n",
      "predict val...\n",
      "predict test...\n",
      "159.84367 224.37108\n",
      "67.98425 224.37108 388.41602 1.0\n",
      "FOLD 2789\n",
      "train [41.158180236816406, 6.517460823059082]\n",
      "val [40.636192321777344, 6.440119743347168]\n",
      "predict val...\n",
      "predict test...\n",
      "122.53714 228.76125\n",
      "100.35156 228.76125 333.56433 1.0\n",
      "FOLD 2790\n",
      "train [38.730098724365234, 6.459020137786865]\n",
      "val [47.868167877197266, 6.731720924377441]\n",
      "predict val...\n",
      "predict test...\n",
      "140.42119 225.3467\n",
      "-46.04834 225.3467 346.67798 0.9804560260586319\n",
      "FOLD 2791\n",
      "train [38.58142852783203, 6.470484733581543]\n",
      "val [48.11717987060547, 6.79379940032959]\n",
      "predict val...\n",
      "predict test...\n",
      "141.05148 228.19183\n",
      "150.76245 228.19183 286.8418 1.0\n",
      "FOLD 2792\n",
      "train [41.24283981323242, 6.536611080169678]\n",
      "val [45.11328125, 6.608480453491211]\n",
      "predict val...\n",
      "predict test...\n",
      "132.14929 255.04707\n",
      "110.47351 255.04707 401.2434 1.0\n",
      "FOLD 2793\n",
      "train [38.54043197631836, 6.440577507019043]\n",
      "val [53.45753479003906, 6.687314033508301]\n",
      "predict val...\n",
      "predict test...\n",
      "156.65318 228.63284\n",
      "85.90137 228.63284 367.44434 1.0\n",
      "FOLD 2794\n",
      "train [40.249141693115234, 6.5095534324646]\n",
      "val [40.159854888916016, 6.436514854431152]\n",
      "predict val...\n",
      "predict test...\n",
      "119.13238 239.6247\n",
      "78.88452 239.6247 348.88403 1.0\n",
      "FOLD 2795\n",
      "train [38.18002700805664, 6.458085536956787]\n",
      "val [47.94899368286133, 6.737383842468262]\n",
      "predict val...\n",
      "predict test...\n",
      "141.51703 236.74313\n",
      "-23.596191 236.74313 377.30933 0.9869706840390879\n",
      "FOLD 2796\n",
      "train [40.60049819946289, 6.501255035400391]\n",
      "val [45.99824523925781, 6.828480243682861]\n",
      "predict val...\n",
      "predict test...\n",
      "135.64536 237.26384\n",
      "51.3938 237.26384 516.1079 1.0\n",
      "FOLD 2797\n",
      "train [37.04415512084961, 6.397302150726318]\n",
      "val [52.735443115234375, 6.960231781005859]\n",
      "predict val...\n",
      "predict test...\n",
      "150.98827 222.63202\n",
      "72.775635 222.63202 358.6809 1.0\n",
      "FOLD 2798\n",
      "train [36.512550354003906, 6.3809661865234375]\n",
      "val [54.87482833862305, 6.635527610778809]\n",
      "predict val...\n",
      "predict test...\n",
      "158.58334 210.22263\n",
      "48.685303 210.22263 388.01392 1.0\n",
      "FOLD 2799\n",
      "train [40.78596878051758, 6.515918731689453]\n",
      "val [41.575042724609375, 6.506882190704346]\n",
      "predict val...\n",
      "predict test...\n",
      "124.13233 241.24115\n",
      "89.491455 241.24115 361.81445 1.0\n",
      "FOLD 2800\n",
      "train [38.70508575439453, 6.458436489105225]\n",
      "val [48.329776763916016, 6.736261367797852]\n",
      "predict val...\n",
      "predict test...\n",
      "143.70728 225.93555\n",
      "12.1796875 225.93555 380.8413 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20h 27min 26s, sys: 2h 3min 47s, total: 22h 31min 14s\n",
      "Wall time: 15h 55min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cnt = 0\n",
    "resultsigma_opt = []\n",
    "resultsigma_mean = []\n",
    "resultmin = []\n",
    "resultmean = []\n",
    "resultmax = []\n",
    "\n",
    "Qa=[]\n",
    "MLa=[]\n",
    "Da=[]\n",
    "EPOCHSa=[]\n",
    "Fold = []\n",
    "Scorea = []\n",
    "\n",
    "#EPOCHS=800\n",
    "for D in np.arange(10,150,10):\n",
    "    for ML in np.arange(.5,.9,0.1):\n",
    "        for EPOCHS in range(100,1100,100):\n",
    "            for tr_idx, val_idx in kf.split(z):\n",
    "                pred = np.zeros((z.shape[0], 3))\n",
    "                nh = z.shape[1]\n",
    "                pe = np.zeros((ze.shape[0], 3))\n",
    "\n",
    "                cnt += 1\n",
    "                print(f\"FOLD {cnt}\")\n",
    "                net = make_model(nh,D,ML)\n",
    "                History = net.fit(z[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "                    validation_data=(z[val_idx], y[val_idx]), verbose=0) #\n",
    "                print(\"train\", net.evaluate(z[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "                print(\"val\", net.evaluate(z[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "                print(\"predict val...\")\n",
    "                pred = net.predict(z[val_idx], batch_size=BATCH_SIZE, verbose=0)\n",
    "                print(\"predict test...\")\n",
    "                pe += net.predict(ze, batch_size=BATCH_SIZE, verbose=0) / NFOLD\n",
    "                #Scores = score_fold(y_true = y, y_pred = pred)\n",
    "\n",
    "                sigma_opt = mean_absolute_error(y[val_idx], pred[:, 1])\n",
    "                unc = pred[:, 2] - pred[:, 0]\n",
    "                sigma_mean = np.mean(unc)\n",
    "                print(sigma_opt, sigma_mean)\n",
    "                print(unc.min(), unc.mean(), unc.max(), (unc>=0).mean())\n",
    "                um=unc.min().astype(np.float32)\n",
    "                umn=unc.mean().astype(np.float32)\n",
    "                umx=unc.max().astype(np.float32)\n",
    "\n",
    "                resultsigma_opt.append(sigma_opt)\n",
    "                resultsigma_mean.append(sigma_mean)\n",
    "                resultmin.append(um) \n",
    "                resultmean.append(umn) \n",
    "                resultmax.append(umx) \n",
    "                #Scorea.append(Scores)\n",
    "\n",
    "                Qa.append(BATCH_SIZE) \n",
    "                Da.append(D) \n",
    "                MLa.append(ML)\n",
    "                EPOCHSa.append(EPOCHS)\n",
    "                Fold.append({cnt})\n",
    "\n",
    "                del(net,um,umn,umx,sigma_mean,unc, sigma_opt, pe,pred)\n",
    "\n",
    "    pyplot.plot(History.history['score'])\n",
    "    pyplot.show()              \n",
    "#=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2315., 2214., 2061., ..., 2908., 2975., 2774.], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [resultsigma_opt,resultsigma_mean,resultmin,resultmean,resultmax,Da,MLa,EPOCHSa,Qa,Fold]\n",
    "\n",
    "Confidence = pd.DataFrame(conf_list).transpose()\n",
    "Confidence.columns = [['resultsigma_opt','resultsigma_mean','resultmin','resultmean','resultmax','Da','MLa','EPOCHSa','Qa','Fold']]\n",
    "\n",
    "#confidenceMin = Confidence.sort_values('resultsigma_opt').iloc[[0]]\n",
    "Confidence\n",
    "Confidence.to_csv(\"Confidence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-f3872c1b7bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msigma_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0munc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msigma_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "sigma_opt = mean_absolute_error(y, pred[:, 1])\n",
    "unc = pred[:, 2] - pred[:, 0]\n",
    "sigma_mean = np.mean(unc)\n",
    "print(sigma_opt, sigma_mean)\n",
    "um=unc.min() .astype(np.float32)\n",
    "umn=unc.mean().astype(np.float32)\n",
    "umx=unc.max().astype(np.float32)\n",
    "\n",
    "um\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.randint(0, y.shape[0], 10)\n",
    "plt.plot(y[idxs], label=\"ground truth\")\n",
    "plt.plot(pred[idxs, 0], label=\"q25\")\n",
    "plt.plot(pred[idxs, 1], label=\"q50\")\n",
    "plt.plot(pred[idxs, 2], label=\"q75\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unc.min(), unc.mean(), unc.max(), (unc>=0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(unc)\n",
    "plt.title(\"uncertainty in prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['FVC1'] = pe[:, 1]\n",
    "sub['Confidence1'] = pe[:, 2] - pe[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = sub[['Patient_Week','FVC','Confidence','FVC1','Confidence1']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.loc[~subm.FVC1.isnull()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.loc[~subm.FVC1.isnull(),'FVC'] = subm.loc[~subm.FVC1.isnull(),'FVC1']\n",
    "if sigma_mean<70:\n",
    "    subm['Confidence'] = sigma_opt\n",
    "else:\n",
    "    subm.loc[~subm.FVC1.isnull(),'Confidence'] = subm.loc[~subm.FVC1.isnull(),'Confidence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otest = pd.read_csv('/home/jacoblamkey/Documents/Data/.kaggle/test.csv')\n",
    "for i in range(len(otest)):\n",
    "    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'FVC'] = otest.FVC[i]\n",
    "    subm.loc[subm['Patient_Week']==otest.Patient[i]+'_'+str(otest.Weeks[i]), 'Confidence'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub80 = pd.read_csv(\"../input/sub800/submission.csv\")\n",
    "#df1=pd.concat([sub80, subm.loc], axis=1, ignore_index=True)\n",
    "plt.plot(sub80.FVC, subm.FVC, label=\"ground truth\")\n",
    "sub80 = pd.DataFrame(sub80)\n",
    "#subm = pd.DataFrame(subm)\n",
    "#sub80[\"FVCdif\"] = sub80[\"FVC\"] - subm[\"FVC\"]\n",
    "\n",
    "plt.show()\n",
    "print(sub80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
