{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Input, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bayesian Methods for Hackers style sheet\n",
    "plt.style.use('bmh')\n",
    "\n",
    "np.random.seed(1234567890)\n",
    "\n",
    "class PeriodicLogger(Callback):\n",
    "    \"\"\"\n",
    "    A helper callback class that only prints the losses once in 'display' epochs\n",
    "    \"\"\"\n",
    "    def __init__(self, display=100):\n",
    "        self.display = display\n",
    "\n",
    "    def on_train_begin(self, logs={}):      \n",
    "        self.epochs = 0    \n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):    \n",
    "        self.epochs += 1     \n",
    "        if self.epochs % self.display == 0:\n",
    "            print (\"Epoch: %d - loss: %f - val_loss: %f\" % (self.epochs, logs['loss'], logs['val_loss']))\n",
    " \n",
    "            \n",
    "periodic_logger_250 = PeriodicLogger(250)\n",
    "\n",
    "per_meter_mapping = {\n",
    "    'Mercaz': 500,\n",
    "    'Old North': 350,\n",
    "    'Florentine': 230\n",
    "}\n",
    "\n",
    "per_room_additional_price = {\n",
    "    'Mercaz': 15. * 10**4,\n",
    "    'Old North': 8. * 10**4,\n",
    "    'Florentine': 5. * 10**4\n",
    "}\n",
    "\n",
    "\n",
    "def house_price_func(row):\n",
    "    \"\"\"\n",
    "    house_price_func is the function f(a,s,n).\n",
    "    \n",
    "    :param row: dict (contains the keys: ['area', 'size', 'n_rooms'])\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    area, size, n_rooms = row['area'], row['size'], row['n_rooms']\n",
    "    return size * per_meter_mapping[area] + n_rooms * per_room_additional_price[area]\n",
    "\n",
    "AREAS = ['Mercaz', 'Old North', 'Florentine']\n",
    "\n",
    "def create_samples(n_samples):\n",
    "    \"\"\"\n",
    "    Helper method that creates dataset DataFrames\n",
    "    \n",
    "    Note that the np.random.choice call only determines the number of rooms and the size of the house\n",
    "    (the price, which we calculate later, is deterministic)\n",
    "    \n",
    "    :param n_samples: int (number of samples for each area (suburb))\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    for n_rooms in np.random.choice(range(1, 6), n_samples):\n",
    "        samples += [(area, int(np.random.normal(25, 5)), n_rooms) for area in AREAS]\n",
    "        \n",
    "    return pd.DataFrame(samples, columns=['area', 'size', 'n_rooms'])\n",
    "\n",
    "train = create_samples(n_samples=1000)\n",
    "val = create_samples(n_samples=100)\n",
    "\n",
    "train['price'] = train.apply(house_price_func, axis=1)\n",
    "val['price'] = val.apply(house_price_func, axis=1)\n",
    "\n",
    "train.head()\n",
    "\n",
    "continuous_cols = ['size', 'n_rooms']\n",
    "categorical_cols = ['area']\n",
    "y_col = ['price']\n",
    "\n",
    "X_train_continuous = train[continuous_cols]\n",
    "X_train_categorical = train[categorical_cols]\n",
    "y_train = train[y_col]\n",
    "\n",
    "X_val_continuous = val[continuous_cols]\n",
    "X_val_categorical = val[categorical_cols]\n",
    "y_val = val[y_col]\n",
    "\n",
    "# Normalizing both train and test sets to have 0 mean and std. of 1 using the train set mean and std.\n",
    "# This will give each feature an equal initial importance and speed up the training time\n",
    "train_mean = X_train_continuous.mean(axis=0)\n",
    "train_std = X_train_continuous.std(axis=0)\n",
    "\n",
    "X_train_continuous = X_train_continuous - train_mean\n",
    "X_train_continuous /= train_std\n",
    "\n",
    "X_val_continuous = X_val_continuous - train_mean\n",
    "X_val_continuous /= train_std\n",
    "\n",
    "class EmbeddingMapping():\n",
    "    \"\"\"\n",
    "    Helper class for handling categorical variables\n",
    "    \n",
    "    An instance of this class should be defined for each categorical variable we want to use.\n",
    "    \"\"\"\n",
    "    def __init__(self, series):\n",
    "        # get a list of unique values\n",
    "        values = series.unique().tolist()\n",
    "        \n",
    "        # Set a dictionary mapping from values to integer value\n",
    "        # In our example this will be {'Mercaz': 1, 'Old North': 2, 'Florentine': 3}\n",
    "        self.embedding_dict = {value: int_value+1 for int_value, value in enumerate(values)}\n",
    "        \n",
    "        # The num_values will be used as the input_dim when defining the embedding layer. \n",
    "        # It will also be returned for unseen values \n",
    "        self.num_values = len(values) + 1\n",
    "\n",
    "    def get_mapping(self, value):\n",
    "        # If the value was seen in the training set, return its integer mapping\n",
    "        if value in self.embedding_dict:\n",
    "            return self.embedding_dict[value]\n",
    "        \n",
    "        # Else, return the same integer for unseen values\n",
    "        else:\n",
    "            return self.num_values\n",
    "        \n",
    "area_mapping = EmbeddingMapping(X_train_categorical['area'])\n",
    "\n",
    "X_train_categorical = X_train_categorical.assign(area_mapping=X_train_categorical['area'].apply(area_mapping.get_mapping))\n",
    "X_val_categorical = X_val_categorical.assign(area_mapping=X_val_categorical['area'].apply(area_mapping.get_mapping))\n",
    "\n",
    "# Define the embedding input\n",
    "area_input = Input(shape=(1,), dtype='int32') \n",
    "\n",
    "# Decide to what vector size we want to map our 'area' variable. \n",
    "# I'll use 1 here because we only have three areas\n",
    "embeddings_output = 1\n",
    "\n",
    "# Letâ€™s define the embedding layer and flatten it\n",
    "area_embedings = Embedding(output_dim=embeddings_output, input_dim=area_mapping.num_values, input_length=1)(area_input)\n",
    "area_embedings = keras.layers.Reshape((embeddings_output,))(area_embedings)\n",
    "\n",
    "\n",
    "# Define the continuous variables input (just like before)\n",
    "continuous_input = Input(shape=(X_train_continuous.shape[1], ))\n",
    "\n",
    "# Concatenate continuous and embeddings inputs\n",
    "all_input = keras.layers.concatenate([continuous_input, area_embedings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_mapping.num_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
